<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.15, kappa_enc=0.0, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0decoder0.15dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on decoder', 0.15)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.68; ppl: 31787.88; 4676 src tok/s; 4868 tgt tok/s;      9 s elapsed
Epoch  1,   100/  454; acc:  14.55; ppl: 1392.03; 5362 src tok/s; 5542 tgt tok/s;     17 s elapsed
Epoch  1,   150/  454; acc:  17.54; ppl: 568.06; 5395 src tok/s; 5597 tgt tok/s;     25 s elapsed
Epoch  1,   200/  454; acc:  20.28; ppl: 276.08; 5438 src tok/s; 5637 tgt tok/s;     32 s elapsed
Epoch  1,   250/  454; acc:  23.82; ppl: 184.46; 5427 src tok/s; 5620 tgt tok/s;     40 s elapsed
Epoch  1,   300/  454; acc:  27.88; ppl: 122.79; 5273 src tok/s; 5493 tgt tok/s;     48 s elapsed
Epoch  1,   350/  454; acc:  30.02; ppl:  95.81; 5358 src tok/s; 5575 tgt tok/s;     56 s elapsed
Epoch  1,   400/  454; acc:  31.29; ppl:  80.80; 5402 src tok/s; 5580 tgt tok/s;     64 s elapsed
Epoch  1,   450/  454; acc:  32.98; ppl:  67.93; 5286 src tok/s; 5494 tgt tok/s;     71 s elapsed
Train perplexity: 345.606
Train accuracy: 23.077
Validation perplexity: 60.1973
Validation accuracy: 35.9444

Epoch  2,    50/  454; acc:  36.68; ppl:  51.40; 5314 src tok/s; 5517 tgt tok/s;      8 s elapsed
Epoch  2,   100/  454; acc:  38.07; ppl:  46.98; 5273 src tok/s; 5453 tgt tok/s;     16 s elapsed
Epoch  2,   150/  454; acc:  42.09; ppl:  35.71; 5332 src tok/s; 5601 tgt tok/s;     23 s elapsed
Epoch  2,   200/  454; acc:  41.99; ppl:  34.29; 5451 src tok/s; 5629 tgt tok/s;     31 s elapsed
Epoch  2,   250/  454; acc:  44.08; ppl:  30.20; 5441 src tok/s; 5622 tgt tok/s;     39 s elapsed
Epoch  2,   300/  454; acc:  48.09; ppl:  22.93; 5387 src tok/s; 5607 tgt tok/s;     47 s elapsed
Epoch  2,   350/  454; acc:  48.59; ppl:  22.44; 5406 src tok/s; 5635 tgt tok/s;     54 s elapsed
Epoch  2,   400/  454; acc:  49.62; ppl:  20.61; 5438 src tok/s; 5605 tgt tok/s;     62 s elapsed
Epoch  2,   450/  454; acc:  51.11; ppl:  19.34; 5329 src tok/s; 5542 tgt tok/s;     70 s elapsed
Train perplexity: 29.6399
Train accuracy: 44.5409
Validation perplexity: 17.1998
Validation accuracy: 53.2496

Epoch  3,    50/  454; acc:  54.58; ppl:  14.57; 5229 src tok/s; 5424 tgt tok/s;      8 s elapsed
Epoch  3,   100/  454; acc:  54.96; ppl:  13.91; 5483 src tok/s; 5681 tgt tok/s;     16 s elapsed
Epoch  3,   150/  454; acc:  55.52; ppl:  13.39; 5495 src tok/s; 5710 tgt tok/s;     23 s elapsed
Epoch  3,   200/  454; acc:  56.27; ppl:  13.06; 5346 src tok/s; 5552 tgt tok/s;     31 s elapsed
Epoch  3,   250/  454; acc:  55.71; ppl:  13.63; 5400 src tok/s; 5558 tgt tok/s;     39 s elapsed
Epoch  3,   300/  454; acc:  58.80; ppl:  11.26; 5356 src tok/s; 5571 tgt tok/s;     47 s elapsed
Epoch  3,   350/  454; acc:  57.44; ppl:  11.74; 5314 src tok/s; 5556 tgt tok/s;     55 s elapsed
Epoch  3,   400/  454; acc:  58.69; ppl:  10.84; 5363 src tok/s; 5570 tgt tok/s;     62 s elapsed
Epoch  3,   450/  454; acc:  58.89; ppl:  10.82; 5376 src tok/s; 5553 tgt tok/s;     70 s elapsed
Train perplexity: 12.4839
Train accuracy: 56.7923
Validation perplexity: 9.94604
Validation accuracy: 60.7138

Epoch  4,    50/  454; acc:  61.99; ppl:   8.48; 5260 src tok/s; 5475 tgt tok/s;      8 s elapsed
Epoch  4,   100/  454; acc:  61.81; ppl:   8.31; 5502 src tok/s; 5685 tgt tok/s;     16 s elapsed
Epoch  4,   150/  454; acc:  62.17; ppl:   8.17; 5452 src tok/s; 5656 tgt tok/s;     23 s elapsed
Epoch  4,   200/  454; acc:  62.08; ppl:   8.42; 5381 src tok/s; 5582 tgt tok/s;     31 s elapsed
Epoch  4,   250/  454; acc:  61.11; ppl:   8.63; 5405 src tok/s; 5599 tgt tok/s;     39 s elapsed
Epoch  4,   300/  454; acc:  62.92; ppl:   7.78; 5363 src tok/s; 5617 tgt tok/s;     47 s elapsed
Epoch  4,   350/  454; acc:  62.76; ppl:   7.96; 5337 src tok/s; 5542 tgt tok/s;     54 s elapsed
Epoch  4,   400/  454; acc:  62.01; ppl:   8.24; 5343 src tok/s; 5541 tgt tok/s;     62 s elapsed
Epoch  4,   450/  454; acc:  62.77; ppl:   7.87; 5341 src tok/s; 5515 tgt tok/s;     70 s elapsed
Train perplexity: 8.19348
Train accuracy: 62.2035
Validation perplexity: 8.40587
Validation accuracy: 63.5093

Epoch  5,    50/  454; acc:  66.39; ppl:   6.02; 5353 src tok/s; 5553 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  64.81; ppl:   6.46; 5485 src tok/s; 5666 tgt tok/s;     16 s elapsed
Epoch  5,   150/  454; acc:  66.97; ppl:   5.75; 5306 src tok/s; 5588 tgt tok/s;     23 s elapsed
Epoch  5,   200/  454; acc:  65.08; ppl:   6.45; 5309 src tok/s; 5442 tgt tok/s;     31 s elapsed
Epoch  5,   250/  454; acc:  66.45; ppl:   5.89; 5176 src tok/s; 5440 tgt tok/s;     39 s elapsed
Epoch  5,   300/  454; acc:  64.92; ppl:   6.50; 5448 src tok/s; 5585 tgt tok/s;     47 s elapsed
Epoch  5,   350/  454; acc:  66.50; ppl:   5.88; 5342 src tok/s; 5604 tgt tok/s;     55 s elapsed
Epoch  5,   400/  454; acc:  64.67; ppl:   6.61; 5383 src tok/s; 5551 tgt tok/s;     63 s elapsed
Epoch  5,   450/  454; acc:  66.36; ppl:   5.92; 5288 src tok/s; 5505 tgt tok/s;     70 s elapsed
Train perplexity: 6.16603
Train accuracy: 65.7649
Validation perplexity: 7.60112
Validation accuracy: 64.2117

Epoch  6,    50/  454; acc:  67.31; ppl:   5.26; 5369 src tok/s; 5538 tgt tok/s;      8 s elapsed
Epoch  6,   100/  454; acc:  69.97; ppl:   4.43; 5342 src tok/s; 5589 tgt tok/s;     16 s elapsed
Epoch  6,   150/  454; acc:  68.69; ppl:   4.88; 5378 src tok/s; 5562 tgt tok/s;     24 s elapsed
Epoch  6,   200/  454; acc:  68.32; ppl:   5.01; 5417 src tok/s; 5617 tgt tok/s;     31 s elapsed
Epoch  6,   250/  454; acc:  68.87; ppl:   4.75; 5370 src tok/s; 5580 tgt tok/s;     39 s elapsed
Epoch  6,   300/  454; acc:  67.31; ppl:   5.23; 5287 src tok/s; 5477 tgt tok/s;     47 s elapsed
Epoch  6,   350/  454; acc:  68.32; ppl:   4.97; 5484 src tok/s; 5683 tgt tok/s;     55 s elapsed
Epoch  6,   400/  454; acc:  67.78; ppl:   5.16; 5377 src tok/s; 5591 tgt tok/s;     62 s elapsed
Epoch  6,   450/  454; acc:  68.45; ppl:   4.99; 5345 src tok/s; 5571 tgt tok/s;     70 s elapsed
Train perplexity: 4.97711
Train accuracy: 68.2725
Validation perplexity: 6.91187
Validation accuracy: 66.4325

Epoch  7,    50/  454; acc:  71.84; ppl:   3.86; 5254 src tok/s; 5467 tgt tok/s;      8 s elapsed
Epoch  7,   100/  454; acc:  70.91; ppl:   4.10; 5481 src tok/s; 5681 tgt tok/s;     16 s elapsed
Epoch  7,   150/  454; acc:  70.70; ppl:   4.13; 5501 src tok/s; 5679 tgt tok/s;     23 s elapsed
Epoch  7,   200/  454; acc:  70.49; ppl:   4.11; 5305 src tok/s; 5543 tgt tok/s;     31 s elapsed
Epoch  7,   250/  454; acc:  71.02; ppl:   4.00; 5357 src tok/s; 5601 tgt tok/s;     39 s elapsed
Epoch  7,   300/  454; acc:  69.18; ppl:   4.51; 5381 src tok/s; 5530 tgt tok/s;     47 s elapsed
Epoch  7,   350/  454; acc:  71.15; ppl:   4.00; 5378 src tok/s; 5621 tgt tok/s;     54 s elapsed
Epoch  7,   400/  454; acc:  69.00; ppl:   4.50; 5265 src tok/s; 5438 tgt tok/s;     63 s elapsed
Epoch  7,   450/  454; acc:  69.95; ppl:   4.29; 5402 src tok/s; 5618 tgt tok/s;     70 s elapsed
Train perplexity: 4.18824
Train accuracy: 70.3727
Validation perplexity: 6.89727
Validation accuracy: 65.8507

Epoch  8,    50/  454; acc:  72.97; ppl:   3.48; 5331 src tok/s; 5517 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  73.73; ppl:   3.33; 5437 src tok/s; 5648 tgt tok/s;     16 s elapsed
Epoch  8,   150/  454; acc:  72.60; ppl:   3.55; 5220 src tok/s; 5455 tgt tok/s;     23 s elapsed
Epoch  8,   200/  454; acc:  72.44; ppl:   3.59; 5486 src tok/s; 5682 tgt tok/s;     31 s elapsed
Epoch  8,   250/  454; acc:  72.79; ppl:   3.47; 5425 src tok/s; 5665 tgt tok/s;     39 s elapsed
Epoch  8,   300/  454; acc:  71.25; ppl:   3.76; 5317 src tok/s; 5508 tgt tok/s;     47 s elapsed
Epoch  8,   350/  454; acc:  70.95; ppl:   3.85; 5368 src tok/s; 5551 tgt tok/s;     55 s elapsed
Epoch  8,   400/  454; acc:  72.02; ppl:   3.62; 5283 src tok/s; 5506 tgt tok/s;     63 s elapsed
Epoch  8,   450/  454; acc:  71.54; ppl:   3.79; 5411 src tok/s; 5573 tgt tok/s;     70 s elapsed
Train perplexity: 3.5998
Train accuracy: 72.2696
Validation perplexity: 6.81189
Validation accuracy: 66.9292
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.46; ppl:   2.83; 5392 src tok/s; 5588 tgt tok/s;      8 s elapsed
Epoch  9,   100/  454; acc:  78.17; ppl:   2.56; 5358 src tok/s; 5584 tgt tok/s;     16 s elapsed
Epoch  9,   150/  454; acc:  77.02; ppl:   2.75; 5416 src tok/s; 5609 tgt tok/s;     24 s elapsed
Epoch  9,   200/  454; acc:  77.95; ppl:   2.61; 5295 src tok/s; 5526 tgt tok/s;     31 s elapsed
Epoch  9,   250/  454; acc:  76.69; ppl:   2.78; 5408 src tok/s; 5566 tgt tok/s;     39 s elapsed
Epoch  9,   300/  454; acc:  77.74; ppl:   2.61; 4803 src tok/s; 5014 tgt tok/s;     48 s elapsed
Epoch  9,   350/  454; acc:  77.72; ppl:   2.65; 5567 src tok/s; 5770 tgt tok/s;     55 s elapsed
Epoch  9,   400/  454; acc:  76.82; ppl:   2.75; 5421 src tok/s; 5606 tgt tok/s;     63 s elapsed
Epoch  9,   450/  454; acc:  77.20; ppl:   2.71; 5322 src tok/s; 5535 tgt tok/s;     71 s elapsed
Train perplexity: 2.6988
Train accuracy: 77.2771
Validation perplexity: 6.31309
Validation accuracy: 68.2063
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.50; ppl:   2.25; 5358 src tok/s; 5536 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  82.00; ppl:   2.15; 4992 src tok/s; 5217 tgt tok/s;     16 s elapsed
Epoch 10,   150/  454; acc:  81.82; ppl:   2.14; 5213 src tok/s; 5437 tgt tok/s;     24 s elapsed
Epoch 10,   200/  454; acc:  80.55; ppl:   2.31; 5108 src tok/s; 5263 tgt tok/s;     33 s elapsed
Epoch 10,   250/  454; acc:  81.87; ppl:   2.13; 5109 src tok/s; 5345 tgt tok/s;     41 s elapsed
Epoch 10,   300/  454; acc:  80.44; ppl:   2.30; 5196 src tok/s; 5377 tgt tok/s;     49 s elapsed
Epoch 10,   350/  454; acc:  81.43; ppl:   2.19; 5114 src tok/s; 5306 tgt tok/s;     57 s elapsed
Epoch 10,   400/  454; acc:  80.37; ppl:   2.31; 5137 src tok/s; 5313 tgt tok/s;     65 s elapsed
Epoch 10,   450/  454; acc:  81.64; ppl:   2.14; 5000 src tok/s; 5200 tgt tok/s;     73 s elapsed
Train perplexity: 2.2238
Train accuracy: 81.1062
Validation perplexity: 6.37121
Validation accuracy: 69.6041
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.27; ppl:   2.01; 5135 src tok/s; 5343 tgt tok/s;      8 s elapsed
Epoch 11,   100/  454; acc:  83.52; ppl:   2.00; 5216 src tok/s; 5399 tgt tok/s;     16 s elapsed
Epoch 11,   150/  454; acc:  83.52; ppl:   1.97; 5016 src tok/s; 5198 tgt tok/s;     25 s elapsed
Epoch 11,   200/  454; acc:  83.13; ppl:   1.99; 5043 src tok/s; 5250 tgt tok/s;     33 s elapsed
Epoch 11,   250/  454; acc:  82.43; ppl:   2.08; 5205 src tok/s; 5384 tgt tok/s;     41 s elapsed
Epoch 11,   300/  454; acc:  83.65; ppl:   1.97; 5137 src tok/s; 5342 tgt tok/s;     49 s elapsed
Epoch 11,   350/  454; acc:  81.84; ppl:   2.15; 5165 src tok/s; 5367 tgt tok/s;     57 s elapsed
Epoch 11,   400/  454; acc:  84.02; ppl:   1.91; 5146 src tok/s; 5332 tgt tok/s;     65 s elapsed
Epoch 11,   450/  454; acc:  82.76; ppl:   2.03; 5049 src tok/s; 5239 tgt tok/s;     74 s elapsed
Train perplexity: 2.0104
Train accuracy: 83.1209
Validation perplexity: 6.56421
Validation accuracy: 69.299
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  85.43; ppl:   1.81; 5047 src tok/s; 5267 tgt tok/s;      8 s elapsed
Epoch 12,   100/  454; acc:  83.94; ppl:   1.94; 5207 src tok/s; 5362 tgt tok/s;     16 s elapsed
Epoch 12,   150/  454; acc:  84.73; ppl:   1.88; 5178 src tok/s; 5383 tgt tok/s;     24 s elapsed
Epoch 12,   200/  454; acc:  83.58; ppl:   1.98; 5075 src tok/s; 5296 tgt tok/s;     33 s elapsed
Epoch 12,   250/  454; acc:  83.91; ppl:   1.96; 5161 src tok/s; 5351 tgt tok/s;     41 s elapsed
Epoch 12,   300/  454; acc:  84.86; ppl:   1.84; 5038 src tok/s; 5235 tgt tok/s;     49 s elapsed
Epoch 12,   350/  454; acc:  83.59; ppl:   1.96; 5207 src tok/s; 5358 tgt tok/s;     58 s elapsed
Epoch 12,   400/  454; acc:  84.39; ppl:   1.90; 5048 src tok/s; 5277 tgt tok/s;     66 s elapsed
Epoch 12,   450/  454; acc:  83.96; ppl:   1.95; 5123 src tok/s; 5294 tgt tok/s;     74 s elapsed
Train perplexity: 1.91172
Train accuracy: 84.2777
Validation perplexity: 6.63239
Validation accuracy: 69.448
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.43; ppl:   1.90; 5224 src tok/s; 5367 tgt tok/s;      9 s elapsed
Epoch 13,   100/  454; acc:  85.59; ppl:   1.81; 5146 src tok/s; 5398 tgt tok/s;     16 s elapsed
Epoch 13,   150/  454; acc:  84.98; ppl:   1.86; 5095 src tok/s; 5301 tgt tok/s;     25 s elapsed
Epoch 13,   200/  454; acc:  84.82; ppl:   1.87; 5044 src tok/s; 5243 tgt tok/s;     33 s elapsed
Epoch 13,   250/  454; acc:  84.82; ppl:   1.86; 5092 src tok/s; 5308 tgt tok/s;     41 s elapsed
Epoch 13,   300/  454; acc:  84.96; ppl:   1.85; 5267 src tok/s; 5429 tgt tok/s;     49 s elapsed
Epoch 13,   350/  454; acc:  85.03; ppl:   1.85; 5178 src tok/s; 5341 tgt tok/s;     57 s elapsed
Epoch 13,   400/  454; acc:  84.12; ppl:   1.92; 5134 src tok/s; 5338 tgt tok/s;     65 s elapsed
Epoch 13,   450/  454; acc:  84.82; ppl:   1.87; 4945 src tok/s; 5149 tgt tok/s;     74 s elapsed
Train perplexity: 1.86277
Train accuracy: 84.8514
Validation perplexity: 6.71628
Validation accuracy: 69.1358
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  84.36; ppl:   1.90; 5142 src tok/s; 5324 tgt tok/s;      9 s elapsed
Epoch 14,   100/  454; acc:  86.16; ppl:   1.76; 5049 src tok/s; 5287 tgt tok/s;     16 s elapsed
Epoch 14,   150/  454; acc:  84.26; ppl:   1.93; 5230 src tok/s; 5346 tgt tok/s;     25 s elapsed
Epoch 14,   200/  454; acc:  86.17; ppl:   1.75; 5103 src tok/s; 5354 tgt tok/s;     33 s elapsed
Epoch 14,   250/  454; acc:  86.07; ppl:   1.77; 5027 src tok/s; 5246 tgt tok/s;     41 s elapsed
Epoch 14,   300/  454; acc:  84.05; ppl:   1.94; 5133 src tok/s; 5302 tgt tok/s;     49 s elapsed
Epoch 14,   350/  454; acc:  85.91; ppl:   1.78; 5189 src tok/s; 5369 tgt tok/s;     57 s elapsed
Epoch 14,   400/  454; acc:  84.55; ppl:   1.87; 5186 src tok/s; 5377 tgt tok/s;     65 s elapsed
Epoch 14,   450/  454; acc:  84.79; ppl:   1.88; 5055 src tok/s; 5261 tgt tok/s;     74 s elapsed
Train perplexity: 1.84121
Train accuracy: 85.1312
Validation perplexity: 6.74765
Validation accuracy: 69.228
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.49; ppl:   1.81; 4658 src tok/s; 4846 tgt tok/s;      9 s elapsed
Epoch 15,   100/  454; acc:  85.77; ppl:   1.80; 5239 src tok/s; 5413 tgt tok/s;     17 s elapsed
Epoch 15,   150/  454; acc:  85.20; ppl:   1.85; 5103 src tok/s; 5351 tgt tok/s;     25 s elapsed
Epoch 15,   200/  454; acc:  85.12; ppl:   1.84; 5373 src tok/s; 5538 tgt tok/s;     33 s elapsed
Epoch 15,   250/  454; acc:  86.00; ppl:   1.75; 4905 src tok/s; 5072 tgt tok/s;     41 s elapsed
Epoch 15,   300/  454; acc:  84.42; ppl:   1.92; 5136 src tok/s; 5310 tgt tok/s;     50 s elapsed
Epoch 15,   350/  454; acc:  85.81; ppl:   1.79; 5123 src tok/s; 5324 tgt tok/s;     58 s elapsed
Epoch 15,   400/  454; acc:  84.71; ppl:   1.87; 5164 src tok/s; 5376 tgt tok/s;     66 s elapsed
Epoch 15,   450/  454; acc:  85.87; ppl:   1.78; 5094 src tok/s; 5307 tgt tok/s;     74 s elapsed
Train perplexity: 1.8284
Train accuracy: 85.3257
Validation perplexity: 6.76496
Validation accuracy: 69.2848
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  84.85; ppl:   1.87; 5125 src tok/s; 5291 tgt tok/s;      8 s elapsed
Epoch 16,   100/  454; acc:  86.06; ppl:   1.76; 5136 src tok/s; 5386 tgt tok/s;     16 s elapsed
Epoch 16,   150/  454; acc:  86.46; ppl:   1.72; 5016 src tok/s; 5247 tgt tok/s;     24 s elapsed
Epoch 16,   200/  454; acc:  84.30; ppl:   1.92; 5267 src tok/s; 5412 tgt tok/s;     33 s elapsed
Epoch 16,   250/  454; acc:  85.93; ppl:   1.75; 5204 src tok/s; 5413 tgt tok/s;     41 s elapsed
Epoch 16,   300/  454; acc:  84.38; ppl:   1.92; 5181 src tok/s; 5370 tgt tok/s;     49 s elapsed
Epoch 16,   350/  454; acc:  85.06; ppl:   1.85; 5159 src tok/s; 5350 tgt tok/s;     57 s elapsed
Epoch 16,   400/  454; acc:  85.92; ppl:   1.77; 5051 src tok/s; 5257 tgt tok/s;     65 s elapsed
Epoch 16,   450/  454; acc:  85.07; ppl:   1.84; 5111 src tok/s; 5283 tgt tok/s;     73 s elapsed
Train perplexity: 1.82187
Train accuracy: 85.3327
Validation perplexity: 6.76888
Validation accuracy: 69.2919
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.35; ppl:   1.82; 5198 src tok/s; 5389 tgt tok/s;      8 s elapsed
Epoch 17,   100/  454; acc:  85.71; ppl:   1.80; 5004 src tok/s; 5226 tgt tok/s;     16 s elapsed
Epoch 17,   150/  454; acc:  86.09; ppl:   1.75; 5128 src tok/s; 5337 tgt tok/s;     24 s elapsed
Epoch 17,   200/  454; acc:  84.69; ppl:   1.89; 5183 src tok/s; 5344 tgt tok/s;     33 s elapsed
Epoch 17,   250/  454; acc:  85.82; ppl:   1.79; 5165 src tok/s; 5379 tgt tok/s;     41 s elapsed
Epoch 17,   300/  454; acc:  85.10; ppl:   1.88; 5111 src tok/s; 5304 tgt tok/s;     49 s elapsed
Epoch 17,   350/  454; acc:  84.82; ppl:   1.88; 5154 src tok/s; 5342 tgt tok/s;     57 s elapsed
Epoch 17,   400/  454; acc:  85.84; ppl:   1.77; 5176 src tok/s; 5350 tgt tok/s;     65 s elapsed
Epoch 17,   450/  454; acc:  85.93; ppl:   1.77; 5063 src tok/s; 5278 tgt tok/s;     73 s elapsed
Train perplexity: 1.82086
Train accuracy: 85.4265
Validation perplexity: 6.77407
Validation accuracy: 69.299
Decaying learning rate to 0.000976562
