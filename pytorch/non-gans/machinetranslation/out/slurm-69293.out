<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.05, kappa_enc=0.2, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.20decoder0.05dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.2)
('Using Kappa L2 loss on decoder', 0.05)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.47; ppl: 23254.45; 4783 src tok/s; 4981 tgt tok/s;      9 s elapsed
Epoch  1,   100/  454; acc:  15.13; ppl: 1342.69; 5458 src tok/s; 5618 tgt tok/s;     16 s elapsed
Epoch  1,   150/  454; acc:  19.17; ppl: 477.60; 5377 src tok/s; 5619 tgt tok/s;     24 s elapsed
Epoch  1,   200/  454; acc:  21.18; ppl: 281.22; 5532 src tok/s; 5704 tgt tok/s;     32 s elapsed
Epoch  1,   250/  454; acc:  25.24; ppl: 165.95; 5344 src tok/s; 5548 tgt tok/s;     40 s elapsed
Epoch  1,   300/  454; acc:  27.57; ppl: 125.57; 5217 src tok/s; 5438 tgt tok/s;     48 s elapsed
Epoch  1,   350/  454; acc:  29.66; ppl:  96.00; 5438 src tok/s; 5642 tgt tok/s;     55 s elapsed
Epoch  1,   400/  454; acc:  32.08; ppl:  76.02; 5300 src tok/s; 5526 tgt tok/s;     63 s elapsed
Epoch  1,   450/  454; acc:  33.19; ppl:  69.00; 5239 src tok/s; 5415 tgt tok/s;     71 s elapsed
Train perplexity: 320.782
Train accuracy: 23.6627
Validation perplexity: 62.132
Validation accuracy: 32.8863

Epoch  2,    50/  454; acc:  37.73; ppl:  48.43; 5392 src tok/s; 5643 tgt tok/s;      7 s elapsed
Epoch  2,   100/  454; acc:  39.37; ppl:  43.80; 5466 src tok/s; 5646 tgt tok/s;     15 s elapsed
Epoch  2,   150/  454; acc:  41.54; ppl:  36.38; 5354 src tok/s; 5573 tgt tok/s;     23 s elapsed
Epoch  2,   200/  454; acc:  43.76; ppl:  30.69; 5403 src tok/s; 5595 tgt tok/s;     31 s elapsed
Epoch  2,   250/  454; acc:  45.93; ppl:  26.56; 5305 src tok/s; 5548 tgt tok/s;     39 s elapsed
Epoch  2,   300/  454; acc:  46.70; ppl:  25.06; 5410 src tok/s; 5602 tgt tok/s;     47 s elapsed
Epoch  2,   350/  454; acc:  50.28; ppl:  20.20; 5452 src tok/s; 5676 tgt tok/s;     54 s elapsed
Epoch  2,   400/  454; acc:  49.38; ppl:  21.17; 5394 src tok/s; 5556 tgt tok/s;     62 s elapsed
Epoch  2,   450/  454; acc:  51.73; ppl:  18.58; 5310 src tok/s; 5481 tgt tok/s;     70 s elapsed
Train perplexity: 28.3689
Train accuracy: 45.2401
Validation perplexity: 16.9815
Validation accuracy: 53.0438

Epoch  3,    50/  454; acc:  55.27; ppl:  13.95; 5482 src tok/s; 5700 tgt tok/s;      8 s elapsed
Epoch  3,   100/  454; acc:  54.45; ppl:  14.35; 5302 src tok/s; 5518 tgt tok/s;     16 s elapsed
Epoch  3,   150/  454; acc:  55.40; ppl:  13.79; 5318 src tok/s; 5513 tgt tok/s;     23 s elapsed
Epoch  3,   200/  454; acc:  56.09; ppl:  12.84; 5401 src tok/s; 5607 tgt tok/s;     31 s elapsed
Epoch  3,   250/  454; acc:  57.65; ppl:  11.77; 5291 src tok/s; 5547 tgt tok/s;     39 s elapsed
Epoch  3,   300/  454; acc:  56.09; ppl:  12.68; 5466 src tok/s; 5630 tgt tok/s;     47 s elapsed
Epoch  3,   350/  454; acc:  57.51; ppl:  11.58; 5443 src tok/s; 5629 tgt tok/s;     55 s elapsed
Epoch  3,   400/  454; acc:  60.06; ppl:  10.06; 5297 src tok/s; 5515 tgt tok/s;     62 s elapsed
Epoch  3,   450/  454; acc:  58.69; ppl:  11.08; 5286 src tok/s; 5453 tgt tok/s;     70 s elapsed
Train perplexity: 12.3601
Train accuracy: 56.8253
Validation perplexity: 10.0575
Validation accuracy: 60.7067

Epoch  4,    50/  454; acc:  61.97; ppl:   8.23; 5375 src tok/s; 5603 tgt tok/s;      8 s elapsed
Epoch  4,   100/  454; acc:  60.82; ppl:   8.93; 5429 src tok/s; 5634 tgt tok/s;     16 s elapsed
Epoch  4,   150/  454; acc:  60.74; ppl:   9.02; 5460 src tok/s; 5640 tgt tok/s;     24 s elapsed
Epoch  4,   200/  454; acc:  63.15; ppl:   7.76; 5411 src tok/s; 5665 tgt tok/s;     31 s elapsed
Epoch  4,   250/  454; acc:  62.06; ppl:   8.23; 5360 src tok/s; 5554 tgt tok/s;     39 s elapsed
Epoch  4,   300/  454; acc:  62.18; ppl:   8.19; 5310 src tok/s; 5501 tgt tok/s;     47 s elapsed
Epoch  4,   350/  454; acc:  62.39; ppl:   8.12; 5403 src tok/s; 5586 tgt tok/s;     55 s elapsed
Epoch  4,   400/  454; acc:  63.28; ppl:   7.58; 5377 src tok/s; 5588 tgt tok/s;     62 s elapsed
Epoch  4,   450/  454; acc:  63.10; ppl:   7.68; 5296 src tok/s; 5480 tgt tok/s;     70 s elapsed
Train perplexity: 8.17309
Train accuracy: 62.1951
Validation perplexity: 8.2606
Validation accuracy: 62.8778

Epoch  5,    50/  454; acc:  65.83; ppl:   6.25; 5214 src tok/s; 5426 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  65.99; ppl:   6.05; 5262 src tok/s; 5426 tgt tok/s;     16 s elapsed
Epoch  5,   150/  454; acc:  65.85; ppl:   6.07; 5269 src tok/s; 5522 tgt tok/s;     24 s elapsed
Epoch  5,   200/  454; acc:  65.14; ppl:   6.41; 5435 src tok/s; 5604 tgt tok/s;     32 s elapsed
Epoch  5,   250/  454; acc:  64.91; ppl:   6.36; 5380 src tok/s; 5573 tgt tok/s;     40 s elapsed
Epoch  5,   300/  454; acc:  66.91; ppl:   5.73; 5366 src tok/s; 5603 tgt tok/s;     47 s elapsed
Epoch  5,   350/  454; acc:  65.65; ppl:   6.15; 5387 src tok/s; 5577 tgt tok/s;     55 s elapsed
Epoch  5,   400/  454; acc:  65.42; ppl:   6.33; 5378 src tok/s; 5574 tgt tok/s;     63 s elapsed
Epoch  5,   450/  454; acc:  65.61; ppl:   6.19; 5360 src tok/s; 5571 tgt tok/s;     71 s elapsed
Train perplexity: 6.16878
Train accuracy: 65.6965
Validation perplexity: 7.41174
Validation accuracy: 65.3328

Epoch  6,    50/  454; acc:  69.17; ppl:   4.66; 5518 src tok/s; 5683 tgt tok/s;      8 s elapsed
Epoch  6,   100/  454; acc:  68.79; ppl:   4.75; 5239 src tok/s; 5471 tgt tok/s;     16 s elapsed
Epoch  6,   150/  454; acc:  69.80; ppl:   4.54; 5201 src tok/s; 5423 tgt tok/s;     23 s elapsed
Epoch  6,   200/  454; acc:  67.05; ppl:   5.34; 5431 src tok/s; 5612 tgt tok/s;     31 s elapsed
Epoch  6,   250/  454; acc:  68.55; ppl:   4.84; 5429 src tok/s; 5653 tgt tok/s;     39 s elapsed
Epoch  6,   300/  454; acc:  67.51; ppl:   5.23; 5052 src tok/s; 5256 tgt tok/s;     47 s elapsed
Epoch  6,   350/  454; acc:  67.89; ppl:   5.14; 5582 src tok/s; 5791 tgt tok/s;     55 s elapsed
Epoch  6,   400/  454; acc:  67.99; ppl:   5.02; 5472 src tok/s; 5683 tgt tok/s;     63 s elapsed
Epoch  6,   450/  454; acc:  68.12; ppl:   5.10; 5042 src tok/s; 5208 tgt tok/s;     71 s elapsed
Train perplexity: 4.96042
Train accuracy: 68.2938
Validation perplexity: 6.61515
Validation accuracy: 67.7097

Epoch  7,    50/  454; acc:  72.32; ppl:   3.79; 5263 src tok/s; 5504 tgt tok/s;      8 s elapsed
Epoch  7,   100/  454; acc:  70.20; ppl:   4.21; 5499 src tok/s; 5692 tgt tok/s;     16 s elapsed
Epoch  7,   150/  454; acc:  71.61; ppl:   3.83; 5276 src tok/s; 5530 tgt tok/s;     23 s elapsed
Epoch  7,   200/  454; acc:  69.38; ppl:   4.46; 5463 src tok/s; 5593 tgt tok/s;     31 s elapsed
Epoch  7,   250/  454; acc:  69.79; ppl:   4.25; 5378 src tok/s; 5561 tgt tok/s;     39 s elapsed
Epoch  7,   300/  454; acc:  71.15; ppl:   4.01; 5332 src tok/s; 5542 tgt tok/s;     47 s elapsed
Epoch  7,   350/  454; acc:  70.20; ppl:   4.20; 5430 src tok/s; 5633 tgt tok/s;     55 s elapsed
Epoch  7,   400/  454; acc:  69.82; ppl:   4.36; 5308 src tok/s; 5519 tgt tok/s;     63 s elapsed
Epoch  7,   450/  454; acc:  69.76; ppl:   4.38; 5218 src tok/s; 5426 tgt tok/s;     70 s elapsed
Train perplexity: 4.16358
Train accuracy: 70.45
Validation perplexity: 6.72762
Validation accuracy: 67.2201
Decaying learning rate to 0.5

Epoch  8,    50/  454; acc:  74.81; ppl:   3.19; 5472 src tok/s; 5664 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  75.90; ppl:   2.98; 5294 src tok/s; 5514 tgt tok/s;     16 s elapsed
Epoch  8,   150/  454; acc:  77.24; ppl:   2.78; 5231 src tok/s; 5487 tgt tok/s;     23 s elapsed
Epoch  8,   200/  454; acc:  74.61; ppl:   3.24; 5489 src tok/s; 5662 tgt tok/s;     31 s elapsed
Epoch  8,   250/  454; acc:  75.56; ppl:   3.09; 5305 src tok/s; 5535 tgt tok/s;     39 s elapsed
Epoch  8,   300/  454; acc:  75.56; ppl:   3.03; 5436 src tok/s; 5607 tgt tok/s;     47 s elapsed
Epoch  8,   350/  454; acc:  75.79; ppl:   2.99; 5300 src tok/s; 5486 tgt tok/s;     55 s elapsed
Epoch  8,   400/  454; acc:  75.32; ppl:   3.10; 5432 src tok/s; 5636 tgt tok/s;     62 s elapsed
Epoch  8,   450/  454; acc:  76.00; ppl:   2.95; 5334 src tok/s; 5559 tgt tok/s;     70 s elapsed
Train perplexity: 3.05216
Train accuracy: 75.5492
Validation perplexity: 6.03733
Validation accuracy: 69.0294
Decaying learning rate to 0.25

Epoch  9,    50/  454; acc:  79.00; ppl:   2.50; 4825 src tok/s; 4981 tgt tok/s;      9 s elapsed
Epoch  9,   100/  454; acc:  79.67; ppl:   2.41; 5470 src tok/s; 5728 tgt tok/s;     16 s elapsed
Epoch  9,   150/  454; acc:  78.48; ppl:   2.60; 5546 src tok/s; 5736 tgt tok/s;     24 s elapsed
Epoch  9,   200/  454; acc:  80.06; ppl:   2.36; 5104 src tok/s; 5333 tgt tok/s;     32 s elapsed
Epoch  9,   250/  454; acc:  79.71; ppl:   2.44; 5194 src tok/s; 5425 tgt tok/s;     40 s elapsed
Epoch  9,   300/  454; acc:  79.08; ppl:   2.54; 5258 src tok/s; 5430 tgt tok/s;     48 s elapsed
Epoch  9,   350/  454; acc:  79.44; ppl:   2.46; 5240 src tok/s; 5441 tgt tok/s;     56 s elapsed
Epoch  9,   400/  454; acc:  78.72; ppl:   2.56; 5431 src tok/s; 5584 tgt tok/s;     64 s elapsed
Epoch  9,   450/  454; acc:  79.16; ppl:   2.49; 5370 src tok/s; 5585 tgt tok/s;     72 s elapsed
Train perplexity: 2.48506
Train accuracy: 79.2568
Validation perplexity: 6.12885
Validation accuracy: 69.1713
Decaying learning rate to 0.125

Epoch 10,    50/  454; acc:  82.10; ppl:   2.17; 5403 src tok/s; 5636 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  81.09; ppl:   2.28; 5402 src tok/s; 5608 tgt tok/s;     16 s elapsed
Epoch 10,   150/  454; acc:  82.92; ppl:   2.08; 5412 src tok/s; 5634 tgt tok/s;     23 s elapsed
Epoch 10,   200/  454; acc:  80.02; ppl:   2.39; 5241 src tok/s; 5416 tgt tok/s;     31 s elapsed
Epoch 10,   250/  454; acc:  81.96; ppl:   2.16; 5302 src tok/s; 5545 tgt tok/s;     39 s elapsed
Epoch 10,   300/  454; acc:  80.97; ppl:   2.28; 5426 src tok/s; 5604 tgt tok/s;     47 s elapsed
Epoch 10,   350/  454; acc:  81.29; ppl:   2.21; 5394 src tok/s; 5565 tgt tok/s;     55 s elapsed
Epoch 10,   400/  454; acc:  81.44; ppl:   2.22; 5475 src tok/s; 5675 tgt tok/s;     62 s elapsed
Epoch 10,   450/  454; acc:  81.39; ppl:   2.24; 5363 src tok/s; 5567 tgt tok/s;     70 s elapsed
Train perplexity: 2.22716
Train accuracy: 81.4439
Validation perplexity: 6.22609
Validation accuracy: 69.299
Decaying learning rate to 0.0625

Epoch 11,    50/  454; acc:  82.86; ppl:   2.08; 5468 src tok/s; 5673 tgt tok/s;      8 s elapsed
Epoch 11,   100/  454; acc:  82.46; ppl:   2.10; 5383 src tok/s; 5572 tgt tok/s;     16 s elapsed
Epoch 11,   150/  454; acc:  83.38; ppl:   2.02; 5278 src tok/s; 5506 tgt tok/s;     23 s elapsed
Epoch 11,   200/  454; acc:  81.84; ppl:   2.19; 5405 src tok/s; 5562 tgt tok/s;     31 s elapsed
Epoch 11,   250/  454; acc:  82.75; ppl:   2.07; 5406 src tok/s; 5644 tgt tok/s;     39 s elapsed
Epoch 11,   300/  454; acc:  81.66; ppl:   2.22; 5349 src tok/s; 5546 tgt tok/s;     47 s elapsed
Epoch 11,   350/  454; acc:  82.31; ppl:   2.13; 5380 src tok/s; 5546 tgt tok/s;     55 s elapsed
Epoch 11,   400/  454; acc:  83.07; ppl:   2.05; 5390 src tok/s; 5616 tgt tok/s;     62 s elapsed
Epoch 11,   450/  454; acc:  82.46; ppl:   2.10; 5273 src tok/s; 5499 tgt tok/s;     70 s elapsed
Train perplexity: 2.10701
Train accuracy: 82.517
Validation perplexity: 6.33035
Validation accuracy: 69.3699
Decaying learning rate to 0.03125

Epoch 12,    50/  454; acc:  82.78; ppl:   2.11; 5485 src tok/s; 5663 tgt tok/s;      8 s elapsed
Epoch 12,   100/  454; acc:  83.80; ppl:   1.96; 5236 src tok/s; 5475 tgt tok/s;     16 s elapsed
Epoch 12,   150/  454; acc:  82.24; ppl:   2.13; 5418 src tok/s; 5599 tgt tok/s;     24 s elapsed
Epoch 12,   200/  454; acc:  83.47; ppl:   2.02; 5367 src tok/s; 5596 tgt tok/s;     31 s elapsed
Epoch 12,   250/  454; acc:  83.19; ppl:   2.08; 5404 src tok/s; 5590 tgt tok/s;     39 s elapsed
Epoch 12,   300/  454; acc:  83.23; ppl:   2.04; 5519 src tok/s; 5743 tgt tok/s;     47 s elapsed
Epoch 12,   350/  454; acc:  82.86; ppl:   2.08; 5398 src tok/s; 5581 tgt tok/s;     55 s elapsed
Epoch 12,   400/  454; acc:  83.62; ppl:   1.99; 5388 src tok/s; 5593 tgt tok/s;     62 s elapsed
Epoch 12,   450/  454; acc:  82.82; ppl:   2.05; 5311 src tok/s; 5508 tgt tok/s;     70 s elapsed
Train perplexity: 2.05164
Train accuracy: 83.1136
Validation perplexity: 6.36933
Validation accuracy: 69.4906
Decaying learning rate to 0.015625

Epoch 13,    50/  454; acc:  84.29; ppl:   1.91; 5285 src tok/s; 5536 tgt tok/s;      8 s elapsed
Epoch 13,   100/  454; acc:  82.72; ppl:   2.09; 5471 src tok/s; 5633 tgt tok/s;     16 s elapsed
Epoch 13,   150/  454; acc:  83.02; ppl:   2.07; 5371 src tok/s; 5547 tgt tok/s;     24 s elapsed
Epoch 13,   200/  454; acc:  83.75; ppl:   1.99; 5351 src tok/s; 5567 tgt tok/s;     31 s elapsed
Epoch 13,   250/  454; acc:  84.15; ppl:   1.96; 5351 src tok/s; 5575 tgt tok/s;     39 s elapsed
Epoch 13,   300/  454; acc:  82.77; ppl:   2.11; 5328 src tok/s; 5501 tgt tok/s;     47 s elapsed
Epoch 13,   350/  454; acc:  83.38; ppl:   2.03; 5282 src tok/s; 5502 tgt tok/s;     55 s elapsed
Epoch 13,   400/  454; acc:  83.38; ppl:   2.01; 5429 src tok/s; 5638 tgt tok/s;     63 s elapsed
Epoch 13,   450/  454; acc:  83.18; ppl:   2.04; 5346 src tok/s; 5534 tgt tok/s;     70 s elapsed
Train perplexity: 2.02248
Train accuracy: 83.3956
Validation perplexity: 6.40348
Validation accuracy: 69.3558
Decaying learning rate to 0.0078125

Epoch 14,    50/  454; acc:  83.35; ppl:   2.02; 5226 src tok/s; 5416 tgt tok/s;      8 s elapsed
Epoch 14,   100/  454; acc:  83.82; ppl:   1.98; 5229 src tok/s; 5453 tgt tok/s;     16 s elapsed
Epoch 14,   150/  454; acc:  83.99; ppl:   1.97; 5339 src tok/s; 5537 tgt tok/s;     24 s elapsed
Epoch 14,   200/  454; acc:  83.91; ppl:   1.99; 5486 src tok/s; 5666 tgt tok/s;     32 s elapsed
Epoch 14,   250/  454; acc:  84.05; ppl:   1.96; 5374 src tok/s; 5606 tgt tok/s;     39 s elapsed
Epoch 14,   300/  454; acc:  82.92; ppl:   2.06; 5486 src tok/s; 5665 tgt tok/s;     47 s elapsed
Epoch 14,   350/  454; acc:  83.48; ppl:   2.02; 5196 src tok/s; 5416 tgt tok/s;     55 s elapsed
Epoch 14,   400/  454; acc:  83.25; ppl:   2.03; 5388 src tok/s; 5592 tgt tok/s;     63 s elapsed
Epoch 14,   450/  454; acc:  83.20; ppl:   2.05; 5360 src tok/s; 5551 tgt tok/s;     71 s elapsed
Train perplexity: 2.00681
Train accuracy: 83.5596
Validation perplexity: 6.42544
Validation accuracy: 69.3699
Decaying learning rate to 0.00390625

Epoch 15,    50/  454; acc:  83.67; ppl:   2.00; 5410 src tok/s; 5585 tgt tok/s;      8 s elapsed
Epoch 15,   100/  454; acc:  84.07; ppl:   1.96; 5365 src tok/s; 5573 tgt tok/s;     15 s elapsed
Epoch 15,   150/  454; acc:  83.73; ppl:   1.98; 5391 src tok/s; 5605 tgt tok/s;     23 s elapsed
Epoch 15,   200/  454; acc:  82.96; ppl:   2.06; 5298 src tok/s; 5482 tgt tok/s;     31 s elapsed
Epoch 15,   250/  454; acc:  83.02; ppl:   2.09; 5305 src tok/s; 5510 tgt tok/s;     39 s elapsed
Epoch 15,   300/  454; acc:  84.07; ppl:   1.97; 5451 src tok/s; 5666 tgt tok/s;     47 s elapsed
Epoch 15,   350/  454; acc:  83.73; ppl:   2.00; 5250 src tok/s; 5455 tgt tok/s;     55 s elapsed
Epoch 15,   400/  454; acc:  83.95; ppl:   1.93; 5436 src tok/s; 5655 tgt tok/s;     63 s elapsed
Epoch 15,   450/  454; acc:  83.36; ppl:   2.03; 5308 src tok/s; 5508 tgt tok/s;     70 s elapsed
Train perplexity: 1.99962
Train accuracy: 83.6422
Validation perplexity: 6.43006
Validation accuracy: 69.3416
Decaying learning rate to 0.00195312

Epoch 16,    50/  454; acc:  84.22; ppl:   1.96; 5246 src tok/s; 5428 tgt tok/s;      8 s elapsed
Epoch 16,   100/  454; acc:  83.32; ppl:   2.05; 5474 src tok/s; 5701 tgt tok/s;     16 s elapsed
Epoch 16,   150/  454; acc:  83.98; ppl:   1.97; 5376 src tok/s; 5563 tgt tok/s;     24 s elapsed
Epoch 16,   200/  454; acc:  83.21; ppl:   2.03; 5320 src tok/s; 5535 tgt tok/s;     31 s elapsed
Epoch 16,   250/  454; acc:  84.21; ppl:   1.95; 5319 src tok/s; 5514 tgt tok/s;     39 s elapsed
Epoch 16,   300/  454; acc:  83.54; ppl:   1.99; 5320 src tok/s; 5521 tgt tok/s;     47 s elapsed
Epoch 16,   350/  454; acc:  85.13; ppl:   1.85; 5278 src tok/s; 5517 tgt tok/s;     54 s elapsed
Epoch 16,   400/  454; acc:  82.27; ppl:   2.16; 5313 src tok/s; 5480 tgt tok/s;     63 s elapsed
Epoch 16,   450/  454; acc:  83.48; ppl:   2.00; 5172 src tok/s; 5377 tgt tok/s;     71 s elapsed
Train perplexity: 1.9968
Train accuracy: 83.674
Validation perplexity: 6.43076
Validation accuracy: 69.3699
Decaying learning rate to 0.000976562

Epoch 17,    50/  454; acc:  82.93; ppl:   2.06; 5379 src tok/s; 5559 tgt tok/s;      8 s elapsed
Epoch 17,   100/  454; acc:  84.21; ppl:   1.93; 5313 src tok/s; 5559 tgt tok/s;     16 s elapsed
Epoch 17,   150/  454; acc:  83.42; ppl:   2.04; 5464 src tok/s; 5635 tgt tok/s;     24 s elapsed
Epoch 17,   200/  454; acc:  84.25; ppl:   1.94; 5234 src tok/s; 5458 tgt tok/s;     31 s elapsed
Epoch 17,   250/  454; acc:  84.57; ppl:   1.90; 5154 src tok/s; 5396 tgt tok/s;     39 s elapsed
Epoch 17,   300/  454; acc:  82.92; ppl:   2.07; 5448 src tok/s; 5613 tgt tok/s;     47 s elapsed
Epoch 17,   350/  454; acc:  83.02; ppl:   2.07; 5408 src tok/s; 5578 tgt tok/s;     55 s elapsed
Epoch 17,   400/  454; acc:  84.23; ppl:   1.94; 5381 src tok/s; 5602 tgt tok/s;     63 s elapsed
Epoch 17,   450/  454; acc:  84.06; ppl:   1.95; 5326 src tok/s; 5537 tgt tok/s;     70 s elapsed
Train perplexity: 1.99469
Train accuracy: 83.6918
Validation perplexity: 6.43089
Validation accuracy: 69.3416
Decaying learning rate to 0.000488281
