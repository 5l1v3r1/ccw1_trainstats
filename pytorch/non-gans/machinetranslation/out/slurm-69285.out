<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.0, kappa_enc=0.15, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.15decoder0dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.15)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   9.29; ppl: 10969.92; 4859 src tok/s; 5043 tgt tok/s;      8 s elapsed
Epoch  1,   100/  454; acc:  14.69; ppl: 1153.63; 5496 src tok/s; 5637 tgt tok/s;     16 s elapsed
Epoch  1,   150/  454; acc:  17.81; ppl: 469.04; 5468 src tok/s; 5658 tgt tok/s;     24 s elapsed
Epoch  1,   200/  454; acc:  21.46; ppl: 258.19; 5377 src tok/s; 5645 tgt tok/s;     32 s elapsed
Epoch  1,   250/  454; acc:  24.65; ppl: 168.04; 5494 src tok/s; 5737 tgt tok/s;     39 s elapsed
Epoch  1,   300/  454; acc:  27.67; ppl: 118.33; 5481 src tok/s; 5659 tgt tok/s;     47 s elapsed
Epoch  1,   350/  454; acc:  29.25; ppl:  97.25; 5497 src tok/s; 5696 tgt tok/s;     55 s elapsed
Epoch  1,   400/  454; acc:  31.91; ppl:  76.85; 5402 src tok/s; 5647 tgt tok/s;     62 s elapsed
Epoch  1,   450/  454; acc:  33.22; ppl:  68.44; 5463 src tok/s; 5657 tgt tok/s;     70 s elapsed
Train perplexity: 285.68
Train accuracy: 23.426
Validation perplexity: 52.4647
Validation accuracy: 38.1084

Epoch  2,    50/  454; acc:  35.04; ppl:  56.16; 5425 src tok/s; 5601 tgt tok/s;      8 s elapsed
Epoch  2,   100/  454; acc:  39.29; ppl:  41.73; 5479 src tok/s; 5742 tgt tok/s;     15 s elapsed
Epoch  2,   150/  454; acc:  40.49; ppl:  39.63; 5521 src tok/s; 5719 tgt tok/s;     23 s elapsed
Epoch  2,   200/  454; acc:  43.29; ppl:  32.00; 5377 src tok/s; 5606 tgt tok/s;     31 s elapsed
Epoch  2,   250/  454; acc:  46.76; ppl:  25.95; 5465 src tok/s; 5688 tgt tok/s;     38 s elapsed
Epoch  2,   300/  454; acc:  47.07; ppl:  24.59; 5537 src tok/s; 5696 tgt tok/s;     46 s elapsed
Epoch  2,   350/  454; acc:  48.88; ppl:  22.28; 5529 src tok/s; 5747 tgt tok/s;     53 s elapsed
Epoch  2,   400/  454; acc:  49.32; ppl:  21.03; 5409 src tok/s; 5589 tgt tok/s;     61 s elapsed
Epoch  2,   450/  454; acc:  51.18; ppl:  18.76; 5427 src tok/s; 5649 tgt tok/s;     69 s elapsed
Train perplexity: 29.4526
Train accuracy: 44.586
Validation perplexity: 17.2389
Validation accuracy: 51.717

Epoch  3,    50/  454; acc:  54.37; ppl:  14.52; 5331 src tok/s; 5555 tgt tok/s;      8 s elapsed
Epoch  3,   100/  454; acc:  53.92; ppl:  14.85; 5529 src tok/s; 5703 tgt tok/s;     15 s elapsed
Epoch  3,   150/  454; acc:  55.17; ppl:  13.76; 5480 src tok/s; 5705 tgt tok/s;     23 s elapsed
Epoch  3,   200/  454; acc:  55.90; ppl:  13.47; 5440 src tok/s; 5637 tgt tok/s;     31 s elapsed
Epoch  3,   250/  454; acc:  56.87; ppl:  12.37; 5492 src tok/s; 5699 tgt tok/s;     38 s elapsed
Epoch  3,   300/  454; acc:  57.22; ppl:  11.86; 5492 src tok/s; 5702 tgt tok/s;     46 s elapsed
Epoch  3,   350/  454; acc:  57.79; ppl:  11.71; 5576 src tok/s; 5766 tgt tok/s;     54 s elapsed
Epoch  3,   400/  454; acc:  58.02; ppl:  11.25; 5454 src tok/s; 5690 tgt tok/s;     61 s elapsed
Epoch  3,   450/  454; acc:  59.68; ppl:  10.15; 5349 src tok/s; 5546 tgt tok/s;     69 s elapsed
Train perplexity: 12.5607
Train accuracy: 56.5742
Validation perplexity: 10.4316
Validation accuracy: 60.0823

Epoch  4,    50/  454; acc:  59.97; ppl:   9.28; 5351 src tok/s; 5511 tgt tok/s;      8 s elapsed
Epoch  4,   100/  454; acc:  62.58; ppl:   8.05; 5360 src tok/s; 5623 tgt tok/s;     16 s elapsed
Epoch  4,   150/  454; acc:  61.32; ppl:   8.76; 5442 src tok/s; 5621 tgt tok/s;     23 s elapsed
Epoch  4,   200/  454; acc:  62.82; ppl:   7.96; 5481 src tok/s; 5694 tgt tok/s;     31 s elapsed
Epoch  4,   250/  454; acc:  61.91; ppl:   8.03; 5508 src tok/s; 5693 tgt tok/s;     39 s elapsed
Epoch  4,   300/  454; acc:  62.71; ppl:   7.98; 5385 src tok/s; 5629 tgt tok/s;     47 s elapsed
Epoch  4,   350/  454; acc:  62.21; ppl:   8.24; 5479 src tok/s; 5661 tgt tok/s;     54 s elapsed
Epoch  4,   400/  454; acc:  63.23; ppl:   7.55; 5461 src tok/s; 5687 tgt tok/s;     62 s elapsed
Epoch  4,   450/  454; acc:  62.89; ppl:   7.78; 5485 src tok/s; 5679 tgt tok/s;     69 s elapsed
Train perplexity: 8.17209
Train accuracy: 62.1722
Validation perplexity: 8.24113
Validation accuracy: 63.2468

Epoch  5,    50/  454; acc:  65.56; ppl:   6.19; 5189 src tok/s; 5355 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  65.74; ppl:   6.17; 5414 src tok/s; 5617 tgt tok/s;     16 s elapsed
Epoch  5,   150/  454; acc:  66.07; ppl:   6.04; 5399 src tok/s; 5615 tgt tok/s;     23 s elapsed
Epoch  5,   200/  454; acc:  65.15; ppl:   6.28; 5450 src tok/s; 5653 tgt tok/s;     31 s elapsed
Epoch  5,   250/  454; acc:  65.25; ppl:   6.29; 5492 src tok/s; 5685 tgt tok/s;     39 s elapsed
Epoch  5,   300/  454; acc:  65.50; ppl:   6.17; 5407 src tok/s; 5633 tgt tok/s;     47 s elapsed
Epoch  5,   350/  454; acc:  65.46; ppl:   6.16; 5360 src tok/s; 5574 tgt tok/s;     55 s elapsed
Epoch  5,   400/  454; acc:  65.53; ppl:   6.11; 5485 src tok/s; 5691 tgt tok/s;     62 s elapsed
Epoch  5,   450/  454; acc:  65.82; ppl:   6.12; 5468 src tok/s; 5686 tgt tok/s;     70 s elapsed
Train perplexity: 6.16991
Train accuracy: 65.5609
Validation perplexity: 7.31086
Validation accuracy: 65.1057

Epoch  6,    50/  454; acc:  69.67; ppl:   4.58; 5334 src tok/s; 5538 tgt tok/s;      8 s elapsed
Epoch  6,   100/  454; acc:  68.37; ppl:   4.93; 5466 src tok/s; 5651 tgt tok/s;     16 s elapsed
Epoch  6,   150/  454; acc:  66.61; ppl:   5.46; 5481 src tok/s; 5646 tgt tok/s;     24 s elapsed
Epoch  6,   200/  454; acc:  70.21; ppl:   4.39; 5357 src tok/s; 5636 tgt tok/s;     31 s elapsed
Epoch  6,   250/  454; acc:  67.84; ppl:   5.08; 5538 src tok/s; 5721 tgt tok/s;     39 s elapsed
Epoch  6,   300/  454; acc:  68.10; ppl:   4.98; 5418 src tok/s; 5619 tgt tok/s;     46 s elapsed
Epoch  6,   350/  454; acc:  68.40; ppl:   4.95; 5500 src tok/s; 5716 tgt tok/s;     54 s elapsed
Epoch  6,   400/  454; acc:  67.65; ppl:   5.18; 5443 src tok/s; 5649 tgt tok/s;     62 s elapsed
Epoch  6,   450/  454; acc:  67.47; ppl:   5.17; 5432 src tok/s; 5652 tgt tok/s;     69 s elapsed
Train perplexity: 4.96895
Train accuracy: 68.2226
Validation perplexity: 6.87563
Validation accuracy: 65.8011

Epoch  7,    50/  454; acc:  71.12; ppl:   4.03; 5276 src tok/s; 5488 tgt tok/s;      8 s elapsed
Epoch  7,   100/  454; acc:  71.19; ppl:   3.98; 5478 src tok/s; 5691 tgt tok/s;     16 s elapsed
Epoch  7,   150/  454; acc:  70.35; ppl:   4.17; 5506 src tok/s; 5691 tgt tok/s;     23 s elapsed
Epoch  7,   200/  454; acc:  71.30; ppl:   4.04; 5432 src tok/s; 5643 tgt tok/s;     31 s elapsed
Epoch  7,   250/  454; acc:  69.70; ppl:   4.34; 5479 src tok/s; 5664 tgt tok/s;     39 s elapsed
Epoch  7,   300/  454; acc:  71.10; ppl:   3.98; 5423 src tok/s; 5647 tgt tok/s;     46 s elapsed
Epoch  7,   350/  454; acc:  69.55; ppl:   4.36; 5504 src tok/s; 5707 tgt tok/s;     54 s elapsed
Epoch  7,   400/  454; acc:  70.31; ppl:   4.30; 5574 src tok/s; 5780 tgt tok/s;     61 s elapsed
Epoch  7,   450/  454; acc:  69.65; ppl:   4.35; 5375 src tok/s; 5589 tgt tok/s;     69 s elapsed
Train perplexity: 4.16558
Train accuracy: 70.4888
Validation perplexity: 7.06369
Validation accuracy: 66.39
Decaying learning rate to 0.5

Epoch  8,    50/  454; acc:  75.59; ppl:   3.02; 5446 src tok/s; 5649 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  75.43; ppl:   3.08; 5524 src tok/s; 5748 tgt tok/s;     15 s elapsed
Epoch  8,   150/  454; acc:  75.96; ppl:   2.99; 5440 src tok/s; 5672 tgt tok/s;     23 s elapsed
Epoch  8,   200/  454; acc:  75.66; ppl:   3.09; 5409 src tok/s; 5606 tgt tok/s;     31 s elapsed
Epoch  8,   250/  454; acc:  75.64; ppl:   3.07; 5443 src tok/s; 5662 tgt tok/s;     38 s elapsed
Epoch  8,   300/  454; acc:  74.88; ppl:   3.15; 5598 src tok/s; 5756 tgt tok/s;     46 s elapsed
Epoch  8,   350/  454; acc:  75.35; ppl:   3.06; 5501 src tok/s; 5693 tgt tok/s;     54 s elapsed
Epoch  8,   400/  454; acc:  75.69; ppl:   2.98; 5356 src tok/s; 5569 tgt tok/s;     61 s elapsed
Epoch  8,   450/  454; acc:  75.39; ppl:   3.05; 5394 src tok/s; 5611 tgt tok/s;     69 s elapsed
Train perplexity: 3.05686
Train accuracy: 75.4919
Validation perplexity: 6.1929
Validation accuracy: 68.5398
Decaying learning rate to 0.25

Epoch  9,    50/  454; acc:  79.35; ppl:   2.46; 5405 src tok/s; 5625 tgt tok/s;      8 s elapsed
Epoch  9,   100/  454; acc:  79.00; ppl:   2.51; 5020 src tok/s; 5193 tgt tok/s;     16 s elapsed
Epoch  9,   150/  454; acc:  78.79; ppl:   2.53; 5639 src tok/s; 5821 tgt tok/s;     24 s elapsed
Epoch  9,   200/  454; acc:  79.78; ppl:   2.40; 5534 src tok/s; 5757 tgt tok/s;     31 s elapsed
Epoch  9,   250/  454; acc:  78.33; ppl:   2.63; 5516 src tok/s; 5708 tgt tok/s;     39 s elapsed
Epoch  9,   300/  454; acc:  79.66; ppl:   2.43; 5505 src tok/s; 5729 tgt tok/s;     46 s elapsed
Epoch  9,   350/  454; acc:  78.82; ppl:   2.51; 5178 src tok/s; 5387 tgt tok/s;     55 s elapsed
Epoch  9,   400/  454; acc:  79.56; ppl:   2.40; 5332 src tok/s; 5564 tgt tok/s;     62 s elapsed
Epoch  9,   450/  454; acc:  78.92; ppl:   2.49; 5503 src tok/s; 5689 tgt tok/s;     70 s elapsed
Train perplexity: 2.48346
Train accuracy: 79.1339
Validation perplexity: 6.22793
Validation accuracy: 69.1074
Decaying learning rate to 0.125

Epoch 10,    50/  454; acc:  80.99; ppl:   2.30; 5382 src tok/s; 5553 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  82.55; ppl:   2.11; 5355 src tok/s; 5617 tgt tok/s;     16 s elapsed
Epoch 10,   150/  454; acc:  81.95; ppl:   2.16; 5357 src tok/s; 5586 tgt tok/s;     23 s elapsed
Epoch 10,   200/  454; acc:  80.89; ppl:   2.27; 5673 src tok/s; 5852 tgt tok/s;     31 s elapsed
Epoch 10,   250/  454; acc:  80.27; ppl:   2.37; 5491 src tok/s; 5644 tgt tok/s;     39 s elapsed
Epoch 10,   300/  454; acc:  81.98; ppl:   2.14; 5350 src tok/s; 5651 tgt tok/s;     46 s elapsed
Epoch 10,   350/  454; acc:  80.28; ppl:   2.35; 5624 src tok/s; 5787 tgt tok/s;     54 s elapsed
Epoch 10,   400/  454; acc:  82.31; ppl:   2.11; 5470 src tok/s; 5706 tgt tok/s;     61 s elapsed
Epoch 10,   450/  454; acc:  81.05; ppl:   2.24; 5675 src tok/s; 5864 tgt tok/s;     69 s elapsed
Train perplexity: 2.22908
Train accuracy: 81.3455
Validation perplexity: 6.39778
Validation accuracy: 68.8804
Decaying learning rate to 0.0625

Epoch 11,    50/  454; acc:  82.40; ppl:   2.13; 5505 src tok/s; 5671 tgt tok/s;      8 s elapsed
Epoch 11,   100/  454; acc:  82.99; ppl:   2.05; 5354 src tok/s; 5614 tgt tok/s;     15 s elapsed
Epoch 11,   150/  454; acc:  83.52; ppl:   2.02; 5517 src tok/s; 5723 tgt tok/s;     23 s elapsed
Epoch 11,   200/  454; acc:  82.03; ppl:   2.16; 5487 src tok/s; 5676 tgt tok/s;     31 s elapsed
Epoch 11,   250/  454; acc:  82.44; ppl:   2.10; 5423 src tok/s; 5632 tgt tok/s;     38 s elapsed
Epoch 11,   300/  454; acc:  82.12; ppl:   2.16; 5384 src tok/s; 5598 tgt tok/s;     46 s elapsed
Epoch 11,   350/  454; acc:  82.28; ppl:   2.11; 5521 src tok/s; 5758 tgt tok/s;     54 s elapsed
Epoch 11,   400/  454; acc:  82.39; ppl:   2.11; 5458 src tok/s; 5659 tgt tok/s;     61 s elapsed
Epoch 11,   450/  454; acc:  81.96; ppl:   2.15; 5422 src tok/s; 5602 tgt tok/s;     69 s elapsed
Train perplexity: 2.10718
Train accuracy: 82.4642
Validation perplexity: 6.49582
Validation accuracy: 68.9229
Decaying learning rate to 0.03125

Epoch 12,    50/  454; acc:  83.08; ppl:   2.03; 5541 src tok/s; 5764 tgt tok/s;      8 s elapsed
Epoch 12,   100/  454; acc:  82.76; ppl:   2.08; 5414 src tok/s; 5613 tgt tok/s;     15 s elapsed
Epoch 12,   150/  454; acc:  82.97; ppl:   2.06; 5417 src tok/s; 5652 tgt tok/s;     23 s elapsed
Epoch 12,   200/  454; acc:  83.28; ppl:   2.06; 5417 src tok/s; 5635 tgt tok/s;     31 s elapsed
Epoch 12,   250/  454; acc:  83.49; ppl:   2.00; 5456 src tok/s; 5677 tgt tok/s;     38 s elapsed
Epoch 12,   300/  454; acc:  83.45; ppl:   2.03; 5545 src tok/s; 5711 tgt tok/s;     46 s elapsed
Epoch 12,   350/  454; acc:  82.52; ppl:   2.11; 5460 src tok/s; 5629 tgt tok/s;     54 s elapsed
Epoch 12,   400/  454; acc:  82.92; ppl:   2.05; 5428 src tok/s; 5664 tgt tok/s;     62 s elapsed
Epoch 12,   450/  454; acc:  82.80; ppl:   2.06; 5487 src tok/s; 5666 tgt tok/s;     69 s elapsed
Train perplexity: 2.05171
Train accuracy: 83.0564
Validation perplexity: 6.53992
Validation accuracy: 68.9513
Decaying learning rate to 0.015625

Epoch 13,    50/  454; acc:  83.52; ppl:   1.99; 5410 src tok/s; 5634 tgt tok/s;      7 s elapsed
Epoch 13,   100/  454; acc:  83.50; ppl:   2.00; 5631 src tok/s; 5806 tgt tok/s;     15 s elapsed
Epoch 13,   150/  454; acc:  83.62; ppl:   1.99; 5376 src tok/s; 5607 tgt tok/s;     23 s elapsed
Epoch 13,   200/  454; acc:  83.20; ppl:   2.05; 5451 src tok/s; 5641 tgt tok/s;     31 s elapsed
Epoch 13,   250/  454; acc:  82.70; ppl:   2.13; 5404 src tok/s; 5600 tgt tok/s;     38 s elapsed
Epoch 13,   300/  454; acc:  83.83; ppl:   1.95; 5520 src tok/s; 5736 tgt tok/s;     46 s elapsed
Epoch 13,   350/  454; acc:  84.35; ppl:   1.94; 5410 src tok/s; 5659 tgt tok/s;     53 s elapsed
Epoch 13,   400/  454; acc:  82.80; ppl:   2.09; 5512 src tok/s; 5701 tgt tok/s;     61 s elapsed
Epoch 13,   450/  454; acc:  83.49; ppl:   2.01; 5342 src tok/s; 5546 tgt tok/s;     69 s elapsed
Train perplexity: 2.02207
Train accuracy: 83.3768
Validation perplexity: 6.55816
Validation accuracy: 68.9513
Decaying learning rate to 0.0078125

Epoch 14,    50/  454; acc:  85.09; ppl:   1.86; 5268 src tok/s; 5505 tgt tok/s;      7 s elapsed
Epoch 14,   100/  454; acc:  82.33; ppl:   2.14; 5507 src tok/s; 5672 tgt tok/s;     16 s elapsed
Epoch 14,   150/  454; acc:  83.96; ppl:   1.97; 5481 src tok/s; 5734 tgt tok/s;     23 s elapsed
Epoch 14,   200/  454; acc:  83.16; ppl:   2.03; 5506 src tok/s; 5670 tgt tok/s;     31 s elapsed
Epoch 14,   250/  454; acc:  82.85; ppl:   2.08; 5559 src tok/s; 5732 tgt tok/s;     39 s elapsed
Epoch 14,   300/  454; acc:  83.98; ppl:   1.95; 5527 src tok/s; 5755 tgt tok/s;     46 s elapsed
Epoch 14,   350/  454; acc:  83.63; ppl:   2.02; 5443 src tok/s; 5649 tgt tok/s;     54 s elapsed
Epoch 14,   400/  454; acc:  83.61; ppl:   2.01; 5439 src tok/s; 5676 tgt tok/s;     61 s elapsed
Epoch 14,   450/  454; acc:  83.50; ppl:   1.99; 5377 src tok/s; 5580 tgt tok/s;     69 s elapsed
Train perplexity: 2.00842
Train accuracy: 83.5294
Validation perplexity: 6.57248
Validation accuracy: 68.9726
Decaying learning rate to 0.00390625

Epoch 15,    50/  454; acc:  83.99; ppl:   1.94; 5390 src tok/s; 5635 tgt tok/s;      8 s elapsed
Epoch 15,   100/  454; acc:  83.34; ppl:   2.04; 5451 src tok/s; 5623 tgt tok/s;     15 s elapsed
Epoch 15,   150/  454; acc:  83.73; ppl:   2.00; 5486 src tok/s; 5720 tgt tok/s;     23 s elapsed
Epoch 15,   200/  454; acc:  83.54; ppl:   2.00; 5068 src tok/s; 5234 tgt tok/s;     31 s elapsed
Epoch 15,   250/  454; acc:  82.60; ppl:   2.12; 5634 src tok/s; 5773 tgt tok/s;     39 s elapsed
Epoch 15,   300/  454; acc:  84.43; ppl:   1.90; 5612 src tok/s; 5859 tgt tok/s;     46 s elapsed
Epoch 15,   350/  454; acc:  83.11; ppl:   2.05; 5478 src tok/s; 5684 tgt tok/s;     54 s elapsed
Epoch 15,   400/  454; acc:  84.04; ppl:   1.94; 5165 src tok/s; 5396 tgt tok/s;     62 s elapsed
Epoch 15,   450/  454; acc:  83.44; ppl:   2.04; 5330 src tok/s; 5536 tgt tok/s;     70 s elapsed
Train perplexity: 2.0016
Train accuracy: 83.5965
Validation perplexity: 6.57906
Validation accuracy: 68.9726
Decaying learning rate to 0.00195312

Epoch 16,    50/  454; acc:  83.51; ppl:   2.04; 5385 src tok/s; 5576 tgt tok/s;      8 s elapsed
Epoch 16,   100/  454; acc:  84.06; ppl:   1.94; 5376 src tok/s; 5604 tgt tok/s;     16 s elapsed
Epoch 16,   150/  454; acc:  83.55; ppl:   2.00; 5572 src tok/s; 5732 tgt tok/s;     24 s elapsed
Epoch 16,   200/  454; acc:  84.28; ppl:   1.95; 5515 src tok/s; 5755 tgt tok/s;     31 s elapsed
Epoch 16,   250/  454; acc:  84.18; ppl:   1.98; 5483 src tok/s; 5696 tgt tok/s;     38 s elapsed
Epoch 16,   300/  454; acc:  83.46; ppl:   2.04; 5511 src tok/s; 5716 tgt tok/s;     46 s elapsed
Epoch 16,   350/  454; acc:  83.95; ppl:   1.97; 5412 src tok/s; 5661 tgt tok/s;     53 s elapsed
Epoch 16,   400/  454; acc:  83.18; ppl:   2.06; 5612 src tok/s; 5781 tgt tok/s;     61 s elapsed
Epoch 16,   450/  454; acc:  83.37; ppl:   2.02; 5476 src tok/s; 5687 tgt tok/s;     69 s elapsed
Train perplexity: 1.99815
Train accuracy: 83.729
Validation perplexity: 6.58481
Validation accuracy: 68.9513
Decaying learning rate to 0.000976562

Epoch 17,    50/  454; acc:  83.23; ppl:   2.05; 5542 src tok/s; 5712 tgt tok/s;      8 s elapsed
Epoch 17,   100/  454; acc:  84.14; ppl:   1.95; 5412 src tok/s; 5645 tgt tok/s;     15 s elapsed
Epoch 17,   150/  454; acc:  84.27; ppl:   1.92; 5479 src tok/s; 5699 tgt tok/s;     23 s elapsed
Epoch 17,   200/  454; acc:  83.16; ppl:   2.06; 5456 src tok/s; 5668 tgt tok/s;     31 s elapsed
Epoch 17,   250/  454; acc:  83.82; ppl:   1.97; 5472 src tok/s; 5674 tgt tok/s;     38 s elapsed
Epoch 17,   300/  454; acc:  83.43; ppl:   2.03; 5452 src tok/s; 5660 tgt tok/s;     46 s elapsed
Epoch 17,   350/  454; acc:  84.62; ppl:   1.89; 5357 src tok/s; 5613 tgt tok/s;     53 s elapsed
Epoch 17,   400/  454; acc:  83.00; ppl:   2.07; 5693 src tok/s; 5854 tgt tok/s;     61 s elapsed
Epoch 17,   450/  454; acc:  83.60; ppl:   2.00; 5400 src tok/s; 5614 tgt tok/s;     69 s elapsed
Train perplexity: 1.99534
Train accuracy: 83.6678
Validation perplexity: 6.58819
Validation accuracy: 68.9442
Decaying learning rate to 0.000488281
