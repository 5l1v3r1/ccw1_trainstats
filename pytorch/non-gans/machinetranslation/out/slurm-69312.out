<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.3, kappa_enc=0.3, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.30decoder0.30dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.3)
('Using Kappa L2 loss on decoder', 0.3)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:  10.23; ppl: 24832.63; 2794 src tok/s; 2892 tgt tok/s;     16 s elapsed
Epoch  1,   100/  454; acc:  15.82; ppl: 1375.96; 3298 src tok/s; 3416 tgt tok/s;     28 s elapsed
Epoch  1,   150/  454; acc:  18.72; ppl: 424.26; 3293 src tok/s; 3413 tgt tok/s;     41 s elapsed
Epoch  1,   200/  454; acc:  21.64; ppl: 251.00; 3346 src tok/s; 3488 tgt tok/s;     53 s elapsed
Epoch  1,   250/  454; acc:  24.42; ppl: 175.17; 3297 src tok/s; 3399 tgt tok/s;     66 s elapsed
Epoch  1,   300/  454; acc:  28.45; ppl: 114.34; 3143 src tok/s; 3291 tgt tok/s;     79 s elapsed
Epoch  1,   350/  454; acc:  29.59; ppl:  94.81; 3167 src tok/s; 3283 tgt tok/s;     92 s elapsed
Epoch  1,   400/  454; acc:  31.54; ppl:  76.02; 3205 src tok/s; 3326 tgt tok/s;    105 s elapsed
Epoch  1,   450/  454; acc:  32.58; ppl:  68.94; 3095 src tok/s; 3216 tgt tok/s;    119 s elapsed
Train perplexity: 322.008
Train accuracy: 23.672
Validation perplexity: 52.5009
Validation accuracy: 35.5329

Epoch  2,    50/  454; acc:  35.38; ppl:  54.01; 3175 src tok/s; 3311 tgt tok/s;     13 s elapsed
Epoch  2,   100/  454; acc:  36.06; ppl:  50.99; 3157 src tok/s; 3269 tgt tok/s;     27 s elapsed
Epoch  2,   150/  454; acc:  41.69; ppl:  36.16; 3025 src tok/s; 3187 tgt tok/s;     40 s elapsed
Epoch  2,   200/  454; acc:  41.48; ppl:  34.74; 3143 src tok/s; 3246 tgt tok/s;     54 s elapsed
Epoch  2,   250/  454; acc:  43.42; ppl:  31.17; 3178 src tok/s; 3262 tgt tok/s;     68 s elapsed
Epoch  2,   300/  454; acc:  48.48; ppl:  22.86; 3113 src tok/s; 3256 tgt tok/s;     80 s elapsed
Epoch  2,   350/  454; acc:  47.87; ppl:  23.34; 3114 src tok/s; 3189 tgt tok/s;     95 s elapsed
Epoch  2,   400/  454; acc:  51.73; ppl:  18.53; 3102 src tok/s; 3255 tgt tok/s;    107 s elapsed
Epoch  2,   450/  454; acc:  51.41; ppl:  18.94; 3120 src tok/s; 3232 tgt tok/s;    121 s elapsed
Train perplexity: 30.0681
Train accuracy: 44.1646
Validation perplexity: 16.1764
Validation accuracy: 54.6616

Epoch  3,    50/  454; acc:  54.59; ppl:  14.31; 3197 src tok/s; 3323 tgt tok/s;     13 s elapsed
Epoch  3,   100/  454; acc:  54.46; ppl:  14.70; 3124 src tok/s; 3235 tgt tok/s;     26 s elapsed
Epoch  3,   150/  454; acc:  56.14; ppl:  13.28; 3056 src tok/s; 3192 tgt tok/s;     40 s elapsed
Epoch  3,   200/  454; acc:  55.24; ppl:  13.82; 3115 src tok/s; 3221 tgt tok/s;     54 s elapsed
Epoch  3,   250/  454; acc:  55.87; ppl:  13.17; 3190 src tok/s; 3284 tgt tok/s;     68 s elapsed
Epoch  3,   300/  454; acc:  58.65; ppl:  11.15; 3135 src tok/s; 3284 tgt tok/s;     80 s elapsed
Epoch  3,   350/  454; acc:  58.45; ppl:  10.78; 3139 src tok/s; 3262 tgt tok/s;     93 s elapsed
Epoch  3,   400/  454; acc:  57.84; ppl:  11.39; 3061 src tok/s; 3178 tgt tok/s;    107 s elapsed
Epoch  3,   450/  454; acc:  59.07; ppl:  10.49; 3112 src tok/s; 3218 tgt tok/s;    121 s elapsed
Train perplexity: 12.4728
Train accuracy: 56.7057
Validation perplexity: 10.5426
Validation accuracy: 59.5502

Epoch  4,    50/  454; acc:  62.72; ppl:   8.07; 3084 src tok/s; 3242 tgt tok/s;     13 s elapsed
Epoch  4,   100/  454; acc:  60.85; ppl:   8.71; 3184 src tok/s; 3271 tgt tok/s;     27 s elapsed
Epoch  4,   150/  454; acc:  62.77; ppl:   7.89; 3084 src tok/s; 3226 tgt tok/s;     40 s elapsed
Epoch  4,   200/  454; acc:  60.51; ppl:   9.12; 3139 src tok/s; 3241 tgt tok/s;     54 s elapsed
Epoch  4,   250/  454; acc:  62.30; ppl:   8.14; 3095 src tok/s; 3215 tgt tok/s;     67 s elapsed
Epoch  4,   300/  454; acc:  62.31; ppl:   7.98; 3159 src tok/s; 3281 tgt tok/s;     81 s elapsed
Epoch  4,   350/  454; acc:  62.25; ppl:   8.08; 3171 src tok/s; 3285 tgt tok/s;     94 s elapsed
Epoch  4,   400/  454; acc:  63.23; ppl:   7.78; 3141 src tok/s; 3266 tgt tok/s;    107 s elapsed
Epoch  4,   450/  454; acc:  63.18; ppl:   7.77; 3081 src tok/s; 3194 tgt tok/s;    120 s elapsed
Train perplexity: 8.18082
Train accuracy: 62.1819
Validation perplexity: 8.62891
Validation accuracy: 62.7998

Epoch  5,    50/  454; acc:  66.17; ppl:   5.88; 3236 src tok/s; 3354 tgt tok/s;     13 s elapsed
Epoch  5,   100/  454; acc:  64.98; ppl:   6.40; 3175 src tok/s; 3284 tgt tok/s;     26 s elapsed
Epoch  5,   150/  454; acc:  65.87; ppl:   6.12; 3095 src tok/s; 3207 tgt tok/s;     40 s elapsed
Epoch  5,   200/  454; acc:  65.98; ppl:   6.16; 3060 src tok/s; 3179 tgt tok/s;     54 s elapsed
Epoch  5,   250/  454; acc:  65.21; ppl:   6.31; 3090 src tok/s; 3214 tgt tok/s;     67 s elapsed
Epoch  5,   300/  454; acc:  65.93; ppl:   6.01; 3184 src tok/s; 3302 tgt tok/s;     80 s elapsed
Epoch  5,   350/  454; acc:  65.65; ppl:   6.16; 3119 src tok/s; 3218 tgt tok/s;     94 s elapsed
Epoch  5,   400/  454; acc:  65.48; ppl:   6.21; 3185 src tok/s; 3314 tgt tok/s;    107 s elapsed
Epoch  5,   450/  454; acc:  66.50; ppl:   5.98; 3097 src tok/s; 3241 tgt tok/s;    120 s elapsed
Train perplexity: 6.15576
Train accuracy: 65.6894
Validation perplexity: 7.37565
Validation accuracy: 65.2263

Epoch  6,    50/  454; acc:  68.46; ppl:   4.97; 3154 src tok/s; 3265 tgt tok/s;     14 s elapsed
Epoch  6,   100/  454; acc:  68.98; ppl:   4.79; 3144 src tok/s; 3270 tgt tok/s;     27 s elapsed
Epoch  6,   150/  454; acc:  68.19; ppl:   4.92; 3117 src tok/s; 3216 tgt tok/s;     40 s elapsed
Epoch  6,   200/  454; acc:  68.04; ppl:   4.99; 3040 src tok/s; 3146 tgt tok/s;     54 s elapsed
Epoch  6,   250/  454; acc:  68.63; ppl:   4.88; 3159 src tok/s; 3289 tgt tok/s;     67 s elapsed
Epoch  6,   300/  454; acc:  67.77; ppl:   5.17; 3131 src tok/s; 3245 tgt tok/s;     81 s elapsed
Epoch  6,   350/  454; acc:  68.35; ppl:   4.87; 3094 src tok/s; 3226 tgt tok/s;     94 s elapsed
Epoch  6,   400/  454; acc:  68.11; ppl:   5.08; 3140 src tok/s; 3262 tgt tok/s;    108 s elapsed
Epoch  6,   450/  454; acc:  67.60; ppl:   5.18; 3126 src tok/s; 3254 tgt tok/s;    121 s elapsed
Train perplexity: 4.98223
Train accuracy: 68.2437
Validation perplexity: 6.99355
Validation accuracy: 65.9784

Epoch  7,    50/  454; acc:  71.32; ppl:   3.99; 3152 src tok/s; 3285 tgt tok/s;     13 s elapsed
Epoch  7,   100/  454; acc:  71.14; ppl:   4.04; 3155 src tok/s; 3265 tgt tok/s;     27 s elapsed
Epoch  7,   150/  454; acc:  71.06; ppl:   4.03; 3136 src tok/s; 3268 tgt tok/s;     40 s elapsed
Epoch  7,   200/  454; acc:  69.55; ppl:   4.42; 3146 src tok/s; 3251 tgt tok/s;     53 s elapsed
Epoch  7,   250/  454; acc:  71.19; ppl:   4.04; 3069 src tok/s; 3207 tgt tok/s;     66 s elapsed
Epoch  7,   300/  454; acc:  68.68; ppl:   4.60; 3145 src tok/s; 3239 tgt tok/s;     80 s elapsed
Epoch  7,   350/  454; acc:  69.53; ppl:   4.34; 3155 src tok/s; 3260 tgt tok/s;     94 s elapsed
Epoch  7,   400/  454; acc:  71.17; ppl:   4.02; 3120 src tok/s; 3264 tgt tok/s;    107 s elapsed
Epoch  7,   450/  454; acc:  69.77; ppl:   4.37; 3118 src tok/s; 3224 tgt tok/s;    120 s elapsed
Train perplexity: 4.19852
Train accuracy: 70.3879
Validation perplexity: 6.69695
Validation accuracy: 66.9079

Epoch  8,    50/  454; acc:  72.72; ppl:   3.57; 3182 src tok/s; 3292 tgt tok/s;     14 s elapsed
Epoch  8,   100/  454; acc:  73.24; ppl:   3.43; 3089 src tok/s; 3214 tgt tok/s;     27 s elapsed
Epoch  8,   150/  454; acc:  73.11; ppl:   3.45; 3061 src tok/s; 3181 tgt tok/s;     40 s elapsed
Epoch  8,   200/  454; acc:  72.03; ppl:   3.60; 3228 src tok/s; 3334 tgt tok/s;     54 s elapsed
Epoch  8,   250/  454; acc:  72.52; ppl:   3.51; 3141 src tok/s; 3258 tgt tok/s;     67 s elapsed
Epoch  8,   300/  454; acc:  71.10; ppl:   3.91; 3135 src tok/s; 3268 tgt tok/s;     80 s elapsed
Epoch  8,   350/  454; acc:  71.75; ppl:   3.72; 3070 src tok/s; 3206 tgt tok/s;     94 s elapsed
Epoch  8,   400/  454; acc:  72.07; ppl:   3.70; 3178 src tok/s; 3281 tgt tok/s;    107 s elapsed
Epoch  8,   450/  454; acc:  71.51; ppl:   3.72; 3092 src tok/s; 3200 tgt tok/s;    121 s elapsed
Train perplexity: 3.62006
Train accuracy: 72.2374
Validation perplexity: 6.85962
Validation accuracy: 67.0569
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.13; ppl:   2.74; 3167 src tok/s; 3288 tgt tok/s;     13 s elapsed
Epoch  9,   100/  454; acc:  77.41; ppl:   2.67; 3188 src tok/s; 3311 tgt tok/s;     26 s elapsed
Epoch  9,   150/  454; acc:  78.14; ppl:   2.59; 3139 src tok/s; 3269 tgt tok/s;     39 s elapsed
Epoch  9,   200/  454; acc:  76.62; ppl:   2.82; 3196 src tok/s; 3302 tgt tok/s;     53 s elapsed
Epoch  9,   250/  454; acc:  76.34; ppl:   2.87; 3101 src tok/s; 3213 tgt tok/s;     67 s elapsed
Epoch  9,   300/  454; acc:  78.42; ppl:   2.53; 3123 src tok/s; 3257 tgt tok/s;     80 s elapsed
Epoch  9,   350/  454; acc:  77.19; ppl:   2.70; 3125 src tok/s; 3246 tgt tok/s;     93 s elapsed
Epoch  9,   400/  454; acc:  76.70; ppl:   2.76; 3154 src tok/s; 3264 tgt tok/s;    107 s elapsed
Epoch  9,   450/  454; acc:  76.88; ppl:   2.76; 3030 src tok/s; 3144 tgt tok/s;    120 s elapsed
Train perplexity: 2.7131
Train accuracy: 77.1995
Validation perplexity: 6.2905
Validation accuracy: 69.228
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.53; ppl:   2.29; 3138 src tok/s; 3253 tgt tok/s;     14 s elapsed
Epoch 10,   100/  454; acc:  81.77; ppl:   2.16; 3135 src tok/s; 3276 tgt tok/s;     27 s elapsed
Epoch 10,   150/  454; acc:  81.84; ppl:   2.15; 3116 src tok/s; 3256 tgt tok/s;     40 s elapsed
Epoch 10,   200/  454; acc:  80.44; ppl:   2.31; 3086 src tok/s; 3192 tgt tok/s;     54 s elapsed
Epoch 10,   250/  454; acc:  80.01; ppl:   2.36; 3143 src tok/s; 3231 tgt tok/s;     68 s elapsed
Epoch 10,   300/  454; acc:  81.52; ppl:   2.16; 3157 src tok/s; 3283 tgt tok/s;     81 s elapsed
Epoch 10,   350/  454; acc:  81.44; ppl:   2.16; 3130 src tok/s; 3268 tgt tok/s;     94 s elapsed
Epoch 10,   400/  454; acc:  80.46; ppl:   2.31; 3096 src tok/s; 3198 tgt tok/s;    108 s elapsed
Epoch 10,   450/  454; acc:  81.10; ppl:   2.21; 3152 src tok/s; 3260 tgt tok/s;    121 s elapsed
Train perplexity: 2.23137
Train accuracy: 81.0068
Validation perplexity: 6.47088
Validation accuracy: 68.8449
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  82.32; ppl:   2.09; 3195 src tok/s; 3296 tgt tok/s;     14 s elapsed
Epoch 11,   100/  454; acc:  84.12; ppl:   1.92; 3136 src tok/s; 3273 tgt tok/s;     27 s elapsed
Epoch 11,   150/  454; acc:  82.82; ppl:   2.06; 3101 src tok/s; 3220 tgt tok/s;     40 s elapsed
Epoch 11,   200/  454; acc:  83.86; ppl:   1.96; 3079 src tok/s; 3195 tgt tok/s;     54 s elapsed
Epoch 11,   250/  454; acc:  83.68; ppl:   1.97; 3131 src tok/s; 3267 tgt tok/s;     67 s elapsed
Epoch 11,   300/  454; acc:  82.30; ppl:   2.09; 3213 src tok/s; 3324 tgt tok/s;     80 s elapsed
Epoch 11,   350/  454; acc:  82.66; ppl:   2.09; 3106 src tok/s; 3225 tgt tok/s;     94 s elapsed
Epoch 11,   400/  454; acc:  83.52; ppl:   1.97; 3143 src tok/s; 3262 tgt tok/s;    107 s elapsed
Epoch 11,   450/  454; acc:  83.03; ppl:   2.02; 3069 src tok/s; 3178 tgt tok/s;    120 s elapsed
Train perplexity: 2.01838
Train accuracy: 83.118
Validation perplexity: 6.55359
Validation accuracy: 69.3274
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  85.23; ppl:   1.82; 3155 src tok/s; 3286 tgt tok/s;     13 s elapsed
Epoch 12,   100/  454; acc:  83.50; ppl:   2.01; 3081 src tok/s; 3189 tgt tok/s;     27 s elapsed
Epoch 12,   150/  454; acc:  85.82; ppl:   1.79; 3103 src tok/s; 3244 tgt tok/s;     40 s elapsed
Epoch 12,   200/  454; acc:  83.00; ppl:   2.04; 3188 src tok/s; 3281 tgt tok/s;     54 s elapsed
Epoch 12,   250/  454; acc:  83.65; ppl:   1.95; 3162 src tok/s; 3281 tgt tok/s;     67 s elapsed
Epoch 12,   300/  454; acc:  84.45; ppl:   1.88; 3111 src tok/s; 3246 tgt tok/s;     80 s elapsed
Epoch 12,   350/  454; acc:  83.96; ppl:   1.94; 3137 src tok/s; 3244 tgt tok/s;     94 s elapsed
Epoch 12,   400/  454; acc:  84.69; ppl:   1.90; 3064 src tok/s; 3188 tgt tok/s;    107 s elapsed
Epoch 12,   450/  454; acc:  83.80; ppl:   1.95; 3070 src tok/s; 3171 tgt tok/s;    121 s elapsed
Train perplexity: 1.9177
Train accuracy: 84.2366
Validation perplexity: 6.63199
Validation accuracy: 69.2635
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  85.54; ppl:   1.80; 3147 src tok/s; 3283 tgt tok/s;     13 s elapsed
Epoch 13,   100/  454; acc:  83.98; ppl:   1.95; 3118 src tok/s; 3227 tgt tok/s;     27 s elapsed
Epoch 13,   150/  454; acc:  84.89; ppl:   1.86; 3166 src tok/s; 3273 tgt tok/s;     40 s elapsed
Epoch 13,   200/  454; acc:  84.67; ppl:   1.88; 3143 src tok/s; 3255 tgt tok/s;     53 s elapsed
Epoch 13,   250/  454; acc:  85.11; ppl:   1.85; 3164 src tok/s; 3298 tgt tok/s;     67 s elapsed
Epoch 13,   300/  454; acc:  84.62; ppl:   1.87; 3129 src tok/s; 3233 tgt tok/s;     80 s elapsed
Epoch 13,   350/  454; acc:  85.09; ppl:   1.84; 3111 src tok/s; 3242 tgt tok/s;     93 s elapsed
Epoch 13,   400/  454; acc:  84.41; ppl:   1.90; 3099 src tok/s; 3207 tgt tok/s;    107 s elapsed
Epoch 13,   450/  454; acc:  84.25; ppl:   1.89; 3094 src tok/s; 3214 tgt tok/s;    120 s elapsed
Train perplexity: 1.86914
Train accuracy: 84.7477
Validation perplexity: 6.71757
Validation accuracy: 69.2351
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  86.00; ppl:   1.77; 3209 src tok/s; 3341 tgt tok/s;     13 s elapsed
Epoch 14,   100/  454; acc:  84.63; ppl:   1.92; 3154 src tok/s; 3260 tgt tok/s;     26 s elapsed
Epoch 14,   150/  454; acc:  85.30; ppl:   1.83; 3099 src tok/s; 3238 tgt tok/s;     40 s elapsed
Epoch 14,   200/  454; acc:  85.11; ppl:   1.85; 3144 src tok/s; 3247 tgt tok/s;     53 s elapsed
Epoch 14,   250/  454; acc:  84.84; ppl:   1.88; 3094 src tok/s; 3224 tgt tok/s;     66 s elapsed
Epoch 14,   300/  454; acc:  85.42; ppl:   1.80; 3208 src tok/s; 3320 tgt tok/s;     80 s elapsed
Epoch 14,   350/  454; acc:  85.00; ppl:   1.83; 3110 src tok/s; 3247 tgt tok/s;     93 s elapsed
Epoch 14,   400/  454; acc:  84.71; ppl:   1.87; 3187 src tok/s; 3301 tgt tok/s;    106 s elapsed
Epoch 14,   450/  454; acc:  85.03; ppl:   1.84; 3058 src tok/s; 3157 tgt tok/s;    120 s elapsed
Train perplexity: 1.84426
Train accuracy: 85.0779
Validation perplexity: 6.7311
Validation accuracy: 69.3061
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.56; ppl:   1.82; 3187 src tok/s; 3309 tgt tok/s;     13 s elapsed
Epoch 15,   100/  454; acc:  84.95; ppl:   1.84; 3182 src tok/s; 3303 tgt tok/s;     26 s elapsed
Epoch 15,   150/  454; acc:  85.46; ppl:   1.81; 3140 src tok/s; 3271 tgt tok/s;     40 s elapsed
Epoch 15,   200/  454; acc:  84.94; ppl:   1.86; 3122 src tok/s; 3262 tgt tok/s;     53 s elapsed
Epoch 15,   250/  454; acc:  85.71; ppl:   1.77; 3117 src tok/s; 3234 tgt tok/s;     66 s elapsed
Epoch 15,   300/  454; acc:  84.69; ppl:   1.89; 3155 src tok/s; 3266 tgt tok/s;     80 s elapsed
Epoch 15,   350/  454; acc:  85.04; ppl:   1.86; 3164 src tok/s; 3275 tgt tok/s;     93 s elapsed
Epoch 15,   400/  454; acc:  85.52; ppl:   1.82; 3136 src tok/s; 3251 tgt tok/s;    107 s elapsed
Epoch 15,   450/  454; acc:  84.78; ppl:   1.84; 3146 src tok/s; 3243 tgt tok/s;    120 s elapsed
Train perplexity: 1.83439
Train accuracy: 85.2006
Validation perplexity: 6.75166
Validation accuracy: 69.3132
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  84.83; ppl:   1.87; 3202 src tok/s; 3311 tgt tok/s;     13 s elapsed
Epoch 16,   100/  454; acc:  86.24; ppl:   1.75; 3136 src tok/s; 3255 tgt tok/s;     26 s elapsed
Epoch 16,   150/  454; acc:  84.62; ppl:   1.90; 3187 src tok/s; 3297 tgt tok/s;     40 s elapsed
Epoch 16,   200/  454; acc:  86.17; ppl:   1.73; 3126 src tok/s; 3261 tgt tok/s;     53 s elapsed
Epoch 16,   250/  454; acc:  84.20; ppl:   1.92; 3160 src tok/s; 3263 tgt tok/s;     67 s elapsed
Epoch 16,   300/  454; acc:  85.68; ppl:   1.78; 3148 src tok/s; 3277 tgt tok/s;     80 s elapsed
Epoch 16,   350/  454; acc:  85.98; ppl:   1.77; 3127 src tok/s; 3253 tgt tok/s;     93 s elapsed
Epoch 16,   400/  454; acc:  84.77; ppl:   1.89; 3154 src tok/s; 3263 tgt tok/s;    106 s elapsed
Epoch 16,   450/  454; acc:  85.13; ppl:   1.86; 3146 src tok/s; 3272 tgt tok/s;    120 s elapsed
Train perplexity: 1.82822
Train accuracy: 85.2911
Validation perplexity: 6.76175
Validation accuracy: 69.2848
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  84.94; ppl:   1.88; 3170 src tok/s; 3280 tgt tok/s;     13 s elapsed
Epoch 17,   100/  454; acc:  85.78; ppl:   1.78; 3154 src tok/s; 3284 tgt tok/s;     27 s elapsed
Epoch 17,   150/  454; acc:  84.72; ppl:   1.87; 3152 src tok/s; 3257 tgt tok/s;     40 s elapsed
Epoch 17,   200/  454; acc:  85.87; ppl:   1.77; 3154 src tok/s; 3282 tgt tok/s;     53 s elapsed
Epoch 17,   250/  454; acc:  84.48; ppl:   1.90; 3164 src tok/s; 3281 tgt tok/s;     67 s elapsed
Epoch 17,   300/  454; acc:  85.77; ppl:   1.79; 3172 src tok/s; 3284 tgt tok/s;     80 s elapsed
Epoch 17,   350/  454; acc:  85.73; ppl:   1.80; 3119 src tok/s; 3251 tgt tok/s;     93 s elapsed
Epoch 17,   400/  454; acc:  85.31; ppl:   1.83; 3120 src tok/s; 3237 tgt tok/s;    107 s elapsed
Epoch 17,   450/  454; acc:  85.48; ppl:   1.80; 3095 src tok/s; 3221 tgt tok/s;    120 s elapsed
Train perplexity: 1.82606
Train accuracy: 85.3039
Validation perplexity: 6.76366
Validation accuracy: 69.2848
Decaying learning rate to 0.000976562
