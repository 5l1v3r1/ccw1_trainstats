<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.4, kappa_enc=0.4, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/seeds/encoder0.4decoder0.4dropout0.3wdropTrueseed2', seed=2, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.4)
('Using Kappa L2 loss on decoder', 0.4)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.69; ppl: 18303.36; 2504 src tok/s; 2609 tgt tok/s;     16 s elapsed
Epoch  1,   100/  454; acc:  14.52; ppl: 1218.86; 3014 src tok/s; 3136 tgt tok/s;     30 s elapsed
Epoch  1,   150/  454; acc:  19.03; ppl: 454.82; 3023 src tok/s; 3154 tgt tok/s;     44 s elapsed
Epoch  1,   200/  454; acc:  21.55; ppl: 241.12; 3048 src tok/s; 3138 tgt tok/s;     58 s elapsed
Epoch  1,   250/  454; acc:  26.79; ppl: 146.97; 2950 src tok/s; 3092 tgt tok/s;     71 s elapsed
Epoch  1,   300/  454; acc:  26.79; ppl: 127.77; 3031 src tok/s; 3120 tgt tok/s;     86 s elapsed
Epoch  1,   350/  454; acc:  29.82; ppl:  94.19; 2981 src tok/s; 3096 tgt tok/s;    100 s elapsed
Epoch  1,   400/  454; acc:  32.04; ppl:  76.69; 3017 src tok/s; 3132 tgt tok/s;    114 s elapsed
Epoch  1,   450/  454; acc:  33.51; ppl:  64.91; 2958 src tok/s; 3056 tgt tok/s;    128 s elapsed
Train perplexity: 296.724
Train accuracy: 23.7349
Validation perplexity: 61.923
Validation accuracy: 34.5466

Epoch  2,    50/  454; acc:  36.16; ppl:  52.23; 2979 src tok/s; 3093 tgt tok/s;     14 s elapsed
Epoch  2,   100/  454; acc:  38.41; ppl:  44.05; 3003 src tok/s; 3099 tgt tok/s;     28 s elapsed
Epoch  2,   150/  454; acc:  39.78; ppl:  40.84; 3006 src tok/s; 3110 tgt tok/s;     43 s elapsed
Epoch  2,   200/  454; acc:  44.83; ppl:  29.52; 2994 src tok/s; 3121 tgt tok/s;     56 s elapsed
Epoch  2,   250/  454; acc:  45.16; ppl:  28.15; 3040 src tok/s; 3164 tgt tok/s;     70 s elapsed
Epoch  2,   300/  454; acc:  47.16; ppl:  24.83; 2953 src tok/s; 3081 tgt tok/s;     84 s elapsed
Epoch  2,   350/  454; acc:  48.49; ppl:  22.77; 3053 src tok/s; 3161 tgt tok/s;     98 s elapsed
Epoch  2,   400/  454; acc:  50.72; ppl:  19.19; 3086 src tok/s; 3211 tgt tok/s;    111 s elapsed
Epoch  2,   450/  454; acc:  51.99; ppl:  17.89; 2935 src tok/s; 3037 tgt tok/s;    125 s elapsed
Train perplexity: 29.0578
Train accuracy: 44.7766
Validation perplexity: 17.315
Validation accuracy: 51.9157

Epoch  3,    50/  454; acc:  53.46; ppl:  15.59; 3003 src tok/s; 3112 tgt tok/s;     14 s elapsed
Epoch  3,   100/  454; acc:  56.60; ppl:  13.06; 3026 src tok/s; 3162 tgt tok/s;     28 s elapsed
Epoch  3,   150/  454; acc:  54.69; ppl:  14.34; 2991 src tok/s; 3070 tgt tok/s;     42 s elapsed
Epoch  3,   200/  454; acc:  57.97; ppl:  11.68; 2938 src tok/s; 3083 tgt tok/s;     56 s elapsed
Epoch  3,   250/  454; acc:  57.02; ppl:  12.19; 2980 src tok/s; 3084 tgt tok/s;     70 s elapsed
Epoch  3,   300/  454; acc:  57.33; ppl:  11.74; 3036 src tok/s; 3147 tgt tok/s;     84 s elapsed
Epoch  3,   350/  454; acc:  57.80; ppl:  11.68; 3076 src tok/s; 3192 tgt tok/s;     98 s elapsed
Epoch  3,   400/  454; acc:  58.09; ppl:  11.33; 2990 src tok/s; 3108 tgt tok/s;    112 s elapsed
Epoch  3,   450/  454; acc:  58.71; ppl:  10.93; 2981 src tok/s; 3090 tgt tok/s;    126 s elapsed
Train perplexity: 12.4323
Train accuracy: 56.8519
Validation perplexity: 10.1723
Validation accuracy: 59.9049

Epoch  4,    50/  454; acc:  62.24; ppl:   8.37; 2960 src tok/s; 3079 tgt tok/s;     14 s elapsed
Epoch  4,   100/  454; acc:  60.74; ppl:   9.00; 3008 src tok/s; 3093 tgt tok/s;     28 s elapsed
Epoch  4,   150/  454; acc:  63.07; ppl:   7.82; 2988 src tok/s; 3128 tgt tok/s;     42 s elapsed
Epoch  4,   200/  454; acc:  61.00; ppl:   8.88; 2990 src tok/s; 3095 tgt tok/s;     56 s elapsed
Epoch  4,   250/  454; acc:  62.97; ppl:   7.86; 2975 src tok/s; 3104 tgt tok/s;     70 s elapsed
Epoch  4,   300/  454; acc:  61.55; ppl:   8.49; 3028 src tok/s; 3129 tgt tok/s;     84 s elapsed
Epoch  4,   350/  454; acc:  64.33; ppl:   7.19; 2998 src tok/s; 3135 tgt tok/s;     97 s elapsed
Epoch  4,   400/  454; acc:  61.62; ppl:   8.29; 3038 src tok/s; 3147 tgt tok/s;    112 s elapsed
Epoch  4,   450/  454; acc:  63.01; ppl:   7.88; 3032 src tok/s; 3134 tgt tok/s;    126 s elapsed
Train perplexity: 8.18873
Train accuracy: 62.26
Validation perplexity: 8.08156
Validation accuracy: 63.7718

Epoch  5,    50/  454; acc:  65.77; ppl:   6.08; 2874 src tok/s; 3006 tgt tok/s;     14 s elapsed
Epoch  5,   100/  454; acc:  65.76; ppl:   6.12; 3035 src tok/s; 3140 tgt tok/s;     29 s elapsed
Epoch  5,   150/  454; acc:  64.98; ppl:   6.48; 3019 src tok/s; 3126 tgt tok/s;     42 s elapsed
Epoch  5,   200/  454; acc:  66.20; ppl:   6.00; 3045 src tok/s; 3158 tgt tok/s;     56 s elapsed
Epoch  5,   250/  454; acc:  66.04; ppl:   6.11; 3058 src tok/s; 3166 tgt tok/s;     70 s elapsed
Epoch  5,   300/  454; acc:  66.09; ppl:   6.08; 2945 src tok/s; 3061 tgt tok/s;     84 s elapsed
Epoch  5,   350/  454; acc:  64.73; ppl:   6.60; 3067 src tok/s; 3160 tgt tok/s;     98 s elapsed
Epoch  5,   400/  454; acc:  66.12; ppl:   6.01; 2963 src tok/s; 3099 tgt tok/s;    112 s elapsed
Epoch  5,   450/  454; acc:  65.91; ppl:   6.11; 3021 src tok/s; 3133 tgt tok/s;    126 s elapsed
Train perplexity: 6.16735
Train accuracy: 65.7506
Validation perplexity: 7.08999
Validation accuracy: 66.1984

Epoch  6,    50/  454; acc:  69.97; ppl:   4.50; 2957 src tok/s; 3075 tgt tok/s;     14 s elapsed
Epoch  6,   100/  454; acc:  68.26; ppl:   4.99; 3001 src tok/s; 3103 tgt tok/s;     28 s elapsed
Epoch  6,   150/  454; acc:  69.38; ppl:   4.68; 2972 src tok/s; 3100 tgt tok/s;     42 s elapsed
Epoch  6,   200/  454; acc:  67.05; ppl:   5.43; 2998 src tok/s; 3102 tgt tok/s;     56 s elapsed
Epoch  6,   250/  454; acc:  68.46; ppl:   4.96; 3063 src tok/s; 3186 tgt tok/s;     70 s elapsed
Epoch  6,   300/  454; acc:  68.27; ppl:   5.02; 3036 src tok/s; 3152 tgt tok/s;     84 s elapsed
Epoch  6,   350/  454; acc:  68.84; ppl:   4.77; 3006 src tok/s; 3135 tgt tok/s;     97 s elapsed
Epoch  6,   400/  454; acc:  67.39; ppl:   5.30; 2992 src tok/s; 3095 tgt tok/s;    112 s elapsed
Epoch  6,   450/  454; acc:  68.07; ppl:   5.19; 2964 src tok/s; 3064 tgt tok/s;    126 s elapsed
Train perplexity: 4.97795
Train accuracy: 68.3993
Validation perplexity: 7.35379
Validation accuracy: 64.1762
Decaying learning rate to 0.5

Epoch  7,    50/  454; acc:  72.61; ppl:   3.73; 2939 src tok/s; 3046 tgt tok/s;     14 s elapsed
Epoch  7,   100/  454; acc:  73.68; ppl:   3.51; 2992 src tok/s; 3118 tgt tok/s;     28 s elapsed
Epoch  7,   150/  454; acc:  72.53; ppl:   3.79; 3002 src tok/s; 3094 tgt tok/s;     43 s elapsed
Epoch  7,   200/  454; acc:  74.72; ppl:   3.27; 3003 src tok/s; 3132 tgt tok/s;     56 s elapsed
Epoch  7,   250/  454; acc:  73.18; ppl:   3.60; 2988 src tok/s; 3097 tgt tok/s;     71 s elapsed
Epoch  7,   300/  454; acc:  74.26; ppl:   3.42; 3010 src tok/s; 3146 tgt tok/s;     84 s elapsed
Epoch  7,   350/  454; acc:  73.17; ppl:   3.60; 3003 src tok/s; 3097 tgt tok/s;     98 s elapsed
Epoch  7,   400/  454; acc:  73.77; ppl:   3.50; 3072 src tok/s; 3190 tgt tok/s;    112 s elapsed
Epoch  7,   450/  454; acc:  73.55; ppl:   3.55; 2992 src tok/s; 3105 tgt tok/s;    126 s elapsed
Train perplexity: 3.55216
Train accuracy: 73.5027
Validation perplexity: 6.04305
Validation accuracy: 68.7314
Decaying learning rate to 0.25

Epoch  8,    50/  454; acc:  77.45; ppl:   2.84; 2994 src tok/s; 3098 tgt tok/s;     14 s elapsed
Epoch  8,   100/  454; acc:  77.23; ppl:   2.85; 2960 src tok/s; 3090 tgt tok/s;     28 s elapsed
Epoch  8,   150/  454; acc:  77.83; ppl:   2.73; 3047 src tok/s; 3169 tgt tok/s;     42 s elapsed
Epoch  8,   200/  454; acc:  76.47; ppl:   2.97; 3033 src tok/s; 3134 tgt tok/s;     56 s elapsed
Epoch  8,   250/  454; acc:  76.81; ppl:   2.95; 2977 src tok/s; 3101 tgt tok/s;     70 s elapsed
Epoch  8,   300/  454; acc:  77.58; ppl:   2.79; 3060 src tok/s; 3161 tgt tok/s;     84 s elapsed
Epoch  8,   350/  454; acc:  76.83; ppl:   2.90; 3019 src tok/s; 3131 tgt tok/s;     97 s elapsed
Epoch  8,   400/  454; acc:  76.95; ppl:   2.88; 3034 src tok/s; 3147 tgt tok/s;    111 s elapsed
Epoch  8,   450/  454; acc:  76.93; ppl:   2.87; 2984 src tok/s; 3100 tgt tok/s;    125 s elapsed
Train perplexity: 2.86167
Train accuracy: 77.1322
Validation perplexity: 6.03901
Validation accuracy: 69.0861
Decaying learning rate to 0.125

Epoch  9,    50/  454; acc:  79.27; ppl:   2.57; 2995 src tok/s; 3117 tgt tok/s;     14 s elapsed
Epoch  9,   100/  454; acc:  80.20; ppl:   2.45; 3053 src tok/s; 3153 tgt tok/s;     28 s elapsed
Epoch  9,   150/  454; acc:  78.62; ppl:   2.61; 3064 src tok/s; 3158 tgt tok/s;     42 s elapsed
Epoch  9,   200/  454; acc:  80.16; ppl:   2.43; 3029 src tok/s; 3166 tgt tok/s;     55 s elapsed
Epoch  9,   250/  454; acc:  78.34; ppl:   2.68; 2998 src tok/s; 3087 tgt tok/s;     70 s elapsed
Epoch  9,   300/  454; acc:  80.12; ppl:   2.41; 2993 src tok/s; 3132 tgt tok/s;     83 s elapsed
Epoch  9,   350/  454; acc:  79.38; ppl:   2.51; 3056 src tok/s; 3176 tgt tok/s;     97 s elapsed
Epoch  9,   400/  454; acc:  78.33; ppl:   2.64; 2979 src tok/s; 3093 tgt tok/s;    111 s elapsed
Epoch  9,   450/  454; acc:  78.78; ppl:   2.59; 2920 src tok/s; 3041 tgt tok/s;    125 s elapsed
Train perplexity: 2.54477
Train accuracy: 79.2274
Validation perplexity: 6.12746
Validation accuracy: 69.6183
Decaying learning rate to 0.0625

Epoch 10,    50/  454; acc:  81.03; ppl:   2.32; 2960 src tok/s; 3074 tgt tok/s;     14 s elapsed
Epoch 10,   100/  454; acc:  80.18; ppl:   2.45; 3028 src tok/s; 3129 tgt tok/s;     28 s elapsed
Epoch 10,   150/  454; acc:  81.30; ppl:   2.28; 3036 src tok/s; 3186 tgt tok/s;     41 s elapsed
Epoch 10,   200/  454; acc:  79.40; ppl:   2.53; 2990 src tok/s; 3091 tgt tok/s;     56 s elapsed
Epoch 10,   250/  454; acc:  80.68; ppl:   2.35; 3083 src tok/s; 3194 tgt tok/s;     70 s elapsed
Epoch 10,   300/  454; acc:  80.29; ppl:   2.41; 3013 src tok/s; 3134 tgt tok/s;     83 s elapsed
Epoch 10,   350/  454; acc:  79.69; ppl:   2.47; 2956 src tok/s; 3066 tgt tok/s;     98 s elapsed
Epoch 10,   400/  454; acc:  80.61; ppl:   2.34; 2942 src tok/s; 3057 tgt tok/s;    112 s elapsed
Epoch 10,   450/  454; acc:  80.44; ppl:   2.39; 2970 src tok/s; 3071 tgt tok/s;    126 s elapsed
Train perplexity: 2.39752
Train accuracy: 80.3727
Validation perplexity: 6.1916
Validation accuracy: 69.2564
Decaying learning rate to 0.03125

Epoch 11,    50/  454; acc:  81.03; ppl:   2.33; 2925 src tok/s; 3052 tgt tok/s;     14 s elapsed
Epoch 11,   100/  454; acc:  80.93; ppl:   2.34; 3056 src tok/s; 3167 tgt tok/s;     28 s elapsed
Epoch 11,   150/  454; acc:  81.82; ppl:   2.21; 2906 src tok/s; 3024 tgt tok/s;     42 s elapsed
Epoch 11,   200/  454; acc:  80.88; ppl:   2.37; 3000 src tok/s; 3108 tgt tok/s;     56 s elapsed
Epoch 11,   250/  454; acc:  81.17; ppl:   2.31; 2983 src tok/s; 3082 tgt tok/s;     70 s elapsed
Epoch 11,   300/  454; acc:  80.41; ppl:   2.38; 2983 src tok/s; 3100 tgt tok/s;     85 s elapsed
Epoch 11,   350/  454; acc:  80.84; ppl:   2.36; 3057 src tok/s; 3165 tgt tok/s;     98 s elapsed
Epoch 11,   400/  454; acc:  80.79; ppl:   2.32; 3016 src tok/s; 3141 tgt tok/s;    112 s elapsed
Epoch 11,   450/  454; acc:  81.43; ppl:   2.27; 3013 src tok/s; 3118 tgt tok/s;    126 s elapsed
Train perplexity: 2.32077
Train accuracy: 81.0332
Validation perplexity: 6.24045
Validation accuracy: 69.4196
Decaying learning rate to 0.015625

Epoch 12,    50/  454; acc:  81.15; ppl:   2.32; 2918 src tok/s; 3038 tgt tok/s;     14 s elapsed
Epoch 12,   100/  454; acc:  81.23; ppl:   2.28; 3109 src tok/s; 3205 tgt tok/s;     28 s elapsed
Epoch 12,   150/  454; acc:  81.69; ppl:   2.25; 3052 src tok/s; 3155 tgt tok/s;     42 s elapsed
Epoch 12,   200/  454; acc:  81.45; ppl:   2.27; 2909 src tok/s; 3023 tgt tok/s;     56 s elapsed
Epoch 12,   250/  454; acc:  81.63; ppl:   2.23; 2991 src tok/s; 3130 tgt tok/s;     70 s elapsed
Epoch 12,   300/  454; acc:  80.84; ppl:   2.33; 3022 src tok/s; 3132 tgt tok/s;     84 s elapsed
Epoch 12,   350/  454; acc:  80.75; ppl:   2.33; 3073 src tok/s; 3175 tgt tok/s;     98 s elapsed
Epoch 12,   400/  454; acc:  81.47; ppl:   2.25; 2995 src tok/s; 3113 tgt tok/s;    111 s elapsed
Epoch 12,   450/  454; acc:  80.79; ppl:   2.33; 3011 src tok/s; 3121 tgt tok/s;    126 s elapsed
Train perplexity: 2.28643
Train accuracy: 81.2454
Validation perplexity: 6.25536
Validation accuracy: 69.448
Decaying learning rate to 0.0078125

Epoch 13,    50/  454; acc:  82.00; ppl:   2.19; 2956 src tok/s; 3097 tgt tok/s;     13 s elapsed
Epoch 13,   100/  454; acc:  80.96; ppl:   2.32; 3045 src tok/s; 3142 tgt tok/s;     28 s elapsed
Epoch 13,   150/  454; acc:  82.28; ppl:   2.17; 3021 src tok/s; 3131 tgt tok/s;     42 s elapsed
Epoch 13,   200/  454; acc:  80.87; ppl:   2.35; 2977 src tok/s; 3077 tgt tok/s;     56 s elapsed
Epoch 13,   250/  454; acc:  82.27; ppl:   2.19; 3001 src tok/s; 3130 tgt tok/s;     70 s elapsed
Epoch 13,   300/  454; acc:  80.31; ppl:   2.41; 3008 src tok/s; 3112 tgt tok/s;     84 s elapsed
Epoch 13,   350/  454; acc:  81.75; ppl:   2.22; 3035 src tok/s; 3139 tgt tok/s;     98 s elapsed
Epoch 13,   400/  454; acc:  80.90; ppl:   2.31; 2980 src tok/s; 3094 tgt tok/s;    112 s elapsed
Epoch 13,   450/  454; acc:  81.68; ppl:   2.24; 3012 src tok/s; 3139 tgt tok/s;    125 s elapsed
Train perplexity: 2.26707
Train accuracy: 81.4505
Validation perplexity: 6.27708
Validation accuracy: 69.3841
Decaying learning rate to 0.00390625

Epoch 14,    50/  454; acc:  80.57; ppl:   2.38; 2920 src tok/s; 3017 tgt tok/s;     15 s elapsed
Epoch 14,   100/  454; acc:  82.08; ppl:   2.19; 3048 src tok/s; 3162 tgt tok/s;     28 s elapsed
Epoch 14,   150/  454; acc:  82.26; ppl:   2.18; 2983 src tok/s; 3126 tgt tok/s;     42 s elapsed
Epoch 14,   200/  454; acc:  81.08; ppl:   2.33; 3043 src tok/s; 3141 tgt tok/s;     56 s elapsed
Epoch 14,   250/  454; acc:  81.22; ppl:   2.28; 3029 src tok/s; 3133 tgt tok/s;     70 s elapsed
Epoch 14,   300/  454; acc:  81.85; ppl:   2.24; 3072 src tok/s; 3173 tgt tok/s;     84 s elapsed
Epoch 14,   350/  454; acc:  81.64; ppl:   2.22; 2946 src tok/s; 3082 tgt tok/s;     98 s elapsed
Epoch 14,   400/  454; acc:  81.38; ppl:   2.25; 3053 src tok/s; 3173 tgt tok/s;    112 s elapsed
Epoch 14,   450/  454; acc:  81.49; ppl:   2.28; 3004 src tok/s; 3125 tgt tok/s;    125 s elapsed
Train perplexity: 2.25953
Train accuracy: 81.5169
Validation perplexity: 6.28455
Validation accuracy: 69.3558
Decaying learning rate to 0.00195312

Epoch 15,    50/  454; acc:  81.30; ppl:   2.29; 2891 src tok/s; 3018 tgt tok/s;     14 s elapsed
Epoch 15,   100/  454; acc:  81.65; ppl:   2.24; 3047 src tok/s; 3139 tgt tok/s;     28 s elapsed
Epoch 15,   150/  454; acc:  81.98; ppl:   2.19; 3054 src tok/s; 3172 tgt tok/s;     42 s elapsed
Epoch 15,   200/  454; acc:  80.96; ppl:   2.31; 2975 src tok/s; 3079 tgt tok/s;     56 s elapsed
Epoch 15,   250/  454; acc:  81.05; ppl:   2.33; 3058 src tok/s; 3154 tgt tok/s;     70 s elapsed
Epoch 15,   300/  454; acc:  82.08; ppl:   2.20; 3014 src tok/s; 3143 tgt tok/s;     84 s elapsed
Epoch 15,   350/  454; acc:  82.45; ppl:   2.13; 3038 src tok/s; 3170 tgt tok/s;     97 s elapsed
Epoch 15,   400/  454; acc:  80.92; ppl:   2.33; 3031 src tok/s; 3148 tgt tok/s;    111 s elapsed
Epoch 15,   450/  454; acc:  81.64; ppl:   2.25; 2950 src tok/s; 3067 tgt tok/s;    125 s elapsed
Train perplexity: 2.25347
Train accuracy: 81.544
Validation perplexity: 6.28838
Validation accuracy: 69.3628
Decaying learning rate to 0.000976562

Epoch 16,    50/  454; acc:  81.98; ppl:   2.18; 2976 src tok/s; 3113 tgt tok/s;     14 s elapsed
Epoch 16,   100/  454; acc:  81.29; ppl:   2.31; 3034 src tok/s; 3128 tgt tok/s;     28 s elapsed
Epoch 16,   150/  454; acc:  81.91; ppl:   2.23; 2995 src tok/s; 3115 tgt tok/s;     42 s elapsed
Epoch 16,   200/  454; acc:  81.27; ppl:   2.29; 3057 src tok/s; 3167 tgt tok/s;     56 s elapsed
Epoch 16,   250/  454; acc:  81.70; ppl:   2.22; 3040 src tok/s; 3164 tgt tok/s;     69 s elapsed
Epoch 16,   300/  454; acc:  81.56; ppl:   2.23; 3017 src tok/s; 3120 tgt tok/s;     84 s elapsed
Epoch 16,   350/  454; acc:  81.45; ppl:   2.29; 3010 src tok/s; 3109 tgt tok/s;     98 s elapsed
Epoch 16,   400/  454; acc:  81.38; ppl:   2.26; 2988 src tok/s; 3121 tgt tok/s;    111 s elapsed
Epoch 16,   450/  454; acc:  81.57; ppl:   2.24; 3004 src tok/s; 3113 tgt tok/s;    125 s elapsed
Train perplexity: 2.25211
Train accuracy: 81.5437
Validation perplexity: 6.28884
Validation accuracy: 69.3558
Decaying learning rate to 0.000488281

Epoch 17,    50/  454; acc:  81.19; ppl:   2.33; 3008 src tok/s; 3117 tgt tok/s;     14 s elapsed
Epoch 17,   100/  454; acc:  82.16; ppl:   2.20; 2988 src tok/s; 3107 tgt tok/s;     28 s elapsed
Epoch 17,   150/  454; acc:  81.38; ppl:   2.29; 3022 src tok/s; 3141 tgt tok/s;     42 s elapsed
Epoch 17,   200/  454; acc:  81.58; ppl:   2.24; 2932 src tok/s; 3042 tgt tok/s;     56 s elapsed
Epoch 17,   250/  454; acc:  81.46; ppl:   2.27; 3063 src tok/s; 3182 tgt tok/s;     70 s elapsed
Epoch 17,   300/  454; acc:  81.62; ppl:   2.24; 3078 src tok/s; 3185 tgt tok/s;     84 s elapsed
Epoch 17,   350/  454; acc:  81.93; ppl:   2.19; 3051 src tok/s; 3161 tgt tok/s;     97 s elapsed
Epoch 17,   400/  454; acc:  81.26; ppl:   2.29; 2960 src tok/s; 3074 tgt tok/s;    112 s elapsed
Epoch 17,   450/  454; acc:  81.54; ppl:   2.25; 2960 src tok/s; 3072 tgt tok/s;    126 s elapsed
Train perplexity: 2.25143
Train accuracy: 81.5942
Validation perplexity: 6.28961
Validation accuracy: 69.3558
Decaying learning rate to 0.000244141
