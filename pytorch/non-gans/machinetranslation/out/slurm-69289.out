<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.2, kappa_enc=0.15, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.15decoder0.20dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.15)
('Using Kappa L2 loss on decoder', 0.2)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.30; ppl: 29112.28; 2567 src tok/s; 2684 tgt tok/s;     16 s elapsed
Epoch  1,   100/  454; acc:  13.63; ppl: 2127.51; 2679 src tok/s; 2773 tgt tok/s;     32 s elapsed
Epoch  1,   150/  454; acc:  17.21; ppl: 664.17; 2613 src tok/s; 2716 tgt tok/s;     48 s elapsed
Epoch  1,   200/  454; acc:  19.84; ppl: 326.42; 2774 src tok/s; 2866 tgt tok/s;     63 s elapsed
Epoch  1,   250/  454; acc:  24.45; ppl: 183.76; 2612 src tok/s; 2722 tgt tok/s;     79 s elapsed
Epoch  1,   300/  454; acc:  26.00; ppl: 140.75; 2718 src tok/s; 2813 tgt tok/s;     95 s elapsed
Epoch  1,   350/  454; acc:  29.09; ppl: 103.55; 2595 src tok/s; 2698 tgt tok/s;    111 s elapsed
Epoch  1,   400/  454; acc:  31.29; ppl:  82.94; 2606 src tok/s; 2688 tgt tok/s;    127 s elapsed
Epoch  1,   450/  454; acc:  33.74; ppl:  68.28; 2629 src tok/s; 2727 tgt tok/s;    143 s elapsed
Train perplexity: 381.901
Train accuracy: 22.7202
Validation perplexity: 62.4846
Validation accuracy: 33.234

Epoch  2,    50/  454; acc:  35.29; ppl:  58.53; 2541 src tok/s; 2622 tgt tok/s;     17 s elapsed
Epoch  2,   100/  454; acc:  39.07; ppl:  44.00; 2742 src tok/s; 2845 tgt tok/s;     32 s elapsed
Epoch  2,   150/  454; acc:  40.69; ppl:  38.75; 2587 src tok/s; 2691 tgt tok/s;     48 s elapsed
Epoch  2,   200/  454; acc:  43.54; ppl:  32.50; 2624 src tok/s; 2718 tgt tok/s;     64 s elapsed
Epoch  2,   250/  454; acc:  45.24; ppl:  27.51; 2637 src tok/s; 2740 tgt tok/s;     80 s elapsed
Epoch  2,   300/  454; acc:  47.28; ppl:  24.90; 2654 src tok/s; 2750 tgt tok/s;     96 s elapsed
Epoch  2,   350/  454; acc:  48.03; ppl:  23.65; 2673 src tok/s; 2766 tgt tok/s;    112 s elapsed
Epoch  2,   400/  454; acc:  51.41; ppl:  19.38; 2556 src tok/s; 2672 tgt tok/s;    128 s elapsed
Epoch  2,   450/  454; acc:  51.25; ppl:  19.48; 2727 src tok/s; 2840 tgt tok/s;    143 s elapsed
Train perplexity: 29.9505
Train accuracy: 44.6771
Validation perplexity: 16.3442
Validation accuracy: 52.6394

Epoch  3,    50/  454; acc:  54.23; ppl:  14.84; 2565 src tok/s; 2670 tgt tok/s;     16 s elapsed
Epoch  3,   100/  454; acc:  54.39; ppl:  14.91; 2743 src tok/s; 2834 tgt tok/s;     32 s elapsed
Epoch  3,   150/  454; acc:  56.39; ppl:  13.01; 2560 src tok/s; 2670 tgt tok/s;     48 s elapsed
Epoch  3,   200/  454; acc:  55.57; ppl:  13.57; 2669 src tok/s; 2770 tgt tok/s;     64 s elapsed
Epoch  3,   250/  454; acc:  56.59; ppl:  12.36; 2680 src tok/s; 2780 tgt tok/s;     79 s elapsed
Epoch  3,   300/  454; acc:  57.09; ppl:  12.06; 2600 src tok/s; 2715 tgt tok/s;     95 s elapsed
Epoch  3,   350/  454; acc:  57.63; ppl:  11.70; 2773 src tok/s; 2884 tgt tok/s;    110 s elapsed
Epoch  3,   400/  454; acc:  58.09; ppl:  11.63; 2644 src tok/s; 2722 tgt tok/s;    126 s elapsed
Epoch  3,   450/  454; acc:  58.41; ppl:  10.96; 2673 src tok/s; 2764 tgt tok/s;    142 s elapsed
Train perplexity: 12.682
Train accuracy: 56.5328
Validation perplexity: 9.91122
Validation accuracy: 61.2885

Epoch  4,    50/  454; acc:  60.48; ppl:   9.32; 2499 src tok/s; 2594 tgt tok/s;     17 s elapsed
Epoch  4,   100/  454; acc:  62.49; ppl:   8.02; 2637 src tok/s; 2744 tgt tok/s;     33 s elapsed
Epoch  4,   150/  454; acc:  63.06; ppl:   7.79; 2714 src tok/s; 2832 tgt tok/s;     47 s elapsed
Epoch  4,   200/  454; acc:  60.75; ppl:   8.96; 2668 src tok/s; 2738 tgt tok/s;     64 s elapsed
Epoch  4,   250/  454; acc:  62.51; ppl:   8.04; 2729 src tok/s; 2845 tgt tok/s;     79 s elapsed
Epoch  4,   300/  454; acc:  61.67; ppl:   8.48; 2641 src tok/s; 2727 tgt tok/s;     95 s elapsed
Epoch  4,   350/  454; acc:  61.91; ppl:   8.23; 2717 src tok/s; 2818 tgt tok/s;    111 s elapsed
Epoch  4,   400/  454; acc:  61.61; ppl:   8.41; 2493 src tok/s; 2599 tgt tok/s;    127 s elapsed
Epoch  4,   450/  454; acc:  63.40; ppl:   7.66; 2552 src tok/s; 2656 tgt tok/s;    143 s elapsed
Train perplexity: 8.33021
Train accuracy: 61.9338
Validation perplexity: 8.77483
Validation accuracy: 62.6153

Epoch  5,    50/  454; acc:  65.72; ppl:   6.27; 2607 src tok/s; 2697 tgt tok/s;     16 s elapsed
Epoch  5,   100/  454; acc:  65.06; ppl:   6.44; 2547 src tok/s; 2640 tgt tok/s;     33 s elapsed
Epoch  5,   150/  454; acc:  65.98; ppl:   6.11; 2692 src tok/s; 2801 tgt tok/s;     48 s elapsed
Epoch  5,   200/  454; acc:  64.21; ppl:   6.76; 2599 src tok/s; 2690 tgt tok/s;     65 s elapsed
Epoch  5,   250/  454; acc:  66.87; ppl:   5.84; 2733 src tok/s; 2856 tgt tok/s;     79 s elapsed
Epoch  5,   300/  454; acc:  64.84; ppl:   6.61; 2603 src tok/s; 2694 tgt tok/s;     96 s elapsed
Epoch  5,   350/  454; acc:  65.52; ppl:   6.24; 2671 src tok/s; 2773 tgt tok/s;    112 s elapsed
Epoch  5,   400/  454; acc:  65.72; ppl:   6.25; 2647 src tok/s; 2745 tgt tok/s;    128 s elapsed
Epoch  5,   450/  454; acc:  65.78; ppl:   6.14; 2616 src tok/s; 2711 tgt tok/s;    143 s elapsed
Train perplexity: 6.28276
Train accuracy: 65.5406
Validation perplexity: 7.4663
Validation accuracy: 64.8361

Epoch  6,    50/  454; acc:  69.82; ppl:   4.57; 2655 src tok/s; 2771 tgt tok/s;     15 s elapsed
Epoch  6,   100/  454; acc:  67.30; ppl:   5.32; 2643 src tok/s; 2722 tgt tok/s;     32 s elapsed
Epoch  6,   150/  454; acc:  68.81; ppl:   4.88; 2654 src tok/s; 2749 tgt tok/s;     47 s elapsed
Epoch  6,   200/  454; acc:  67.36; ppl:   5.23; 2510 src tok/s; 2610 tgt tok/s;     64 s elapsed
Epoch  6,   250/  454; acc:  68.34; ppl:   4.85; 2671 src tok/s; 2762 tgt tok/s;     80 s elapsed
Epoch  6,   300/  454; acc:  67.33; ppl:   5.27; 2610 src tok/s; 2714 tgt tok/s;     96 s elapsed
Epoch  6,   350/  454; acc:  67.84; ppl:   5.07; 2537 src tok/s; 2625 tgt tok/s;    113 s elapsed
Epoch  6,   400/  454; acc:  67.51; ppl:   5.29; 2694 src tok/s; 2812 tgt tok/s;    128 s elapsed
Epoch  6,   450/  454; acc:  67.93; ppl:   5.11; 2550 src tok/s; 2648 tgt tok/s;    144 s elapsed
Train perplexity: 5.05412
Train accuracy: 68.049
Validation perplexity: 6.99274
Validation accuracy: 66.0494

Epoch  7,    50/  454; acc:  70.95; ppl:   4.05; 2729 src tok/s; 2828 tgt tok/s;     15 s elapsed
Epoch  7,   100/  454; acc:  70.75; ppl:   4.08; 2631 src tok/s; 2718 tgt tok/s;     31 s elapsed
Epoch  7,   150/  454; acc:  71.42; ppl:   3.95; 2569 src tok/s; 2695 tgt tok/s;     47 s elapsed
Epoch  7,   200/  454; acc:  68.96; ppl:   4.60; 2646 src tok/s; 2727 tgt tok/s;     64 s elapsed
Epoch  7,   250/  454; acc:  70.48; ppl:   4.17; 2588 src tok/s; 2687 tgt tok/s;     80 s elapsed
Epoch  7,   300/  454; acc:  70.10; ppl:   4.28; 2702 src tok/s; 2808 tgt tok/s;     95 s elapsed
Epoch  7,   350/  454; acc:  70.56; ppl:   4.20; 2584 src tok/s; 2685 tgt tok/s;    111 s elapsed
Epoch  7,   400/  454; acc:  69.19; ppl:   4.46; 2717 src tok/s; 2811 tgt tok/s;    127 s elapsed
Epoch  7,   450/  454; acc:  69.90; ppl:   4.31; 2594 src tok/s; 2702 tgt tok/s;    143 s elapsed
Train perplexity: 4.23444
Train accuracy: 70.2325
Validation perplexity: 6.62156
Validation accuracy: 66.766

Epoch  8,    50/  454; acc:  73.64; ppl:   3.40; 2629 src tok/s; 2738 tgt tok/s;     16 s elapsed
Epoch  8,   100/  454; acc:  72.45; ppl:   3.59; 2633 src tok/s; 2713 tgt tok/s;     32 s elapsed
Epoch  8,   150/  454; acc:  71.09; ppl:   3.91; 2652 src tok/s; 2748 tgt tok/s;     48 s elapsed
Epoch  8,   200/  454; acc:  73.03; ppl:   3.42; 2718 src tok/s; 2839 tgt tok/s;     63 s elapsed
Epoch  8,   250/  454; acc:  71.95; ppl:   3.65; 2584 src tok/s; 2679 tgt tok/s;     80 s elapsed
Epoch  8,   300/  454; acc:  72.27; ppl:   3.67; 2681 src tok/s; 2791 tgt tok/s;     95 s elapsed
Epoch  8,   350/  454; acc:  71.15; ppl:   3.86; 2586 src tok/s; 2675 tgt tok/s;    112 s elapsed
Epoch  8,   400/  454; acc:  72.28; ppl:   3.64; 2596 src tok/s; 2704 tgt tok/s;    127 s elapsed
Epoch  8,   450/  454; acc:  71.12; ppl:   3.84; 2672 src tok/s; 2764 tgt tok/s;    143 s elapsed
Train perplexity: 3.65983
Train accuracy: 72.1112
Validation perplexity: 6.50991
Validation accuracy: 67.6316
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.75; ppl:   2.79; 2616 src tok/s; 2715 tgt tok/s;     16 s elapsed
Epoch  9,   100/  454; acc:  77.56; ppl:   2.69; 2705 src tok/s; 2820 tgt tok/s;     31 s elapsed
Epoch  9,   150/  454; acc:  77.43; ppl:   2.68; 2646 src tok/s; 2738 tgt tok/s;     47 s elapsed
Epoch  9,   200/  454; acc:  76.79; ppl:   2.77; 2680 src tok/s; 2773 tgt tok/s;     63 s elapsed
Epoch  9,   250/  454; acc:  78.45; ppl:   2.55; 2576 src tok/s; 2693 tgt tok/s;     78 s elapsed
Epoch  9,   300/  454; acc:  76.11; ppl:   2.88; 2712 src tok/s; 2795 tgt tok/s;     95 s elapsed
Epoch  9,   350/  454; acc:  76.72; ppl:   2.83; 2654 src tok/s; 2757 tgt tok/s;    111 s elapsed
Epoch  9,   400/  454; acc:  77.42; ppl:   2.70; 2635 src tok/s; 2733 tgt tok/s;    127 s elapsed
Epoch  9,   450/  454; acc:  77.46; ppl:   2.68; 2634 src tok/s; 2741 tgt tok/s;    142 s elapsed
Train perplexity: 2.73563
Train accuracy: 77.1441
Validation perplexity: 6.15251
Validation accuracy: 68.8378
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.47; ppl:   2.22; 2626 src tok/s; 2727 tgt tok/s;     16 s elapsed
Epoch 10,   100/  454; acc:  80.52; ppl:   2.29; 2662 src tok/s; 2765 tgt tok/s;     32 s elapsed
Epoch 10,   150/  454; acc:  80.25; ppl:   2.31; 2599 src tok/s; 2698 tgt tok/s;     48 s elapsed
Epoch 10,   200/  454; acc:  81.90; ppl:   2.13; 2584 src tok/s; 2669 tgt tok/s;     64 s elapsed
Epoch 10,   250/  454; acc:  80.31; ppl:   2.32; 2720 src tok/s; 2803 tgt tok/s;     80 s elapsed
Epoch 10,   300/  454; acc:  81.53; ppl:   2.19; 2454 src tok/s; 2593 tgt tok/s;     96 s elapsed
Epoch 10,   350/  454; acc:  81.09; ppl:   2.21; 2679 src tok/s; 2789 tgt tok/s;    112 s elapsed
Epoch 10,   400/  454; acc:  79.95; ppl:   2.35; 2584 src tok/s; 2664 tgt tok/s;    128 s elapsed
Epoch 10,   450/  454; acc:  80.64; ppl:   2.27; 2622 src tok/s; 2708 tgt tok/s;    144 s elapsed
Train perplexity: 2.25185
Train accuracy: 80.8638
Validation perplexity: 6.27778
Validation accuracy: 69.0649
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.29; ppl:   2.04; 2605 src tok/s; 2717 tgt tok/s;     16 s elapsed
Epoch 11,   100/  454; acc:  82.86; ppl:   2.05; 2608 src tok/s; 2701 tgt tok/s;     32 s elapsed
Epoch 11,   150/  454; acc:  83.83; ppl:   1.97; 2609 src tok/s; 2702 tgt tok/s;     48 s elapsed
Epoch 11,   200/  454; acc:  82.43; ppl:   2.10; 2555 src tok/s; 2652 tgt tok/s;     65 s elapsed
Epoch 11,   250/  454; acc:  82.33; ppl:   2.12; 2692 src tok/s; 2781 tgt tok/s;     81 s elapsed
Epoch 11,   300/  454; acc:  84.00; ppl:   1.94; 2527 src tok/s; 2646 tgt tok/s;     97 s elapsed
Epoch 11,   350/  454; acc:  82.81; ppl:   2.02; 2646 src tok/s; 2739 tgt tok/s;    113 s elapsed
Epoch 11,   400/  454; acc:  83.12; ppl:   2.03; 2619 src tok/s; 2716 tgt tok/s;    129 s elapsed
Epoch 11,   450/  454; acc:  82.72; ppl:   2.05; 2565 src tok/s; 2654 tgt tok/s;    145 s elapsed
Train perplexity: 2.03102
Train accuracy: 83.0663
Validation perplexity: 6.40958
Validation accuracy: 69.1784
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  83.62; ppl:   1.99; 2663 src tok/s; 2756 tgt tok/s;     16 s elapsed
Epoch 12,   100/  454; acc:  84.42; ppl:   1.90; 2603 src tok/s; 2716 tgt tok/s;     32 s elapsed
Epoch 12,   150/  454; acc:  84.63; ppl:   1.87; 2630 src tok/s; 2740 tgt tok/s;     48 s elapsed
Epoch 12,   200/  454; acc:  83.81; ppl:   1.95; 2579 src tok/s; 2671 tgt tok/s;     64 s elapsed
Epoch 12,   250/  454; acc:  83.51; ppl:   2.00; 2672 src tok/s; 2781 tgt tok/s;     80 s elapsed
Epoch 12,   300/  454; acc:  84.58; ppl:   1.87; 2569 src tok/s; 2667 tgt tok/s;     96 s elapsed
Epoch 12,   350/  454; acc:  84.04; ppl:   1.95; 2629 src tok/s; 2730 tgt tok/s;    112 s elapsed
Epoch 12,   400/  454; acc:  84.29; ppl:   1.92; 2787 src tok/s; 2887 tgt tok/s;    127 s elapsed
Epoch 12,   450/  454; acc:  83.98; ppl:   1.93; 2565 src tok/s; 2647 tgt tok/s;    143 s elapsed
Train perplexity: 1.93026
Train accuracy: 84.1075
Validation perplexity: 6.52192
Validation accuracy: 69.4906
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  85.17; ppl:   1.86; 2622 src tok/s; 2725 tgt tok/s;     16 s elapsed
Epoch 13,   100/  454; acc:  84.78; ppl:   1.88; 2679 src tok/s; 2783 tgt tok/s;     32 s elapsed
Epoch 13,   150/  454; acc:  85.75; ppl:   1.77; 2702 src tok/s; 2824 tgt tok/s;     46 s elapsed
Epoch 13,   200/  454; acc:  83.85; ppl:   1.96; 2700 src tok/s; 2773 tgt tok/s;     63 s elapsed
Epoch 13,   250/  454; acc:  85.81; ppl:   1.78; 2546 src tok/s; 2657 tgt tok/s;     78 s elapsed
Epoch 13,   300/  454; acc:  83.85; ppl:   1.95; 2728 src tok/s; 2825 tgt tok/s;     94 s elapsed
Epoch 13,   350/  454; acc:  83.68; ppl:   2.00; 2623 src tok/s; 2722 tgt tok/s;    111 s elapsed
Epoch 13,   400/  454; acc:  84.91; ppl:   1.85; 2662 src tok/s; 2764 tgt tok/s;    126 s elapsed
Epoch 13,   450/  454; acc:  84.74; ppl:   1.88; 2642 src tok/s; 2737 tgt tok/s;    142 s elapsed
Train perplexity: 1.88305
Train accuracy: 84.7085
Validation perplexity: 6.57527
Validation accuracy: 69.2777
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  84.59; ppl:   1.90; 2757 src tok/s; 2869 tgt tok/s;     15 s elapsed
Epoch 14,   100/  454; acc:  85.54; ppl:   1.81; 2606 src tok/s; 2707 tgt tok/s;     31 s elapsed
Epoch 14,   150/  454; acc:  84.94; ppl:   1.85; 2702 src tok/s; 2788 tgt tok/s;     47 s elapsed
Epoch 14,   200/  454; acc:  85.06; ppl:   1.83; 2587 src tok/s; 2696 tgt tok/s;     63 s elapsed
Epoch 14,   250/  454; acc:  84.36; ppl:   1.92; 2517 src tok/s; 2596 tgt tok/s;     80 s elapsed
Epoch 14,   300/  454; acc:  85.81; ppl:   1.79; 2656 src tok/s; 2779 tgt tok/s;     95 s elapsed
Epoch 14,   350/  454; acc:  85.96; ppl:   1.79; 2617 src tok/s; 2734 tgt tok/s;    111 s elapsed
Epoch 14,   400/  454; acc:  84.38; ppl:   1.92; 2691 src tok/s; 2778 tgt tok/s;    127 s elapsed
Epoch 14,   450/  454; acc:  85.22; ppl:   1.85; 2548 src tok/s; 2634 tgt tok/s;    143 s elapsed
Train perplexity: 1.85519
Train accuracy: 85.0466
Validation perplexity: 6.60906
Validation accuracy: 69.3487
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  84.94; ppl:   1.87; 2680 src tok/s; 2783 tgt tok/s;     16 s elapsed
Epoch 15,   100/  454; acc:  84.97; ppl:   1.85; 2533 src tok/s; 2631 tgt tok/s;     32 s elapsed
Epoch 15,   150/  454; acc:  84.19; ppl:   1.92; 2557 src tok/s; 2626 tgt tok/s;     50 s elapsed
Epoch 15,   200/  454; acc:  86.54; ppl:   1.73; 2596 src tok/s; 2720 tgt tok/s;     65 s elapsed
Epoch 15,   250/  454; acc:  85.42; ppl:   1.82; 2525 src tok/s; 2623 tgt tok/s;     81 s elapsed
Epoch 15,   300/  454; acc:  84.52; ppl:   1.89; 2620 src tok/s; 2711 tgt tok/s;     98 s elapsed
Epoch 15,   350/  454; acc:  85.58; ppl:   1.81; 2506 src tok/s; 2616 tgt tok/s;    114 s elapsed
Epoch 15,   400/  454; acc:  84.56; ppl:   1.89; 2681 src tok/s; 2774 tgt tok/s;    130 s elapsed
Epoch 15,   450/  454; acc:  85.43; ppl:   1.83; 2576 src tok/s; 2674 tgt tok/s;    146 s elapsed
Train perplexity: 1.84606
Train accuracy: 85.1193
Validation perplexity: 6.61991
Validation accuracy: 69.2919
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.57; ppl:   1.79; 2658 src tok/s; 2759 tgt tok/s;     16 s elapsed
Epoch 16,   100/  454; acc:  84.87; ppl:   1.90; 2610 src tok/s; 2712 tgt tok/s;     32 s elapsed
Epoch 16,   150/  454; acc:  85.76; ppl:   1.79; 2552 src tok/s; 2650 tgt tok/s;     48 s elapsed
Epoch 16,   200/  454; acc:  84.46; ppl:   1.91; 2713 src tok/s; 2820 tgt tok/s;     64 s elapsed
Epoch 16,   250/  454; acc:  85.57; ppl:   1.80; 2521 src tok/s; 2627 tgt tok/s;     80 s elapsed
Epoch 16,   300/  454; acc:  84.98; ppl:   1.87; 2793 src tok/s; 2874 tgt tok/s;     96 s elapsed
Epoch 16,   350/  454; acc:  84.46; ppl:   1.91; 2572 src tok/s; 2660 tgt tok/s;    112 s elapsed
Epoch 16,   400/  454; acc:  85.87; ppl:   1.77; 2537 src tok/s; 2626 tgt tok/s;    128 s elapsed
Epoch 16,   450/  454; acc:  86.27; ppl:   1.75; 2601 src tok/s; 2731 tgt tok/s;    144 s elapsed
Train perplexity: 1.83929
Train accuracy: 85.226
Validation perplexity: 6.62949
Validation accuracy: 69.3203
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  86.42; ppl:   1.74; 2586 src tok/s; 2705 tgt tok/s;     15 s elapsed
Epoch 17,   100/  454; acc:  84.35; ppl:   1.94; 2761 src tok/s; 2842 tgt tok/s;     31 s elapsed
Epoch 17,   150/  454; acc:  85.18; ppl:   1.84; 2600 src tok/s; 2699 tgt tok/s;     47 s elapsed
Epoch 17,   200/  454; acc:  85.22; ppl:   1.84; 2592 src tok/s; 2690 tgt tok/s;     63 s elapsed
Epoch 17,   250/  454; acc:  85.62; ppl:   1.79; 2534 src tok/s; 2631 tgt tok/s;     80 s elapsed
Epoch 17,   300/  454; acc:  84.77; ppl:   1.89; 2601 src tok/s; 2702 tgt tok/s;     96 s elapsed
Epoch 17,   350/  454; acc:  85.24; ppl:   1.83; 2633 src tok/s; 2718 tgt tok/s;    112 s elapsed
Epoch 17,   400/  454; acc:  85.50; ppl:   1.83; 2547 src tok/s; 2655 tgt tok/s;    129 s elapsed
Epoch 17,   450/  454; acc:  84.82; ppl:   1.87; 2644 src tok/s; 2739 tgt tok/s;    145 s elapsed
Train perplexity: 1.83898
Train accuracy: 85.2403
Validation perplexity: 6.62862
Validation accuracy: 69.3203
Decaying learning rate to 0.000976562
