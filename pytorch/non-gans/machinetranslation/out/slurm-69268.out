<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.2, kappa_enc=0.0, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0decoder0.20dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on decoder', 0.2)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   9.64; ppl: 10906.58; 2710 src tok/s; 2826 tgt tok/s;     15 s elapsed
Epoch  1,   100/  454; acc:  14.95; ppl: 1104.69; 2822 src tok/s; 2902 tgt tok/s;     30 s elapsed
Epoch  1,   150/  454; acc:  18.15; ppl: 540.74; 2722 src tok/s; 2829 tgt tok/s;     46 s elapsed
Epoch  1,   200/  454; acc:  22.03; ppl: 262.84; 2814 src tok/s; 2936 tgt tok/s;     61 s elapsed
Epoch  1,   250/  454; acc:  24.28; ppl: 167.05; 2698 src tok/s; 2809 tgt tok/s;     76 s elapsed
Epoch  1,   300/  454; acc:  28.11; ppl: 117.67; 2687 src tok/s; 2793 tgt tok/s;     92 s elapsed
Epoch  1,   350/  454; acc:  29.54; ppl:  97.23; 2783 src tok/s; 2879 tgt tok/s;    107 s elapsed
Epoch  1,   400/  454; acc:  32.46; ppl:  74.05; 2807 src tok/s; 2912 tgt tok/s;    122 s elapsed
Epoch  1,   450/  454; acc:  32.98; ppl:  68.51; 2759 src tok/s; 2851 tgt tok/s;    137 s elapsed
Train perplexity: 288.183
Train accuracy: 23.6873
Validation perplexity: 48.2137
Validation accuracy: 37.6898

Epoch  2,    50/  454; acc:  38.12; ppl:  46.16; 2760 src tok/s; 2893 tgt tok/s;     14 s elapsed
Epoch  2,   100/  454; acc:  37.61; ppl:  47.87; 2771 src tok/s; 2845 tgt tok/s;     30 s elapsed
Epoch  2,   150/  454; acc:  41.04; ppl:  38.15; 2742 src tok/s; 2850 tgt tok/s;     45 s elapsed
Epoch  2,   200/  454; acc:  42.21; ppl:  34.06; 2732 src tok/s; 2846 tgt tok/s;     61 s elapsed
Epoch  2,   250/  454; acc:  44.60; ppl:  28.79; 2849 src tok/s; 2961 tgt tok/s;     76 s elapsed
Epoch  2,   300/  454; acc:  47.11; ppl:  24.69; 2783 src tok/s; 2883 tgt tok/s;     91 s elapsed
Epoch  2,   350/  454; acc:  47.80; ppl:  23.38; 2762 src tok/s; 2840 tgt tok/s;    107 s elapsed
Epoch  2,   400/  454; acc:  51.94; ppl:  18.48; 2678 src tok/s; 2801 tgt tok/s;    122 s elapsed
Epoch  2,   450/  454; acc:  52.13; ppl:  17.63; 2716 src tok/s; 2824 tgt tok/s;    137 s elapsed
Train perplexity: 29.1671
Train accuracy: 44.7526
Validation perplexity: 16.0246
Validation accuracy: 53.725

Epoch  3,    50/  454; acc:  53.30; ppl:  15.49; 2770 src tok/s; 2882 tgt tok/s;     15 s elapsed
Epoch  3,   100/  454; acc:  54.74; ppl:  14.37; 2725 src tok/s; 2818 tgt tok/s;     31 s elapsed
Epoch  3,   150/  454; acc:  55.27; ppl:  13.81; 2786 src tok/s; 2875 tgt tok/s;     46 s elapsed
Epoch  3,   200/  454; acc:  57.38; ppl:  12.22; 2727 src tok/s; 2841 tgt tok/s;     61 s elapsed
Epoch  3,   250/  454; acc:  55.77; ppl:  13.03; 2855 src tok/s; 2945 tgt tok/s;     76 s elapsed
Epoch  3,   300/  454; acc:  58.41; ppl:  11.00; 2745 src tok/s; 2857 tgt tok/s;     91 s elapsed
Epoch  3,   350/  454; acc:  58.52; ppl:  11.10; 2772 src tok/s; 2896 tgt tok/s;    106 s elapsed
Epoch  3,   400/  454; acc:  58.25; ppl:  11.20; 2741 src tok/s; 2849 tgt tok/s;    121 s elapsed
Epoch  3,   450/  454; acc:  58.73; ppl:  10.95; 2741 src tok/s; 2844 tgt tok/s;    136 s elapsed
Train perplexity: 12.4804
Train accuracy: 56.7041
Validation perplexity: 10.4649
Validation accuracy: 59.4579

Epoch  4,    50/  454; acc:  61.85; ppl:   8.43; 2786 src tok/s; 2897 tgt tok/s;     15 s elapsed
Epoch  4,   100/  454; acc:  61.25; ppl:   8.59; 2760 src tok/s; 2866 tgt tok/s;     30 s elapsed
Epoch  4,   150/  454; acc:  62.10; ppl:   8.34; 2743 src tok/s; 2859 tgt tok/s;     45 s elapsed
Epoch  4,   200/  454; acc:  61.34; ppl:   8.67; 2732 src tok/s; 2829 tgt tok/s;     61 s elapsed
Epoch  4,   250/  454; acc:  61.78; ppl:   8.40; 2826 src tok/s; 2917 tgt tok/s;     76 s elapsed
Epoch  4,   300/  454; acc:  62.94; ppl:   7.92; 2756 src tok/s; 2874 tgt tok/s;     91 s elapsed
Epoch  4,   350/  454; acc:  62.04; ppl:   8.10; 2734 src tok/s; 2830 tgt tok/s;    106 s elapsed
Epoch  4,   400/  454; acc:  63.65; ppl:   7.47; 2822 src tok/s; 2935 tgt tok/s;    121 s elapsed
Epoch  4,   450/  454; acc:  62.71; ppl:   7.87; 2796 src tok/s; 2897 tgt tok/s;    136 s elapsed
Train perplexity: 8.19369
Train accuracy: 62.1888
Validation perplexity: 8.60956
Validation accuracy: 62.0335

Epoch  5,    50/  454; acc:  65.86; ppl:   6.14; 2786 src tok/s; 2893 tgt tok/s;     15 s elapsed
Epoch  5,   100/  454; acc:  66.01; ppl:   5.96; 2830 src tok/s; 2940 tgt tok/s;     30 s elapsed
Epoch  5,   150/  454; acc:  65.52; ppl:   6.17; 2816 src tok/s; 2923 tgt tok/s;     45 s elapsed
Epoch  5,   200/  454; acc:  65.29; ppl:   6.41; 2689 src tok/s; 2795 tgt tok/s;     60 s elapsed
Epoch  5,   250/  454; acc:  65.47; ppl:   6.28; 2737 src tok/s; 2844 tgt tok/s;     76 s elapsed
Epoch  5,   300/  454; acc:  66.00; ppl:   6.11; 2797 src tok/s; 2897 tgt tok/s;     91 s elapsed
Epoch  5,   350/  454; acc:  66.66; ppl:   5.92; 2806 src tok/s; 2907 tgt tok/s;    105 s elapsed
Epoch  5,   400/  454; acc:  65.37; ppl:   6.28; 2863 src tok/s; 2954 tgt tok/s;    120 s elapsed
Epoch  5,   450/  454; acc:  65.70; ppl:   6.25; 2805 src tok/s; 2920 tgt tok/s;    135 s elapsed
Train perplexity: 6.16039
Train accuracy: 65.7797
Validation perplexity: 7.92493
Validation accuracy: 63.5093

Epoch  6,    50/  454; acc:  68.39; ppl:   4.95; 2750 src tok/s; 2838 tgt tok/s;     16 s elapsed
Epoch  6,   100/  454; acc:  68.88; ppl:   4.85; 2758 src tok/s; 2878 tgt tok/s;     31 s elapsed
Epoch  6,   150/  454; acc:  70.12; ppl:   4.53; 2616 src tok/s; 2771 tgt tok/s;     45 s elapsed
Epoch  6,   200/  454; acc:  66.80; ppl:   5.40; 2699 src tok/s; 2761 tgt tok/s;     62 s elapsed
Epoch  6,   250/  454; acc:  67.40; ppl:   5.23; 2763 src tok/s; 2852 tgt tok/s;     78 s elapsed
Epoch  6,   300/  454; acc:  68.45; ppl:   4.90; 2779 src tok/s; 2890 tgt tok/s;     92 s elapsed
Epoch  6,   350/  454; acc:  69.03; ppl:   4.79; 2727 src tok/s; 2853 tgt tok/s;    107 s elapsed
Epoch  6,   400/  454; acc:  67.28; ppl:   5.28; 2702 src tok/s; 2799 tgt tok/s;    123 s elapsed
Epoch  6,   450/  454; acc:  68.42; ppl:   4.97; 2816 src tok/s; 2910 tgt tok/s;    138 s elapsed
Train perplexity: 4.98818
Train accuracy: 68.2908
Validation perplexity: 6.97992
Validation accuracy: 65.8223

Epoch  7,    50/  454; acc:  71.09; ppl:   4.03; 2729 src tok/s; 2828 tgt tok/s;     16 s elapsed
Epoch  7,   100/  454; acc:  71.44; ppl:   3.96; 2792 src tok/s; 2918 tgt tok/s;     30 s elapsed
Epoch  7,   150/  454; acc:  70.23; ppl:   4.29; 2734 src tok/s; 2820 tgt tok/s;     46 s elapsed
Epoch  7,   200/  454; acc:  71.12; ppl:   3.99; 2739 src tok/s; 2853 tgt tok/s;     61 s elapsed
Epoch  7,   250/  454; acc:  70.54; ppl:   4.10; 2772 src tok/s; 2877 tgt tok/s;     76 s elapsed
Epoch  7,   300/  454; acc:  69.81; ppl:   4.28; 2714 src tok/s; 2818 tgt tok/s;     92 s elapsed
Epoch  7,   350/  454; acc:  69.11; ppl:   4.44; 2856 src tok/s; 2961 tgt tok/s;    107 s elapsed
Epoch  7,   400/  454; acc:  70.19; ppl:   4.20; 2792 src tok/s; 2902 tgt tok/s;    121 s elapsed
Epoch  7,   450/  454; acc:  70.36; ppl:   4.25; 2748 src tok/s; 2840 tgt tok/s;    136 s elapsed
Train perplexity: 4.16995
Train accuracy: 70.4264
Validation perplexity: 6.66578
Validation accuracy: 66.5035

Epoch  8,    50/  454; acc:  73.54; ppl:   3.37; 2807 src tok/s; 2905 tgt tok/s;     15 s elapsed
Epoch  8,   100/  454; acc:  73.65; ppl:   3.37; 2765 src tok/s; 2884 tgt tok/s;     30 s elapsed
Epoch  8,   150/  454; acc:  73.19; ppl:   3.43; 2666 src tok/s; 2782 tgt tok/s;     45 s elapsed
Epoch  8,   200/  454; acc:  71.24; ppl:   3.85; 2760 src tok/s; 2853 tgt tok/s;     61 s elapsed
Epoch  8,   250/  454; acc:  72.35; ppl:   3.60; 2815 src tok/s; 2915 tgt tok/s;     76 s elapsed
Epoch  8,   300/  454; acc:  72.35; ppl:   3.56; 2796 src tok/s; 2902 tgt tok/s;     91 s elapsed
Epoch  8,   350/  454; acc:  72.16; ppl:   3.66; 2804 src tok/s; 2906 tgt tok/s;    105 s elapsed
Epoch  8,   400/  454; acc:  71.94; ppl:   3.77; 2719 src tok/s; 2810 tgt tok/s;    121 s elapsed
Epoch  8,   450/  454; acc:  71.05; ppl:   3.84; 2748 src tok/s; 2860 tgt tok/s;    136 s elapsed
Train perplexity: 3.59915
Train accuracy: 72.3978
Validation perplexity: 6.73821
Validation accuracy: 66.241
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.31; ppl:   2.73; 2758 src tok/s; 2877 tgt tok/s;     15 s elapsed
Epoch  9,   100/  454; acc:  77.67; ppl:   2.68; 2732 src tok/s; 2830 tgt tok/s;     31 s elapsed
Epoch  9,   150/  454; acc:  76.77; ppl:   2.78; 2767 src tok/s; 2856 tgt tok/s;     46 s elapsed
Epoch  9,   200/  454; acc:  77.97; ppl:   2.58; 2677 src tok/s; 2790 tgt tok/s;     62 s elapsed
Epoch  9,   250/  454; acc:  77.20; ppl:   2.76; 2820 src tok/s; 2931 tgt tok/s;     76 s elapsed
Epoch  9,   300/  454; acc:  77.79; ppl:   2.63; 2846 src tok/s; 2952 tgt tok/s;     91 s elapsed
Epoch  9,   350/  454; acc:  77.91; ppl:   2.63; 2774 src tok/s; 2892 tgt tok/s;    106 s elapsed
Epoch  9,   400/  454; acc:  76.42; ppl:   2.83; 2723 src tok/s; 2812 tgt tok/s;    122 s elapsed
Epoch  9,   450/  454; acc:  77.49; ppl:   2.68; 2636 src tok/s; 2732 tgt tok/s;    137 s elapsed
Train perplexity: 2.69761
Train accuracy: 77.3974
Validation perplexity: 6.11884
Validation accuracy: 69.5331
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.71; ppl:   2.28; 2751 src tok/s; 2847 tgt tok/s;     16 s elapsed
Epoch 10,   100/  454; acc:  81.90; ppl:   2.15; 2808 src tok/s; 2917 tgt tok/s;     30 s elapsed
Epoch 10,   150/  454; acc:  80.97; ppl:   2.25; 2700 src tok/s; 2811 tgt tok/s;     46 s elapsed
Epoch 10,   200/  454; acc:  81.50; ppl:   2.19; 2712 src tok/s; 2812 tgt tok/s;     61 s elapsed
Epoch 10,   250/  454; acc:  81.63; ppl:   2.14; 2801 src tok/s; 2922 tgt tok/s;     76 s elapsed
Epoch 10,   300/  454; acc:  80.43; ppl:   2.30; 2769 src tok/s; 2862 tgt tok/s;     91 s elapsed
Epoch 10,   350/  454; acc:  81.77; ppl:   2.11; 2744 src tok/s; 2848 tgt tok/s;    106 s elapsed
Epoch 10,   400/  454; acc:  80.38; ppl:   2.30; 2733 src tok/s; 2835 tgt tok/s;    122 s elapsed
Epoch 10,   450/  454; acc:  81.15; ppl:   2.21; 2728 src tok/s; 2837 tgt tok/s;    137 s elapsed
Train perplexity: 2.21669
Train accuracy: 81.1236
Validation perplexity: 6.21226
Validation accuracy: 69.6821
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.26; ppl:   2.02; 2779 src tok/s; 2877 tgt tok/s;     15 s elapsed
Epoch 11,   100/  454; acc:  83.75; ppl:   1.96; 2823 src tok/s; 2921 tgt tok/s;     30 s elapsed
Epoch 11,   150/  454; acc:  82.86; ppl:   2.05; 2805 src tok/s; 2890 tgt tok/s;     46 s elapsed
Epoch 11,   200/  454; acc:  84.01; ppl:   1.93; 2617 src tok/s; 2728 tgt tok/s;     61 s elapsed
Epoch 11,   250/  454; acc:  84.40; ppl:   1.91; 2704 src tok/s; 2840 tgt tok/s;     76 s elapsed
Epoch 11,   300/  454; acc:  81.90; ppl:   2.13; 2778 src tok/s; 2872 tgt tok/s;     92 s elapsed
Epoch 11,   350/  454; acc:  82.89; ppl:   2.02; 2625 src tok/s; 2731 tgt tok/s;    108 s elapsed
Epoch 11,   400/  454; acc:  83.27; ppl:   1.99; 2750 src tok/s; 2855 tgt tok/s;    123 s elapsed
Epoch 11,   450/  454; acc:  82.75; ppl:   2.04; 2770 src tok/s; 2870 tgt tok/s;    138 s elapsed
Train perplexity: 2.00557
Train accuracy: 83.232
Validation perplexity: 6.40629
Validation accuracy: 69.6112
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.42; ppl:   1.92; 2830 src tok/s; 2958 tgt tok/s;     15 s elapsed
Epoch 12,   100/  454; acc:  84.46; ppl:   1.91; 2761 src tok/s; 2851 tgt tok/s;     30 s elapsed
Epoch 12,   150/  454; acc:  83.92; ppl:   1.95; 2764 src tok/s; 2868 tgt tok/s;     45 s elapsed
Epoch 12,   200/  454; acc:  84.82; ppl:   1.86; 2833 src tok/s; 2953 tgt tok/s;     60 s elapsed
Epoch 12,   250/  454; acc:  84.70; ppl:   1.91; 2715 src tok/s; 2802 tgt tok/s;     75 s elapsed
Epoch 12,   300/  454; acc:  84.70; ppl:   1.87; 2702 src tok/s; 2802 tgt tok/s;     91 s elapsed
Epoch 12,   350/  454; acc:  85.47; ppl:   1.81; 2756 src tok/s; 2877 tgt tok/s;    105 s elapsed
Epoch 12,   400/  454; acc:  83.41; ppl:   1.99; 2834 src tok/s; 2917 tgt tok/s;    121 s elapsed
Epoch 12,   450/  454; acc:  84.09; ppl:   1.92; 2729 src tok/s; 2841 tgt tok/s;    136 s elapsed
Train perplexity: 1.90622
Train accuracy: 84.4242
Validation perplexity: 6.48106
Validation accuracy: 69.8311
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  85.14; ppl:   1.85; 2777 src tok/s; 2889 tgt tok/s;     15 s elapsed
Epoch 13,   100/  454; acc:  84.44; ppl:   1.91; 2838 src tok/s; 2924 tgt tok/s;     30 s elapsed
Epoch 13,   150/  454; acc:  85.35; ppl:   1.81; 2805 src tok/s; 2893 tgt tok/s;     45 s elapsed
Epoch 13,   200/  454; acc:  85.15; ppl:   1.83; 2699 src tok/s; 2806 tgt tok/s;     60 s elapsed
Epoch 13,   250/  454; acc:  85.54; ppl:   1.82; 2834 src tok/s; 2939 tgt tok/s;     75 s elapsed
Epoch 13,   300/  454; acc:  84.58; ppl:   1.88; 2738 src tok/s; 2851 tgt tok/s;     90 s elapsed
Epoch 13,   350/  454; acc:  84.87; ppl:   1.87; 2722 src tok/s; 2839 tgt tok/s;    106 s elapsed
Epoch 13,   400/  454; acc:  84.91; ppl:   1.88; 2836 src tok/s; 2945 tgt tok/s;    121 s elapsed
Epoch 13,   450/  454; acc:  85.03; ppl:   1.85; 2694 src tok/s; 2807 tgt tok/s;    136 s elapsed
Train perplexity: 1.8567
Train accuracy: 84.972
Validation perplexity: 6.56725
Validation accuracy: 69.6396
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.77; ppl:   1.78; 2724 src tok/s; 2868 tgt tok/s;     14 s elapsed
Epoch 14,   100/  454; acc:  84.62; ppl:   1.92; 2760 src tok/s; 2844 tgt tok/s;     30 s elapsed
Epoch 14,   150/  454; acc:  84.76; ppl:   1.88; 2702 src tok/s; 2804 tgt tok/s;     46 s elapsed
Epoch 14,   200/  454; acc:  85.98; ppl:   1.77; 2693 src tok/s; 2814 tgt tok/s;     61 s elapsed
Epoch 14,   250/  454; acc:  85.46; ppl:   1.81; 2716 src tok/s; 2819 tgt tok/s;     77 s elapsed
Epoch 14,   300/  454; acc:  84.72; ppl:   1.87; 2723 src tok/s; 2815 tgt tok/s;     92 s elapsed
Epoch 14,   350/  454; acc:  85.64; ppl:   1.79; 2793 src tok/s; 2885 tgt tok/s;    108 s elapsed
Epoch 14,   400/  454; acc:  85.15; ppl:   1.85; 2798 src tok/s; 2896 tgt tok/s;    123 s elapsed
Epoch 14,   450/  454; acc:  85.25; ppl:   1.83; 2796 src tok/s; 2907 tgt tok/s;    137 s elapsed
Train perplexity: 1.83447
Train accuracy: 85.2269
Validation perplexity: 6.60755
Validation accuracy: 69.746
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.79; ppl:   1.78; 2784 src tok/s; 2899 tgt tok/s;     15 s elapsed
Epoch 15,   100/  454; acc:  84.92; ppl:   1.85; 2744 src tok/s; 2842 tgt tok/s;     30 s elapsed
Epoch 15,   150/  454; acc:  85.93; ppl:   1.79; 2956 src tok/s; 3078 tgt tok/s;     44 s elapsed
Epoch 15,   200/  454; acc:  85.11; ppl:   1.86; 3049 src tok/s; 3158 tgt tok/s;     58 s elapsed
Epoch 15,   250/  454; acc:  85.60; ppl:   1.81; 2846 src tok/s; 2976 tgt tok/s;     73 s elapsed
Epoch 15,   300/  454; acc:  85.47; ppl:   1.81; 2737 src tok/s; 2819 tgt tok/s;     88 s elapsed
Epoch 15,   350/  454; acc:  85.56; ppl:   1.82; 2746 src tok/s; 2845 tgt tok/s;    104 s elapsed
Epoch 15,   400/  454; acc:  85.18; ppl:   1.83; 2817 src tok/s; 2931 tgt tok/s;    119 s elapsed
Epoch 15,   450/  454; acc:  85.76; ppl:   1.78; 2732 src tok/s; 2838 tgt tok/s;    133 s elapsed
Train perplexity: 1.82201
Train accuracy: 85.4265
Validation perplexity: 6.62063
Validation accuracy: 69.7744
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.52; ppl:   1.82; 2782 src tok/s; 2872 tgt tok/s;     15 s elapsed
Epoch 16,   100/  454; acc:  85.49; ppl:   1.81; 2708 src tok/s; 2832 tgt tok/s;     31 s elapsed
Epoch 16,   150/  454; acc:  84.34; ppl:   1.91; 2792 src tok/s; 2883 tgt tok/s;     46 s elapsed
Epoch 16,   200/  454; acc:  86.24; ppl:   1.74; 2720 src tok/s; 2835 tgt tok/s;     61 s elapsed
Epoch 16,   250/  454; acc:  85.25; ppl:   1.84; 2763 src tok/s; 2851 tgt tok/s;     77 s elapsed
Epoch 16,   300/  454; acc:  85.95; ppl:   1.77; 2837 src tok/s; 2946 tgt tok/s;     91 s elapsed
Epoch 16,   350/  454; acc:  85.26; ppl:   1.84; 2831 src tok/s; 2928 tgt tok/s;    106 s elapsed
Epoch 16,   400/  454; acc:  86.08; ppl:   1.77; 2804 src tok/s; 2932 tgt tok/s;    121 s elapsed
Epoch 16,   450/  454; acc:  84.87; ppl:   1.86; 2824 src tok/s; 2929 tgt tok/s;    135 s elapsed
Train perplexity: 1.81545
Train accuracy: 85.4617
Validation perplexity: 6.63008
Validation accuracy: 69.746
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.05; ppl:   1.85; 2827 src tok/s; 2909 tgt tok/s;     15 s elapsed
Epoch 17,   100/  454; acc:  85.71; ppl:   1.79; 2748 src tok/s; 2856 tgt tok/s;     30 s elapsed
Epoch 17,   150/  454; acc:  84.70; ppl:   1.89; 2841 src tok/s; 2935 tgt tok/s;     46 s elapsed
Epoch 17,   200/  454; acc:  86.44; ppl:   1.73; 2781 src tok/s; 2899 tgt tok/s;     60 s elapsed
Epoch 17,   250/  454; acc:  85.52; ppl:   1.82; 2836 src tok/s; 2958 tgt tok/s;     75 s elapsed
Epoch 17,   300/  454; acc:  85.88; ppl:   1.80; 2800 src tok/s; 2915 tgt tok/s;     90 s elapsed
Epoch 17,   350/  454; acc:  85.64; ppl:   1.79; 2717 src tok/s; 2832 tgt tok/s;    105 s elapsed
Epoch 17,   400/  454; acc:  85.23; ppl:   1.83; 2850 src tok/s; 2944 tgt tok/s;    120 s elapsed
Epoch 17,   450/  454; acc:  85.22; ppl:   1.84; 2716 src tok/s; 2818 tgt tok/s;    135 s elapsed
Train perplexity: 1.8161
Train accuracy: 85.4604
Validation perplexity: 6.63369
Validation accuracy: 69.7744
Decaying learning rate to 0.000976562
