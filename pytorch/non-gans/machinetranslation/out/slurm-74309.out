<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.5, kappa_enc=0.4, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/seeds/encoder0.4decoder0.5dropout0.3wdropTrueseed4', seed=4, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.4)
('Using Kappa L2 loss on decoder', 0.5)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   7.92; ppl: 53870.90; 2838 src tok/s; 2931 tgt tok/s;     16 s elapsed
Epoch  1,   100/  454; acc:  14.70; ppl: 1876.32; 3274 src tok/s; 3419 tgt tok/s;     28 s elapsed
Epoch  1,   150/  454; acc:  17.46; ppl: 683.85; 3357 src tok/s; 3478 tgt tok/s;     40 s elapsed
Epoch  1,   200/  454; acc:  21.05; ppl: 283.92; 3261 src tok/s; 3393 tgt tok/s;     53 s elapsed
Epoch  1,   250/  454; acc:  24.11; ppl: 183.90; 3243 src tok/s; 3348 tgt tok/s;     66 s elapsed
Epoch  1,   300/  454; acc:  28.35; ppl: 115.98; 3268 src tok/s; 3428 tgt tok/s;     79 s elapsed
Epoch  1,   350/  454; acc:  30.04; ppl:  97.42; 3283 src tok/s; 3405 tgt tok/s;     91 s elapsed
Epoch  1,   400/  454; acc:  30.33; ppl:  85.57; 3241 src tok/s; 3348 tgt tok/s;    104 s elapsed
Epoch  1,   450/  454; acc:  33.10; ppl:  70.81; 3304 src tok/s; 3433 tgt tok/s;    117 s elapsed
Train perplexity: 400.739
Train accuracy: 23.007
Validation perplexity: 61.3968
Validation accuracy: 34.7311

Epoch  2,    50/  454; acc:  35.70; ppl:  52.42; 3257 src tok/s; 3392 tgt tok/s;     13 s elapsed
Epoch  2,   100/  454; acc:  36.89; ppl:  49.26; 3276 src tok/s; 3392 tgt tok/s;     26 s elapsed
Epoch  2,   150/  454; acc:  40.15; ppl:  40.24; 3281 src tok/s; 3384 tgt tok/s;     39 s elapsed
Epoch  2,   200/  454; acc:  43.02; ppl:  33.39; 3323 src tok/s; 3453 tgt tok/s;     51 s elapsed
Epoch  2,   250/  454; acc:  43.31; ppl:  31.71; 3320 src tok/s; 3428 tgt tok/s;     65 s elapsed
Epoch  2,   300/  454; acc:  48.57; ppl:  23.55; 3211 src tok/s; 3360 tgt tok/s;     77 s elapsed
Epoch  2,   350/  454; acc:  48.02; ppl:  23.85; 3220 src tok/s; 3342 tgt tok/s;     90 s elapsed
Epoch  2,   400/  454; acc:  50.23; ppl:  20.22; 3347 src tok/s; 3477 tgt tok/s;    102 s elapsed
Epoch  2,   450/  454; acc:  51.10; ppl:  18.96; 3245 src tok/s; 3362 tgt tok/s;    115 s elapsed
Train perplexity: 30.5721
Train accuracy: 44.1382
Validation perplexity: 16.0328
Validation accuracy: 53.9804

Epoch  3,    50/  454; acc:  52.05; ppl:  16.65; 3250 src tok/s; 3357 tgt tok/s;     14 s elapsed
Epoch  3,   100/  454; acc:  55.20; ppl:  13.96; 3253 src tok/s; 3394 tgt tok/s;     26 s elapsed
Epoch  3,   150/  454; acc:  55.73; ppl:  13.52; 3217 src tok/s; 3358 tgt tok/s;     39 s elapsed
Epoch  3,   200/  454; acc:  55.87; ppl:  13.30; 3247 src tok/s; 3361 tgt tok/s;     52 s elapsed
Epoch  3,   250/  454; acc:  57.63; ppl:  12.38; 3312 src tok/s; 3429 tgt tok/s;     64 s elapsed
Epoch  3,   300/  454; acc:  57.46; ppl:  11.72; 3370 src tok/s; 3492 tgt tok/s;     77 s elapsed
Epoch  3,   350/  454; acc:  57.85; ppl:  11.61; 3287 src tok/s; 3416 tgt tok/s;     89 s elapsed
Epoch  3,   400/  454; acc:  58.36; ppl:  11.23; 3245 src tok/s; 3363 tgt tok/s;    103 s elapsed
Epoch  3,   450/  454; acc:  58.07; ppl:  11.36; 3284 src tok/s; 3404 tgt tok/s;    115 s elapsed
Train perplexity: 12.739
Train accuracy: 56.4946
Validation perplexity: 10.6565
Validation accuracy: 59.3941

Epoch  4,    50/  454; acc:  62.48; ppl:   8.14; 3266 src tok/s; 3414 tgt tok/s;     12 s elapsed
Epoch  4,   100/  454; acc:  60.03; ppl:   9.41; 3334 src tok/s; 3426 tgt tok/s;     25 s elapsed
Epoch  4,   150/  454; acc:  61.95; ppl:   8.33; 3295 src tok/s; 3407 tgt tok/s;     38 s elapsed
Epoch  4,   200/  454; acc:  62.36; ppl:   8.20; 3197 src tok/s; 3325 tgt tok/s;     51 s elapsed
Epoch  4,   250/  454; acc:  61.12; ppl:   8.86; 3200 src tok/s; 3320 tgt tok/s;     65 s elapsed
Epoch  4,   300/  454; acc:  63.52; ppl:   7.55; 3308 src tok/s; 3448 tgt tok/s;     77 s elapsed
Epoch  4,   350/  454; acc:  62.80; ppl:   7.91; 3233 src tok/s; 3364 tgt tok/s;     89 s elapsed
Epoch  4,   400/  454; acc:  61.10; ppl:   8.75; 3270 src tok/s; 3384 tgt tok/s;    103 s elapsed
Epoch  4,   450/  454; acc:  62.66; ppl:   7.92; 3221 src tok/s; 3347 tgt tok/s;    116 s elapsed
Train perplexity: 8.32561
Train accuracy: 61.9944
Validation perplexity: 8.3999
Validation accuracy: 62.7572

Epoch  5,    50/  454; acc:  64.84; ppl:   6.63; 3304 src tok/s; 3406 tgt tok/s;     14 s elapsed
Epoch  5,   100/  454; acc:  66.46; ppl:   5.76; 3220 src tok/s; 3379 tgt tok/s;     26 s elapsed
Epoch  5,   150/  454; acc:  65.24; ppl:   6.36; 3295 src tok/s; 3414 tgt tok/s;     39 s elapsed
Epoch  5,   200/  454; acc:  65.34; ppl:   6.32; 3257 src tok/s; 3368 tgt tok/s;     51 s elapsed
Epoch  5,   250/  454; acc:  64.34; ppl:   6.70; 3319 src tok/s; 3422 tgt tok/s;     65 s elapsed
Epoch  5,   300/  454; acc:  66.84; ppl:   5.80; 3230 src tok/s; 3386 tgt tok/s;     77 s elapsed
Epoch  5,   350/  454; acc:  66.75; ppl:   5.79; 3289 src tok/s; 3424 tgt tok/s;     89 s elapsed
Epoch  5,   400/  454; acc:  65.31; ppl:   6.40; 3258 src tok/s; 3363 tgt tok/s;    103 s elapsed
Epoch  5,   450/  454; acc:  65.27; ppl:   6.28; 3211 src tok/s; 3328 tgt tok/s;    116 s elapsed
Train perplexity: 6.22617
Train accuracy: 65.5852
Validation perplexity: 7.41433
Validation accuracy: 65.276

Epoch  6,    50/  454; acc:  68.30; ppl:   4.96; 3301 src tok/s; 3418 tgt tok/s;     13 s elapsed
Epoch  6,   100/  454; acc:  69.48; ppl:   4.59; 3252 src tok/s; 3388 tgt tok/s;     26 s elapsed
Epoch  6,   150/  454; acc:  68.28; ppl:   5.04; 3275 src tok/s; 3396 tgt tok/s;     39 s elapsed
Epoch  6,   200/  454; acc:  67.70; ppl:   5.07; 3285 src tok/s; 3415 tgt tok/s;     51 s elapsed
Epoch  6,   250/  454; acc:  67.68; ppl:   5.05; 3227 src tok/s; 3352 tgt tok/s;     64 s elapsed
Epoch  6,   300/  454; acc:  68.29; ppl:   5.02; 3276 src tok/s; 3409 tgt tok/s;     77 s elapsed
Epoch  6,   350/  454; acc:  66.84; ppl:   5.37; 3252 src tok/s; 3354 tgt tok/s;     90 s elapsed
Epoch  6,   400/  454; acc:  68.74; ppl:   4.90; 3316 src tok/s; 3449 tgt tok/s;    103 s elapsed
Epoch  6,   450/  454; acc:  67.92; ppl:   5.13; 3258 src tok/s; 3380 tgt tok/s;    115 s elapsed
Train perplexity: 5.00937
Train accuracy: 68.1463
Validation perplexity: 6.83685
Validation accuracy: 66.3474

Epoch  7,    50/  454; acc:  72.17; ppl:   3.79; 3284 src tok/s; 3409 tgt tok/s;     13 s elapsed
Epoch  7,   100/  454; acc:  70.41; ppl:   4.17; 3234 src tok/s; 3374 tgt tok/s;     26 s elapsed
Epoch  7,   150/  454; acc:  71.16; ppl:   4.03; 3262 src tok/s; 3395 tgt tok/s;     38 s elapsed
Epoch  7,   200/  454; acc:  69.41; ppl:   4.46; 3273 src tok/s; 3367 tgt tok/s;     51 s elapsed
Epoch  7,   250/  454; acc:  69.67; ppl:   4.32; 3320 src tok/s; 3435 tgt tok/s;     65 s elapsed
Epoch  7,   300/  454; acc:  70.32; ppl:   4.23; 3238 src tok/s; 3376 tgt tok/s;     77 s elapsed
Epoch  7,   350/  454; acc:  70.75; ppl:   4.03; 3258 src tok/s; 3396 tgt tok/s;     90 s elapsed
Epoch  7,   400/  454; acc:  69.36; ppl:   4.47; 3331 src tok/s; 3440 tgt tok/s;    103 s elapsed
Epoch  7,   450/  454; acc:  70.48; ppl:   4.19; 3238 src tok/s; 3374 tgt tok/s;    115 s elapsed
Train perplexity: 4.20711
Train accuracy: 70.3164
Validation perplexity: 6.87983
Validation accuracy: 66.1771
Decaying learning rate to 0.5

Epoch  8,    50/  454; acc:  74.44; ppl:   3.23; 3178 src tok/s; 3318 tgt tok/s;     13 s elapsed
Epoch  8,   100/  454; acc:  75.93; ppl:   3.04; 3379 src tok/s; 3488 tgt tok/s;     26 s elapsed
Epoch  8,   150/  454; acc:  74.88; ppl:   3.21; 3274 src tok/s; 3399 tgt tok/s;     39 s elapsed
Epoch  8,   200/  454; acc:  76.38; ppl:   2.91; 3243 src tok/s; 3368 tgt tok/s;     51 s elapsed
Epoch  8,   250/  454; acc:  75.21; ppl:   3.09; 3261 src tok/s; 3393 tgt tok/s;     64 s elapsed
Epoch  8,   300/  454; acc:  75.85; ppl:   2.99; 3283 src tok/s; 3405 tgt tok/s;     77 s elapsed
Epoch  8,   350/  454; acc:  75.60; ppl:   3.06; 3234 src tok/s; 3361 tgt tok/s;     90 s elapsed
Epoch  8,   400/  454; acc:  75.41; ppl:   3.03; 3254 src tok/s; 3382 tgt tok/s;    103 s elapsed
Epoch  8,   450/  454; acc:  75.35; ppl:   3.09; 3245 src tok/s; 3355 tgt tok/s;    115 s elapsed
Train perplexity: 3.0737
Train accuracy: 75.4346
Validation perplexity: 6.16881
Validation accuracy: 68.6037
Decaying learning rate to 0.25

Epoch  9,    50/  454; acc:  78.82; ppl:   2.54; 3262 src tok/s; 3377 tgt tok/s;     13 s elapsed
Epoch  9,   100/  454; acc:  79.25; ppl:   2.49; 3271 src tok/s; 3394 tgt tok/s;     26 s elapsed
Epoch  9,   150/  454; acc:  79.23; ppl:   2.52; 3314 src tok/s; 3428 tgt tok/s;     39 s elapsed
Epoch  9,   200/  454; acc:  80.10; ppl:   2.37; 3315 src tok/s; 3463 tgt tok/s;     51 s elapsed
Epoch  9,   250/  454; acc:  78.47; ppl:   2.56; 3213 src tok/s; 3338 tgt tok/s;     64 s elapsed
Epoch  9,   300/  454; acc:  79.34; ppl:   2.45; 3290 src tok/s; 3402 tgt tok/s;     77 s elapsed
Epoch  9,   350/  454; acc:  79.77; ppl:   2.42; 3208 src tok/s; 3344 tgt tok/s;     89 s elapsed
Epoch  9,   400/  454; acc:  78.58; ppl:   2.60; 3304 src tok/s; 3430 tgt tok/s;    103 s elapsed
Epoch  9,   450/  454; acc:  78.37; ppl:   2.58; 3226 src tok/s; 3336 tgt tok/s;    115 s elapsed
Train perplexity: 2.50188
Train accuracy: 79.1066
Validation perplexity: 6.19344
Validation accuracy: 68.9442
Decaying learning rate to 0.125

Epoch 10,    50/  454; acc:  80.81; ppl:   2.32; 3220 src tok/s; 3331 tgt tok/s;     13 s elapsed
Epoch 10,   100/  454; acc:  81.92; ppl:   2.18; 3232 src tok/s; 3377 tgt tok/s;     26 s elapsed
Epoch 10,   150/  454; acc:  82.16; ppl:   2.14; 3233 src tok/s; 3370 tgt tok/s;     39 s elapsed
Epoch 10,   200/  454; acc:  80.51; ppl:   2.31; 3201 src tok/s; 3323 tgt tok/s;     52 s elapsed
Epoch 10,   250/  454; acc:  81.60; ppl:   2.22; 3316 src tok/s; 3441 tgt tok/s;     65 s elapsed
Epoch 10,   300/  454; acc:  80.81; ppl:   2.30; 3288 src tok/s; 3400 tgt tok/s;     78 s elapsed
Epoch 10,   350/  454; acc:  81.45; ppl:   2.21; 3228 src tok/s; 3373 tgt tok/s;     90 s elapsed
Epoch 10,   400/  454; acc:  81.06; ppl:   2.29; 3335 src tok/s; 3439 tgt tok/s;    103 s elapsed
Epoch 10,   450/  454; acc:  81.01; ppl:   2.23; 3280 src tok/s; 3385 tgt tok/s;    116 s elapsed
Train perplexity: 2.24334
Train accuracy: 81.2729
Validation perplexity: 6.35405
Validation accuracy: 69.2777
Decaying learning rate to 0.0625

Epoch 11,    50/  454; acc:  82.28; ppl:   2.14; 3324 src tok/s; 3441 tgt tok/s;     13 s elapsed
Epoch 11,   100/  454; acc:  82.80; ppl:   2.10; 3296 src tok/s; 3424 tgt tok/s;     25 s elapsed
Epoch 11,   150/  454; acc:  82.35; ppl:   2.14; 3261 src tok/s; 3396 tgt tok/s;     38 s elapsed
Epoch 11,   200/  454; acc:  82.91; ppl:   2.07; 3267 src tok/s; 3384 tgt tok/s;     51 s elapsed
Epoch 11,   250/  454; acc:  82.59; ppl:   2.12; 3297 src tok/s; 3416 tgt tok/s;     64 s elapsed
Epoch 11,   300/  454; acc:  82.33; ppl:   2.12; 3247 src tok/s; 3380 tgt tok/s;     77 s elapsed
Epoch 11,   350/  454; acc:  81.72; ppl:   2.21; 3199 src tok/s; 3315 tgt tok/s;     90 s elapsed
Epoch 11,   400/  454; acc:  82.57; ppl:   2.07; 3232 src tok/s; 3355 tgt tok/s;    103 s elapsed
Epoch 11,   450/  454; acc:  81.94; ppl:   2.17; 3265 src tok/s; 3383 tgt tok/s;    116 s elapsed
Train perplexity: 2.1232
Train accuracy: 82.4049
Validation perplexity: 6.44163
Validation accuracy: 69.4054
Decaying learning rate to 0.03125

Epoch 12,    50/  454; acc:  83.43; ppl:   2.02; 3245 src tok/s; 3368 tgt tok/s;     13 s elapsed
Epoch 12,   100/  454; acc:  82.65; ppl:   2.12; 3319 src tok/s; 3440 tgt tok/s;     26 s elapsed
Epoch 12,   150/  454; acc:  82.83; ppl:   2.09; 3269 src tok/s; 3391 tgt tok/s;     38 s elapsed
Epoch 12,   200/  454; acc:  83.14; ppl:   2.03; 3257 src tok/s; 3368 tgt tok/s;     51 s elapsed
Epoch 12,   250/  454; acc:  82.65; ppl:   2.10; 3309 src tok/s; 3418 tgt tok/s;     64 s elapsed
Epoch 12,   300/  454; acc:  83.16; ppl:   2.03; 3228 src tok/s; 3375 tgt tok/s;     77 s elapsed
Epoch 12,   350/  454; acc:  83.02; ppl:   2.07; 3277 src tok/s; 3394 tgt tok/s;     90 s elapsed
Epoch 12,   400/  454; acc:  82.96; ppl:   2.06; 3197 src tok/s; 3343 tgt tok/s;    103 s elapsed
Epoch 12,   450/  454; acc:  82.92; ppl:   2.07; 3185 src tok/s; 3303 tgt tok/s;    116 s elapsed
Train perplexity: 2.06518
Train accuracy: 82.9628
Validation perplexity: 6.50232
Validation accuracy: 69.377
Decaying learning rate to 0.015625

Epoch 13,    50/  454; acc:  83.74; ppl:   2.00; 3300 src tok/s; 3424 tgt tok/s;     13 s elapsed
Epoch 13,   100/  454; acc:  83.19; ppl:   2.05; 3265 src tok/s; 3400 tgt tok/s;     26 s elapsed
Epoch 13,   150/  454; acc:  83.69; ppl:   1.99; 3324 src tok/s; 3435 tgt tok/s;     38 s elapsed
Epoch 13,   200/  454; acc:  83.19; ppl:   2.05; 3229 src tok/s; 3369 tgt tok/s;     51 s elapsed
Epoch 13,   250/  454; acc:  84.03; ppl:   1.94; 3296 src tok/s; 3443 tgt tok/s;     63 s elapsed
Epoch 13,   300/  454; acc:  82.18; ppl:   2.15; 3292 src tok/s; 3387 tgt tok/s;     77 s elapsed
Epoch 13,   350/  454; acc:  83.01; ppl:   2.07; 3273 src tok/s; 3370 tgt tok/s;     90 s elapsed
Epoch 13,   400/  454; acc:  83.57; ppl:   2.00; 3217 src tok/s; 3367 tgt tok/s;    102 s elapsed
Epoch 13,   450/  454; acc:  82.83; ppl:   2.08; 3232 src tok/s; 3347 tgt tok/s;    116 s elapsed
Train perplexity: 2.03562
Train accuracy: 83.2787
Validation perplexity: 6.52964
Validation accuracy: 69.3558
Decaying learning rate to 0.0078125

Epoch 14,    50/  454; acc:  83.14; ppl:   2.06; 3197 src tok/s; 3324 tgt tok/s;     13 s elapsed
Epoch 14,   100/  454; acc:  83.75; ppl:   1.97; 3321 src tok/s; 3462 tgt tok/s;     26 s elapsed
Epoch 14,   150/  454; acc:  83.64; ppl:   2.01; 3273 src tok/s; 3410 tgt tok/s;     38 s elapsed
Epoch 14,   200/  454; acc:  83.19; ppl:   2.04; 3365 src tok/s; 3450 tgt tok/s;     51 s elapsed
Epoch 14,   250/  454; acc:  85.00; ppl:   1.86; 3237 src tok/s; 3391 tgt tok/s;     63 s elapsed
Epoch 14,   300/  454; acc:  82.08; ppl:   2.16; 3291 src tok/s; 3395 tgt tok/s;     77 s elapsed
Epoch 14,   350/  454; acc:  84.15; ppl:   1.94; 3183 src tok/s; 3335 tgt tok/s;     89 s elapsed
Epoch 14,   400/  454; acc:  82.82; ppl:   2.12; 3359 src tok/s; 3439 tgt tok/s;    102 s elapsed
Epoch 14,   450/  454; acc:  83.51; ppl:   2.02; 3211 src tok/s; 3351 tgt tok/s;    115 s elapsed
Train perplexity: 2.02041
Train accuracy: 83.4475
Validation perplexity: 6.54885
Validation accuracy: 69.2919
Decaying learning rate to 0.00390625

Epoch 15,    50/  454; acc:  84.39; ppl:   1.91; 3275 src tok/s; 3413 tgt tok/s;     12 s elapsed
Epoch 15,   100/  454; acc:  82.39; ppl:   2.14; 3289 src tok/s; 3380 tgt tok/s;     26 s elapsed
Epoch 15,   150/  454; acc:  82.45; ppl:   2.14; 3305 src tok/s; 3421 tgt tok/s;     39 s elapsed
Epoch 15,   200/  454; acc:  84.75; ppl:   1.90; 3237 src tok/s; 3387 tgt tok/s;     51 s elapsed
Epoch 15,   250/  454; acc:  84.11; ppl:   1.95; 3279 src tok/s; 3405 tgt tok/s;     64 s elapsed
Epoch 15,   300/  454; acc:  82.98; ppl:   2.06; 3233 src tok/s; 3362 tgt tok/s;     77 s elapsed
Epoch 15,   350/  454; acc:  83.01; ppl:   2.08; 3286 src tok/s; 3381 tgt tok/s;     91 s elapsed
Epoch 15,   400/  454; acc:  84.72; ppl:   1.89; 3275 src tok/s; 3432 tgt tok/s;    103 s elapsed
Epoch 15,   450/  454; acc:  83.40; ppl:   2.01; 3195 src tok/s; 3319 tgt tok/s;    115 s elapsed
Train perplexity: 2.01393
Train accuracy: 83.5121
Validation perplexity: 6.55995
Validation accuracy: 69.2919
Decaying learning rate to 0.00195312

Epoch 16,    50/  454; acc:  83.50; ppl:   2.01; 3295 src tok/s; 3404 tgt tok/s;     13 s elapsed
Epoch 16,   100/  454; acc:  83.19; ppl:   2.05; 3184 src tok/s; 3322 tgt tok/s;     26 s elapsed
Epoch 16,   150/  454; acc:  83.73; ppl:   2.00; 3282 src tok/s; 3399 tgt tok/s;     39 s elapsed
Epoch 16,   200/  454; acc:  83.53; ppl:   2.00; 3299 src tok/s; 3423 tgt tok/s;     52 s elapsed
Epoch 16,   250/  454; acc:  82.89; ppl:   2.08; 3347 src tok/s; 3466 tgt tok/s;     65 s elapsed
Epoch 16,   300/  454; acc:  84.30; ppl:   1.94; 3251 src tok/s; 3385 tgt tok/s;     77 s elapsed
Epoch 16,   350/  454; acc:  83.34; ppl:   2.04; 3199 src tok/s; 3322 tgt tok/s;     90 s elapsed
Epoch 16,   400/  454; acc:  83.70; ppl:   1.97; 3287 src tok/s; 3406 tgt tok/s;    103 s elapsed
Epoch 16,   450/  454; acc:  83.71; ppl:   2.00; 3219 src tok/s; 3347 tgt tok/s;    115 s elapsed
Train perplexity: 2.00975
Train accuracy: 83.5332
Validation perplexity: 6.5623
Validation accuracy: 69.2848
Decaying learning rate to 0.000976562

Epoch 17,    50/  454; acc:  83.29; ppl:   2.04; 3287 src tok/s; 3410 tgt tok/s;     13 s elapsed
Epoch 17,   100/  454; acc:  83.97; ppl:   1.97; 3224 src tok/s; 3348 tgt tok/s;     26 s elapsed
Epoch 17,   150/  454; acc:  82.65; ppl:   2.09; 3234 src tok/s; 3345 tgt tok/s;     39 s elapsed
Epoch 17,   200/  454; acc:  83.92; ppl:   1.94; 3234 src tok/s; 3370 tgt tok/s;     52 s elapsed
Epoch 17,   250/  454; acc:  82.76; ppl:   2.08; 3293 src tok/s; 3408 tgt tok/s;     65 s elapsed
Epoch 17,   300/  454; acc:  84.17; ppl:   1.93; 3268 src tok/s; 3400 tgt tok/s;     77 s elapsed
Epoch 17,   350/  454; acc:  83.52; ppl:   2.00; 3311 src tok/s; 3441 tgt tok/s;     90 s elapsed
Epoch 17,   400/  454; acc:  83.45; ppl:   2.01; 3277 src tok/s; 3405 tgt tok/s;    103 s elapsed
Epoch 17,   450/  454; acc:  84.30; ppl:   1.97; 3244 src tok/s; 3365 tgt tok/s;    115 s elapsed
Train perplexity: 2.00698
Train accuracy: 83.5088
Validation perplexity: 6.56387
Validation accuracy: 69.2848
Decaying learning rate to 0.000488281
