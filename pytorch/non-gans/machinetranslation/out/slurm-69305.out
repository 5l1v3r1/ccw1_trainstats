<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.3, kappa_enc=0.25, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.25decoder0.30dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.25)
('Using Kappa L2 loss on decoder', 0.3)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:  10.33; ppl: 10283.47; 4447 src tok/s; 4616 tgt tok/s;      9 s elapsed
Epoch  1,   100/  454; acc:  15.30; ppl: 1313.44; 5965 src tok/s; 6226 tgt tok/s;     16 s elapsed
Epoch  1,   150/  454; acc:  18.23; ppl: 524.81; 6037 src tok/s; 6244 tgt tok/s;     24 s elapsed
Epoch  1,   200/  454; acc:  22.26; ppl: 239.98; 5966 src tok/s; 6209 tgt tok/s;     30 s elapsed
Epoch  1,   250/  454; acc:  25.49; ppl: 163.85; 6019 src tok/s; 6253 tgt tok/s;     37 s elapsed
Epoch  1,   300/  454; acc:  27.49; ppl: 119.91; 6214 src tok/s; 6412 tgt tok/s;     44 s elapsed
Epoch  1,   350/  454; acc:  29.62; ppl:  93.89; 6009 src tok/s; 6246 tgt tok/s;     51 s elapsed
Epoch  1,   400/  454; acc:  31.88; ppl:  77.84; 5972 src tok/s; 6215 tgt tok/s;     58 s elapsed
Epoch  1,   450/  454; acc:  34.16; ppl:  64.99; 5873 src tok/s; 6089 tgt tok/s;     65 s elapsed
Train perplexity: 290.238
Train accuracy: 23.8968
Validation perplexity: 62.7736
Validation accuracy: 31.2686

Epoch  2,    50/  454; acc:  36.70; ppl:  50.96; 5973 src tok/s; 6225 tgt tok/s;      7 s elapsed
Epoch  2,   100/  454; acc:  37.10; ppl:  48.85; 6016 src tok/s; 6237 tgt tok/s;     14 s elapsed
Epoch  2,   150/  454; acc:  41.98; ppl:  34.68; 5965 src tok/s; 6254 tgt tok/s;     21 s elapsed
Epoch  2,   200/  454; acc:  43.19; ppl:  32.60; 5975 src tok/s; 6159 tgt tok/s;     28 s elapsed
Epoch  2,   250/  454; acc:  46.46; ppl:  25.88; 6081 src tok/s; 6334 tgt tok/s;     35 s elapsed
Epoch  2,   300/  454; acc:  46.18; ppl:  26.26; 5890 src tok/s; 6115 tgt tok/s;     42 s elapsed
Epoch  2,   350/  454; acc:  50.04; ppl:  19.97; 6126 src tok/s; 6338 tgt tok/s;     49 s elapsed
Epoch  2,   400/  454; acc:  50.60; ppl:  20.11; 6041 src tok/s; 6238 tgt tok/s;     56 s elapsed
Epoch  2,   450/  454; acc:  51.62; ppl:  18.18; 5946 src tok/s; 6156 tgt tok/s;     63 s elapsed
Train perplexity: 28.7531
Train accuracy: 44.9373
Validation perplexity: 15.6238
Validation accuracy: 53.8527

Epoch  3,    50/  454; acc:  53.39; ppl:  15.53; 5960 src tok/s; 6148 tgt tok/s;      7 s elapsed
Epoch  3,   100/  454; acc:  55.71; ppl:  13.37; 5980 src tok/s; 6235 tgt tok/s;     14 s elapsed
Epoch  3,   150/  454; acc:  55.16; ppl:  13.65; 5833 src tok/s; 6063 tgt tok/s;     21 s elapsed
Epoch  3,   200/  454; acc:  57.04; ppl:  12.20; 5908 src tok/s; 6130 tgt tok/s;     28 s elapsed
Epoch  3,   250/  454; acc:  57.84; ppl:  11.43; 5958 src tok/s; 6216 tgt tok/s;     35 s elapsed
Epoch  3,   300/  454; acc:  56.14; ppl:  12.96; 6156 src tok/s; 6367 tgt tok/s;     42 s elapsed
Epoch  3,   350/  454; acc:  58.73; ppl:  10.99; 5895 src tok/s; 6111 tgt tok/s;     49 s elapsed
Epoch  3,   400/  454; acc:  58.53; ppl:  11.07; 5965 src tok/s; 6210 tgt tok/s;     56 s elapsed
Epoch  3,   450/  454; acc:  58.39; ppl:  11.03; 6026 src tok/s; 6230 tgt tok/s;     63 s elapsed
Train perplexity: 12.3678
Train accuracy: 56.8
Validation perplexity: 9.86224
Validation accuracy: 60.4442

Epoch  4,    50/  454; acc:  60.47; ppl:   9.21; 5987 src tok/s; 6162 tgt tok/s;      7 s elapsed
Epoch  4,   100/  454; acc:  62.47; ppl:   8.23; 5876 src tok/s; 6153 tgt tok/s;     14 s elapsed
Epoch  4,   150/  454; acc:  63.85; ppl:   7.39; 5787 src tok/s; 6071 tgt tok/s;     21 s elapsed
Epoch  4,   200/  454; acc:  60.26; ppl:   9.06; 6113 src tok/s; 6276 tgt tok/s;     28 s elapsed
Epoch  4,   250/  454; acc:  61.90; ppl:   8.37; 5888 src tok/s; 6085 tgt tok/s;     36 s elapsed
Epoch  4,   300/  454; acc:  63.52; ppl:   7.60; 6011 src tok/s; 6256 tgt tok/s;     42 s elapsed
Epoch  4,   350/  454; acc:  62.84; ppl:   7.84; 6000 src tok/s; 6275 tgt tok/s;     49 s elapsed
Epoch  4,   400/  454; acc:  62.08; ppl:   8.13; 6034 src tok/s; 6255 tgt tok/s;     56 s elapsed
Epoch  4,   450/  454; acc:  63.88; ppl:   7.20; 6045 src tok/s; 6281 tgt tok/s;     63 s elapsed
Train perplexity: 8.14634
Train accuracy: 62.24
Validation perplexity: 8.41274
Validation accuracy: 62.6153

Epoch  5,    50/  454; acc:  64.49; ppl:   6.61; 5980 src tok/s; 6194 tgt tok/s;      7 s elapsed
Epoch  5,   100/  454; acc:  67.25; ppl:   5.50; 5868 src tok/s; 6128 tgt tok/s;     14 s elapsed
Epoch  5,   150/  454; acc:  65.43; ppl:   6.37; 5355 src tok/s; 5566 tgt tok/s;     22 s elapsed
Epoch  5,   200/  454; acc:  65.35; ppl:   6.13; 5652 src tok/s; 5847 tgt tok/s;     29 s elapsed
Epoch  5,   250/  454; acc:  66.43; ppl:   5.95; 5887 src tok/s; 6143 tgt tok/s;     36 s elapsed
Epoch  5,   300/  454; acc:  65.49; ppl:   6.25; 6033 src tok/s; 6220 tgt tok/s;     44 s elapsed
Epoch  5,   350/  454; acc:  65.62; ppl:   6.14; 6016 src tok/s; 6242 tgt tok/s;     50 s elapsed
Epoch  5,   400/  454; acc:  65.84; ppl:   6.23; 6014 src tok/s; 6231 tgt tok/s;     57 s elapsed
Epoch  5,   450/  454; acc:  65.89; ppl:   5.99; 5965 src tok/s; 6190 tgt tok/s;     64 s elapsed
Train perplexity: 6.12273
Train accuracy: 65.7568
Validation perplexity: 7.3877
Validation accuracy: 64.9354

Epoch  6,    50/  454; acc:  69.43; ppl:   4.68; 6042 src tok/s; 6279 tgt tok/s;      7 s elapsed
Epoch  6,   100/  454; acc:  68.26; ppl:   4.96; 5888 src tok/s; 6123 tgt tok/s;     14 s elapsed
Epoch  6,   150/  454; acc:  69.15; ppl:   4.70; 5904 src tok/s; 6155 tgt tok/s;     21 s elapsed
Epoch  6,   200/  454; acc:  67.79; ppl:   5.12; 6034 src tok/s; 6247 tgt tok/s;     28 s elapsed
Epoch  6,   250/  454; acc:  69.37; ppl:   4.73; 5988 src tok/s; 6243 tgt tok/s;     35 s elapsed
Epoch  6,   300/  454; acc:  67.97; ppl:   5.06; 6066 src tok/s; 6269 tgt tok/s;     42 s elapsed
Epoch  6,   350/  454; acc:  67.22; ppl:   5.23; 6048 src tok/s; 6224 tgt tok/s;     49 s elapsed
Epoch  6,   400/  454; acc:  68.52; ppl:   4.91; 5913 src tok/s; 6156 tgt tok/s;     56 s elapsed
Epoch  6,   450/  454; acc:  67.39; ppl:   5.23; 5980 src tok/s; 6216 tgt tok/s;     63 s elapsed
Train perplexity: 4.95755
Train accuracy: 68.3313
Validation perplexity: 6.84927
Validation accuracy: 65.9997

Epoch  7,    50/  454; acc:  72.30; ppl:   3.75; 5838 src tok/s; 6087 tgt tok/s;      7 s elapsed
Epoch  7,   100/  454; acc:  70.20; ppl:   4.18; 6049 src tok/s; 6250 tgt tok/s;     14 s elapsed
Epoch  7,   150/  454; acc:  70.70; ppl:   4.09; 5853 src tok/s; 6084 tgt tok/s;     21 s elapsed
Epoch  7,   200/  454; acc:  70.66; ppl:   4.18; 6014 src tok/s; 6245 tgt tok/s;     28 s elapsed
Epoch  7,   250/  454; acc:  70.40; ppl:   4.14; 6075 src tok/s; 6310 tgt tok/s;     35 s elapsed
Epoch  7,   300/  454; acc:  70.51; ppl:   4.21; 5896 src tok/s; 6132 tgt tok/s;     42 s elapsed
Epoch  7,   350/  454; acc:  70.28; ppl:   4.18; 6064 src tok/s; 6274 tgt tok/s;     49 s elapsed
Epoch  7,   400/  454; acc:  69.50; ppl:   4.35; 5949 src tok/s; 6165 tgt tok/s;     56 s elapsed
Epoch  7,   450/  454; acc:  69.42; ppl:   4.43; 5825 src tok/s; 6035 tgt tok/s;     63 s elapsed
Train perplexity: 4.15946
Train accuracy: 70.4634
Validation perplexity: 6.51629
Validation accuracy: 67.064

Epoch  8,    50/  454; acc:  73.58; ppl:   3.35; 5722 src tok/s; 5979 tgt tok/s;      7 s elapsed
Epoch  8,   100/  454; acc:  72.74; ppl:   3.48; 6031 src tok/s; 6237 tgt tok/s;     14 s elapsed
Epoch  8,   150/  454; acc:  73.06; ppl:   3.43; 5940 src tok/s; 6190 tgt tok/s;     21 s elapsed
Epoch  8,   200/  454; acc:  71.96; ppl:   3.75; 6090 src tok/s; 6268 tgt tok/s;     28 s elapsed
Epoch  8,   250/  454; acc:  71.77; ppl:   3.71; 6042 src tok/s; 6255 tgt tok/s;     35 s elapsed
Epoch  8,   300/  454; acc:  72.28; ppl:   3.66; 5929 src tok/s; 6216 tgt tok/s;     42 s elapsed
Epoch  8,   350/  454; acc:  71.13; ppl:   3.83; 6061 src tok/s; 6239 tgt tok/s;     49 s elapsed
Epoch  8,   400/  454; acc:  72.51; ppl:   3.54; 5989 src tok/s; 6231 tgt tok/s;     56 s elapsed
Epoch  8,   450/  454; acc:  72.05; ppl:   3.62; 5949 src tok/s; 6180 tgt tok/s;     63 s elapsed
Train perplexity: 3.6036
Train accuracy: 72.2985
Validation perplexity: 6.54223
Validation accuracy: 67.2343
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.97; ppl:   2.73; 5918 src tok/s; 6106 tgt tok/s;      7 s elapsed
Epoch  9,   100/  454; acc:  77.65; ppl:   2.67; 5879 src tok/s; 6121 tgt tok/s;     14 s elapsed
Epoch  9,   150/  454; acc:  76.51; ppl:   2.81; 5925 src tok/s; 6152 tgt tok/s;     21 s elapsed
Epoch  9,   200/  454; acc:  77.87; ppl:   2.59; 5853 src tok/s; 6113 tgt tok/s;     28 s elapsed
Epoch  9,   250/  454; acc:  77.22; ppl:   2.68; 6010 src tok/s; 6223 tgt tok/s;     36 s elapsed
Epoch  9,   300/  454; acc:  77.56; ppl:   2.65; 5961 src tok/s; 6207 tgt tok/s;     42 s elapsed
Epoch  9,   350/  454; acc:  77.52; ppl:   2.66; 5892 src tok/s; 6123 tgt tok/s;     49 s elapsed
Epoch  9,   400/  454; acc:  76.52; ppl:   2.81; 6101 src tok/s; 6288 tgt tok/s;     57 s elapsed
Epoch  9,   450/  454; acc:  77.17; ppl:   2.66; 5902 src tok/s; 6135 tgt tok/s;     63 s elapsed
Train perplexity: 2.69457
Train accuracy: 77.2262
Validation perplexity: 6.16906
Validation accuracy: 68.703
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.40; ppl:   2.31; 5892 src tok/s; 6093 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  82.32; ppl:   2.13; 5981 src tok/s; 6213 tgt tok/s;     14 s elapsed
Epoch 10,   150/  454; acc:  81.43; ppl:   2.20; 5872 src tok/s; 6102 tgt tok/s;     21 s elapsed
Epoch 10,   200/  454; acc:  81.12; ppl:   2.20; 6193 src tok/s; 6378 tgt tok/s;     28 s elapsed
Epoch 10,   250/  454; acc:  81.14; ppl:   2.22; 5939 src tok/s; 6154 tgt tok/s;     35 s elapsed
Epoch 10,   300/  454; acc:  80.85; ppl:   2.22; 5951 src tok/s; 6210 tgt tok/s;     42 s elapsed
Epoch 10,   350/  454; acc:  80.66; ppl:   2.24; 6001 src tok/s; 6207 tgt tok/s;     49 s elapsed
Epoch 10,   400/  454; acc:  80.68; ppl:   2.25; 5942 src tok/s; 6198 tgt tok/s;     56 s elapsed
Epoch 10,   450/  454; acc:  81.13; ppl:   2.23; 5872 src tok/s; 6114 tgt tok/s;     63 s elapsed
Train perplexity: 2.22103
Train accuracy: 81.0761
Validation perplexity: 6.21903
Validation accuracy: 69.2493
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.72; ppl:   1.96; 5775 src tok/s; 6031 tgt tok/s;      7 s elapsed
Epoch 11,   100/  454; acc:  83.05; ppl:   2.04; 5984 src tok/s; 6214 tgt tok/s;     14 s elapsed
Epoch 11,   150/  454; acc:  84.19; ppl:   1.91; 5892 src tok/s; 6178 tgt tok/s;     21 s elapsed
Epoch 11,   200/  454; acc:  82.53; ppl:   2.09; 5989 src tok/s; 6184 tgt tok/s;     28 s elapsed
Epoch 11,   250/  454; acc:  83.41; ppl:   1.99; 5999 src tok/s; 6221 tgt tok/s;     35 s elapsed
Epoch 11,   300/  454; acc:  83.44; ppl:   1.99; 5906 src tok/s; 6112 tgt tok/s;     42 s elapsed
Epoch 11,   350/  454; acc:  81.59; ppl:   2.18; 6266 src tok/s; 6433 tgt tok/s;     50 s elapsed
Epoch 11,   400/  454; acc:  84.61; ppl:   1.86; 5767 src tok/s; 6029 tgt tok/s;     56 s elapsed
Epoch 11,   450/  454; acc:  83.63; ppl:   1.95; 5583 src tok/s; 5796 tgt tok/s;     64 s elapsed
Train perplexity: 2.00643
Train accuracy: 83.2452
Validation perplexity: 6.40064
Validation accuracy: 69.3841
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.71; ppl:   1.88; 6219 src tok/s; 6447 tgt tok/s;      7 s elapsed
Epoch 12,   100/  454; acc:  84.26; ppl:   1.94; 6056 src tok/s; 6311 tgt tok/s;     14 s elapsed
Epoch 12,   150/  454; acc:  84.44; ppl:   1.89; 6265 src tok/s; 6480 tgt tok/s;     20 s elapsed
Epoch 12,   200/  454; acc:  84.28; ppl:   1.94; 6412 src tok/s; 6637 tgt tok/s;     27 s elapsed
Epoch 12,   250/  454; acc:  84.42; ppl:   1.90; 5705 src tok/s; 5925 tgt tok/s;     34 s elapsed
Epoch 12,   300/  454; acc:  84.04; ppl:   1.91; 6104 src tok/s; 6336 tgt tok/s;     41 s elapsed
Epoch 12,   350/  454; acc:  85.41; ppl:   1.82; 6109 src tok/s; 6388 tgt tok/s;     48 s elapsed
Epoch 12,   400/  454; acc:  83.40; ppl:   2.00; 6247 src tok/s; 6454 tgt tok/s;     55 s elapsed
Epoch 12,   450/  454; acc:  84.10; ppl:   1.93; 6171 src tok/s; 6383 tgt tok/s;     62 s elapsed
Train perplexity: 1.90912
Train accuracy: 84.357
Validation perplexity: 6.46633
Validation accuracy: 69.3628
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  85.35; ppl:   1.82; 6132 src tok/s; 6351 tgt tok/s;      7 s elapsed
Epoch 13,   100/  454; acc:  84.60; ppl:   1.89; 6083 src tok/s; 6304 tgt tok/s;     14 s elapsed
Epoch 13,   150/  454; acc:  84.07; ppl:   1.94; 6099 src tok/s; 6323 tgt tok/s;     21 s elapsed
Epoch 13,   200/  454; acc:  86.19; ppl:   1.76; 6106 src tok/s; 6373 tgt tok/s;     27 s elapsed
Epoch 13,   250/  454; acc:  85.46; ppl:   1.80; 6027 src tok/s; 6315 tgt tok/s;     34 s elapsed
Epoch 13,   300/  454; acc:  84.23; ppl:   1.93; 6221 src tok/s; 6402 tgt tok/s;     41 s elapsed
Epoch 13,   350/  454; acc:  85.45; ppl:   1.80; 6147 src tok/s; 6383 tgt tok/s;     48 s elapsed
Epoch 13,   400/  454; acc:  83.96; ppl:   1.95; 6296 src tok/s; 6515 tgt tok/s;     55 s elapsed
Epoch 13,   450/  454; acc:  84.85; ppl:   1.84; 6041 src tok/s; 6290 tgt tok/s;     61 s elapsed
Train perplexity: 1.86087
Train accuracy: 84.8991
Validation perplexity: 6.52763
Validation accuracy: 69.4338
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.82; ppl:   1.77; 6153 src tok/s; 6407 tgt tok/s;      7 s elapsed
Epoch 14,   100/  454; acc:  84.91; ppl:   1.87; 6170 src tok/s; 6417 tgt tok/s;     14 s elapsed
Epoch 14,   150/  454; acc:  84.91; ppl:   1.86; 6004 src tok/s; 6266 tgt tok/s;     20 s elapsed
Epoch 14,   200/  454; acc:  85.78; ppl:   1.80; 6231 src tok/s; 6463 tgt tok/s;     27 s elapsed
Epoch 14,   250/  454; acc:  84.81; ppl:   1.85; 6098 src tok/s; 6295 tgt tok/s;     34 s elapsed
Epoch 14,   300/  454; acc:  84.94; ppl:   1.86; 6242 src tok/s; 6471 tgt tok/s;     41 s elapsed
Epoch 14,   350/  454; acc:  84.56; ppl:   1.88; 6108 src tok/s; 6329 tgt tok/s;     48 s elapsed
Epoch 14,   400/  454; acc:  85.68; ppl:   1.80; 6240 src tok/s; 6484 tgt tok/s;     54 s elapsed
Epoch 14,   450/  454; acc:  84.85; ppl:   1.85; 6194 src tok/s; 6408 tgt tok/s;     61 s elapsed
Train perplexity: 1.83601
Train accuracy: 85.1424
Validation perplexity: 6.55855
Validation accuracy: 69.3558
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.88; ppl:   1.79; 6047 src tok/s; 6271 tgt tok/s;      7 s elapsed
Epoch 15,   100/  454; acc:  84.73; ppl:   1.88; 6189 src tok/s; 6399 tgt tok/s;     14 s elapsed
Epoch 15,   150/  454; acc:  85.46; ppl:   1.80; 6072 src tok/s; 6287 tgt tok/s;     21 s elapsed
Epoch 15,   200/  454; acc:  85.22; ppl:   1.84; 6200 src tok/s; 6444 tgt tok/s;     27 s elapsed
Epoch 15,   250/  454; acc:  85.89; ppl:   1.76; 6149 src tok/s; 6431 tgt tok/s;     34 s elapsed
Epoch 15,   300/  454; acc:  84.76; ppl:   1.86; 6251 src tok/s; 6464 tgt tok/s;     41 s elapsed
Epoch 15,   350/  454; acc:  84.88; ppl:   1.86; 6174 src tok/s; 6383 tgt tok/s;     48 s elapsed
Epoch 15,   400/  454; acc:  85.65; ppl:   1.80; 6233 src tok/s; 6505 tgt tok/s;     54 s elapsed
Epoch 15,   450/  454; acc:  85.29; ppl:   1.83; 6168 src tok/s; 6375 tgt tok/s;     61 s elapsed
Train perplexity: 1.82441
Train accuracy: 85.3116
Validation perplexity: 6.56854
Validation accuracy: 69.4338
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  84.99; ppl:   1.87; 6105 src tok/s; 6287 tgt tok/s;      7 s elapsed
Epoch 16,   100/  454; acc:  86.39; ppl:   1.74; 5925 src tok/s; 6216 tgt tok/s;     14 s elapsed
Epoch 16,   150/  454; acc:  85.90; ppl:   1.80; 6072 src tok/s; 6294 tgt tok/s;     21 s elapsed
Epoch 16,   200/  454; acc:  85.25; ppl:   1.81; 5812 src tok/s; 6029 tgt tok/s;     28 s elapsed
Epoch 16,   250/  454; acc:  85.51; ppl:   1.82; 5727 src tok/s; 5948 tgt tok/s;     35 s elapsed
Epoch 16,   300/  454; acc:  85.11; ppl:   1.85; 5798 src tok/s; 6011 tgt tok/s;     43 s elapsed
Epoch 16,   350/  454; acc:  85.39; ppl:   1.84; 5957 src tok/s; 6202 tgt tok/s;     50 s elapsed
Epoch 16,   400/  454; acc:  85.62; ppl:   1.82; 6151 src tok/s; 6375 tgt tok/s;     56 s elapsed
Epoch 16,   450/  454; acc:  85.30; ppl:   1.83; 6107 src tok/s; 6315 tgt tok/s;     63 s elapsed
Train perplexity: 1.82007
Train accuracy: 85.4949
Validation perplexity: 6.58125
Validation accuracy: 69.377
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.48; ppl:   1.83; 5996 src tok/s; 6209 tgt tok/s;      7 s elapsed
Epoch 17,   100/  454; acc:  85.47; ppl:   1.81; 6133 src tok/s; 6402 tgt tok/s;     14 s elapsed
Epoch 17,   150/  454; acc:  85.01; ppl:   1.85; 6143 src tok/s; 6363 tgt tok/s;     21 s elapsed
Epoch 17,   200/  454; acc:  85.95; ppl:   1.76; 6037 src tok/s; 6296 tgt tok/s;     28 s elapsed
Epoch 17,   250/  454; acc:  83.69; ppl:   1.97; 6212 src tok/s; 6392 tgt tok/s;     35 s elapsed
Epoch 17,   300/  454; acc:  87.16; ppl:   1.68; 5936 src tok/s; 6236 tgt tok/s;     41 s elapsed
Epoch 17,   350/  454; acc:  85.62; ppl:   1.79; 6082 src tok/s; 6309 tgt tok/s;     48 s elapsed
Epoch 17,   400/  454; acc:  84.88; ppl:   1.87; 6101 src tok/s; 6313 tgt tok/s;     55 s elapsed
Epoch 17,   450/  454; acc:  85.88; ppl:   1.77; 6073 src tok/s; 6268 tgt tok/s;     62 s elapsed
Train perplexity: 1.81758
Train accuracy: 85.3952
Validation perplexity: 6.58751
Validation accuracy: 69.3416
Decaying learning rate to 0.000976562
