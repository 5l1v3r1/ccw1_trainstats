<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.1, kappa_enc=0.3, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.30decoder0.10dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.3)
('Using Kappa L2 loss on decoder', 0.1)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   9.40; ppl: 30530.85; 3463 src tok/s; 3604 tgt tok/s;     12 s elapsed
Epoch  1,   100/  454; acc:  14.84; ppl: 1554.56; 6009 src tok/s; 6220 tgt tok/s;     19 s elapsed
Epoch  1,   150/  454; acc:  19.26; ppl: 387.61; 5737 src tok/s; 5957 tgt tok/s;     26 s elapsed
Epoch  1,   200/  454; acc:  21.23; ppl: 253.33; 5715 src tok/s; 5927 tgt tok/s;     34 s elapsed
Epoch  1,   250/  454; acc:  24.04; ppl: 173.46; 5358 src tok/s; 5534 tgt tok/s;     42 s elapsed
Epoch  1,   300/  454; acc:  27.86; ppl: 119.30; 5371 src tok/s; 5579 tgt tok/s;     49 s elapsed
Epoch  1,   350/  454; acc:  30.10; ppl:  93.92; 5350 src tok/s; 5584 tgt tok/s;     57 s elapsed
Epoch  1,   400/  454; acc:  31.33; ppl:  80.80; 5314 src tok/s; 5499 tgt tok/s;     65 s elapsed
Epoch  1,   450/  454; acc:  33.98; ppl:  65.09; 5286 src tok/s; 5500 tgt tok/s;     73 s elapsed
Train perplexity: 322.661
Train accuracy: 23.6613
Validation perplexity: 51.2264
Validation accuracy: 37.5408

Epoch  2,    50/  454; acc:  34.83; ppl:  56.08; 5478 src tok/s; 5641 tgt tok/s;      8 s elapsed
Epoch  2,   100/  454; acc:  40.45; ppl:  40.11; 5253 src tok/s; 5486 tgt tok/s;     16 s elapsed
Epoch  2,   150/  454; acc:  42.16; ppl:  35.66; 5276 src tok/s; 5475 tgt tok/s;     24 s elapsed
Epoch  2,   200/  454; acc:  42.37; ppl:  33.40; 5445 src tok/s; 5649 tgt tok/s;     31 s elapsed
Epoch  2,   250/  454; acc:  46.17; ppl:  26.56; 5559 src tok/s; 5745 tgt tok/s;     39 s elapsed
Epoch  2,   300/  454; acc:  47.68; ppl:  23.87; 5339 src tok/s; 5539 tgt tok/s;     47 s elapsed
Epoch  2,   350/  454; acc:  48.29; ppl:  22.54; 5352 src tok/s; 5563 tgt tok/s;     55 s elapsed
Epoch  2,   400/  454; acc:  51.62; ppl:  18.15; 5360 src tok/s; 5603 tgt tok/s;     62 s elapsed
Epoch  2,   450/  454; acc:  51.75; ppl:  17.99; 5331 src tok/s; 5525 tgt tok/s;     70 s elapsed
Train perplexity: 28.5373
Train accuracy: 45.0146
Validation perplexity: 17.0064
Validation accuracy: 51.2062

Epoch  3,    50/  454; acc:  54.65; ppl:  14.06; 5523 src tok/s; 5741 tgt tok/s;      8 s elapsed
Epoch  3,   100/  454; acc:  54.52; ppl:  14.58; 5384 src tok/s; 5600 tgt tok/s;     15 s elapsed
Epoch  3,   150/  454; acc:  55.76; ppl:  13.35; 5470 src tok/s; 5676 tgt tok/s;     23 s elapsed
Epoch  3,   200/  454; acc:  55.85; ppl:  13.33; 5356 src tok/s; 5555 tgt tok/s;     31 s elapsed
Epoch  3,   250/  454; acc:  56.60; ppl:  12.46; 5364 src tok/s; 5568 tgt tok/s;     39 s elapsed
Epoch  3,   300/  454; acc:  57.64; ppl:  11.89; 5374 src tok/s; 5570 tgt tok/s;     47 s elapsed
Epoch  3,   350/  454; acc:  58.38; ppl:  10.93; 5381 src tok/s; 5562 tgt tok/s;     55 s elapsed
Epoch  3,   400/  454; acc:  59.87; ppl:  10.10; 5385 src tok/s; 5595 tgt tok/s;     62 s elapsed
Epoch  3,   450/  454; acc:  58.76; ppl:  10.95; 5357 src tok/s; 5566 tgt tok/s;     70 s elapsed
Train perplexity: 12.3255
Train accuracy: 56.8902
Validation perplexity: 10.4821
Validation accuracy: 60.2242

Epoch  4,    50/  454; acc:  61.71; ppl:   8.48; 5526 src tok/s; 5751 tgt tok/s;      8 s elapsed
Epoch  4,   100/  454; acc:  61.42; ppl:   8.49; 5500 src tok/s; 5687 tgt tok/s;     15 s elapsed
Epoch  4,   150/  454; acc:  61.03; ppl:   8.75; 5363 src tok/s; 5523 tgt tok/s;     23 s elapsed
Epoch  4,   200/  454; acc:  62.94; ppl:   7.97; 5352 src tok/s; 5588 tgt tok/s;     31 s elapsed
Epoch  4,   250/  454; acc:  61.93; ppl:   8.28; 5379 src tok/s; 5599 tgt tok/s;     39 s elapsed
Epoch  4,   300/  454; acc:  62.55; ppl:   8.00; 5487 src tok/s; 5704 tgt tok/s;     46 s elapsed
Epoch  4,   350/  454; acc:  63.07; ppl:   7.77; 5330 src tok/s; 5575 tgt tok/s;     54 s elapsed
Epoch  4,   400/  454; acc:  62.59; ppl:   7.92; 5463 src tok/s; 5655 tgt tok/s;     62 s elapsed
Epoch  4,   450/  454; acc:  63.00; ppl:   7.78; 5434 src tok/s; 5607 tgt tok/s;     69 s elapsed
Train perplexity: 8.15901
Train accuracy: 62.2304
Validation perplexity: 8.24603
Validation accuracy: 62.7501

Epoch  5,    50/  454; acc:  65.69; ppl:   6.16; 5303 src tok/s; 5531 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  65.57; ppl:   6.08; 5586 src tok/s; 5789 tgt tok/s;     15 s elapsed
Epoch  5,   150/  454; acc:  65.44; ppl:   6.32; 5377 src tok/s; 5586 tgt tok/s;     23 s elapsed
Epoch  5,   200/  454; acc:  65.63; ppl:   6.09; 5486 src tok/s; 5688 tgt tok/s;     31 s elapsed
Epoch  5,   250/  454; acc:  65.02; ppl:   6.47; 5431 src tok/s; 5594 tgt tok/s;     39 s elapsed
Epoch  5,   300/  454; acc:  66.18; ppl:   5.97; 5555 src tok/s; 5775 tgt tok/s;     46 s elapsed
Epoch  5,   350/  454; acc:  65.69; ppl:   6.19; 5429 src tok/s; 5611 tgt tok/s;     54 s elapsed
Epoch  5,   400/  454; acc:  65.46; ppl:   6.27; 5464 src tok/s; 5699 tgt tok/s;     62 s elapsed
Epoch  5,   450/  454; acc:  65.81; ppl:   6.13; 5358 src tok/s; 5560 tgt tok/s;     69 s elapsed
Train perplexity: 6.17895
Train accuracy: 65.6301
Validation perplexity: 7.12692
Validation accuracy: 65.5031

Epoch  6,    50/  454; acc:  69.26; ppl:   4.66; 5525 src tok/s; 5774 tgt tok/s;      7 s elapsed
Epoch  6,   100/  454; acc:  68.52; ppl:   4.86; 5493 src tok/s; 5690 tgt tok/s;     15 s elapsed
Epoch  6,   150/  454; acc:  68.97; ppl:   4.77; 5383 src tok/s; 5602 tgt tok/s;     23 s elapsed
Epoch  6,   200/  454; acc:  67.75; ppl:   5.12; 5476 src tok/s; 5649 tgt tok/s;     31 s elapsed
Epoch  6,   250/  454; acc:  68.45; ppl:   4.92; 5487 src tok/s; 5689 tgt tok/s;     38 s elapsed
Epoch  6,   300/  454; acc:  67.68; ppl:   5.15; 5450 src tok/s; 5655 tgt tok/s;     46 s elapsed
Epoch  6,   350/  454; acc:  67.01; ppl:   5.36; 5512 src tok/s; 5694 tgt tok/s;     54 s elapsed
Epoch  6,   400/  454; acc:  68.86; ppl:   4.81; 5414 src tok/s; 5660 tgt tok/s;     61 s elapsed
Epoch  6,   450/  454; acc:  67.39; ppl:   5.21; 5398 src tok/s; 5573 tgt tok/s;     69 s elapsed
Train perplexity: 4.97718
Train accuracy: 68.2153
Validation perplexity: 6.89936
Validation accuracy: 65.7372

Epoch  7,    50/  454; acc:  72.51; ppl:   3.67; 5408 src tok/s; 5663 tgt tok/s;      7 s elapsed
Epoch  7,   100/  454; acc:  69.74; ppl:   4.34; 5586 src tok/s; 5716 tgt tok/s;     15 s elapsed
Epoch  7,   150/  454; acc:  69.85; ppl:   4.32; 5425 src tok/s; 5636 tgt tok/s;     23 s elapsed
Epoch  7,   200/  454; acc:  70.83; ppl:   4.02; 5442 src tok/s; 5662 tgt tok/s;     31 s elapsed
Epoch  7,   250/  454; acc:  70.47; ppl:   4.12; 5504 src tok/s; 5695 tgt tok/s;     38 s elapsed
Epoch  7,   300/  454; acc:  70.56; ppl:   4.16; 5452 src tok/s; 5666 tgt tok/s;     46 s elapsed
Epoch  7,   350/  454; acc:  68.78; ppl:   4.55; 5324 src tok/s; 5547 tgt tok/s;     54 s elapsed
Epoch  7,   400/  454; acc:  70.72; ppl:   4.15; 5357 src tok/s; 5558 tgt tok/s;     62 s elapsed
Epoch  7,   450/  454; acc:  70.09; ppl:   4.27; 5427 src tok/s; 5637 tgt tok/s;     69 s elapsed
Train perplexity: 4.17437
Train accuracy: 70.3854
Validation perplexity: 6.88024
Validation accuracy: 66.7376

Epoch  8,    50/  454; acc:  72.49; ppl:   3.52; 5422 src tok/s; 5618 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  73.95; ppl:   3.27; 5417 src tok/s; 5622 tgt tok/s;     16 s elapsed
Epoch  8,   150/  454; acc:  72.60; ppl:   3.59; 5504 src tok/s; 5723 tgt tok/s;     23 s elapsed
Epoch  8,   200/  454; acc:  72.79; ppl:   3.51; 5491 src tok/s; 5675 tgt tok/s;     31 s elapsed
Epoch  8,   250/  454; acc:  72.64; ppl:   3.58; 5416 src tok/s; 5649 tgt tok/s;     38 s elapsed
Epoch  8,   300/  454; acc:  71.38; ppl:   3.76; 5473 src tok/s; 5677 tgt tok/s;     46 s elapsed
Epoch  8,   350/  454; acc:  72.09; ppl:   3.66; 5427 src tok/s; 5656 tgt tok/s;     54 s elapsed
Epoch  8,   400/  454; acc:  71.15; ppl:   3.85; 5515 src tok/s; 5706 tgt tok/s;     62 s elapsed
Epoch  8,   450/  454; acc:  71.22; ppl:   3.78; 5371 src tok/s; 5565 tgt tok/s;     69 s elapsed
Train perplexity: 3.61173
Train accuracy: 72.2435
Validation perplexity: 6.42736
Validation accuracy: 67.3407
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.10; ppl:   2.91; 5509 src tok/s; 5692 tgt tok/s;      8 s elapsed
Epoch  9,   100/  454; acc:  77.90; ppl:   2.61; 5432 src tok/s; 5691 tgt tok/s;     15 s elapsed
Epoch  9,   150/  454; acc:  77.13; ppl:   2.76; 5543 src tok/s; 5713 tgt tok/s;     23 s elapsed
Epoch  9,   200/  454; acc:  78.29; ppl:   2.58; 5412 src tok/s; 5614 tgt tok/s;     31 s elapsed
Epoch  9,   250/  454; acc:  77.51; ppl:   2.70; 5455 src tok/s; 5668 tgt tok/s;     38 s elapsed
Epoch  9,   300/  454; acc:  77.32; ppl:   2.67; 5441 src tok/s; 5622 tgt tok/s;     46 s elapsed
Epoch  9,   350/  454; acc:  76.41; ppl:   2.82; 5439 src tok/s; 5626 tgt tok/s;     54 s elapsed
Epoch  9,   400/  454; acc:  78.18; ppl:   2.57; 5469 src tok/s; 5703 tgt tok/s;     61 s elapsed
Epoch  9,   450/  454; acc:  76.53; ppl:   2.80; 5321 src tok/s; 5542 tgt tok/s;     69 s elapsed
Train perplexity: 2.71117
Train accuracy: 77.2697
Validation perplexity: 6.19118
Validation accuracy: 68.7881
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.82; ppl:   2.27; 5492 src tok/s; 5716 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  81.34; ppl:   2.19; 5556 src tok/s; 5745 tgt tok/s;     15 s elapsed
Epoch 10,   150/  454; acc:  80.52; ppl:   2.30; 5437 src tok/s; 5665 tgt tok/s;     23 s elapsed
Epoch 10,   200/  454; acc:  81.81; ppl:   2.14; 5486 src tok/s; 5697 tgt tok/s;     30 s elapsed
Epoch 10,   250/  454; acc:  81.90; ppl:   2.13; 5457 src tok/s; 5664 tgt tok/s;     38 s elapsed
Epoch 10,   300/  454; acc:  80.21; ppl:   2.32; 5545 src tok/s; 5722 tgt tok/s;     46 s elapsed
Epoch 10,   350/  454; acc:  81.06; ppl:   2.22; 5485 src tok/s; 5714 tgt tok/s;     53 s elapsed
Epoch 10,   400/  454; acc:  80.72; ppl:   2.27; 5556 src tok/s; 5790 tgt tok/s;     61 s elapsed
Epoch 10,   450/  454; acc:  80.50; ppl:   2.26; 5439 src tok/s; 5603 tgt tok/s;     69 s elapsed
Train perplexity: 2.23118
Train accuracy: 81.0044
Validation perplexity: 6.24667
Validation accuracy: 69.228
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.67; ppl:   1.97; 5604 src tok/s; 5813 tgt tok/s;      7 s elapsed
Epoch 11,   100/  454; acc:  83.08; ppl:   2.06; 5481 src tok/s; 5673 tgt tok/s;     15 s elapsed
Epoch 11,   150/  454; acc:  84.11; ppl:   1.94; 5460 src tok/s; 5704 tgt tok/s;     22 s elapsed
Epoch 11,   200/  454; acc:  82.88; ppl:   2.04; 5462 src tok/s; 5657 tgt tok/s;     30 s elapsed
Epoch 11,   250/  454; acc:  83.22; ppl:   2.01; 5439 src tok/s; 5643 tgt tok/s;     38 s elapsed
Epoch 11,   300/  454; acc:  82.98; ppl:   2.03; 5594 src tok/s; 5810 tgt tok/s;     46 s elapsed
Epoch 11,   350/  454; acc:  82.79; ppl:   2.06; 5404 src tok/s; 5615 tgt tok/s;     53 s elapsed
Epoch 11,   400/  454; acc:  83.08; ppl:   2.01; 5560 src tok/s; 5738 tgt tok/s;     61 s elapsed
Epoch 11,   450/  454; acc:  83.61; ppl:   1.95; 5347 src tok/s; 5569 tgt tok/s;     69 s elapsed
Train perplexity: 2.01547
Train accuracy: 83.2057
Validation perplexity: 6.35388
Validation accuracy: 69.1997
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  83.98; ppl:   1.95; 5497 src tok/s; 5675 tgt tok/s;      8 s elapsed
Epoch 12,   100/  454; acc:  85.16; ppl:   1.82; 5506 src tok/s; 5743 tgt tok/s;     15 s elapsed
Epoch 12,   150/  454; acc:  84.70; ppl:   1.87; 5505 src tok/s; 5735 tgt tok/s;     23 s elapsed
Epoch 12,   200/  454; acc:  83.54; ppl:   1.98; 5474 src tok/s; 5660 tgt tok/s;     31 s elapsed
Epoch 12,   250/  454; acc:  83.73; ppl:   1.99; 5412 src tok/s; 5621 tgt tok/s;     38 s elapsed
Epoch 12,   300/  454; acc:  84.67; ppl:   1.89; 5688 src tok/s; 5918 tgt tok/s;     46 s elapsed
Epoch 12,   350/  454; acc:  84.32; ppl:   1.90; 5434 src tok/s; 5625 tgt tok/s;     53 s elapsed
Epoch 12,   400/  454; acc:  83.93; ppl:   1.93; 5505 src tok/s; 5721 tgt tok/s;     61 s elapsed
Epoch 12,   450/  454; acc:  83.74; ppl:   1.94; 5427 src tok/s; 5607 tgt tok/s;     69 s elapsed
Train perplexity: 1.91664
Train accuracy: 84.2191
Validation perplexity: 6.5068
Validation accuracy: 69.3487
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.02; ppl:   1.95; 5173 src tok/s; 5314 tgt tok/s;      9 s elapsed
Epoch 13,   100/  454; acc:  85.89; ppl:   1.77; 5324 src tok/s; 5604 tgt tok/s;     16 s elapsed
Epoch 13,   150/  454; acc:  84.36; ppl:   1.92; 5419 src tok/s; 5625 tgt tok/s;     24 s elapsed
Epoch 13,   200/  454; acc:  85.44; ppl:   1.79; 5409 src tok/s; 5617 tgt tok/s;     32 s elapsed
Epoch 13,   250/  454; acc:  84.12; ppl:   1.94; 5386 src tok/s; 5588 tgt tok/s;     40 s elapsed
Epoch 13,   300/  454; acc:  85.84; ppl:   1.77; 5413 src tok/s; 5628 tgt tok/s;     47 s elapsed
Epoch 13,   350/  454; acc:  85.69; ppl:   1.79; 5435 src tok/s; 5677 tgt tok/s;     54 s elapsed
Epoch 13,   400/  454; acc:  83.88; ppl:   1.97; 5525 src tok/s; 5683 tgt tok/s;     62 s elapsed
Epoch 13,   450/  454; acc:  84.39; ppl:   1.92; 5314 src tok/s; 5498 tgt tok/s;     70 s elapsed
Train perplexity: 1.86773
Train accuracy: 84.8412
Validation perplexity: 6.52856
Validation accuracy: 69.3132
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  84.42; ppl:   1.92; 5346 src tok/s; 5519 tgt tok/s;      8 s elapsed
Epoch 14,   100/  454; acc:  85.61; ppl:   1.80; 5368 src tok/s; 5621 tgt tok/s;     16 s elapsed
Epoch 14,   150/  454; acc:  85.05; ppl:   1.86; 5539 src tok/s; 5739 tgt tok/s;     23 s elapsed
Epoch 14,   200/  454; acc:  85.44; ppl:   1.82; 5511 src tok/s; 5710 tgt tok/s;     31 s elapsed
Epoch 14,   250/  454; acc:  85.25; ppl:   1.82; 5517 src tok/s; 5720 tgt tok/s;     38 s elapsed
Epoch 14,   300/  454; acc:  84.59; ppl:   1.88; 5550 src tok/s; 5756 tgt tok/s;     46 s elapsed
Epoch 14,   350/  454; acc:  85.15; ppl:   1.86; 5410 src tok/s; 5639 tgt tok/s;     54 s elapsed
Epoch 14,   400/  454; acc:  85.07; ppl:   1.83; 5417 src tok/s; 5625 tgt tok/s;     61 s elapsed
Epoch 14,   450/  454; acc:  85.28; ppl:   1.83; 5326 src tok/s; 5504 tgt tok/s;     69 s elapsed
Train perplexity: 1.84648
Train accuracy: 85.0935
Validation perplexity: 6.56595
Validation accuracy: 69.3203
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  86.50; ppl:   1.72; 5393 src tok/s; 5627 tgt tok/s;      7 s elapsed
Epoch 15,   100/  454; acc:  84.60; ppl:   1.90; 5359 src tok/s; 5524 tgt tok/s;     16 s elapsed
Epoch 15,   150/  454; acc:  85.27; ppl:   1.81; 5601 src tok/s; 5792 tgt tok/s;     23 s elapsed
Epoch 15,   200/  454; acc:  85.06; ppl:   1.87; 5468 src tok/s; 5679 tgt tok/s;     31 s elapsed
Epoch 15,   250/  454; acc:  84.70; ppl:   1.86; 5539 src tok/s; 5717 tgt tok/s;     38 s elapsed
Epoch 15,   300/  454; acc:  85.01; ppl:   1.87; 5293 src tok/s; 5523 tgt tok/s;     46 s elapsed
Epoch 15,   350/  454; acc:  85.46; ppl:   1.80; 5419 src tok/s; 5611 tgt tok/s;     54 s elapsed
Epoch 15,   400/  454; acc:  85.26; ppl:   1.83; 5251 src tok/s; 5465 tgt tok/s;     62 s elapsed
Epoch 15,   450/  454; acc:  85.70; ppl:   1.79; 5348 src tok/s; 5588 tgt tok/s;     70 s elapsed
Train perplexity: 1.83229
Train accuracy: 85.2296
Validation perplexity: 6.58322
Validation accuracy: 69.2919
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  86.00; ppl:   1.76; 5503 src tok/s; 5747 tgt tok/s;      7 s elapsed
Epoch 16,   100/  454; acc:  85.05; ppl:   1.86; 5500 src tok/s; 5676 tgt tok/s;     15 s elapsed
Epoch 16,   150/  454; acc:  84.85; ppl:   1.88; 5489 src tok/s; 5691 tgt tok/s;     23 s elapsed
Epoch 16,   200/  454; acc:  85.77; ppl:   1.79; 5372 src tok/s; 5569 tgt tok/s;     31 s elapsed
Epoch 16,   250/  454; acc:  86.06; ppl:   1.77; 5425 src tok/s; 5660 tgt tok/s;     38 s elapsed
Epoch 16,   300/  454; acc:  84.20; ppl:   1.92; 5541 src tok/s; 5735 tgt tok/s;     46 s elapsed
Epoch 16,   350/  454; acc:  84.73; ppl:   1.89; 5435 src tok/s; 5611 tgt tok/s;     54 s elapsed
Epoch 16,   400/  454; acc:  86.14; ppl:   1.75; 5360 src tok/s; 5572 tgt tok/s;     62 s elapsed
Epoch 16,   450/  454; acc:  85.30; ppl:   1.82; 5391 src tok/s; 5612 tgt tok/s;     69 s elapsed
Train perplexity: 1.82584
Train accuracy: 85.3342
Validation perplexity: 6.59472
Validation accuracy: 69.2351
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.41; ppl:   1.81; 5512 src tok/s; 5722 tgt tok/s;      8 s elapsed
Epoch 17,   100/  454; acc:  85.54; ppl:   1.80; 5406 src tok/s; 5634 tgt tok/s;     15 s elapsed
Epoch 17,   150/  454; acc:  86.38; ppl:   1.74; 5472 src tok/s; 5688 tgt tok/s;     23 s elapsed
Epoch 17,   200/  454; acc:  84.65; ppl:   1.90; 5554 src tok/s; 5728 tgt tok/s;     31 s elapsed
Epoch 17,   250/  454; acc:  86.61; ppl:   1.73; 5362 src tok/s; 5586 tgt tok/s;     38 s elapsed
Epoch 17,   300/  454; acc:  84.31; ppl:   1.91; 5406 src tok/s; 5573 tgt tok/s;     46 s elapsed
Epoch 17,   350/  454; acc:  84.81; ppl:   1.87; 5252 src tok/s; 5424 tgt tok/s;     54 s elapsed
Epoch 17,   400/  454; acc:  85.39; ppl:   1.82; 5346 src tok/s; 5595 tgt tok/s;     62 s elapsed
Epoch 17,   450/  454; acc:  85.31; ppl:   1.81; 5417 src tok/s; 5625 tgt tok/s;     70 s elapsed
Train perplexity: 1.82426
Train accuracy: 85.3341
Validation perplexity: 6.59534
Validation accuracy: 69.2635
Decaying learning rate to 0.000976562
