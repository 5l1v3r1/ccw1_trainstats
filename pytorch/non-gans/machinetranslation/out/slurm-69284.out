<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.3, kappa_enc=0.1, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.1decoder0.30dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.1)
('Using Kappa L2 loss on decoder', 0.3)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   9.80; ppl: 9789.10; 2858 src tok/s; 2975 tgt tok/s;     15 s elapsed
Epoch  1,   100/  454; acc:  15.41; ppl: 1178.56; 2936 src tok/s; 3048 tgt tok/s;     29 s elapsed
Epoch  1,   150/  454; acc:  17.77; ppl: 535.68; 2959 src tok/s; 3052 tgt tok/s;     44 s elapsed
Epoch  1,   200/  454; acc:  22.14; ppl: 238.81; 2981 src tok/s; 3100 tgt tok/s;     57 s elapsed
Epoch  1,   250/  454; acc:  24.46; ppl: 163.34; 2971 src tok/s; 3084 tgt tok/s;     71 s elapsed
Epoch  1,   300/  454; acc:  27.82; ppl: 116.93; 2851 src tok/s; 2955 tgt tok/s;     86 s elapsed
Epoch  1,   350/  454; acc:  30.09; ppl:  87.77; 2976 src tok/s; 3092 tgt tok/s;    100 s elapsed
Epoch  1,   400/  454; acc:  30.91; ppl:  79.91; 2926 src tok/s; 3027 tgt tok/s;    115 s elapsed
Epoch  1,   450/  454; acc:  33.42; ppl:  65.98; 2907 src tok/s; 3022 tgt tok/s;    129 s elapsed
Train perplexity: 284.934
Train accuracy: 23.5988
Validation perplexity: 50.4349
Validation accuracy: 37.6259

Epoch  2,    50/  454; acc:  37.24; ppl:  48.84; 2904 src tok/s; 3035 tgt tok/s;     14 s elapsed
Epoch  2,   100/  454; acc:  38.05; ppl:  47.53; 2979 src tok/s; 3079 tgt tok/s;     28 s elapsed
Epoch  2,   150/  454; acc:  41.28; ppl:  36.93; 2942 src tok/s; 3055 tgt tok/s;     43 s elapsed
Epoch  2,   200/  454; acc:  43.77; ppl:  30.94; 2921 src tok/s; 3024 tgt tok/s;     57 s elapsed
Epoch  2,   250/  454; acc:  44.90; ppl:  27.88; 2947 src tok/s; 3050 tgt tok/s;     71 s elapsed
Epoch  2,   300/  454; acc:  46.48; ppl:  25.97; 2930 src tok/s; 3032 tgt tok/s;     86 s elapsed
Epoch  2,   350/  454; acc:  47.52; ppl:  24.09; 2951 src tok/s; 3028 tgt tok/s;    101 s elapsed
Epoch  2,   400/  454; acc:  51.57; ppl:  17.87; 2890 src tok/s; 3033 tgt tok/s;    114 s elapsed
Epoch  2,   450/  454; acc:  51.45; ppl:  18.54; 2908 src tok/s; 3031 tgt tok/s;    129 s elapsed
Train perplexity: 29.1659
Train accuracy: 44.7064
Validation perplexity: 18.118
Validation accuracy: 50.4541

Epoch  3,    50/  454; acc:  53.29; ppl:  15.51; 2899 src tok/s; 2998 tgt tok/s;     14 s elapsed
Epoch  3,   100/  454; acc:  55.66; ppl:  13.61; 2917 src tok/s; 3026 tgt tok/s;     29 s elapsed
Epoch  3,   150/  454; acc:  54.76; ppl:  14.18; 2904 src tok/s; 3013 tgt tok/s;     43 s elapsed
Epoch  3,   200/  454; acc:  56.58; ppl:  12.50; 2932 src tok/s; 3053 tgt tok/s;     58 s elapsed
Epoch  3,   250/  454; acc:  57.57; ppl:  11.96; 2882 src tok/s; 3030 tgt tok/s;     72 s elapsed
Epoch  3,   300/  454; acc:  56.59; ppl:  12.22; 2994 src tok/s; 3079 tgt tok/s;     86 s elapsed
Epoch  3,   350/  454; acc:  56.43; ppl:  12.46; 2973 src tok/s; 3065 tgt tok/s;    101 s elapsed
Epoch  3,   400/  454; acc:  59.09; ppl:  10.64; 2937 src tok/s; 3065 tgt tok/s;    115 s elapsed
Epoch  3,   450/  454; acc:  59.14; ppl:  10.69; 2886 src tok/s; 2999 tgt tok/s;    129 s elapsed
Train perplexity: 12.5512
Train accuracy: 56.5712
Validation perplexity: 9.80744
Validation accuracy: 61.2317

Epoch  4,    50/  454; acc:  61.14; ppl:   8.89; 2905 src tok/s; 3008 tgt tok/s;     15 s elapsed
Epoch  4,   100/  454; acc:  62.92; ppl:   7.93; 2958 src tok/s; 3080 tgt tok/s;     29 s elapsed
Epoch  4,   150/  454; acc:  62.25; ppl:   8.33; 2931 src tok/s; 3040 tgt tok/s;     42 s elapsed
Epoch  4,   200/  454; acc:  61.25; ppl:   8.64; 2884 src tok/s; 2977 tgt tok/s;     57 s elapsed
Epoch  4,   250/  454; acc:  61.62; ppl:   8.59; 2993 src tok/s; 3095 tgt tok/s;     72 s elapsed
Epoch  4,   300/  454; acc:  62.21; ppl:   8.27; 2970 src tok/s; 3083 tgt tok/s;     86 s elapsed
Epoch  4,   350/  454; acc:  62.75; ppl:   7.92; 2823 src tok/s; 2957 tgt tok/s;    100 s elapsed
Epoch  4,   400/  454; acc:  62.37; ppl:   7.95; 2929 src tok/s; 3040 tgt tok/s;    115 s elapsed
Epoch  4,   450/  454; acc:  62.77; ppl:   7.74; 2935 src tok/s; 3039 tgt tok/s;    129 s elapsed
Train perplexity: 8.23945
Train accuracy: 62.152
Validation perplexity: 8.20054
Validation accuracy: 63.2752

Epoch  5,    50/  454; acc:  65.98; ppl:   6.07; 2895 src tok/s; 3003 tgt tok/s;     15 s elapsed
Epoch  5,   100/  454; acc:  65.64; ppl:   6.14; 2918 src tok/s; 3049 tgt tok/s;     29 s elapsed
Epoch  5,   150/  454; acc:  65.91; ppl:   6.28; 2978 src tok/s; 3084 tgt tok/s;     43 s elapsed
Epoch  5,   200/  454; acc:  65.63; ppl:   6.29; 2912 src tok/s; 3018 tgt tok/s;     57 s elapsed
Epoch  5,   250/  454; acc:  65.28; ppl:   6.27; 2901 src tok/s; 3024 tgt tok/s;     72 s elapsed
Epoch  5,   300/  454; acc:  65.28; ppl:   6.36; 2904 src tok/s; 3019 tgt tok/s;     86 s elapsed
Epoch  5,   350/  454; acc:  65.54; ppl:   6.11; 2982 src tok/s; 3081 tgt tok/s;    100 s elapsed
Epoch  5,   400/  454; acc:  65.41; ppl:   6.21; 2917 src tok/s; 3027 tgt tok/s;    115 s elapsed
Epoch  5,   450/  454; acc:  65.11; ppl:   6.22; 2905 src tok/s; 3003 tgt tok/s;    129 s elapsed
Train perplexity: 6.21223
Train accuracy: 65.5477
Validation perplexity: 7.28882
Validation accuracy: 64.8787

Epoch  6,    50/  454; acc:  68.64; ppl:   4.86; 2837 src tok/s; 2978 tgt tok/s;     14 s elapsed
Epoch  6,   100/  454; acc:  68.27; ppl:   4.93; 2979 src tok/s; 3078 tgt tok/s;     29 s elapsed
Epoch  6,   150/  454; acc:  69.31; ppl:   4.68; 2927 src tok/s; 3028 tgt tok/s;     43 s elapsed
Epoch  6,   200/  454; acc:  67.67; ppl:   5.11; 2938 src tok/s; 3055 tgt tok/s;     57 s elapsed
Epoch  6,   250/  454; acc:  67.57; ppl:   5.17; 2957 src tok/s; 3054 tgt tok/s;     72 s elapsed
Epoch  6,   300/  454; acc:  69.71; ppl:   4.69; 2972 src tok/s; 3090 tgt tok/s;     86 s elapsed
Epoch  6,   350/  454; acc:  67.10; ppl:   5.40; 2940 src tok/s; 3035 tgt tok/s;    101 s elapsed
Epoch  6,   400/  454; acc:  68.05; ppl:   4.94; 2895 src tok/s; 3022 tgt tok/s;    115 s elapsed
Epoch  6,   450/  454; acc:  68.57; ppl:   4.93; 2918 src tok/s; 3022 tgt tok/s;    128 s elapsed
Train perplexity: 4.98108
Train accuracy: 68.2586
Validation perplexity: 6.84209
Validation accuracy: 65.645

Epoch  7,    50/  454; acc:  70.09; ppl:   4.21; 2891 src tok/s; 2991 tgt tok/s;     15 s elapsed
Epoch  7,   100/  454; acc:  71.31; ppl:   3.96; 2894 src tok/s; 3006 tgt tok/s;     29 s elapsed
Epoch  7,   150/  454; acc:  69.96; ppl:   4.28; 2913 src tok/s; 3018 tgt tok/s;     44 s elapsed
Epoch  7,   200/  454; acc:  70.51; ppl:   4.14; 2938 src tok/s; 3062 tgt tok/s;     58 s elapsed
Epoch  7,   250/  454; acc:  71.17; ppl:   3.98; 2897 src tok/s; 3028 tgt tok/s;     72 s elapsed
Epoch  7,   300/  454; acc:  69.65; ppl:   4.39; 2931 src tok/s; 3024 tgt tok/s;     87 s elapsed
Epoch  7,   350/  454; acc:  70.07; ppl:   4.30; 2987 src tok/s; 3092 tgt tok/s;    101 s elapsed
Epoch  7,   400/  454; acc:  70.82; ppl:   4.13; 2988 src tok/s; 3112 tgt tok/s;    115 s elapsed
Epoch  7,   450/  454; acc:  69.94; ppl:   4.33; 2935 src tok/s; 3044 tgt tok/s;    129 s elapsed
Train perplexity: 4.19332
Train accuracy: 70.3658
Validation perplexity: 6.58973
Validation accuracy: 66.5319

Epoch  8,    50/  454; acc:  73.51; ppl:   3.35; 2947 src tok/s; 3064 tgt tok/s;     14 s elapsed
Epoch  8,   100/  454; acc:  73.53; ppl:   3.39; 2957 src tok/s; 3064 tgt tok/s;     28 s elapsed
Epoch  8,   150/  454; acc:  73.21; ppl:   3.40; 2948 src tok/s; 3084 tgt tok/s;     42 s elapsed
Epoch  8,   200/  454; acc:  71.10; ppl:   3.78; 3015 src tok/s; 3114 tgt tok/s;     57 s elapsed
Epoch  8,   250/  454; acc:  72.56; ppl:   3.54; 2921 src tok/s; 3041 tgt tok/s;     70 s elapsed
Epoch  8,   300/  454; acc:  71.17; ppl:   3.84; 2926 src tok/s; 3028 tgt tok/s;     85 s elapsed
Epoch  8,   350/  454; acc:  70.94; ppl:   3.89; 2939 src tok/s; 3035 tgt tok/s;    100 s elapsed
Epoch  8,   400/  454; acc:  72.23; ppl:   3.60; 2974 src tok/s; 3096 tgt tok/s;    114 s elapsed
Epoch  8,   450/  454; acc:  71.71; ppl:   3.77; 2938 src tok/s; 3051 tgt tok/s;    128 s elapsed
Train perplexity: 3.61784
Train accuracy: 72.187
Validation perplexity: 6.51366
Validation accuracy: 67.0498
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.24; ppl:   2.76; 2937 src tok/s; 3056 tgt tok/s;     14 s elapsed
Epoch  9,   100/  454; acc:  77.30; ppl:   2.72; 2941 src tok/s; 3042 tgt tok/s;     29 s elapsed
Epoch  9,   150/  454; acc:  78.25; ppl:   2.57; 2959 src tok/s; 3078 tgt tok/s;     42 s elapsed
Epoch  9,   200/  454; acc:  76.47; ppl:   2.79; 2892 src tok/s; 2992 tgt tok/s;     57 s elapsed
Epoch  9,   250/  454; acc:  77.44; ppl:   2.67; 2956 src tok/s; 3074 tgt tok/s;     71 s elapsed
Epoch  9,   300/  454; acc:  76.83; ppl:   2.79; 2979 src tok/s; 3081 tgt tok/s;     85 s elapsed
Epoch  9,   350/  454; acc:  76.99; ppl:   2.74; 2965 src tok/s; 3078 tgt tok/s;    100 s elapsed
Epoch  9,   400/  454; acc:  77.76; ppl:   2.63; 2928 src tok/s; 3043 tgt tok/s;    114 s elapsed
Epoch  9,   450/  454; acc:  76.85; ppl:   2.74; 2942 src tok/s; 3057 tgt tok/s;    128 s elapsed
Train perplexity: 2.70698
Train accuracy: 77.2469
Validation perplexity: 6.09011
Validation accuracy: 68.7598
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.00; ppl:   2.25; 3021 src tok/s; 3119 tgt tok/s;     14 s elapsed
Epoch 10,   100/  454; acc:  81.17; ppl:   2.24; 2962 src tok/s; 3066 tgt tok/s;     28 s elapsed
Epoch 10,   150/  454; acc:  81.39; ppl:   2.20; 2899 src tok/s; 3005 tgt tok/s;     42 s elapsed
Epoch 10,   200/  454; acc:  81.61; ppl:   2.17; 3030 src tok/s; 3137 tgt tok/s;     56 s elapsed
Epoch 10,   250/  454; acc:  80.73; ppl:   2.25; 3021 src tok/s; 3123 tgt tok/s;     71 s elapsed
Epoch 10,   300/  454; acc:  81.20; ppl:   2.21; 2892 src tok/s; 3010 tgt tok/s;     85 s elapsed
Epoch 10,   350/  454; acc:  80.36; ppl:   2.31; 2888 src tok/s; 2996 tgt tok/s;    100 s elapsed
Epoch 10,   400/  454; acc:  81.60; ppl:   2.16; 2902 src tok/s; 3023 tgt tok/s;    114 s elapsed
Epoch 10,   450/  454; acc:  80.25; ppl:   2.28; 2897 src tok/s; 3027 tgt tok/s;    128 s elapsed
Train perplexity: 2.22856
Train accuracy: 81.0452
Validation perplexity: 6.16777
Validation accuracy: 69.3487
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.87; ppl:   1.95; 2906 src tok/s; 3032 tgt tok/s;     14 s elapsed
Epoch 11,   100/  454; acc:  83.08; ppl:   2.04; 2942 src tok/s; 3041 tgt tok/s;     29 s elapsed
Epoch 11,   150/  454; acc:  84.51; ppl:   1.90; 3017 src tok/s; 3139 tgt tok/s;     42 s elapsed
Epoch 11,   200/  454; acc:  82.27; ppl:   2.09; 2951 src tok/s; 3058 tgt tok/s;     57 s elapsed
Epoch 11,   250/  454; acc:  83.30; ppl:   2.02; 2977 src tok/s; 3095 tgt tok/s;     71 s elapsed
Epoch 11,   300/  454; acc:  83.49; ppl:   1.99; 2970 src tok/s; 3085 tgt tok/s;     85 s elapsed
Epoch 11,   350/  454; acc:  81.63; ppl:   2.16; 2963 src tok/s; 3056 tgt tok/s;    100 s elapsed
Epoch 11,   400/  454; acc:  84.32; ppl:   1.88; 2977 src tok/s; 3103 tgt tok/s;    113 s elapsed
Epoch 11,   450/  454; acc:  82.60; ppl:   2.08; 2929 src tok/s; 3035 tgt tok/s;    127 s elapsed
Train perplexity: 2.01298
Train accuracy: 83.1987
Validation perplexity: 6.34106
Validation accuracy: 69.4267
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.62; ppl:   1.90; 2894 src tok/s; 2997 tgt tok/s;     14 s elapsed
Epoch 12,   100/  454; acc:  84.72; ppl:   1.89; 2960 src tok/s; 3078 tgt tok/s;     29 s elapsed
Epoch 12,   150/  454; acc:  84.75; ppl:   1.88; 2925 src tok/s; 3053 tgt tok/s;     42 s elapsed
Epoch 12,   200/  454; acc:  83.95; ppl:   1.94; 2978 src tok/s; 3087 tgt tok/s;     57 s elapsed
Epoch 12,   250/  454; acc:  83.25; ppl:   2.01; 2953 src tok/s; 3052 tgt tok/s;     72 s elapsed
Epoch 12,   300/  454; acc:  84.71; ppl:   1.86; 2976 src tok/s; 3106 tgt tok/s;     85 s elapsed
Epoch 12,   350/  454; acc:  84.46; ppl:   1.88; 2965 src tok/s; 3090 tgt tok/s;     99 s elapsed
Epoch 12,   400/  454; acc:  83.82; ppl:   1.95; 3002 src tok/s; 3090 tgt tok/s;    114 s elapsed
Epoch 12,   450/  454; acc:  84.63; ppl:   1.89; 2965 src tok/s; 3080 tgt tok/s;    127 s elapsed
Train perplexity: 1.91099
Train accuracy: 84.3092
Validation perplexity: 6.43891
Validation accuracy: 69.3699
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.98; ppl:   1.86; 2931 src tok/s; 3050 tgt tok/s;     14 s elapsed
Epoch 13,   100/  454; acc:  84.89; ppl:   1.86; 2977 src tok/s; 3077 tgt tok/s;     28 s elapsed
Epoch 13,   150/  454; acc:  85.42; ppl:   1.82; 2976 src tok/s; 3088 tgt tok/s;     42 s elapsed
Epoch 13,   200/  454; acc:  84.56; ppl:   1.90; 2943 src tok/s; 3042 tgt tok/s;     57 s elapsed
Epoch 13,   250/  454; acc:  84.41; ppl:   1.93; 2954 src tok/s; 3057 tgt tok/s;     71 s elapsed
Epoch 13,   300/  454; acc:  85.43; ppl:   1.81; 2930 src tok/s; 3055 tgt tok/s;     85 s elapsed
Epoch 13,   350/  454; acc:  85.67; ppl:   1.80; 2901 src tok/s; 3038 tgt tok/s;     99 s elapsed
Epoch 13,   400/  454; acc:  83.98; ppl:   1.94; 2967 src tok/s; 3069 tgt tok/s;    114 s elapsed
Epoch 13,   450/  454; acc:  84.55; ppl:   1.88; 2911 src tok/s; 3022 tgt tok/s;    128 s elapsed
Train perplexity: 1.86695
Train accuracy: 84.8522
Validation perplexity: 6.49529
Validation accuracy: 69.4693
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.09; ppl:   1.85; 3003 src tok/s; 3106 tgt tok/s;     14 s elapsed
Epoch 14,   100/  454; acc:  84.99; ppl:   1.83; 3003 src tok/s; 3110 tgt tok/s;     28 s elapsed
Epoch 14,   150/  454; acc:  84.93; ppl:   1.88; 2937 src tok/s; 3061 tgt tok/s;     42 s elapsed
Epoch 14,   200/  454; acc:  85.11; ppl:   1.83; 2960 src tok/s; 3059 tgt tok/s;     56 s elapsed
Epoch 14,   250/  454; acc:  85.32; ppl:   1.84; 2962 src tok/s; 3076 tgt tok/s;     71 s elapsed
Epoch 14,   300/  454; acc:  85.27; ppl:   1.83; 2940 src tok/s; 3061 tgt tok/s;     85 s elapsed
Epoch 14,   350/  454; acc:  84.92; ppl:   1.86; 2966 src tok/s; 3075 tgt tok/s;     99 s elapsed
Epoch 14,   400/  454; acc:  85.03; ppl:   1.86; 2924 src tok/s; 3044 tgt tok/s;    113 s elapsed
Epoch 14,   450/  454; acc:  85.19; ppl:   1.83; 2878 src tok/s; 2980 tgt tok/s;    128 s elapsed
Train perplexity: 1.8418
Train accuracy: 85.1121
Validation perplexity: 6.53413
Validation accuracy: 69.526
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.91; ppl:   1.79; 2964 src tok/s; 3080 tgt tok/s;     14 s elapsed
Epoch 15,   100/  454; acc:  84.78; ppl:   1.89; 2976 src tok/s; 3097 tgt tok/s;     28 s elapsed
Epoch 15,   150/  454; acc:  84.60; ppl:   1.91; 2968 src tok/s; 3071 tgt tok/s;     43 s elapsed
Epoch 15,   200/  454; acc:  86.05; ppl:   1.75; 2902 src tok/s; 3021 tgt tok/s;     57 s elapsed
Epoch 15,   250/  454; acc:  84.60; ppl:   1.90; 2923 src tok/s; 3028 tgt tok/s;     71 s elapsed
Epoch 15,   300/  454; acc:  86.23; ppl:   1.75; 2948 src tok/s; 3072 tgt tok/s;     85 s elapsed
Epoch 15,   350/  454; acc:  85.82; ppl:   1.78; 2943 src tok/s; 3053 tgt tok/s;     99 s elapsed
Epoch 15,   400/  454; acc:  84.66; ppl:   1.88; 2952 src tok/s; 3049 tgt tok/s;    114 s elapsed
Epoch 15,   450/  454; acc:  85.24; ppl:   1.83; 2948 src tok/s; 3060 tgt tok/s;    128 s elapsed
Train perplexity: 1.83001
Train accuracy: 85.3104
Validation perplexity: 6.54241
Validation accuracy: 69.4551
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.37; ppl:   1.81; 2922 src tok/s; 3024 tgt tok/s;     14 s elapsed
Epoch 16,   100/  454; acc:  85.35; ppl:   1.82; 2881 src tok/s; 3002 tgt tok/s;     29 s elapsed
Epoch 16,   150/  454; acc:  85.42; ppl:   1.84; 2904 src tok/s; 3021 tgt tok/s;     43 s elapsed
Epoch 16,   200/  454; acc:  85.36; ppl:   1.82; 2983 src tok/s; 3088 tgt tok/s;     57 s elapsed
Epoch 16,   250/  454; acc:  86.33; ppl:   1.73; 2997 src tok/s; 3120 tgt tok/s;     71 s elapsed
Epoch 16,   300/  454; acc:  84.44; ppl:   1.92; 2965 src tok/s; 3068 tgt tok/s;     85 s elapsed
Epoch 16,   350/  454; acc:  84.42; ppl:   1.90; 2945 src tok/s; 3047 tgt tok/s;    100 s elapsed
Epoch 16,   400/  454; acc:  86.49; ppl:   1.74; 2976 src tok/s; 3095 tgt tok/s;    114 s elapsed
Epoch 16,   450/  454; acc:  85.96; ppl:   1.80; 2944 src tok/s; 3061 tgt tok/s;    128 s elapsed
Train perplexity: 1.82398
Train accuracy: 85.4075
Validation perplexity: 6.54784
Validation accuracy: 69.3841
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.39; ppl:   1.82; 2953 src tok/s; 3057 tgt tok/s;     14 s elapsed
Epoch 17,   100/  454; acc:  85.45; ppl:   1.80; 2943 src tok/s; 3049 tgt tok/s;     28 s elapsed
Epoch 17,   150/  454; acc:  85.78; ppl:   1.80; 2945 src tok/s; 3056 tgt tok/s;     43 s elapsed
Epoch 17,   200/  454; acc:  85.34; ppl:   1.83; 2942 src tok/s; 3084 tgt tok/s;     57 s elapsed
Epoch 17,   250/  454; acc:  86.03; ppl:   1.77; 2935 src tok/s; 3070 tgt tok/s;     71 s elapsed
Epoch 17,   300/  454; acc:  84.27; ppl:   1.92; 2987 src tok/s; 3064 tgt tok/s;     85 s elapsed
Epoch 17,   350/  454; acc:  85.26; ppl:   1.84; 2975 src tok/s; 3090 tgt tok/s;     99 s elapsed
Epoch 17,   400/  454; acc:  85.91; ppl:   1.79; 2976 src tok/s; 3088 tgt tok/s;    114 s elapsed
Epoch 17,   450/  454; acc:  85.28; ppl:   1.84; 2911 src tok/s; 3021 tgt tok/s;    128 s elapsed
Train perplexity: 1.82181
Train accuracy: 85.4265
Validation perplexity: 6.55325
Validation accuracy: 69.3628
Decaying learning rate to 0.000976562
