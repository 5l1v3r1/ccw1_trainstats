<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.15, kappa_enc=0.3, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.30decoder0.15dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.3)
('Using Kappa L2 loss on decoder', 0.15)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   9.65; ppl: 18423.74; 2777 src tok/s; 2902 tgt tok/s;     14 s elapsed
Epoch  1,   100/  454; acc:  14.54; ppl: 1754.92; 3467 src tok/s; 3568 tgt tok/s;     27 s elapsed
Epoch  1,   150/  454; acc:  17.70; ppl: 565.60; 3159 src tok/s; 3259 tgt tok/s;     41 s elapsed
Epoch  1,   200/  454; acc:  21.36; ppl: 268.20; 3069 src tok/s; 3209 tgt tok/s;     54 s elapsed
Epoch  1,   250/  454; acc:  24.13; ppl: 182.08; 3111 src tok/s; 3204 tgt tok/s;     68 s elapsed
Epoch  1,   300/  454; acc:  28.90; ppl: 113.71; 3083 src tok/s; 3224 tgt tok/s;     81 s elapsed
Epoch  1,   350/  454; acc:  29.15; ppl: 102.32; 3085 src tok/s; 3199 tgt tok/s;     95 s elapsed
Epoch  1,   400/  454; acc:  31.47; ppl:  80.01; 3072 src tok/s; 3192 tgt tok/s;    108 s elapsed
Epoch  1,   450/  454; acc:  32.81; ppl:  71.39; 3000 src tok/s; 3125 tgt tok/s;    122 s elapsed
Train perplexity: 332.693
Train accuracy: 23.3563
Validation perplexity: 65.5021
Validation accuracy: 31.7085

Epoch  2,    50/  454; acc:  35.92; ppl:  55.10; 3077 src tok/s; 3193 tgt tok/s;     14 s elapsed
Epoch  2,   100/  454; acc:  37.84; ppl:  48.07; 3070 src tok/s; 3187 tgt tok/s;     27 s elapsed
Epoch  2,   150/  454; acc:  40.15; ppl:  40.65; 3058 src tok/s; 3168 tgt tok/s;     41 s elapsed
Epoch  2,   200/  454; acc:  43.79; ppl:  31.10; 3073 src tok/s; 3207 tgt tok/s;     55 s elapsed
Epoch  2,   250/  454; acc:  45.26; ppl:  27.84; 3104 src tok/s; 3211 tgt tok/s;     68 s elapsed
Epoch  2,   300/  454; acc:  46.97; ppl:  24.36; 3096 src tok/s; 3225 tgt tok/s;     82 s elapsed
Epoch  2,   350/  454; acc:  47.51; ppl:  24.01; 3127 src tok/s; 3199 tgt tok/s;     96 s elapsed
Epoch  2,   400/  454; acc:  51.36; ppl:  18.54; 3040 src tok/s; 3202 tgt tok/s;    109 s elapsed
Epoch  2,   450/  454; acc:  51.53; ppl:  18.63; 3080 src tok/s; 3190 tgt tok/s;    122 s elapsed
Train perplexity: 29.828
Train accuracy: 44.4883
Validation perplexity: 19.744
Validation accuracy: 51.7029

Epoch  3,    50/  454; acc:  54.84; ppl:  14.57; 3077 src tok/s; 3203 tgt tok/s;     13 s elapsed
Epoch  3,   100/  454; acc:  53.99; ppl:  15.26; 3102 src tok/s; 3194 tgt tok/s;     27 s elapsed
Epoch  3,   150/  454; acc:  55.62; ppl:  13.30; 3073 src tok/s; 3216 tgt tok/s;     40 s elapsed
Epoch  3,   200/  454; acc:  55.42; ppl:  13.74; 3102 src tok/s; 3212 tgt tok/s;     54 s elapsed
Epoch  3,   250/  454; acc:  56.42; ppl:  12.70; 3114 src tok/s; 3230 tgt tok/s;     68 s elapsed
Epoch  3,   300/  454; acc:  57.02; ppl:  12.18; 3083 src tok/s; 3203 tgt tok/s;     81 s elapsed
Epoch  3,   350/  454; acc:  57.99; ppl:  11.49; 3139 src tok/s; 3257 tgt tok/s;     95 s elapsed
Epoch  3,   400/  454; acc:  57.75; ppl:  11.44; 2985 src tok/s; 3098 tgt tok/s;    109 s elapsed
Epoch  3,   450/  454; acc:  58.79; ppl:  10.74; 3052 src tok/s; 3165 tgt tok/s;    122 s elapsed
Train perplexity: 12.734
Train accuracy: 56.434
Validation perplexity: 10.5868
Validation accuracy: 59.4083

Epoch  4,    50/  454; acc:  62.74; ppl:   8.00; 3041 src tok/s; 3171 tgt tok/s;     13 s elapsed
Epoch  4,   100/  454; acc:  60.19; ppl:   9.23; 3058 src tok/s; 3153 tgt tok/s;     28 s elapsed
Epoch  4,   150/  454; acc:  62.34; ppl:   8.15; 3089 src tok/s; 3221 tgt tok/s;     41 s elapsed
Epoch  4,   200/  454; acc:  61.33; ppl:   8.69; 3074 src tok/s; 3184 tgt tok/s;     55 s elapsed
Epoch  4,   250/  454; acc:  61.70; ppl:   8.57; 3120 src tok/s; 3235 tgt tok/s;     69 s elapsed
Epoch  4,   300/  454; acc:  62.96; ppl:   7.71; 3066 src tok/s; 3200 tgt tok/s;     82 s elapsed
Epoch  4,   350/  454; acc:  60.79; ppl:   9.02; 3144 src tok/s; 3241 tgt tok/s;     96 s elapsed
Epoch  4,   400/  454; acc:  63.73; ppl:   7.38; 3075 src tok/s; 3226 tgt tok/s;    109 s elapsed
Epoch  4,   450/  454; acc:  62.42; ppl:   8.09; 3064 src tok/s; 3161 tgt tok/s;    122 s elapsed
Train perplexity: 8.31241
Train accuracy: 61.9985
Validation perplexity: 8.58483
Validation accuracy: 62.8211

Epoch  5,    50/  454; acc:  64.97; ppl:   6.41; 3074 src tok/s; 3182 tgt tok/s;     14 s elapsed
Epoch  5,   100/  454; acc:  66.55; ppl:   5.71; 3095 src tok/s; 3238 tgt tok/s;     27 s elapsed
Epoch  5,   150/  454; acc:  64.69; ppl:   6.46; 3084 src tok/s; 3174 tgt tok/s;     41 s elapsed
Epoch  5,   200/  454; acc:  66.62; ppl:   5.92; 3073 src tok/s; 3217 tgt tok/s;     54 s elapsed
Epoch  5,   250/  454; acc:  65.13; ppl:   6.47; 3051 src tok/s; 3173 tgt tok/s;     68 s elapsed
Epoch  5,   300/  454; acc:  65.10; ppl:   6.37; 3137 src tok/s; 3245 tgt tok/s;     81 s elapsed
Epoch  5,   350/  454; acc:  64.53; ppl:   6.64; 3049 src tok/s; 3139 tgt tok/s;     96 s elapsed
Epoch  5,   400/  454; acc:  66.64; ppl:   5.77; 3130 src tok/s; 3256 tgt tok/s;    109 s elapsed
Epoch  5,   450/  454; acc:  65.67; ppl:   6.25; 3032 src tok/s; 3160 tgt tok/s;    122 s elapsed
Train perplexity: 6.23591
Train accuracy: 65.4909
Validation perplexity: 7.48313
Validation accuracy: 64.5807

Epoch  6,    50/  454; acc:  69.26; ppl:   4.71; 3058 src tok/s; 3169 tgt tok/s;     14 s elapsed
Epoch  6,   100/  454; acc:  68.34; ppl:   4.91; 3053 src tok/s; 3180 tgt tok/s;     27 s elapsed
Epoch  6,   150/  454; acc:  67.00; ppl:   5.41; 3078 src tok/s; 3165 tgt tok/s;     42 s elapsed
Epoch  6,   200/  454; acc:  69.51; ppl:   4.62; 3120 src tok/s; 3248 tgt tok/s;     55 s elapsed
Epoch  6,   250/  454; acc:  68.87; ppl:   4.83; 3078 src tok/s; 3209 tgt tok/s;     68 s elapsed
Epoch  6,   300/  454; acc:  67.18; ppl:   5.41; 3145 src tok/s; 3240 tgt tok/s;     81 s elapsed
Epoch  6,   350/  454; acc:  67.90; ppl:   5.11; 3028 src tok/s; 3173 tgt tok/s;     95 s elapsed
Epoch  6,   400/  454; acc:  68.04; ppl:   5.06; 3095 src tok/s; 3217 tgt tok/s;    109 s elapsed
Epoch  6,   450/  454; acc:  67.79; ppl:   5.17; 3013 src tok/s; 3114 tgt tok/s;    123 s elapsed
Train perplexity: 5.01759
Train accuracy: 68.2049
Validation perplexity: 7.20262
Validation accuracy: 65.5101

Epoch  7,    50/  454; acc:  70.35; ppl:   4.19; 3024 src tok/s; 3137 tgt tok/s;     14 s elapsed
Epoch  7,   100/  454; acc:  70.68; ppl:   4.08; 3123 src tok/s; 3239 tgt tok/s;     27 s elapsed
Epoch  7,   150/  454; acc:  70.74; ppl:   4.12; 3070 src tok/s; 3180 tgt tok/s;     41 s elapsed
Epoch  7,   200/  454; acc:  70.69; ppl:   4.16; 3029 src tok/s; 3157 tgt tok/s;     55 s elapsed
Epoch  7,   250/  454; acc:  70.01; ppl:   4.28; 3164 src tok/s; 3267 tgt tok/s;     68 s elapsed
Epoch  7,   300/  454; acc:  70.17; ppl:   4.21; 3030 src tok/s; 3152 tgt tok/s;     82 s elapsed
Epoch  7,   350/  454; acc:  70.98; ppl:   4.05; 3128 src tok/s; 3233 tgt tok/s;     95 s elapsed
Epoch  7,   400/  454; acc:  68.88; ppl:   4.52; 3065 src tok/s; 3184 tgt tok/s;    109 s elapsed
Epoch  7,   450/  454; acc:  70.24; ppl:   4.22; 3115 src tok/s; 3248 tgt tok/s;    122 s elapsed
Train perplexity: 4.20426
Train accuracy: 70.2999
Validation perplexity: 6.73343
Validation accuracy: 66.4254

Epoch  8,    50/  454; acc:  73.67; ppl:   3.39; 3030 src tok/s; 3162 tgt tok/s;     13 s elapsed
Epoch  8,   100/  454; acc:  72.91; ppl:   3.51; 3081 src tok/s; 3189 tgt tok/s;     27 s elapsed
Epoch  8,   150/  454; acc:  72.53; ppl:   3.59; 3087 src tok/s; 3211 tgt tok/s;     41 s elapsed
Epoch  8,   200/  454; acc:  71.98; ppl:   3.66; 3095 src tok/s; 3195 tgt tok/s;     55 s elapsed
Epoch  8,   250/  454; acc:  70.63; ppl:   3.95; 3135 src tok/s; 3224 tgt tok/s;     69 s elapsed
Epoch  8,   300/  454; acc:  73.51; ppl:   3.43; 2996 src tok/s; 3153 tgt tok/s;     82 s elapsed
Epoch  8,   350/  454; acc:  70.61; ppl:   3.93; 3136 src tok/s; 3245 tgt tok/s;     96 s elapsed
Epoch  8,   400/  454; acc:  73.22; ppl:   3.45; 3129 src tok/s; 3246 tgt tok/s;    109 s elapsed
Epoch  8,   450/  454; acc:  71.19; ppl:   3.82; 3033 src tok/s; 3147 tgt tok/s;    122 s elapsed
Train perplexity: 3.64115
Train accuracy: 72.2105
Validation perplexity: 6.65137
Validation accuracy: 66.6383
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.38; ppl:   2.70; 3117 src tok/s; 3235 tgt tok/s;     13 s elapsed
Epoch  9,   100/  454; acc:  77.40; ppl:   2.72; 3060 src tok/s; 3159 tgt tok/s;     27 s elapsed
Epoch  9,   150/  454; acc:  77.44; ppl:   2.68; 3089 src tok/s; 3204 tgt tok/s;     41 s elapsed
Epoch  9,   200/  454; acc:  77.29; ppl:   2.69; 3084 src tok/s; 3201 tgt tok/s;     54 s elapsed
Epoch  9,   250/  454; acc:  76.38; ppl:   2.83; 3135 src tok/s; 3228 tgt tok/s;     69 s elapsed
Epoch  9,   300/  454; acc:  77.84; ppl:   2.60; 3039 src tok/s; 3182 tgt tok/s;     82 s elapsed
Epoch  9,   350/  454; acc:  77.65; ppl:   2.66; 3084 src tok/s; 3218 tgt tok/s;     95 s elapsed
Epoch  9,   400/  454; acc:  76.42; ppl:   2.81; 3095 src tok/s; 3217 tgt tok/s;    109 s elapsed
Epoch  9,   450/  454; acc:  76.88; ppl:   2.80; 3046 src tok/s; 3158 tgt tok/s;    122 s elapsed
Train perplexity: 2.71887
Train accuracy: 77.1993
Validation perplexity: 6.20885
Validation accuracy: 68.6391
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.82; ppl:   2.15; 3077 src tok/s; 3207 tgt tok/s;     13 s elapsed
Epoch 10,   100/  454; acc:  80.90; ppl:   2.26; 3102 src tok/s; 3195 tgt tok/s;     27 s elapsed
Epoch 10,   150/  454; acc:  81.51; ppl:   2.19; 3138 src tok/s; 3242 tgt tok/s;     41 s elapsed
Epoch 10,   200/  454; acc:  80.90; ppl:   2.26; 3045 src tok/s; 3173 tgt tok/s;     54 s elapsed
Epoch 10,   250/  454; acc:  80.71; ppl:   2.30; 3051 src tok/s; 3180 tgt tok/s;     68 s elapsed
Epoch 10,   300/  454; acc:  81.23; ppl:   2.18; 3085 src tok/s; 3212 tgt tok/s;     82 s elapsed
Epoch 10,   350/  454; acc:  80.99; ppl:   2.23; 3099 src tok/s; 3212 tgt tok/s;     95 s elapsed
Epoch 10,   400/  454; acc:  80.38; ppl:   2.30; 3066 src tok/s; 3173 tgt tok/s;    109 s elapsed
Epoch 10,   450/  454; acc:  80.59; ppl:   2.27; 3043 src tok/s; 3160 tgt tok/s;    122 s elapsed
Train perplexity: 2.23582
Train accuracy: 81.0092
Validation perplexity: 6.26408
Validation accuracy: 69.2422
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.71; ppl:   1.96; 3173 src tok/s; 3274 tgt tok/s;     14 s elapsed
Epoch 11,   100/  454; acc:  82.73; ppl:   2.08; 3026 src tok/s; 3154 tgt tok/s;     27 s elapsed
Epoch 11,   150/  454; acc:  82.69; ppl:   2.08; 3109 src tok/s; 3199 tgt tok/s;     41 s elapsed
Epoch 11,   200/  454; acc:  83.32; ppl:   2.01; 3061 src tok/s; 3190 tgt tok/s;     55 s elapsed
Epoch 11,   250/  454; acc:  82.70; ppl:   2.06; 3119 src tok/s; 3237 tgt tok/s;     68 s elapsed
Epoch 11,   300/  454; acc:  83.52; ppl:   1.97; 3042 src tok/s; 3157 tgt tok/s;     82 s elapsed
Epoch 11,   350/  454; acc:  83.47; ppl:   2.00; 2999 src tok/s; 3136 tgt tok/s;     95 s elapsed
Epoch 11,   400/  454; acc:  82.75; ppl:   2.05; 3146 src tok/s; 3251 tgt tok/s;    109 s elapsed
Epoch 11,   450/  454; acc:  83.83; ppl:   1.94; 3109 src tok/s; 3241 tgt tok/s;    122 s elapsed
Train perplexity: 2.02048
Train accuracy: 83.1515
Validation perplexity: 6.43475
Validation accuracy: 69.4977
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.71; ppl:   1.88; 3092 src tok/s; 3229 tgt tok/s;     13 s elapsed
Epoch 12,   100/  454; acc:  83.90; ppl:   1.95; 3082 src tok/s; 3200 tgt tok/s;     27 s elapsed
Epoch 12,   150/  454; acc:  84.34; ppl:   1.91; 3103 src tok/s; 3215 tgt tok/s;     41 s elapsed
Epoch 12,   200/  454; acc:  84.37; ppl:   1.90; 3094 src tok/s; 3189 tgt tok/s;     54 s elapsed
Epoch 12,   250/  454; acc:  84.36; ppl:   1.91; 3106 src tok/s; 3226 tgt tok/s;     68 s elapsed
Epoch 12,   300/  454; acc:  84.13; ppl:   1.94; 3009 src tok/s; 3130 tgt tok/s;     82 s elapsed
Epoch 12,   350/  454; acc:  84.67; ppl:   1.88; 3055 src tok/s; 3185 tgt tok/s;     95 s elapsed
Epoch 12,   400/  454; acc:  83.93; ppl:   1.97; 3154 src tok/s; 3246 tgt tok/s;    109 s elapsed
Epoch 12,   450/  454; acc:  83.62; ppl:   1.97; 3052 src tok/s; 3170 tgt tok/s;    122 s elapsed
Train perplexity: 1.92045
Train accuracy: 84.2452
Validation perplexity: 6.52884
Validation accuracy: 69.4835
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  83.82; ppl:   1.98; 3071 src tok/s; 3154 tgt tok/s;     15 s elapsed
Epoch 13,   100/  454; acc:  86.42; ppl:   1.71; 3043 src tok/s; 3203 tgt tok/s;     27 s elapsed
Epoch 13,   150/  454; acc:  85.23; ppl:   1.85; 3047 src tok/s; 3157 tgt tok/s;     41 s elapsed
Epoch 13,   200/  454; acc:  84.23; ppl:   1.93; 3072 src tok/s; 3188 tgt tok/s;     55 s elapsed
Epoch 13,   250/  454; acc:  86.72; ppl:   1.70; 3064 src tok/s; 3227 tgt tok/s;     67 s elapsed
Epoch 13,   300/  454; acc:  83.07; ppl:   2.03; 3171 src tok/s; 3248 tgt tok/s;     82 s elapsed
Epoch 13,   350/  454; acc:  85.36; ppl:   1.80; 3119 src tok/s; 3241 tgt tok/s;     95 s elapsed
Epoch 13,   400/  454; acc:  84.23; ppl:   1.94; 3104 src tok/s; 3224 tgt tok/s;    109 s elapsed
Epoch 13,   450/  454; acc:  84.52; ppl:   1.88; 3141 src tok/s; 3246 tgt tok/s;    122 s elapsed
Train perplexity: 1.87146
Train accuracy: 84.8011
Validation perplexity: 6.58968
Validation accuracy: 69.4196
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  84.89; ppl:   1.85; 3067 src tok/s; 3202 tgt tok/s;     13 s elapsed
Epoch 14,   100/  454; acc:  85.60; ppl:   1.81; 3092 src tok/s; 3190 tgt tok/s;     27 s elapsed
Epoch 14,   150/  454; acc:  84.50; ppl:   1.91; 3033 src tok/s; 3161 tgt tok/s;     41 s elapsed
Epoch 14,   200/  454; acc:  85.74; ppl:   1.77; 3082 src tok/s; 3204 tgt tok/s;     55 s elapsed
Epoch 14,   250/  454; acc:  84.45; ppl:   1.92; 3130 src tok/s; 3231 tgt tok/s;     68 s elapsed
Epoch 14,   300/  454; acc:  85.54; ppl:   1.78; 3122 src tok/s; 3258 tgt tok/s;     81 s elapsed
Epoch 14,   350/  454; acc:  84.69; ppl:   1.88; 3153 src tok/s; 3246 tgt tok/s;     95 s elapsed
Epoch 14,   400/  454; acc:  85.45; ppl:   1.82; 3053 src tok/s; 3177 tgt tok/s;    109 s elapsed
Epoch 14,   450/  454; acc:  84.73; ppl:   1.89; 3062 src tok/s; 3174 tgt tok/s;    122 s elapsed
Train perplexity: 1.84802
Train accuracy: 85.0798
Validation perplexity: 6.62029
Validation accuracy: 69.4125
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  84.86; ppl:   1.89; 3141 src tok/s; 3255 tgt tok/s;     14 s elapsed
Epoch 15,   100/  454; acc:  85.81; ppl:   1.78; 3086 src tok/s; 3204 tgt tok/s;     27 s elapsed
Epoch 15,   150/  454; acc:  84.16; ppl:   1.94; 3081 src tok/s; 3207 tgt tok/s;     41 s elapsed
Epoch 15,   200/  454; acc:  86.11; ppl:   1.75; 3125 src tok/s; 3250 tgt tok/s;     54 s elapsed
Epoch 15,   250/  454; acc:  84.91; ppl:   1.88; 3033 src tok/s; 3125 tgt tok/s;     68 s elapsed
Epoch 15,   300/  454; acc:  85.55; ppl:   1.80; 3108 src tok/s; 3246 tgt tok/s;     81 s elapsed
Epoch 15,   350/  454; acc:  86.34; ppl:   1.75; 3072 src tok/s; 3212 tgt tok/s;     94 s elapsed
Epoch 15,   400/  454; acc:  84.69; ppl:   1.89; 3121 src tok/s; 3221 tgt tok/s;    108 s elapsed
Epoch 15,   450/  454; acc:  85.18; ppl:   1.85; 3022 src tok/s; 3130 tgt tok/s;    122 s elapsed
Train perplexity: 1.83827
Train accuracy: 85.259
Validation perplexity: 6.63049
Validation accuracy: 69.3558
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  86.07; ppl:   1.78; 3075 src tok/s; 3185 tgt tok/s;     14 s elapsed
Epoch 16,   100/  454; acc:  84.78; ppl:   1.87; 3083 src tok/s; 3217 tgt tok/s;     27 s elapsed
Epoch 16,   150/  454; acc:  84.99; ppl:   1.85; 3088 src tok/s; 3203 tgt tok/s;     41 s elapsed
Epoch 16,   200/  454; acc:  85.33; ppl:   1.85; 3047 src tok/s; 3166 tgt tok/s;     55 s elapsed
Epoch 16,   250/  454; acc:  85.49; ppl:   1.82; 3133 src tok/s; 3254 tgt tok/s;     68 s elapsed
Epoch 16,   300/  454; acc:  85.01; ppl:   1.86; 3064 src tok/s; 3177 tgt tok/s;     82 s elapsed
Epoch 16,   350/  454; acc:  86.14; ppl:   1.76; 3092 src tok/s; 3238 tgt tok/s;     95 s elapsed
Epoch 16,   400/  454; acc:  84.74; ppl:   1.88; 3118 src tok/s; 3213 tgt tok/s;    109 s elapsed
Epoch 16,   450/  454; acc:  85.36; ppl:   1.83; 3030 src tok/s; 3131 tgt tok/s;    122 s elapsed
Train perplexity: 1.83162
Train accuracy: 85.3345
Validation perplexity: 6.64262
Validation accuracy: 69.3558
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  84.18; ppl:   1.92; 3101 src tok/s; 3202 tgt tok/s;     14 s elapsed
Epoch 17,   100/  454; acc:  85.76; ppl:   1.78; 3049 src tok/s; 3181 tgt tok/s;     27 s elapsed
Epoch 17,   150/  454; acc:  86.01; ppl:   1.75; 3036 src tok/s; 3157 tgt tok/s;     41 s elapsed
Epoch 17,   200/  454; acc:  84.79; ppl:   1.88; 3115 src tok/s; 3206 tgt tok/s;     55 s elapsed
Epoch 17,   250/  454; acc:  84.75; ppl:   1.91; 3067 src tok/s; 3173 tgt tok/s;     68 s elapsed
Epoch 17,   300/  454; acc:  86.13; ppl:   1.75; 3077 src tok/s; 3199 tgt tok/s;     82 s elapsed
Epoch 17,   350/  454; acc:  85.40; ppl:   1.82; 3110 src tok/s; 3234 tgt tok/s;     95 s elapsed
Epoch 17,   400/  454; acc:  85.58; ppl:   1.81; 3083 src tok/s; 3217 tgt tok/s;    109 s elapsed
Epoch 17,   450/  454; acc:  85.16; ppl:   1.85; 3127 src tok/s; 3237 tgt tok/s;    122 s elapsed
Train perplexity: 1.82844
Train accuracy: 85.3167
Validation perplexity: 6.64927
Validation accuracy: 69.3274
Decaying learning rate to 0.000976562
