<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.05, kappa_enc=0.05, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.05decoder0.05dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.05)
('Using Kappa L2 loss on decoder', 0.05)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:  10.34; ppl: 9580.71; 4798 src tok/s; 5010 tgt tok/s;      8 s elapsed
Epoch  1,   100/  454; acc:  14.16; ppl: 2263.91; 6861 src tok/s; 7070 tgt tok/s;     15 s elapsed
Epoch  1,   150/  454; acc:  17.64; ppl: 592.36; 6724 src tok/s; 6932 tgt tok/s;     21 s elapsed
Epoch  1,   200/  454; acc:  21.18; ppl: 268.82; 6400 src tok/s; 6694 tgt tok/s;     27 s elapsed
Epoch  1,   250/  454; acc:  24.04; ppl: 186.77; 6658 src tok/s; 6967 tgt tok/s;     33 s elapsed
Epoch  1,   300/  454; acc:  25.45; ppl: 141.97; 6796 src tok/s; 7019 tgt tok/s;     40 s elapsed
Epoch  1,   350/  454; acc:  29.00; ppl: 102.41; 6789 src tok/s; 7026 tgt tok/s;     46 s elapsed
Epoch  1,   400/  454; acc:  30.84; ppl:  83.04; 6690 src tok/s; 6954 tgt tok/s;     52 s elapsed
Epoch  1,   450/  454; acc:  32.87; ppl:  68.53; 6558 src tok/s; 6795 tgt tok/s;     59 s elapsed
Train perplexity: 328.776
Train accuracy: 22.927
Validation perplexity: 61.0512
Validation accuracy: 32.9715

Epoch  2,    50/  454; acc:  34.57; ppl:  57.01; 6469 src tok/s; 6738 tgt tok/s;      6 s elapsed
Epoch  2,   100/  454; acc:  36.69; ppl:  50.42; 6576 src tok/s; 6821 tgt tok/s;     13 s elapsed
Epoch  2,   150/  454; acc:  38.44; ppl:  44.01; 6724 src tok/s; 7011 tgt tok/s;     19 s elapsed
Epoch  2,   200/  454; acc:  40.24; ppl:  39.86; 6587 src tok/s; 6833 tgt tok/s;     25 s elapsed
Epoch  2,   250/  454; acc:  42.88; ppl:  33.02; 6611 src tok/s; 6879 tgt tok/s;     32 s elapsed
Epoch  2,   300/  454; acc:  44.78; ppl:  28.57; 6564 src tok/s; 6810 tgt tok/s;     38 s elapsed
Epoch  2,   350/  454; acc:  48.09; ppl:  23.30; 6610 src tok/s; 6895 tgt tok/s;     44 s elapsed
Epoch  2,   400/  454; acc:  48.55; ppl:  22.88; 6841 src tok/s; 7019 tgt tok/s;     51 s elapsed
Epoch  2,   450/  454; acc:  49.69; ppl:  20.62; 6605 src tok/s; 6819 tgt tok/s;     57 s elapsed
Train perplexity: 33.2903
Train accuracy: 42.7338
Validation perplexity: 16.4892
Validation accuracy: 53.3773

Epoch  3,    50/  454; acc:  52.30; ppl:  16.68; 6363 src tok/s; 6610 tgt tok/s;      7 s elapsed
Epoch  3,   100/  454; acc:  54.47; ppl:  14.72; 6442 src tok/s; 6699 tgt tok/s;     13 s elapsed
Epoch  3,   150/  454; acc:  54.61; ppl:  14.48; 6512 src tok/s; 6775 tgt tok/s;     19 s elapsed
Epoch  3,   200/  454; acc:  54.19; ppl:  14.75; 6520 src tok/s; 6771 tgt tok/s;     26 s elapsed
Epoch  3,   250/  454; acc:  57.21; ppl:  12.41; 6424 src tok/s; 6701 tgt tok/s;     32 s elapsed
Epoch  3,   300/  454; acc:  55.61; ppl:  13.14; 6710 src tok/s; 6942 tgt tok/s;     39 s elapsed
Epoch  3,   350/  454; acc:  57.72; ppl:  11.80; 6635 src tok/s; 6856 tgt tok/s;     45 s elapsed
Epoch  3,   400/  454; acc:  57.59; ppl:  11.62; 6572 src tok/s; 6809 tgt tok/s;     51 s elapsed
Epoch  3,   450/  454; acc:  58.45; ppl:  11.27; 6493 src tok/s; 6726 tgt tok/s;     58 s elapsed
Train perplexity: 13.303
Train accuracy: 55.8143
Validation perplexity: 10.2791
Validation accuracy: 60.7493

Epoch  4,    50/  454; acc:  60.58; ppl:   9.22; 6448 src tok/s; 6696 tgt tok/s;      6 s elapsed
Epoch  4,   100/  454; acc:  60.97; ppl:   8.92; 6677 src tok/s; 6920 tgt tok/s;     13 s elapsed
Epoch  4,   150/  454; acc:  61.28; ppl:   8.69; 6464 src tok/s; 6699 tgt tok/s;     19 s elapsed
Epoch  4,   200/  454; acc:  61.48; ppl:   8.68; 6506 src tok/s; 6778 tgt tok/s;     26 s elapsed
Epoch  4,   250/  454; acc:  61.56; ppl:   8.66; 6516 src tok/s; 6737 tgt tok/s;     32 s elapsed
Epoch  4,   300/  454; acc:  62.39; ppl:   8.10; 6539 src tok/s; 6805 tgt tok/s;     39 s elapsed
Epoch  4,   350/  454; acc:  62.91; ppl:   7.86; 6628 src tok/s; 6927 tgt tok/s;     45 s elapsed
Epoch  4,   400/  454; acc:  61.63; ppl:   8.53; 6577 src tok/s; 6789 tgt tok/s;     51 s elapsed
Epoch  4,   450/  454; acc:  62.50; ppl:   7.89; 6488 src tok/s; 6735 tgt tok/s;     58 s elapsed
Train perplexity: 8.48883
Train accuracy: 61.7105
Validation perplexity: 8.78412
Validation accuracy: 61.7993

Epoch  5,    50/  454; acc:  65.75; ppl:   6.17; 6285 src tok/s; 6549 tgt tok/s;      7 s elapsed
Epoch  5,   100/  454; acc:  65.19; ppl:   6.40; 6519 src tok/s; 6761 tgt tok/s;     13 s elapsed
Epoch  5,   150/  454; acc:  64.01; ppl:   6.79; 6579 src tok/s; 6779 tgt tok/s;     20 s elapsed
Epoch  5,   200/  454; acc:  65.94; ppl:   6.07; 6381 src tok/s; 6667 tgt tok/s;     26 s elapsed
Epoch  5,   250/  454; acc:  63.83; ppl:   6.86; 6639 src tok/s; 6827 tgt tok/s;     33 s elapsed
Epoch  5,   300/  454; acc:  65.85; ppl:   6.12; 6465 src tok/s; 6744 tgt tok/s;     39 s elapsed
Epoch  5,   350/  454; acc:  65.50; ppl:   6.30; 6460 src tok/s; 6709 tgt tok/s;     45 s elapsed
Epoch  5,   400/  454; acc:  65.75; ppl:   6.18; 6548 src tok/s; 6792 tgt tok/s;     52 s elapsed
Epoch  5,   450/  454; acc:  65.39; ppl:   6.29; 6486 src tok/s; 6740 tgt tok/s;     58 s elapsed
Train perplexity: 6.34208
Train accuracy: 65.2578
Validation perplexity: 7.45718
Validation accuracy: 64.6232

Epoch  6,    50/  454; acc:  69.16; ppl:   4.79; 6226 src tok/s; 6514 tgt tok/s;      7 s elapsed
Epoch  6,   100/  454; acc:  67.73; ppl:   5.17; 6529 src tok/s; 6723 tgt tok/s;     13 s elapsed
Epoch  6,   150/  454; acc:  68.64; ppl:   4.88; 6595 src tok/s; 6816 tgt tok/s;     20 s elapsed
Epoch  6,   200/  454; acc:  67.55; ppl:   5.21; 6466 src tok/s; 6765 tgt tok/s;     26 s elapsed
Epoch  6,   250/  454; acc:  69.49; ppl:   4.61; 6279 src tok/s; 6607 tgt tok/s;     32 s elapsed
Epoch  6,   300/  454; acc:  66.82; ppl:   5.46; 6692 src tok/s; 6888 tgt tok/s;     39 s elapsed
Epoch  6,   350/  454; acc:  66.80; ppl:   5.41; 6540 src tok/s; 6707 tgt tok/s;     46 s elapsed
Epoch  6,   400/  454; acc:  68.36; ppl:   4.96; 6389 src tok/s; 6675 tgt tok/s;     52 s elapsed
Epoch  6,   450/  454; acc:  67.19; ppl:   5.23; 6483 src tok/s; 6690 tgt tok/s;     58 s elapsed
Train perplexity: 5.071
Train accuracy: 67.9859
Validation perplexity: 6.94459
Validation accuracy: 66.3332

Epoch  7,    50/  454; acc:  71.75; ppl:   3.90; 6349 src tok/s; 6599 tgt tok/s;      6 s elapsed
Epoch  7,   100/  454; acc:  69.78; ppl:   4.40; 6649 src tok/s; 6875 tgt tok/s;     13 s elapsed
Epoch  7,   150/  454; acc:  70.50; ppl:   4.19; 6543 src tok/s; 6766 tgt tok/s;     19 s elapsed
Epoch  7,   200/  454; acc:  69.64; ppl:   4.31; 6465 src tok/s; 6713 tgt tok/s;     26 s elapsed
Epoch  7,   250/  454; acc:  69.29; ppl:   4.46; 6420 src tok/s; 6669 tgt tok/s;     32 s elapsed
Epoch  7,   300/  454; acc:  70.77; ppl:   4.05; 6569 src tok/s; 6806 tgt tok/s;     39 s elapsed
Epoch  7,   350/  454; acc:  70.05; ppl:   4.22; 6701 src tok/s; 6963 tgt tok/s;     45 s elapsed
Epoch  7,   400/  454; acc:  69.52; ppl:   4.40; 6472 src tok/s; 6729 tgt tok/s;     51 s elapsed
Epoch  7,   450/  454; acc:  69.61; ppl:   4.45; 6455 src tok/s; 6711 tgt tok/s;     58 s elapsed
Train perplexity: 4.25556
Train accuracy: 70.12
Validation perplexity: 6.62795
Validation accuracy: 66.6383

Epoch  8,    50/  454; acc:  73.41; ppl:   3.42; 6505 src tok/s; 6731 tgt tok/s;      7 s elapsed
Epoch  8,   100/  454; acc:  72.87; ppl:   3.54; 6474 src tok/s; 6710 tgt tok/s;     13 s elapsed
Epoch  8,   150/  454; acc:  72.70; ppl:   3.51; 6567 src tok/s; 6824 tgt tok/s;     19 s elapsed
Epoch  8,   200/  454; acc:  71.62; ppl:   3.75; 6728 src tok/s; 6969 tgt tok/s;     26 s elapsed
Epoch  8,   250/  454; acc:  73.02; ppl:   3.47; 6433 src tok/s; 6745 tgt tok/s;     32 s elapsed
Epoch  8,   300/  454; acc:  70.63; ppl:   3.97; 6691 src tok/s; 6908 tgt tok/s;     38 s elapsed
Epoch  8,   350/  454; acc:  72.44; ppl:   3.54; 6571 src tok/s; 6858 tgt tok/s;     44 s elapsed
Epoch  8,   400/  454; acc:  70.45; ppl:   4.06; 6760 src tok/s; 6988 tgt tok/s;     51 s elapsed
Epoch  8,   450/  454; acc:  71.62; ppl:   3.79; 6476 src tok/s; 6722 tgt tok/s;     57 s elapsed
Train perplexity: 3.6704
Train accuracy: 72.0659
Validation perplexity: 6.47757
Validation accuracy: 66.8582
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.12; ppl:   2.87; 6629 src tok/s; 6847 tgt tok/s;      7 s elapsed
Epoch  9,   100/  454; acc:  78.14; ppl:   2.59; 6515 src tok/s; 6791 tgt tok/s;     13 s elapsed
Epoch  9,   150/  454; acc:  77.48; ppl:   2.66; 6507 src tok/s; 6758 tgt tok/s;     19 s elapsed
Epoch  9,   200/  454; acc:  76.68; ppl:   2.79; 6564 src tok/s; 6850 tgt tok/s;     26 s elapsed
Epoch  9,   250/  454; acc:  77.56; ppl:   2.62; 6527 src tok/s; 6789 tgt tok/s;     32 s elapsed
Epoch  9,   300/  454; acc:  76.68; ppl:   2.78; 6677 src tok/s; 6904 tgt tok/s;     38 s elapsed
Epoch  9,   350/  454; acc:  76.48; ppl:   2.86; 6536 src tok/s; 6766 tgt tok/s;     45 s elapsed
Epoch  9,   400/  454; acc:  76.62; ppl:   2.78; 6713 src tok/s; 6932 tgt tok/s;     51 s elapsed
Epoch  9,   450/  454; acc:  77.10; ppl:   2.73; 6486 src tok/s; 6756 tgt tok/s;     57 s elapsed
Train perplexity: 2.73931
Train accuracy: 76.9818
Validation perplexity: 6.24932
Validation accuracy: 68.5398
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  79.40; ppl:   2.42; 6559 src tok/s; 6735 tgt tok/s;      7 s elapsed
Epoch 10,   100/  454; acc:  81.97; ppl:   2.09; 6493 src tok/s; 6816 tgt tok/s;     13 s elapsed
Epoch 10,   150/  454; acc:  79.74; ppl:   2.38; 6470 src tok/s; 6644 tgt tok/s;     20 s elapsed
Epoch 10,   200/  454; acc:  81.79; ppl:   2.13; 6524 src tok/s; 6832 tgt tok/s;     26 s elapsed
Epoch 10,   250/  454; acc:  80.48; ppl:   2.29; 6494 src tok/s; 6743 tgt tok/s;     32 s elapsed
Epoch 10,   300/  454; acc:  81.01; ppl:   2.24; 6535 src tok/s; 6812 tgt tok/s;     39 s elapsed
Epoch 10,   350/  454; acc:  81.37; ppl:   2.18; 6588 src tok/s; 6829 tgt tok/s;     45 s elapsed
Epoch 10,   400/  454; acc:  80.48; ppl:   2.30; 6503 src tok/s; 6756 tgt tok/s;     51 s elapsed
Epoch 10,   450/  454; acc:  81.11; ppl:   2.22; 6433 src tok/s; 6689 tgt tok/s;     58 s elapsed
Train perplexity: 2.25527
Train accuracy: 80.7625
Validation perplexity: 6.21291
Validation accuracy: 69.0152
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  84.08; ppl:   1.92; 6355 src tok/s; 6662 tgt tok/s;      6 s elapsed
Epoch 11,   100/  454; acc:  82.04; ppl:   2.12; 6619 src tok/s; 6796 tgt tok/s;     13 s elapsed
Epoch 11,   150/  454; acc:  83.67; ppl:   1.97; 6462 src tok/s; 6749 tgt tok/s;     19 s elapsed
Epoch 11,   200/  454; acc:  82.64; ppl:   2.07; 6681 src tok/s; 6892 tgt tok/s;     26 s elapsed
Epoch 11,   250/  454; acc:  83.47; ppl:   1.99; 6427 src tok/s; 6687 tgt tok/s;     32 s elapsed
Epoch 11,   300/  454; acc:  82.58; ppl:   2.07; 6526 src tok/s; 6772 tgt tok/s;     39 s elapsed
Epoch 11,   350/  454; acc:  82.33; ppl:   2.10; 6501 src tok/s; 6734 tgt tok/s;     45 s elapsed
Epoch 11,   400/  454; acc:  83.03; ppl:   1.99; 6577 src tok/s; 6860 tgt tok/s;     51 s elapsed
Epoch 11,   450/  454; acc:  83.05; ppl:   2.04; 6456 src tok/s; 6694 tgt tok/s;     58 s elapsed
Train perplexity: 2.03493
Train accuracy: 82.9409
Validation perplexity: 6.39786
Validation accuracy: 69.0649
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  83.64; ppl:   1.97; 6296 src tok/s; 6520 tgt tok/s;      7 s elapsed
Epoch 12,   100/  454; acc:  84.41; ppl:   1.89; 6491 src tok/s; 6752 tgt tok/s;     13 s elapsed
Epoch 12,   150/  454; acc:  84.70; ppl:   1.87; 6517 src tok/s; 6768 tgt tok/s;     20 s elapsed
Epoch 12,   200/  454; acc:  83.81; ppl:   1.95; 6628 src tok/s; 6880 tgt tok/s;     26 s elapsed
Epoch 12,   250/  454; acc:  83.52; ppl:   2.00; 6571 src tok/s; 6816 tgt tok/s;     33 s elapsed
Epoch 12,   300/  454; acc:  84.60; ppl:   1.86; 6528 src tok/s; 6824 tgt tok/s;     39 s elapsed
Epoch 12,   350/  454; acc:  84.29; ppl:   1.90; 6569 src tok/s; 6815 tgt tok/s;     45 s elapsed
Epoch 12,   400/  454; acc:  83.39; ppl:   2.00; 6473 src tok/s; 6673 tgt tok/s;     52 s elapsed
Epoch 12,   450/  454; acc:  83.63; ppl:   1.99; 6435 src tok/s; 6663 tgt tok/s;     58 s elapsed
Train perplexity: 1.93382
Train accuracy: 84.0219
Validation perplexity: 6.52273
Validation accuracy: 69.15
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.75; ppl:   1.88; 6457 src tok/s; 6674 tgt tok/s;      7 s elapsed
Epoch 13,   100/  454; acc:  84.90; ppl:   1.85; 6654 src tok/s; 6920 tgt tok/s;     13 s elapsed
Epoch 13,   150/  454; acc:  84.77; ppl:   1.86; 6396 src tok/s; 6670 tgt tok/s;     19 s elapsed
Epoch 13,   200/  454; acc:  84.36; ppl:   1.92; 6453 src tok/s; 6692 tgt tok/s;     26 s elapsed
Epoch 13,   250/  454; acc:  85.32; ppl:   1.84; 6454 src tok/s; 6711 tgt tok/s;     32 s elapsed
Epoch 13,   300/  454; acc:  84.32; ppl:   1.91; 6531 src tok/s; 6779 tgt tok/s;     39 s elapsed
Epoch 13,   350/  454; acc:  84.07; ppl:   1.94; 6516 src tok/s; 6761 tgt tok/s;     45 s elapsed
Epoch 13,   400/  454; acc:  84.35; ppl:   1.88; 6652 src tok/s; 6894 tgt tok/s;     51 s elapsed
Epoch 13,   450/  454; acc:  84.42; ppl:   1.89; 6391 src tok/s; 6619 tgt tok/s;     58 s elapsed
Train perplexity: 1.88368
Train accuracy: 84.6011
Validation perplexity: 6.56351
Validation accuracy: 69.1429
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  84.99; ppl:   1.86; 6288 src tok/s; 6552 tgt tok/s;      6 s elapsed
Epoch 14,   100/  454; acc:  84.68; ppl:   1.88; 6493 src tok/s; 6708 tgt tok/s;     13 s elapsed
Epoch 14,   150/  454; acc:  85.26; ppl:   1.84; 6537 src tok/s; 6796 tgt tok/s;     20 s elapsed
Epoch 14,   200/  454; acc:  84.50; ppl:   1.91; 6578 src tok/s; 6815 tgt tok/s;     26 s elapsed
Epoch 14,   250/  454; acc:  85.36; ppl:   1.81; 6468 src tok/s; 6736 tgt tok/s;     32 s elapsed
Epoch 14,   300/  454; acc:  84.62; ppl:   1.90; 6539 src tok/s; 6777 tgt tok/s;     39 s elapsed
Epoch 14,   350/  454; acc:  85.88; ppl:   1.76; 6492 src tok/s; 6766 tgt tok/s;     45 s elapsed
Epoch 14,   400/  454; acc:  84.42; ppl:   1.92; 6659 src tok/s; 6868 tgt tok/s;     52 s elapsed
Epoch 14,   450/  454; acc:  84.67; ppl:   1.87; 6506 src tok/s; 6761 tgt tok/s;     58 s elapsed
Train perplexity: 1.86
Train accuracy: 84.9182
Validation perplexity: 6.60251
Validation accuracy: 69.2138
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.88; ppl:   1.79; 6369 src tok/s; 6653 tgt tok/s;      6 s elapsed
Epoch 15,   100/  454; acc:  83.97; ppl:   1.93; 6541 src tok/s; 6753 tgt tok/s;     13 s elapsed
Epoch 15,   150/  454; acc:  85.26; ppl:   1.83; 6432 src tok/s; 6717 tgt tok/s;     19 s elapsed
Epoch 15,   200/  454; acc:  84.57; ppl:   1.91; 6690 src tok/s; 6925 tgt tok/s;     26 s elapsed
Epoch 15,   250/  454; acc:  85.38; ppl:   1.84; 6536 src tok/s; 6754 tgt tok/s;     32 s elapsed
Epoch 15,   300/  454; acc:  85.32; ppl:   1.81; 6548 src tok/s; 6765 tgt tok/s;     39 s elapsed
Epoch 15,   350/  454; acc:  85.93; ppl:   1.77; 6540 src tok/s; 6830 tgt tok/s;     45 s elapsed
Epoch 15,   400/  454; acc:  84.40; ppl:   1.90; 6525 src tok/s; 6736 tgt tok/s;     51 s elapsed
Epoch 15,   450/  454; acc:  84.74; ppl:   1.85; 6334 src tok/s; 6584 tgt tok/s;     58 s elapsed
Train perplexity: 1.84682
Train accuracy: 85.0583
Validation perplexity: 6.62729
Validation accuracy: 69.1358
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.82; ppl:   1.79; 6341 src tok/s; 6618 tgt tok/s;      6 s elapsed
Epoch 16,   100/  454; acc:  84.92; ppl:   1.88; 6711 src tok/s; 6926 tgt tok/s;     13 s elapsed
Epoch 16,   150/  454; acc:  84.54; ppl:   1.87; 6726 src tok/s; 6963 tgt tok/s;     19 s elapsed
Epoch 16,   200/  454; acc:  85.23; ppl:   1.83; 6554 src tok/s; 6852 tgt tok/s;     26 s elapsed
Epoch 16,   250/  454; acc:  85.92; ppl:   1.79; 6402 src tok/s; 6713 tgt tok/s;     32 s elapsed
Epoch 16,   300/  454; acc:  84.56; ppl:   1.87; 6681 src tok/s; 6872 tgt tok/s;     38 s elapsed
Epoch 16,   350/  454; acc:  85.22; ppl:   1.83; 6613 src tok/s; 6874 tgt tok/s;     45 s elapsed
Epoch 16,   400/  454; acc:  85.20; ppl:   1.87; 6653 src tok/s; 6855 tgt tok/s;     51 s elapsed
Epoch 16,   450/  454; acc:  85.20; ppl:   1.84; 6498 src tok/s; 6743 tgt tok/s;     57 s elapsed
Train perplexity: 1.84225
Train accuracy: 85.17
Validation perplexity: 6.63152
Validation accuracy: 69.1429
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.08; ppl:   1.83; 6431 src tok/s; 6675 tgt tok/s;      7 s elapsed
Epoch 17,   100/  454; acc:  85.62; ppl:   1.81; 6687 src tok/s; 6952 tgt tok/s;     13 s elapsed
Epoch 17,   150/  454; acc:  84.65; ppl:   1.90; 6628 src tok/s; 6868 tgt tok/s;     19 s elapsed
Epoch 17,   200/  454; acc:  85.97; ppl:   1.77; 6640 src tok/s; 6910 tgt tok/s;     25 s elapsed
Epoch 17,   250/  454; acc:  85.42; ppl:   1.82; 6633 src tok/s; 6867 tgt tok/s;     32 s elapsed
Epoch 17,   300/  454; acc:  84.52; ppl:   1.90; 6680 src tok/s; 6919 tgt tok/s;     38 s elapsed
Epoch 17,   350/  454; acc:  84.84; ppl:   1.87; 6534 src tok/s; 6745 tgt tok/s;     45 s elapsed
Epoch 17,   400/  454; acc:  85.29; ppl:   1.81; 6523 src tok/s; 6812 tgt tok/s;     51 s elapsed
Epoch 17,   450/  454; acc:  85.16; ppl:   1.81; 6448 src tok/s; 6714 tgt tok/s;     57 s elapsed
Train perplexity: 1.83691
Train accuracy: 85.1429
Validation perplexity: 6.63589
Validation accuracy: 69.1358
Decaying learning rate to 0.000976562
