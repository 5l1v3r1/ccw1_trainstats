<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.25, kappa_enc=0.3, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.30decoder0.25dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.3)
('Using Kappa L2 loss on decoder', 0.25)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:  10.01; ppl: 16843.76; 4654 src tok/s; 4851 tgt tok/s;      9 s elapsed
Epoch  1,   100/  454; acc:  15.76; ppl: 1057.58; 5479 src tok/s; 5662 tgt tok/s;     17 s elapsed
Epoch  1,   150/  454; acc:  18.75; ppl: 402.95; 5686 src tok/s; 5870 tgt tok/s;     24 s elapsed
Epoch  1,   200/  454; acc:  22.08; ppl: 243.23; 5443 src tok/s; 5719 tgt tok/s;     32 s elapsed
Epoch  1,   250/  454; acc:  25.49; ppl: 160.16; 5612 src tok/s; 5795 tgt tok/s;     39 s elapsed
Epoch  1,   300/  454; acc:  27.98; ppl: 118.31; 5614 src tok/s; 5845 tgt tok/s;     47 s elapsed
Epoch  1,   350/  454; acc:  30.11; ppl:  93.79; 5601 src tok/s; 5792 tgt tok/s;     54 s elapsed
Epoch  1,   400/  454; acc:  31.71; ppl:  76.80; 5511 src tok/s; 5710 tgt tok/s;     62 s elapsed
Epoch  1,   450/  454; acc:  33.90; ppl:  64.00; 5386 src tok/s; 5601 tgt tok/s;     69 s elapsed
Train perplexity: 289.3
Train accuracy: 24.0166
Validation perplexity: 70.4682
Validation accuracy: 34.4047

Epoch  2,    50/  454; acc:  37.57; ppl:  48.27; 5481 src tok/s; 5671 tgt tok/s;      8 s elapsed
Epoch  2,   100/  454; acc:  39.22; ppl:  43.80; 5456 src tok/s; 5665 tgt tok/s;     15 s elapsed
Epoch  2,   150/  454; acc:  41.88; ppl:  36.62; 5653 src tok/s; 5864 tgt tok/s;     23 s elapsed
Epoch  2,   200/  454; acc:  43.64; ppl:  31.33; 5626 src tok/s; 5834 tgt tok/s;     30 s elapsed
Epoch  2,   250/  454; acc:  45.70; ppl:  26.77; 5603 src tok/s; 5772 tgt tok/s;     38 s elapsed
Epoch  2,   300/  454; acc:  47.99; ppl:  23.98; 5499 src tok/s; 5763 tgt tok/s;     45 s elapsed
Epoch  2,   350/  454; acc:  51.24; ppl:  19.27; 5461 src tok/s; 5728 tgt tok/s;     53 s elapsed
Epoch  2,   400/  454; acc:  49.71; ppl:  20.65; 5536 src tok/s; 5705 tgt tok/s;     61 s elapsed
Epoch  2,   450/  454; acc:  51.37; ppl:  18.62; 5507 src tok/s; 5697 tgt tok/s;     68 s elapsed
Train perplexity: 28.1506
Train accuracy: 45.4377
Validation perplexity: 15.0837
Validation accuracy: 55.2008

Epoch  3,    50/  454; acc:  54.11; ppl:  14.53; 5659 src tok/s; 5829 tgt tok/s;      8 s elapsed
Epoch  3,   100/  454; acc:  55.75; ppl:  13.33; 5474 src tok/s; 5719 tgt tok/s;     15 s elapsed
Epoch  3,   150/  454; acc:  56.10; ppl:  12.99; 5490 src tok/s; 5700 tgt tok/s;     23 s elapsed
Epoch  3,   200/  454; acc:  56.12; ppl:  12.84; 5516 src tok/s; 5716 tgt tok/s;     30 s elapsed
Epoch  3,   250/  454; acc:  56.98; ppl:  12.21; 5420 src tok/s; 5620 tgt tok/s;     38 s elapsed
Epoch  3,   300/  454; acc:  57.52; ppl:  11.92; 5599 src tok/s; 5814 tgt tok/s;     46 s elapsed
Epoch  3,   350/  454; acc:  58.73; ppl:  10.98; 5508 src tok/s; 5720 tgt tok/s;     53 s elapsed
Epoch  3,   400/  454; acc:  58.98; ppl:  10.86; 5553 src tok/s; 5775 tgt tok/s;     61 s elapsed
Epoch  3,   450/  454; acc:  58.28; ppl:  11.32; 5519 src tok/s; 5725 tgt tok/s;     68 s elapsed
Train perplexity: 12.2792
Train accuracy: 56.9479
Validation perplexity: 10.4089
Validation accuracy: 59.238

Epoch  4,    50/  454; acc:  62.13; ppl:   8.27; 5458 src tok/s; 5700 tgt tok/s;      7 s elapsed
Epoch  4,   100/  454; acc:  61.63; ppl:   8.48; 5499 src tok/s; 5678 tgt tok/s;     15 s elapsed
Epoch  4,   150/  454; acc:  62.90; ppl:   7.76; 5542 src tok/s; 5786 tgt tok/s;     23 s elapsed
Epoch  4,   200/  454; acc:  61.60; ppl:   8.50; 5511 src tok/s; 5689 tgt tok/s;     30 s elapsed
Epoch  4,   250/  454; acc:  62.59; ppl:   8.03; 5434 src tok/s; 5626 tgt tok/s;     38 s elapsed
Epoch  4,   300/  454; acc:  61.85; ppl:   8.36; 5511 src tok/s; 5715 tgt tok/s;     46 s elapsed
Epoch  4,   350/  454; acc:  64.00; ppl:   7.34; 5458 src tok/s; 5705 tgt tok/s;     53 s elapsed
Epoch  4,   400/  454; acc:  61.38; ppl:   8.44; 5575 src tok/s; 5778 tgt tok/s;     61 s elapsed
Epoch  4,   450/  454; acc:  62.99; ppl:   7.70; 5447 src tok/s; 5638 tgt tok/s;     69 s elapsed
Train perplexity: 8.09105
Train accuracy: 62.3362
Validation perplexity: 8.23648
Validation accuracy: 63.6157

Epoch  5,    50/  454; acc:  65.75; ppl:   6.18; 5456 src tok/s; 5660 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  65.77; ppl:   6.15; 5504 src tok/s; 5711 tgt tok/s;     15 s elapsed
Epoch  5,   150/  454; acc:  65.78; ppl:   6.17; 5483 src tok/s; 5701 tgt tok/s;     23 s elapsed
Epoch  5,   200/  454; acc:  65.60; ppl:   6.16; 5516 src tok/s; 5729 tgt tok/s;     31 s elapsed
Epoch  5,   250/  454; acc:  65.67; ppl:   6.15; 5680 src tok/s; 5851 tgt tok/s;     38 s elapsed
Epoch  5,   300/  454; acc:  65.58; ppl:   6.20; 5495 src tok/s; 5741 tgt tok/s;     45 s elapsed
Epoch  5,   350/  454; acc:  64.67; ppl:   6.46; 5354 src tok/s; 5519 tgt tok/s;     54 s elapsed
Epoch  5,   400/  454; acc:  67.22; ppl:   5.69; 5318 src tok/s; 5553 tgt tok/s;     61 s elapsed
Epoch  5,   450/  454; acc:  65.84; ppl:   6.12; 5495 src tok/s; 5700 tgt tok/s;     69 s elapsed
Train perplexity: 6.145
Train accuracy: 65.7531
Validation perplexity: 7.28154
Validation accuracy: 65.127

Epoch  6,    50/  454; acc:  69.42; ppl:   4.64; 5478 src tok/s; 5679 tgt tok/s;      8 s elapsed
Epoch  6,   100/  454; acc:  67.82; ppl:   5.07; 5406 src tok/s; 5622 tgt tok/s;     15 s elapsed
Epoch  6,   150/  454; acc:  69.01; ppl:   4.88; 5451 src tok/s; 5675 tgt tok/s;     23 s elapsed
Epoch  6,   200/  454; acc:  68.24; ppl:   5.11; 5531 src tok/s; 5722 tgt tok/s;     31 s elapsed
Epoch  6,   250/  454; acc:  67.51; ppl:   5.07; 5555 src tok/s; 5726 tgt tok/s;     39 s elapsed
Epoch  6,   300/  454; acc:  69.04; ppl:   4.74; 5554 src tok/s; 5800 tgt tok/s;     46 s elapsed
Epoch  6,   350/  454; acc:  67.65; ppl:   5.09; 5557 src tok/s; 5746 tgt tok/s;     54 s elapsed
Epoch  6,   400/  454; acc:  69.20; ppl:   4.78; 5461 src tok/s; 5673 tgt tok/s;     61 s elapsed
Epoch  6,   450/  454; acc:  67.73; ppl:   5.09; 4944 src tok/s; 5157 tgt tok/s;     69 s elapsed
Train perplexity: 4.95155
Train accuracy: 68.3534
Validation perplexity: 6.94975
Validation accuracy: 65.1767

Epoch  7,    50/  454; acc:  71.66; ppl:   3.89; 5617 src tok/s; 5846 tgt tok/s;      7 s elapsed
Epoch  7,   100/  454; acc:  71.19; ppl:   3.95; 5586 src tok/s; 5758 tgt tok/s;     15 s elapsed
Epoch  7,   150/  454; acc:  69.91; ppl:   4.28; 5420 src tok/s; 5585 tgt tok/s;     23 s elapsed
Epoch  7,   200/  454; acc:  71.22; ppl:   3.91; 5520 src tok/s; 5781 tgt tok/s;     30 s elapsed
Epoch  7,   250/  454; acc:  71.76; ppl:   3.93; 5346 src tok/s; 5607 tgt tok/s;     38 s elapsed
Epoch  7,   300/  454; acc:  69.20; ppl:   4.44; 5578 src tok/s; 5749 tgt tok/s;     46 s elapsed
Epoch  7,   350/  454; acc:  69.34; ppl:   4.49; 5560 src tok/s; 5710 tgt tok/s;     53 s elapsed
Epoch  7,   400/  454; acc:  70.64; ppl:   4.18; 5424 src tok/s; 5685 tgt tok/s;     61 s elapsed
Epoch  7,   450/  454; acc:  69.50; ppl:   4.46; 5363 src tok/s; 5570 tgt tok/s;     69 s elapsed
Train perplexity: 4.17004
Train accuracy: 70.4649
Validation perplexity: 6.46007
Validation accuracy: 67.511

Epoch  8,    50/  454; acc:  73.22; ppl:   3.39; 5430 src tok/s; 5670 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  72.96; ppl:   3.45; 5522 src tok/s; 5739 tgt tok/s;     15 s elapsed
Epoch  8,   150/  454; acc:  72.19; ppl:   3.67; 5692 src tok/s; 5845 tgt tok/s;     23 s elapsed
Epoch  8,   200/  454; acc:  72.71; ppl:   3.49; 5536 src tok/s; 5780 tgt tok/s;     30 s elapsed
Epoch  8,   250/  454; acc:  72.80; ppl:   3.53; 5480 src tok/s; 5674 tgt tok/s;     38 s elapsed
Epoch  8,   300/  454; acc:  71.86; ppl:   3.73; 5499 src tok/s; 5692 tgt tok/s;     46 s elapsed
Epoch  8,   350/  454; acc:  72.31; ppl:   3.57; 5448 src tok/s; 5654 tgt tok/s;     53 s elapsed
Epoch  8,   400/  454; acc:  71.92; ppl:   3.67; 5500 src tok/s; 5700 tgt tok/s;     61 s elapsed
Epoch  8,   450/  454; acc:  71.14; ppl:   3.85; 5384 src tok/s; 5615 tgt tok/s;     69 s elapsed
Train perplexity: 3.59081
Train accuracy: 72.3514
Validation perplexity: 6.44538
Validation accuracy: 67.2698
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.82; ppl:   2.81; 5455 src tok/s; 5645 tgt tok/s;      8 s elapsed
Epoch  9,   100/  454; acc:  77.80; ppl:   2.65; 5026 src tok/s; 5261 tgt tok/s;     16 s elapsed
Epoch  9,   150/  454; acc:  78.55; ppl:   2.53; 5552 src tok/s; 5797 tgt tok/s;     23 s elapsed
Epoch  9,   200/  454; acc:  76.58; ppl:   2.81; 5680 src tok/s; 5845 tgt tok/s;     31 s elapsed
Epoch  9,   250/  454; acc:  78.12; ppl:   2.59; 5657 src tok/s; 5896 tgt tok/s;     38 s elapsed
Epoch  9,   300/  454; acc:  76.69; ppl:   2.78; 5320 src tok/s; 5503 tgt tok/s;     46 s elapsed
Epoch  9,   350/  454; acc:  77.30; ppl:   2.71; 5489 src tok/s; 5719 tgt tok/s;     54 s elapsed
Epoch  9,   400/  454; acc:  77.22; ppl:   2.72; 5583 src tok/s; 5751 tgt tok/s;     62 s elapsed
Epoch  9,   450/  454; acc:  77.22; ppl:   2.65; 5360 src tok/s; 5577 tgt tok/s;     69 s elapsed
Train perplexity: 2.69599
Train accuracy: 77.3396
Validation perplexity: 6.0946
Validation accuracy: 68.7881
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.55; ppl:   2.31; 5468 src tok/s; 5657 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  82.09; ppl:   2.12; 5449 src tok/s; 5660 tgt tok/s;     15 s elapsed
Epoch 10,   150/  454; acc:  80.07; ppl:   2.38; 5378 src tok/s; 5540 tgt tok/s;     24 s elapsed
Epoch 10,   200/  454; acc:  82.74; ppl:   2.03; 5318 src tok/s; 5570 tgt tok/s;     31 s elapsed
Epoch 10,   250/  454; acc:  82.12; ppl:   2.11; 5400 src tok/s; 5632 tgt tok/s;     38 s elapsed
Epoch 10,   300/  454; acc:  80.62; ppl:   2.28; 5507 src tok/s; 5698 tgt tok/s;     46 s elapsed
Epoch 10,   350/  454; acc:  80.78; ppl:   2.25; 5481 src tok/s; 5672 tgt tok/s;     54 s elapsed
Epoch 10,   400/  454; acc:  80.86; ppl:   2.24; 5463 src tok/s; 5676 tgt tok/s;     62 s elapsed
Epoch 10,   450/  454; acc:  81.21; ppl:   2.22; 5371 src tok/s; 5592 tgt tok/s;     69 s elapsed
Train perplexity: 2.22023
Train accuracy: 81.1661
Validation perplexity: 6.13468
Validation accuracy: 69.526
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  84.45; ppl:   1.90; 5438 src tok/s; 5655 tgt tok/s;      7 s elapsed
Epoch 11,   100/  454; acc:  82.67; ppl:   2.07; 5542 src tok/s; 5716 tgt tok/s;     15 s elapsed
Epoch 11,   150/  454; acc:  84.43; ppl:   1.89; 5497 src tok/s; 5735 tgt tok/s;     23 s elapsed
Epoch 11,   200/  454; acc:  82.07; ppl:   2.14; 5586 src tok/s; 5764 tgt tok/s;     30 s elapsed
Epoch 11,   250/  454; acc:  83.68; ppl:   1.99; 5450 src tok/s; 5672 tgt tok/s;     38 s elapsed
Epoch 11,   300/  454; acc:  82.99; ppl:   2.02; 5609 src tok/s; 5815 tgt tok/s;     46 s elapsed
Epoch 11,   350/  454; acc:  84.17; ppl:   1.89; 5482 src tok/s; 5764 tgt tok/s;     53 s elapsed
Epoch 11,   400/  454; acc:  82.41; ppl:   2.09; 5507 src tok/s; 5668 tgt tok/s;     61 s elapsed
Epoch 11,   450/  454; acc:  82.78; ppl:   2.05; 5265 src tok/s; 5460 tgt tok/s;     69 s elapsed
Train perplexity: 2.00537
Train accuracy: 83.2794
Validation perplexity: 6.31304
Validation accuracy: 69.5828
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  85.90; ppl:   1.78; 5513 src tok/s; 5707 tgt tok/s;      7 s elapsed
Epoch 12,   100/  454; acc:  83.33; ppl:   2.02; 5519 src tok/s; 5696 tgt tok/s;     15 s elapsed
Epoch 12,   150/  454; acc:  84.61; ppl:   1.90; 5395 src tok/s; 5609 tgt tok/s;     23 s elapsed
Epoch 12,   200/  454; acc:  84.23; ppl:   1.91; 5535 src tok/s; 5736 tgt tok/s;     31 s elapsed
Epoch 12,   250/  454; acc:  84.53; ppl:   1.88; 5431 src tok/s; 5653 tgt tok/s;     38 s elapsed
Epoch 12,   300/  454; acc:  83.75; ppl:   1.98; 5435 src tok/s; 5658 tgt tok/s;     46 s elapsed
Epoch 12,   350/  454; acc:  85.09; ppl:   1.85; 5299 src tok/s; 5512 tgt tok/s;     54 s elapsed
Epoch 12,   400/  454; acc:  83.91; ppl:   1.97; 5426 src tok/s; 5622 tgt tok/s;     62 s elapsed
Epoch 12,   450/  454; acc:  84.50; ppl:   1.89; 5350 src tok/s; 5558 tgt tok/s;     69 s elapsed
Train perplexity: 1.90791
Train accuracy: 84.4177
Validation perplexity: 6.42552
Validation accuracy: 69.2706
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  85.38; ppl:   1.82; 5415 src tok/s; 5631 tgt tok/s;      8 s elapsed
Epoch 13,   100/  454; acc:  84.72; ppl:   1.89; 5553 src tok/s; 5761 tgt tok/s;     15 s elapsed
Epoch 13,   150/  454; acc:  85.77; ppl:   1.78; 5633 src tok/s; 5846 tgt tok/s;     22 s elapsed
Epoch 13,   200/  454; acc:  84.18; ppl:   1.93; 5535 src tok/s; 5722 tgt tok/s;     31 s elapsed
Epoch 13,   250/  454; acc:  86.00; ppl:   1.75; 5443 src tok/s; 5670 tgt tok/s;     38 s elapsed
Epoch 13,   300/  454; acc:  83.77; ppl:   1.97; 5415 src tok/s; 5610 tgt tok/s;     46 s elapsed
Epoch 13,   350/  454; acc:  85.57; ppl:   1.80; 5411 src tok/s; 5639 tgt tok/s;     54 s elapsed
Epoch 13,   400/  454; acc:  84.50; ppl:   1.91; 5607 src tok/s; 5791 tgt tok/s;     62 s elapsed
Epoch 13,   450/  454; acc:  84.99; ppl:   1.85; 5395 src tok/s; 5610 tgt tok/s;     69 s elapsed
Train perplexity: 1.85792
Train accuracy: 84.9533
Validation perplexity: 6.48174
Validation accuracy: 69.448
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  84.92; ppl:   1.87; 5501 src tok/s; 5688 tgt tok/s;      8 s elapsed
Epoch 14,   100/  454; acc:  85.97; ppl:   1.78; 5464 src tok/s; 5678 tgt tok/s;     15 s elapsed
Epoch 14,   150/  454; acc:  85.25; ppl:   1.83; 5622 src tok/s; 5800 tgt tok/s;     23 s elapsed
Epoch 14,   200/  454; acc:  85.51; ppl:   1.83; 5349 src tok/s; 5571 tgt tok/s;     31 s elapsed
Epoch 14,   250/  454; acc:  85.01; ppl:   1.85; 5287 src tok/s; 5506 tgt tok/s;     38 s elapsed
Epoch 14,   300/  454; acc:  85.52; ppl:   1.81; 5505 src tok/s; 5726 tgt tok/s;     46 s elapsed
Epoch 14,   350/  454; acc:  84.84; ppl:   1.87; 5600 src tok/s; 5818 tgt tok/s;     54 s elapsed
Epoch 14,   400/  454; acc:  85.31; ppl:   1.82; 5504 src tok/s; 5707 tgt tok/s;     61 s elapsed
Epoch 14,   450/  454; acc:  84.96; ppl:   1.85; 5225 src tok/s; 5434 tgt tok/s;     69 s elapsed
Train perplexity: 1.83513
Train accuracy: 85.2328
Validation perplexity: 6.51733
Validation accuracy: 69.4409
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  86.61; ppl:   1.75; 5424 src tok/s; 5650 tgt tok/s;      8 s elapsed
Epoch 15,   100/  454; acc:  84.52; ppl:   1.90; 5414 src tok/s; 5608 tgt tok/s;     15 s elapsed
Epoch 15,   150/  454; acc:  85.11; ppl:   1.83; 5526 src tok/s; 5706 tgt tok/s;     23 s elapsed
Epoch 15,   200/  454; acc:  86.09; ppl:   1.76; 5553 src tok/s; 5760 tgt tok/s;     31 s elapsed
Epoch 15,   250/  454; acc:  84.65; ppl:   1.88; 5538 src tok/s; 5738 tgt tok/s;     39 s elapsed
Epoch 15,   300/  454; acc:  86.00; ppl:   1.77; 5482 src tok/s; 5755 tgt tok/s;     46 s elapsed
Epoch 15,   350/  454; acc:  84.89; ppl:   1.87; 5607 src tok/s; 5806 tgt tok/s;     53 s elapsed
Epoch 15,   400/  454; acc:  85.57; ppl:   1.79; 5626 src tok/s; 5840 tgt tok/s;     61 s elapsed
Epoch 15,   450/  454; acc:  84.59; ppl:   1.89; 5550 src tok/s; 5723 tgt tok/s;     68 s elapsed
Train perplexity: 1.82408
Train accuracy: 85.3524
Validation perplexity: 6.52734
Validation accuracy: 69.377
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.49; ppl:   1.81; 5449 src tok/s; 5644 tgt tok/s;      8 s elapsed
Epoch 16,   100/  454; acc:  85.45; ppl:   1.83; 5308 src tok/s; 5560 tgt tok/s;     16 s elapsed
Epoch 16,   150/  454; acc:  85.43; ppl:   1.82; 5613 src tok/s; 5801 tgt tok/s;     23 s elapsed
Epoch 16,   200/  454; acc:  85.58; ppl:   1.79; 5515 src tok/s; 5760 tgt tok/s;     31 s elapsed
Epoch 16,   250/  454; acc:  85.29; ppl:   1.83; 5494 src tok/s; 5702 tgt tok/s;     38 s elapsed
Epoch 16,   300/  454; acc:  85.45; ppl:   1.84; 5521 src tok/s; 5704 tgt tok/s;     46 s elapsed
Epoch 16,   350/  454; acc:  85.22; ppl:   1.84; 5538 src tok/s; 5737 tgt tok/s;     54 s elapsed
Epoch 16,   400/  454; acc:  86.05; ppl:   1.77; 5627 src tok/s; 5818 tgt tok/s;     61 s elapsed
Epoch 16,   450/  454; acc:  85.18; ppl:   1.84; 5454 src tok/s; 5661 tgt tok/s;     69 s elapsed
Train perplexity: 1.81872
Train accuracy: 85.4679
Validation perplexity: 6.54217
Validation accuracy: 69.2848
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.57; ppl:   1.80; 5457 src tok/s; 5660 tgt tok/s;      8 s elapsed
Epoch 17,   100/  454; acc:  85.34; ppl:   1.83; 5524 src tok/s; 5706 tgt tok/s;     15 s elapsed
Epoch 17,   150/  454; acc:  85.56; ppl:   1.83; 5460 src tok/s; 5699 tgt tok/s;     23 s elapsed
Epoch 17,   200/  454; acc:  85.91; ppl:   1.78; 5530 src tok/s; 5722 tgt tok/s;     31 s elapsed
Epoch 17,   250/  454; acc:  85.03; ppl:   1.86; 5536 src tok/s; 5746 tgt tok/s;     38 s elapsed
Epoch 17,   300/  454; acc:  86.05; ppl:   1.74; 5631 src tok/s; 5837 tgt tok/s;     46 s elapsed
Epoch 17,   350/  454; acc:  85.12; ppl:   1.84; 5647 src tok/s; 5837 tgt tok/s;     53 s elapsed
Epoch 17,   400/  454; acc:  85.39; ppl:   1.82; 5424 src tok/s; 5652 tgt tok/s;     61 s elapsed
Epoch 17,   450/  454; acc:  85.25; ppl:   1.84; 5382 src tok/s; 5618 tgt tok/s;     68 s elapsed
Train perplexity: 1.81678
Train accuracy: 85.4589
Validation perplexity: 6.54677
Validation accuracy: 69.2919
Decaying learning rate to 0.000976562
