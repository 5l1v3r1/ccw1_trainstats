<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.25, kappa_enc=0.25, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.25decoder0.25dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.25)
('Using Kappa L2 loss on decoder', 0.25)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   9.10; ppl: 13047.94; 2670 src tok/s; 2765 tgt tok/s;     16 s elapsed
Epoch  1,   100/  454; acc:  15.10; ppl: 1115.31; 3361 src tok/s; 3499 tgt tok/s;     28 s elapsed
Epoch  1,   150/  454; acc:  19.25; ppl: 398.51; 3413 src tok/s; 3541 tgt tok/s;     40 s elapsed
Epoch  1,   200/  454; acc:  21.72; ppl: 249.21; 3302 src tok/s; 3420 tgt tok/s;     53 s elapsed
Epoch  1,   250/  454; acc:  25.57; ppl: 162.66; 3389 src tok/s; 3531 tgt tok/s;     65 s elapsed
Epoch  1,   300/  454; acc:  27.14; ppl: 122.16; 3335 src tok/s; 3449 tgt tok/s;     78 s elapsed
Epoch  1,   350/  454; acc:  29.38; ppl:  97.14; 3354 src tok/s; 3470 tgt tok/s;     91 s elapsed
Epoch  1,   400/  454; acc:  31.76; ppl:  78.23; 3297 src tok/s; 3433 tgt tok/s;    103 s elapsed
Epoch  1,   450/  454; acc:  33.15; ppl:  68.42; 3297 src tok/s; 3420 tgt tok/s;    116 s elapsed
Train perplexity: 287.795
Train accuracy: 23.6646
Validation perplexity: 55.5788
Validation accuracy: 36.8738

Epoch  2,    50/  454; acc:  35.59; ppl:  55.11; 3291 src tok/s; 3408 tgt tok/s;     13 s elapsed
Epoch  2,   100/  454; acc:  39.41; ppl:  43.44; 3325 src tok/s; 3461 tgt tok/s;     25 s elapsed
Epoch  2,   150/  454; acc:  41.20; ppl:  37.27; 3234 src tok/s; 3355 tgt tok/s;     38 s elapsed
Epoch  2,   200/  454; acc:  43.14; ppl:  32.16; 3341 src tok/s; 3441 tgt tok/s;     51 s elapsed
Epoch  2,   250/  454; acc:  44.91; ppl:  28.23; 3223 src tok/s; 3354 tgt tok/s;     64 s elapsed
Epoch  2,   300/  454; acc:  48.07; ppl:  23.37; 3314 src tok/s; 3458 tgt tok/s;     77 s elapsed
Epoch  2,   350/  454; acc:  48.25; ppl:  22.84; 3269 src tok/s; 3395 tgt tok/s;     90 s elapsed
Epoch  2,   400/  454; acc:  50.14; ppl:  20.21; 3240 src tok/s; 3359 tgt tok/s;    102 s elapsed
Epoch  2,   450/  454; acc:  50.99; ppl:  19.28; 3262 src tok/s; 3378 tgt tok/s;    115 s elapsed
Train perplexity: 29.3793
Train accuracy: 44.6826
Validation perplexity: 17.105
Validation accuracy: 51.6745

Epoch  3,    50/  454; acc:  54.08; ppl:  14.91; 3270 src tok/s; 3382 tgt tok/s;     13 s elapsed
Epoch  3,   100/  454; acc:  55.01; ppl:  14.43; 3266 src tok/s; 3403 tgt tok/s;     26 s elapsed
Epoch  3,   150/  454; acc:  55.78; ppl:  13.34; 3232 src tok/s; 3362 tgt tok/s;     38 s elapsed
Epoch  3,   200/  454; acc:  55.56; ppl:  13.16; 3330 src tok/s; 3434 tgt tok/s;     51 s elapsed
Epoch  3,   250/  454; acc:  57.31; ppl:  12.13; 3263 src tok/s; 3398 tgt tok/s;     64 s elapsed
Epoch  3,   300/  454; acc:  57.22; ppl:  12.03; 3233 src tok/s; 3348 tgt tok/s;     77 s elapsed
Epoch  3,   350/  454; acc:  58.19; ppl:  11.52; 3195 src tok/s; 3320 tgt tok/s;     90 s elapsed
Epoch  3,   400/  454; acc:  58.47; ppl:  10.94; 3227 src tok/s; 3341 tgt tok/s;    103 s elapsed
Epoch  3,   450/  454; acc:  58.94; ppl:  10.73; 3178 src tok/s; 3307 tgt tok/s;    116 s elapsed
Train perplexity: 12.462
Train accuracy: 56.7759
Validation perplexity: 9.95785
Validation accuracy: 60.9834

Epoch  4,    50/  454; acc:  62.54; ppl:   8.10; 3287 src tok/s; 3417 tgt tok/s;     13 s elapsed
Epoch  4,   100/  454; acc:  61.23; ppl:   8.79; 3217 src tok/s; 3338 tgt tok/s;     26 s elapsed
Epoch  4,   150/  454; acc:  61.88; ppl:   8.35; 3238 src tok/s; 3358 tgt tok/s;     39 s elapsed
Epoch  4,   200/  454; acc:  62.21; ppl:   8.20; 3202 src tok/s; 3335 tgt tok/s;     52 s elapsed
Epoch  4,   250/  454; acc:  63.72; ppl:   7.51; 3200 src tok/s; 3332 tgt tok/s;     64 s elapsed
Epoch  4,   300/  454; acc:  60.75; ppl:   8.70; 3191 src tok/s; 3294 tgt tok/s;     78 s elapsed
Epoch  4,   350/  454; acc:  63.03; ppl:   7.88; 3243 src tok/s; 3374 tgt tok/s;     91 s elapsed
Epoch  4,   400/  454; acc:  62.71; ppl:   7.92; 3244 src tok/s; 3367 tgt tok/s;    104 s elapsed
Epoch  4,   450/  454; acc:  62.43; ppl:   8.02; 3201 src tok/s; 3304 tgt tok/s;    117 s elapsed
Train perplexity: 8.14597
Train accuracy: 62.2952
Validation perplexity: 8.04123
Validation accuracy: 63.8782

Epoch  5,    50/  454; acc:  67.25; ppl:   5.69; 3308 src tok/s; 3442 tgt tok/s;     12 s elapsed
Epoch  5,   100/  454; acc:  64.46; ppl:   6.55; 3237 src tok/s; 3341 tgt tok/s;     26 s elapsed
Epoch  5,   150/  454; acc:  65.45; ppl:   6.18; 3272 src tok/s; 3375 tgt tok/s;     39 s elapsed
Epoch  5,   200/  454; acc:  66.41; ppl:   5.92; 3067 src tok/s; 3232 tgt tok/s;     52 s elapsed
Epoch  5,   250/  454; acc:  65.93; ppl:   6.01; 3208 src tok/s; 3309 tgt tok/s;     65 s elapsed
Epoch  5,   300/  454; acc:  65.81; ppl:   6.18; 3250 src tok/s; 3370 tgt tok/s;     78 s elapsed
Epoch  5,   350/  454; acc:  65.86; ppl:   6.09; 3229 src tok/s; 3353 tgt tok/s;     91 s elapsed
Epoch  5,   400/  454; acc:  65.25; ppl:   6.39; 3210 src tok/s; 3330 tgt tok/s;    104 s elapsed
Epoch  5,   450/  454; acc:  65.45; ppl:   6.26; 3142 src tok/s; 3266 tgt tok/s;    117 s elapsed
Train perplexity: 6.14522
Train accuracy: 65.739
Validation perplexity: 7.11044
Validation accuracy: 66.1558

Epoch  6,    50/  454; acc:  68.98; ppl:   4.66; 3283 src tok/s; 3413 tgt tok/s;     13 s elapsed
Epoch  6,   100/  454; acc:  68.61; ppl:   4.87; 3242 src tok/s; 3356 tgt tok/s;     26 s elapsed
Epoch  6,   150/  454; acc:  68.26; ppl:   5.03; 3233 src tok/s; 3340 tgt tok/s;     39 s elapsed
Epoch  6,   200/  454; acc:  68.22; ppl:   4.99; 3173 src tok/s; 3298 tgt tok/s;     52 s elapsed
Epoch  6,   250/  454; acc:  68.30; ppl:   4.96; 3226 src tok/s; 3352 tgt tok/s;     65 s elapsed
Epoch  6,   300/  454; acc:  68.11; ppl:   5.02; 3180 src tok/s; 3302 tgt tok/s;     78 s elapsed
Epoch  6,   350/  454; acc:  69.06; ppl:   4.70; 3197 src tok/s; 3329 tgt tok/s;     91 s elapsed
Epoch  6,   400/  454; acc:  67.22; ppl:   5.29; 3184 src tok/s; 3298 tgt tok/s;    105 s elapsed
Epoch  6,   450/  454; acc:  67.67; ppl:   5.20; 3087 src tok/s; 3206 tgt tok/s;    118 s elapsed
Train perplexity: 4.9602
Train accuracy: 68.2829
Validation perplexity: 6.68199
Validation accuracy: 67.1846

Epoch  7,    50/  454; acc:  71.24; ppl:   4.03; 3184 src tok/s; 3317 tgt tok/s;     13 s elapsed
Epoch  7,   100/  454; acc:  71.03; ppl:   3.95; 3249 src tok/s; 3377 tgt tok/s;     26 s elapsed
Epoch  7,   150/  454; acc:  70.27; ppl:   4.21; 3208 src tok/s; 3315 tgt tok/s;     40 s elapsed
Epoch  7,   200/  454; acc:  71.03; ppl:   4.07; 3146 src tok/s; 3276 tgt tok/s;     53 s elapsed
Epoch  7,   250/  454; acc:  70.19; ppl:   4.17; 3158 src tok/s; 3278 tgt tok/s;     66 s elapsed
Epoch  7,   300/  454; acc:  70.48; ppl:   4.16; 3226 src tok/s; 3353 tgt tok/s;     79 s elapsed
Epoch  7,   350/  454; acc:  68.98; ppl:   4.55; 3197 src tok/s; 3299 tgt tok/s;     93 s elapsed
Epoch  7,   400/  454; acc:  71.02; ppl:   4.02; 3152 src tok/s; 3279 tgt tok/s;    105 s elapsed
Epoch  7,   450/  454; acc:  69.05; ppl:   4.44; 3164 src tok/s; 3280 tgt tok/s;    118 s elapsed
Train perplexity: 4.17296
Train accuracy: 70.3631
Validation perplexity: 6.54157
Validation accuracy: 67.2485

Epoch  8,    50/  454; acc:  74.44; ppl:   3.20; 3218 src tok/s; 3344 tgt tok/s;     13 s elapsed
Epoch  8,   100/  454; acc:  71.82; ppl:   3.72; 3202 src tok/s; 3313 tgt tok/s;     26 s elapsed
Epoch  8,   150/  454; acc:  72.45; ppl:   3.53; 3274 src tok/s; 3388 tgt tok/s;     39 s elapsed
Epoch  8,   200/  454; acc:  71.76; ppl:   3.71; 3146 src tok/s; 3269 tgt tok/s;     53 s elapsed
Epoch  8,   250/  454; acc:  72.23; ppl:   3.63; 3268 src tok/s; 3364 tgt tok/s;     66 s elapsed
Epoch  8,   300/  454; acc:  71.94; ppl:   3.62; 3145 src tok/s; 3279 tgt tok/s;     79 s elapsed
Epoch  8,   350/  454; acc:  70.56; ppl:   3.97; 3198 src tok/s; 3303 tgt tok/s;     92 s elapsed
Epoch  8,   400/  454; acc:  73.61; ppl:   3.38; 3210 src tok/s; 3374 tgt tok/s;    105 s elapsed
Epoch  8,   450/  454; acc:  71.39; ppl:   3.75; 3162 src tok/s; 3295 tgt tok/s;    117 s elapsed
Train perplexity: 3.61822
Train accuracy: 72.1819
Validation perplexity: 6.48144
Validation accuracy: 67.2769
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.60; ppl:   2.80; 3229 src tok/s; 3355 tgt tok/s;     13 s elapsed
Epoch  9,   100/  454; acc:  77.33; ppl:   2.70; 3187 src tok/s; 3318 tgt tok/s;     26 s elapsed
Epoch  9,   150/  454; acc:  76.23; ppl:   2.88; 3267 src tok/s; 3357 tgt tok/s;     40 s elapsed
Epoch  9,   200/  454; acc:  79.03; ppl:   2.47; 3185 src tok/s; 3339 tgt tok/s;     52 s elapsed
Epoch  9,   250/  454; acc:  76.31; ppl:   2.85; 3166 src tok/s; 3273 tgt tok/s;     66 s elapsed
Epoch  9,   300/  454; acc:  77.83; ppl:   2.59; 3205 src tok/s; 3348 tgt tok/s;     79 s elapsed
Epoch  9,   350/  454; acc:  77.24; ppl:   2.71; 3230 src tok/s; 3325 tgt tok/s;     92 s elapsed
Epoch  9,   400/  454; acc:  77.63; ppl:   2.65; 3165 src tok/s; 3302 tgt tok/s;    105 s elapsed
Epoch  9,   450/  454; acc:  76.95; ppl:   2.73; 3163 src tok/s; 3281 tgt tok/s;    118 s elapsed
Train perplexity: 2.71116
Train accuracy: 77.2011
Validation perplexity: 6.00317
Validation accuracy: 69.0861
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.11; ppl:   2.35; 3211 src tok/s; 3323 tgt tok/s;     14 s elapsed
Epoch 10,   100/  454; acc:  82.22; ppl:   2.09; 3237 src tok/s; 3384 tgt tok/s;     26 s elapsed
Epoch 10,   150/  454; acc:  82.27; ppl:   2.09; 3199 src tok/s; 3345 tgt tok/s;     39 s elapsed
Epoch 10,   200/  454; acc:  80.39; ppl:   2.33; 3214 src tok/s; 3336 tgt tok/s;     52 s elapsed
Epoch 10,   250/  454; acc:  81.33; ppl:   2.18; 3190 src tok/s; 3334 tgt tok/s;     65 s elapsed
Epoch 10,   300/  454; acc:  80.72; ppl:   2.28; 3235 src tok/s; 3339 tgt tok/s;     78 s elapsed
Epoch 10,   350/  454; acc:  80.57; ppl:   2.30; 3197 src tok/s; 3296 tgt tok/s;     92 s elapsed
Epoch 10,   400/  454; acc:  81.25; ppl:   2.16; 3168 src tok/s; 3274 tgt tok/s;    105 s elapsed
Epoch 10,   450/  454; acc:  80.36; ppl:   2.29; 3124 src tok/s; 3239 tgt tok/s;    118 s elapsed
Train perplexity: 2.23042
Train accuracy: 81.0125
Validation perplexity: 6.18029
Validation accuracy: 69.6254
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.90; ppl:   1.95; 3280 src tok/s; 3414 tgt tok/s;     13 s elapsed
Epoch 11,   100/  454; acc:  83.11; ppl:   2.04; 3204 src tok/s; 3304 tgt tok/s;     26 s elapsed
Epoch 11,   150/  454; acc:  84.43; ppl:   1.90; 3198 src tok/s; 3331 tgt tok/s;     38 s elapsed
Epoch 11,   200/  454; acc:  82.04; ppl:   2.14; 3243 src tok/s; 3348 tgt tok/s;     52 s elapsed
Epoch 11,   250/  454; acc:  83.41; ppl:   1.96; 3184 src tok/s; 3314 tgt tok/s;     65 s elapsed
Epoch 11,   300/  454; acc:  83.25; ppl:   2.00; 3129 src tok/s; 3256 tgt tok/s;     78 s elapsed
Epoch 11,   350/  454; acc:  81.61; ppl:   2.15; 3172 src tok/s; 3271 tgt tok/s;     92 s elapsed
Epoch 11,   400/  454; acc:  83.36; ppl:   1.99; 3173 src tok/s; 3320 tgt tok/s;    105 s elapsed
Epoch 11,   450/  454; acc:  83.05; ppl:   2.02; 3177 src tok/s; 3294 tgt tok/s;    118 s elapsed
Train perplexity: 2.01578
Train accuracy: 83.1256
Validation perplexity: 6.35192
Validation accuracy: 69.2777
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  85.16; ppl:   1.84; 3205 src tok/s; 3346 tgt tok/s;     12 s elapsed
Epoch 12,   100/  454; acc:  83.92; ppl:   1.95; 3229 src tok/s; 3343 tgt tok/s;     26 s elapsed
Epoch 12,   150/  454; acc:  83.76; ppl:   1.95; 3147 src tok/s; 3269 tgt tok/s;     39 s elapsed
Epoch 12,   200/  454; acc:  83.92; ppl:   1.95; 3192 src tok/s; 3327 tgt tok/s;     53 s elapsed
Epoch 12,   250/  454; acc:  85.42; ppl:   1.81; 3202 src tok/s; 3343 tgt tok/s;     65 s elapsed
Epoch 12,   300/  454; acc:  83.21; ppl:   2.02; 3212 src tok/s; 3298 tgt tok/s;     79 s elapsed
Epoch 12,   350/  454; acc:  84.63; ppl:   1.89; 3168 src tok/s; 3298 tgt tok/s;     92 s elapsed
Epoch 12,   400/  454; acc:  83.97; ppl:   1.93; 3197 src tok/s; 3301 tgt tok/s;    105 s elapsed
Epoch 12,   450/  454; acc:  84.22; ppl:   1.90; 3169 src tok/s; 3283 tgt tok/s;    118 s elapsed
Train perplexity: 1.91618
Train accuracy: 84.2352
Validation perplexity: 6.46027
Validation accuracy: 69.2493
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.75; ppl:   1.90; 3151 src tok/s; 3281 tgt tok/s;     13 s elapsed
Epoch 13,   100/  454; acc:  85.07; ppl:   1.85; 3176 src tok/s; 3299 tgt tok/s;     27 s elapsed
Epoch 13,   150/  454; acc:  84.60; ppl:   1.89; 3265 src tok/s; 3383 tgt tok/s;     40 s elapsed
Epoch 13,   200/  454; acc:  85.51; ppl:   1.81; 3161 src tok/s; 3298 tgt tok/s;     53 s elapsed
Epoch 13,   250/  454; acc:  84.20; ppl:   1.92; 3190 src tok/s; 3306 tgt tok/s;     66 s elapsed
Epoch 13,   300/  454; acc:  84.90; ppl:   1.85; 3182 src tok/s; 3305 tgt tok/s;     79 s elapsed
Epoch 13,   350/  454; acc:  85.31; ppl:   1.82; 3206 src tok/s; 3312 tgt tok/s;     92 s elapsed
Epoch 13,   400/  454; acc:  84.50; ppl:   1.90; 3182 src tok/s; 3300 tgt tok/s;    105 s elapsed
Epoch 13,   450/  454; acc:  84.60; ppl:   1.86; 3220 src tok/s; 3333 tgt tok/s;    118 s elapsed
Train perplexity: 1.86958
Train accuracy: 84.7981
Validation perplexity: 6.50864
Validation accuracy: 69.2138
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.15; ppl:   1.84; 3242 src tok/s; 3364 tgt tok/s;     13 s elapsed
Epoch 14,   100/  454; acc:  85.54; ppl:   1.81; 3129 src tok/s; 3248 tgt tok/s;     26 s elapsed
Epoch 14,   150/  454; acc:  85.00; ppl:   1.84; 3221 src tok/s; 3365 tgt tok/s;     39 s elapsed
Epoch 14,   200/  454; acc:  85.02; ppl:   1.85; 3189 src tok/s; 3307 tgt tok/s;     52 s elapsed
Epoch 14,   250/  454; acc:  85.18; ppl:   1.85; 3170 src tok/s; 3291 tgt tok/s;     65 s elapsed
Epoch 14,   300/  454; acc:  85.09; ppl:   1.85; 3195 src tok/s; 3303 tgt tok/s;     79 s elapsed
Epoch 14,   350/  454; acc:  85.60; ppl:   1.81; 3156 src tok/s; 3297 tgt tok/s;     91 s elapsed
Epoch 14,   400/  454; acc:  84.60; ppl:   1.91; 3181 src tok/s; 3279 tgt tok/s;    105 s elapsed
Epoch 14,   450/  454; acc:  84.79; ppl:   1.87; 3171 src tok/s; 3286 tgt tok/s;    118 s elapsed
Train perplexity: 1.84454
Train accuracy: 85.1287
Validation perplexity: 6.54161
Validation accuracy: 69.1713
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.45; ppl:   1.82; 3222 src tok/s; 3342 tgt tok/s;     13 s elapsed
Epoch 15,   100/  454; acc:  85.46; ppl:   1.81; 3177 src tok/s; 3317 tgt tok/s;     26 s elapsed
Epoch 15,   150/  454; acc:  84.92; ppl:   1.85; 3194 src tok/s; 3302 tgt tok/s;     39 s elapsed
Epoch 15,   200/  454; acc:  85.48; ppl:   1.80; 3252 src tok/s; 3363 tgt tok/s;     52 s elapsed
Epoch 15,   250/  454; acc:  85.94; ppl:   1.77; 3135 src tok/s; 3290 tgt tok/s;     65 s elapsed
Epoch 15,   300/  454; acc:  84.48; ppl:   1.90; 3239 src tok/s; 3353 tgt tok/s;     79 s elapsed
Epoch 15,   350/  454; acc:  84.22; ppl:   1.92; 3188 src tok/s; 3293 tgt tok/s;     92 s elapsed
Epoch 15,   400/  454; acc:  86.48; ppl:   1.74; 3139 src tok/s; 3259 tgt tok/s;    105 s elapsed
Epoch 15,   450/  454; acc:  84.74; ppl:   1.88; 3155 src tok/s; 3260 tgt tok/s;    118 s elapsed
Train perplexity: 1.83122
Train accuracy: 85.2458
Validation perplexity: 6.55737
Validation accuracy: 69.2138
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.65; ppl:   1.79; 3220 src tok/s; 3347 tgt tok/s;     13 s elapsed
Epoch 16,   100/  454; acc:  84.83; ppl:   1.88; 3185 src tok/s; 3303 tgt tok/s;     26 s elapsed
Epoch 16,   150/  454; acc:  85.67; ppl:   1.79; 3239 src tok/s; 3368 tgt tok/s;     39 s elapsed
Epoch 16,   200/  454; acc:  85.27; ppl:   1.85; 3166 src tok/s; 3278 tgt tok/s;     52 s elapsed
Epoch 16,   250/  454; acc:  85.39; ppl:   1.82; 3104 src tok/s; 3237 tgt tok/s;     66 s elapsed
Epoch 16,   300/  454; acc:  84.80; ppl:   1.85; 3215 src tok/s; 3324 tgt tok/s;     79 s elapsed
Epoch 16,   350/  454; acc:  84.83; ppl:   1.88; 3184 src tok/s; 3279 tgt tok/s;     93 s elapsed
Epoch 16,   400/  454; acc:  85.97; ppl:   1.77; 3165 src tok/s; 3302 tgt tok/s;    105 s elapsed
Epoch 16,   450/  454; acc:  86.25; ppl:   1.76; 3168 src tok/s; 3303 tgt tok/s;    118 s elapsed
Train perplexity: 1.82569
Train accuracy: 85.3455
Validation perplexity: 6.56409
Validation accuracy: 69.228
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  84.83; ppl:   1.86; 3168 src tok/s; 3280 tgt tok/s;     14 s elapsed
Epoch 17,   100/  454; acc:  85.71; ppl:   1.77; 3205 src tok/s; 3335 tgt tok/s;     26 s elapsed
Epoch 17,   150/  454; acc:  84.60; ppl:   1.89; 3217 src tok/s; 3314 tgt tok/s;     40 s elapsed
Epoch 17,   200/  454; acc:  86.41; ppl:   1.73; 3183 src tok/s; 3327 tgt tok/s;     52 s elapsed
Epoch 17,   250/  454; acc:  86.07; ppl:   1.76; 3181 src tok/s; 3319 tgt tok/s;     65 s elapsed
Epoch 17,   300/  454; acc:  84.79; ppl:   1.87; 3224 src tok/s; 3337 tgt tok/s;     79 s elapsed
Epoch 17,   350/  454; acc:  85.45; ppl:   1.82; 3147 src tok/s; 3259 tgt tok/s;     92 s elapsed
Epoch 17,   400/  454; acc:  85.50; ppl:   1.82; 3176 src tok/s; 3306 tgt tok/s;    105 s elapsed
Epoch 17,   450/  454; acc:  85.35; ppl:   1.84; 3141 src tok/s; 3256 tgt tok/s;    118 s elapsed
Train perplexity: 1.82224
Train accuracy: 85.3674
Validation perplexity: 6.56849
Validation accuracy: 69.1713
Decaying learning rate to 0.000976562
