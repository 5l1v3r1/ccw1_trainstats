<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.1, kappa_enc=0.2, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.20decoder0.1dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.2)
('Using Kappa L2 loss on decoder', 0.1)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   7.39; ppl: 22451.12; 2657 src tok/s; 2764 tgt tok/s;     16 s elapsed
Epoch  1,   100/  454; acc:  13.93; ppl: 2030.83; 2842 src tok/s; 2935 tgt tok/s;     31 s elapsed
Epoch  1,   150/  454; acc:  16.48; ppl: 648.22; 2822 src tok/s; 2919 tgt tok/s;     46 s elapsed
Epoch  1,   200/  454; acc:  20.70; ppl: 297.57; 2834 src tok/s; 2951 tgt tok/s;     60 s elapsed
Epoch  1,   250/  454; acc:  24.03; ppl: 199.46; 2845 src tok/s; 2937 tgt tok/s;     76 s elapsed
Epoch  1,   300/  454; acc:  27.52; ppl: 128.57; 2814 src tok/s; 2943 tgt tok/s;     90 s elapsed
Epoch  1,   350/  454; acc:  29.16; ppl: 104.02; 2886 src tok/s; 3009 tgt tok/s;    105 s elapsed
Epoch  1,   400/  454; acc:  31.42; ppl:  83.91; 2796 src tok/s; 2898 tgt tok/s;    119 s elapsed
Epoch  1,   450/  454; acc:  34.06; ppl:  66.34; 2745 src tok/s; 2841 tgt tok/s;    134 s elapsed
Train perplexity: 366.817
Train accuracy: 22.8141
Validation perplexity: 67.3862
Validation accuracy: 34.1067

Epoch  2,    50/  454; acc:  35.98; ppl:  54.94; 2822 src tok/s; 2920 tgt tok/s;     15 s elapsed
Epoch  2,   100/  454; acc:  38.08; ppl:  47.48; 2822 src tok/s; 2933 tgt tok/s;     30 s elapsed
Epoch  2,   150/  454; acc:  39.98; ppl:  40.27; 2794 src tok/s; 2891 tgt tok/s;     45 s elapsed
Epoch  2,   200/  454; acc:  44.04; ppl:  29.84; 2854 src tok/s; 2962 tgt tok/s;     60 s elapsed
Epoch  2,   250/  454; acc:  45.55; ppl:  28.33; 2835 src tok/s; 2938 tgt tok/s;     74 s elapsed
Epoch  2,   300/  454; acc:  45.93; ppl:  26.92; 2703 src tok/s; 2813 tgt tok/s;     90 s elapsed
Epoch  2,   350/  454; acc:  49.69; ppl:  21.02; 2762 src tok/s; 2900 tgt tok/s;    104 s elapsed
Epoch  2,   400/  454; acc:  48.92; ppl:  21.58; 2891 src tok/s; 2979 tgt tok/s;    119 s elapsed
Epoch  2,   450/  454; acc:  50.61; ppl:  19.22; 2812 src tok/s; 2916 tgt tok/s;    134 s elapsed
Train perplexity: 30.1079
Train accuracy: 44.3597
Validation perplexity: 15.3385
Validation accuracy: 54.619

Epoch  3,    50/  454; acc:  55.61; ppl:  13.66; 2831 src tok/s; 2943 tgt tok/s;     14 s elapsed
Epoch  3,   100/  454; acc:  53.53; ppl:  15.11; 2810 src tok/s; 2904 tgt tok/s;     30 s elapsed
Epoch  3,   150/  454; acc:  54.87; ppl:  14.51; 2791 src tok/s; 2900 tgt tok/s;     45 s elapsed
Epoch  3,   200/  454; acc:  55.70; ppl:  13.21; 2843 src tok/s; 2957 tgt tok/s;     59 s elapsed
Epoch  3,   250/  454; acc:  55.54; ppl:  13.24; 2855 src tok/s; 2946 tgt tok/s;     74 s elapsed
Epoch  3,   300/  454; acc:  57.96; ppl:  11.77; 2793 src tok/s; 2907 tgt tok/s;     89 s elapsed
Epoch  3,   350/  454; acc:  58.42; ppl:  11.09; 2881 src tok/s; 2998 tgt tok/s;    103 s elapsed
Epoch  3,   400/  454; acc:  57.99; ppl:  11.39; 2793 src tok/s; 2898 tgt tok/s;    119 s elapsed
Epoch  3,   450/  454; acc:  58.88; ppl:  10.99; 2788 src tok/s; 2902 tgt tok/s;    133 s elapsed
Train perplexity: 12.7141
Train accuracy: 56.4715
Validation perplexity: 10.6496
Validation accuracy: 59.8553

Epoch  4,    50/  454; acc:  60.62; ppl:   8.96; 2836 src tok/s; 2936 tgt tok/s;     15 s elapsed
Epoch  4,   100/  454; acc:  61.97; ppl:   8.54; 2776 src tok/s; 2889 tgt tok/s;     30 s elapsed
Epoch  4,   150/  454; acc:  62.44; ppl:   8.07; 2733 src tok/s; 2842 tgt tok/s;     44 s elapsed
Epoch  4,   200/  454; acc:  61.17; ppl:   8.71; 2869 src tok/s; 2959 tgt tok/s;     60 s elapsed
Epoch  4,   250/  454; acc:  60.72; ppl:   9.09; 2771 src tok/s; 2868 tgt tok/s;     75 s elapsed
Epoch  4,   300/  454; acc:  62.89; ppl:   7.84; 2799 src tok/s; 2922 tgt tok/s;     90 s elapsed
Epoch  4,   350/  454; acc:  62.93; ppl:   7.88; 2837 src tok/s; 2945 tgt tok/s;    104 s elapsed
Epoch  4,   400/  454; acc:  62.13; ppl:   8.24; 2853 src tok/s; 2962 tgt tok/s;    120 s elapsed
Epoch  4,   450/  454; acc:  63.66; ppl:   7.36; 2821 src tok/s; 2945 tgt tok/s;    134 s elapsed
Train perplexity: 8.32074
Train accuracy: 61.9594
Validation perplexity: 8.35337
Validation accuracy: 62.9417

Epoch  5,    50/  454; acc:  66.26; ppl:   6.02; 2797 src tok/s; 2924 tgt tok/s;     14 s elapsed
Epoch  5,   100/  454; acc:  64.93; ppl:   6.33; 2792 src tok/s; 2891 tgt tok/s;     30 s elapsed
Epoch  5,   150/  454; acc:  64.57; ppl:   6.58; 2791 src tok/s; 2910 tgt tok/s;     45 s elapsed
Epoch  5,   200/  454; acc:  66.02; ppl:   5.95; 2880 src tok/s; 2967 tgt tok/s;     59 s elapsed
Epoch  5,   250/  454; acc:  64.93; ppl:   6.52; 2791 src tok/s; 2900 tgt tok/s;     75 s elapsed
Epoch  5,   300/  454; acc:  65.59; ppl:   6.30; 2809 src tok/s; 2918 tgt tok/s;     90 s elapsed
Epoch  5,   350/  454; acc:  65.02; ppl:   6.41; 2835 src tok/s; 2935 tgt tok/s;    105 s elapsed
Epoch  5,   400/  454; acc:  66.42; ppl:   6.01; 2848 src tok/s; 2967 tgt tok/s;    119 s elapsed
Epoch  5,   450/  454; acc:  65.58; ppl:   6.22; 2818 src tok/s; 2915 tgt tok/s;    134 s elapsed
Train perplexity: 6.25681
Train accuracy: 65.474
Validation perplexity: 7.3478
Validation accuracy: 64.9567

Epoch  6,    50/  454; acc:  69.79; ppl:   4.49; 2786 src tok/s; 2922 tgt tok/s;     14 s elapsed
Epoch  6,   100/  454; acc:  66.93; ppl:   5.38; 2825 src tok/s; 2916 tgt tok/s;     30 s elapsed
Epoch  6,   150/  454; acc:  68.45; ppl:   5.01; 2849 src tok/s; 2949 tgt tok/s;     45 s elapsed
Epoch  6,   200/  454; acc:  68.08; ppl:   4.94; 2821 src tok/s; 2930 tgt tok/s;     60 s elapsed
Epoch  6,   250/  454; acc:  68.36; ppl:   4.96; 2774 src tok/s; 2912 tgt tok/s;     74 s elapsed
Epoch  6,   300/  454; acc:  66.82; ppl:   5.36; 2836 src tok/s; 2922 tgt tok/s;     89 s elapsed
Epoch  6,   350/  454; acc:  67.89; ppl:   5.15; 2816 src tok/s; 2892 tgt tok/s;    105 s elapsed
Epoch  6,   400/  454; acc:  68.35; ppl:   4.96; 2774 src tok/s; 2901 tgt tok/s;    120 s elapsed
Epoch  6,   450/  454; acc:  67.99; ppl:   5.07; 2791 src tok/s; 2889 tgt tok/s;    134 s elapsed
Train perplexity: 5.0313
Train accuracy: 68.0642
Validation perplexity: 6.86149
Validation accuracy: 65.8933

Epoch  7,    50/  454; acc:  72.01; ppl:   3.80; 2807 src tok/s; 2914 tgt tok/s;     15 s elapsed
Epoch  7,   100/  454; acc:  70.31; ppl:   4.18; 2839 src tok/s; 2952 tgt tok/s;     30 s elapsed
Epoch  7,   150/  454; acc:  71.01; ppl:   4.09; 2730 src tok/s; 2867 tgt tok/s;     44 s elapsed
Epoch  7,   200/  454; acc:  70.16; ppl:   4.31; 2867 src tok/s; 2948 tgt tok/s;     60 s elapsed
Epoch  7,   250/  454; acc:  69.57; ppl:   4.35; 2868 src tok/s; 2956 tgt tok/s;     75 s elapsed
Epoch  7,   300/  454; acc:  70.69; ppl:   4.11; 2773 src tok/s; 2891 tgt tok/s;     89 s elapsed
Epoch  7,   350/  454; acc:  70.36; ppl:   4.21; 2767 src tok/s; 2889 tgt tok/s;    104 s elapsed
Epoch  7,   400/  454; acc:  69.15; ppl:   4.51; 2810 src tok/s; 2903 tgt tok/s;    120 s elapsed
Epoch  7,   450/  454; acc:  69.42; ppl:   4.46; 2764 src tok/s; 2858 tgt tok/s;    135 s elapsed
Train perplexity: 4.21799
Train accuracy: 70.299
Validation perplexity: 6.87946
Validation accuracy: 65.6095
Decaying learning rate to 0.5

Epoch  8,    50/  454; acc:  74.41; ppl:   3.26; 2842 src tok/s; 2948 tgt tok/s;     15 s elapsed
Epoch  8,   100/  454; acc:  75.87; ppl:   3.02; 2753 src tok/s; 2868 tgt tok/s;     30 s elapsed
Epoch  8,   150/  454; acc:  74.77; ppl:   3.19; 2803 src tok/s; 2905 tgt tok/s;     45 s elapsed
Epoch  8,   200/  454; acc:  76.40; ppl:   2.90; 2813 src tok/s; 2929 tgt tok/s;     60 s elapsed
Epoch  8,   250/  454; acc:  75.84; ppl:   3.02; 2810 src tok/s; 2918 tgt tok/s;     75 s elapsed
Epoch  8,   300/  454; acc:  75.12; ppl:   3.11; 2797 src tok/s; 2897 tgt tok/s;     90 s elapsed
Epoch  8,   350/  454; acc:  75.07; ppl:   3.14; 2850 src tok/s; 2931 tgt tok/s;    105 s elapsed
Epoch  8,   400/  454; acc:  75.48; ppl:   3.03; 2794 src tok/s; 2913 tgt tok/s;    120 s elapsed
Epoch  8,   450/  454; acc:  75.65; ppl:   3.03; 2777 src tok/s; 2896 tgt tok/s;    134 s elapsed
Train perplexity: 3.08136
Train accuracy: 75.3629
Validation perplexity: 6.16675
Validation accuracy: 68.1921
Decaying learning rate to 0.25

Epoch  9,    50/  454; acc:  77.95; ppl:   2.67; 2808 src tok/s; 2902 tgt tok/s;     16 s elapsed
Epoch  9,   100/  454; acc:  80.33; ppl:   2.32; 2792 src tok/s; 2933 tgt tok/s;     30 s elapsed
Epoch  9,   150/  454; acc:  79.53; ppl:   2.44; 2799 src tok/s; 2909 tgt tok/s;     45 s elapsed
Epoch  9,   200/  454; acc:  79.28; ppl:   2.50; 2809 src tok/s; 2919 tgt tok/s;     60 s elapsed
Epoch  9,   250/  454; acc:  79.58; ppl:   2.43; 2830 src tok/s; 2950 tgt tok/s;     74 s elapsed
Epoch  9,   300/  454; acc:  78.34; ppl:   2.60; 2844 src tok/s; 2932 tgt tok/s;     89 s elapsed
Epoch  9,   350/  454; acc:  78.93; ppl:   2.53; 2831 src tok/s; 2936 tgt tok/s;    104 s elapsed
Epoch  9,   400/  454; acc:  78.42; ppl:   2.58; 2774 src tok/s; 2869 tgt tok/s;    119 s elapsed
Epoch  9,   450/  454; acc:  79.09; ppl:   2.49; 2854 src tok/s; 2966 tgt tok/s;    133 s elapsed
Train perplexity: 2.51204
Train accuracy: 78.9986
Validation perplexity: 6.19824
Validation accuracy: 68.93
Decaying learning rate to 0.125

Epoch 10,    50/  454; acc:  81.88; ppl:   2.14; 2848 src tok/s; 2961 tgt tok/s;     14 s elapsed
Epoch 10,   100/  454; acc:  81.27; ppl:   2.25; 2799 src tok/s; 2894 tgt tok/s;     30 s elapsed
Epoch 10,   150/  454; acc:  82.11; ppl:   2.13; 2804 src tok/s; 2938 tgt tok/s;     44 s elapsed
Epoch 10,   200/  454; acc:  80.12; ppl:   2.36; 2843 src tok/s; 2930 tgt tok/s;     59 s elapsed
Epoch 10,   250/  454; acc:  81.59; ppl:   2.20; 2850 src tok/s; 2966 tgt tok/s;     74 s elapsed
Epoch 10,   300/  454; acc:  80.21; ppl:   2.38; 2796 src tok/s; 2898 tgt tok/s;     89 s elapsed
Epoch 10,   350/  454; acc:  81.87; ppl:   2.16; 2808 src tok/s; 2933 tgt tok/s;    104 s elapsed
Epoch 10,   400/  454; acc:  80.14; ppl:   2.36; 2802 src tok/s; 2896 tgt tok/s;    119 s elapsed
Epoch 10,   450/  454; acc:  81.05; ppl:   2.27; 2827 src tok/s; 2923 tgt tok/s;    134 s elapsed
Train perplexity: 2.24874
Train accuracy: 81.1315
Validation perplexity: 6.29866
Validation accuracy: 69.0152
Decaying learning rate to 0.0625

Epoch 11,    50/  454; acc:  82.96; ppl:   2.05; 2811 src tok/s; 2933 tgt tok/s;     15 s elapsed
Epoch 11,   100/  454; acc:  82.30; ppl:   2.13; 2837 src tok/s; 2936 tgt tok/s;     30 s elapsed
Epoch 11,   150/  454; acc:  80.97; ppl:   2.28; 2819 src tok/s; 2909 tgt tok/s;     45 s elapsed
Epoch 11,   200/  454; acc:  83.21; ppl:   2.02; 2828 src tok/s; 2963 tgt tok/s;     59 s elapsed
Epoch 11,   250/  454; acc:  82.39; ppl:   2.12; 2791 src tok/s; 2915 tgt tok/s;     74 s elapsed
Epoch 11,   300/  454; acc:  82.19; ppl:   2.16; 2824 src tok/s; 2913 tgt tok/s;     89 s elapsed
Epoch 11,   350/  454; acc:  83.64; ppl:   1.95; 2746 src tok/s; 2884 tgt tok/s;    104 s elapsed
Epoch 11,   400/  454; acc:  81.20; ppl:   2.26; 2891 src tok/s; 2954 tgt tok/s;    119 s elapsed
Epoch 11,   450/  454; acc:  81.99; ppl:   2.17; 2771 src tok/s; 2873 tgt tok/s;    134 s elapsed
Train perplexity: 2.12729
Train accuracy: 82.3061
Validation perplexity: 6.39657
Validation accuracy: 69.0578
Decaying learning rate to 0.03125

Epoch 12,    50/  454; acc:  82.09; ppl:   2.13; 2800 src tok/s; 2905 tgt tok/s;     15 s elapsed
Epoch 12,   100/  454; acc:  83.65; ppl:   1.98; 2811 src tok/s; 2921 tgt tok/s;     30 s elapsed
Epoch 12,   150/  454; acc:  81.98; ppl:   2.19; 2815 src tok/s; 2898 tgt tok/s;     46 s elapsed
Epoch 12,   200/  454; acc:  84.07; ppl:   1.94; 2772 src tok/s; 2904 tgt tok/s;     60 s elapsed
Epoch 12,   250/  454; acc:  83.64; ppl:   2.01; 2853 src tok/s; 2964 tgt tok/s;     74 s elapsed
Epoch 12,   300/  454; acc:  82.30; ppl:   2.13; 2788 src tok/s; 2895 tgt tok/s;     90 s elapsed
Epoch 12,   350/  454; acc:  83.28; ppl:   2.03; 2852 src tok/s; 2944 tgt tok/s;    104 s elapsed
Epoch 12,   400/  454; acc:  82.17; ppl:   2.13; 2804 src tok/s; 2911 tgt tok/s;    119 s elapsed
Epoch 12,   450/  454; acc:  82.78; ppl:   2.08; 2780 src tok/s; 2886 tgt tok/s;    134 s elapsed
Train perplexity: 2.06865
Train accuracy: 82.8811
Validation perplexity: 6.4606
Validation accuracy: 69.0861
Decaying learning rate to 0.015625

Epoch 13,    50/  454; acc:  83.52; ppl:   2.01; 2787 src tok/s; 2905 tgt tok/s;     15 s elapsed
Epoch 13,   100/  454; acc:  83.11; ppl:   2.06; 2801 src tok/s; 2903 tgt tok/s;     30 s elapsed
Epoch 13,   150/  454; acc:  83.64; ppl:   2.00; 2832 src tok/s; 2957 tgt tok/s;     44 s elapsed
Epoch 13,   200/  454; acc:  82.77; ppl:   2.08; 2847 src tok/s; 2942 tgt tok/s;     60 s elapsed
Epoch 13,   250/  454; acc:  82.23; ppl:   2.16; 2872 src tok/s; 2951 tgt tok/s;     75 s elapsed
Epoch 13,   300/  454; acc:  84.54; ppl:   1.88; 2814 src tok/s; 2956 tgt tok/s;     89 s elapsed
Epoch 13,   350/  454; acc:  82.99; ppl:   2.08; 2783 src tok/s; 2876 tgt tok/s;    104 s elapsed
Epoch 13,   400/  454; acc:  83.45; ppl:   2.02; 2822 src tok/s; 2931 tgt tok/s;    119 s elapsed
Epoch 13,   450/  454; acc:  83.01; ppl:   2.08; 2794 src tok/s; 2892 tgt tok/s;    134 s elapsed
Train perplexity: 2.04029
Train accuracy: 83.2341
Validation perplexity: 6.48661
Validation accuracy: 69.1003
Decaying learning rate to 0.0078125

Epoch 14,    50/  454; acc:  84.00; ppl:   1.96; 2844 src tok/s; 2946 tgt tok/s;     15 s elapsed
Epoch 14,   100/  454; acc:  82.67; ppl:   2.09; 2805 src tok/s; 2912 tgt tok/s;     30 s elapsed
Epoch 14,   150/  454; acc:  82.42; ppl:   2.13; 2837 src tok/s; 2944 tgt tok/s;     45 s elapsed
Epoch 14,   200/  454; acc:  84.57; ppl:   1.92; 2772 src tok/s; 2891 tgt tok/s;     60 s elapsed
Epoch 14,   250/  454; acc:  83.69; ppl:   2.00; 2828 src tok/s; 2942 tgt tok/s;     74 s elapsed
Epoch 14,   300/  454; acc:  83.21; ppl:   2.03; 2821 src tok/s; 2921 tgt tok/s;     89 s elapsed
Epoch 14,   350/  454; acc:  82.74; ppl:   2.09; 2845 src tok/s; 2932 tgt tok/s;    105 s elapsed
Epoch 14,   400/  454; acc:  83.97; ppl:   1.98; 2776 src tok/s; 2903 tgt tok/s;    119 s elapsed
Epoch 14,   450/  454; acc:  83.00; ppl:   2.07; 2802 src tok/s; 2892 tgt tok/s;    134 s elapsed
Train perplexity: 2.02772
Train accuracy: 83.3638
Validation perplexity: 6.50756
Validation accuracy: 68.9939
Decaying learning rate to 0.00390625

Epoch 15,    50/  454; acc:  84.08; ppl:   1.95; 2764 src tok/s; 2884 tgt tok/s;     14 s elapsed
Epoch 15,   100/  454; acc:  82.82; ppl:   2.09; 2835 src tok/s; 2921 tgt tok/s;     30 s elapsed
Epoch 15,   150/  454; acc:  83.51; ppl:   2.01; 2790 src tok/s; 2905 tgt tok/s;     45 s elapsed
Epoch 15,   200/  454; acc:  83.31; ppl:   2.06; 2825 src tok/s; 2922 tgt tok/s;     60 s elapsed
Epoch 15,   250/  454; acc:  84.63; ppl:   1.91; 2811 src tok/s; 2938 tgt tok/s;     74 s elapsed
Epoch 15,   300/  454; acc:  82.75; ppl:   2.10; 2815 src tok/s; 2903 tgt tok/s;     90 s elapsed
Epoch 15,   350/  454; acc:  83.40; ppl:   2.05; 2833 src tok/s; 2944 tgt tok/s;    105 s elapsed
Epoch 15,   400/  454; acc:  83.56; ppl:   1.99; 2845 src tok/s; 2954 tgt tok/s;    119 s elapsed
Epoch 15,   450/  454; acc:  83.50; ppl:   2.01; 2803 src tok/s; 2912 tgt tok/s;    134 s elapsed
Train perplexity: 2.01924
Train accuracy: 83.486
Validation perplexity: 6.51154
Validation accuracy: 69.0578
Decaying learning rate to 0.00195312

Epoch 16,    50/  454; acc:  82.14; ppl:   2.14; 2854 src tok/s; 2961 tgt tok/s;     16 s elapsed
Epoch 16,   100/  454; acc:  85.18; ppl:   1.85; 2846 src tok/s; 2975 tgt tok/s;     29 s elapsed
Epoch 16,   150/  454; acc:  83.28; ppl:   2.03; 2854 src tok/s; 2952 tgt tok/s;     44 s elapsed
Epoch 16,   200/  454; acc:  83.37; ppl:   2.03; 2772 src tok/s; 2874 tgt tok/s;     59 s elapsed
Epoch 16,   250/  454; acc:  83.49; ppl:   2.02; 2809 src tok/s; 2918 tgt tok/s;     74 s elapsed
Epoch 16,   300/  454; acc:  83.33; ppl:   2.03; 2810 src tok/s; 2905 tgt tok/s;     89 s elapsed
Epoch 16,   350/  454; acc:  83.17; ppl:   2.04; 2824 src tok/s; 2912 tgt tok/s;    104 s elapsed
Epoch 16,   400/  454; acc:  83.81; ppl:   1.96; 2811 src tok/s; 2923 tgt tok/s;    119 s elapsed
Epoch 16,   450/  454; acc:  83.63; ppl:   2.00; 2768 src tok/s; 2893 tgt tok/s;    134 s elapsed
Train perplexity: 2.01526
Train accuracy: 83.4316
Validation perplexity: 6.51252
Validation accuracy: 69.0294
Decaying learning rate to 0.000976562

Epoch 17,    50/  454; acc:  82.73; ppl:   2.12; 2822 src tok/s; 2916 tgt tok/s;     15 s elapsed
Epoch 17,   100/  454; acc:  84.85; ppl:   1.87; 2756 src tok/s; 2874 tgt tok/s;     30 s elapsed
Epoch 17,   150/  454; acc:  83.96; ppl:   1.96; 2873 src tok/s; 2985 tgt tok/s;     44 s elapsed
Epoch 17,   200/  454; acc:  82.94; ppl:   2.07; 2807 src tok/s; 2904 tgt tok/s;     60 s elapsed
Epoch 17,   250/  454; acc:  83.96; ppl:   1.95; 2847 src tok/s; 2950 tgt tok/s;     74 s elapsed
Epoch 17,   300/  454; acc:  82.63; ppl:   2.10; 2808 src tok/s; 2914 tgt tok/s;     89 s elapsed
Epoch 17,   350/  454; acc:  83.18; ppl:   2.07; 2816 src tok/s; 2919 tgt tok/s;    104 s elapsed
Epoch 17,   400/  454; acc:  83.99; ppl:   1.95; 2790 src tok/s; 2897 tgt tok/s;    119 s elapsed
Epoch 17,   450/  454; acc:  84.12; ppl:   1.94; 2750 src tok/s; 2876 tgt tok/s;    134 s elapsed
Train perplexity: 2.01051
Train accuracy: 83.5191
Validation perplexity: 6.51355
Validation accuracy: 69.0223
Decaying learning rate to 0.000488281
