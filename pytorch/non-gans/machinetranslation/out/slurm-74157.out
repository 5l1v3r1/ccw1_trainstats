<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.1, kappa_enc=0.3, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.30decoder0.10dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.3)
('Using Kappa L2 loss on decoder', 0.1)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.08; ppl: 35252.98; 4476 src tok/s; 4605 tgt tok/s;     10 s elapsed
Epoch  1,   100/  454; acc:  14.81; ppl: 3077.76; 5451 src tok/s; 5719 tgt tok/s;     17 s elapsed
Epoch  1,   150/  454; acc:  17.46; ppl: 704.21; 5613 src tok/s; 5807 tgt tok/s;     25 s elapsed
Epoch  1,   200/  454; acc:  21.07; ppl: 310.79; 5624 src tok/s; 5829 tgt tok/s;     32 s elapsed
Epoch  1,   250/  454; acc:  23.49; ppl: 187.95; 5703 src tok/s; 5924 tgt tok/s;     39 s elapsed
Epoch  1,   300/  454; acc:  26.89; ppl: 131.64; 5653 src tok/s; 5888 tgt tok/s;     47 s elapsed
Epoch  1,   350/  454; acc:  30.23; ppl:  94.34; 5657 src tok/s; 5863 tgt tok/s;     54 s elapsed
Epoch  1,   400/  454; acc:  31.37; ppl:  82.90; 5641 src tok/s; 5844 tgt tok/s;     62 s elapsed
Epoch  1,   450/  454; acc:  33.72; ppl:  67.03; 5542 src tok/s; 5756 tgt tok/s;     69 s elapsed
Train perplexity: 408.12
Train accuracy: 23.0697
Validation perplexity: 56.5357
Validation accuracy: 35.0929

Epoch  2,    50/  454; acc:  35.30; ppl:  55.66; 5628 src tok/s; 5799 tgt tok/s;      8 s elapsed
Epoch  2,   100/  454; acc:  37.09; ppl:  48.13; 5530 src tok/s; 5749 tgt tok/s;     15 s elapsed
Epoch  2,   150/  454; acc:  37.08; ppl:  48.24; 5744 src tok/s; 5953 tgt tok/s;     22 s elapsed
Epoch  2,   200/  454; acc:  39.21; ppl:  41.04; 5566 src tok/s; 5827 tgt tok/s;     30 s elapsed
Epoch  2,   250/  454; acc:  41.64; ppl:  34.72; 5658 src tok/s; 5854 tgt tok/s;     37 s elapsed
Epoch  2,   300/  454; acc:  44.17; ppl:  30.73; 5671 src tok/s; 5892 tgt tok/s;     45 s elapsed
Epoch  2,   350/  454; acc:  45.89; ppl:  26.38; 5756 src tok/s; 5951 tgt tok/s;     52 s elapsed
Epoch  2,   400/  454; acc:  48.23; ppl:  22.33; 5570 src tok/s; 5803 tgt tok/s;     60 s elapsed
Epoch  2,   450/  454; acc:  50.68; ppl:  19.54; 5475 src tok/s; 5706 tgt tok/s;     67 s elapsed
Train perplexity: 34.2972
Train accuracy: 42.1182
Validation perplexity: 18.15
Validation accuracy: 52.0931

Epoch  3,    50/  454; acc:  53.17; ppl:  16.18; 5588 src tok/s; 5820 tgt tok/s;      7 s elapsed
Epoch  3,   100/  454; acc:  52.96; ppl:  16.05; 5675 src tok/s; 5856 tgt tok/s;     15 s elapsed
Epoch  3,   150/  454; acc:  53.85; ppl:  14.94; 5699 src tok/s; 5905 tgt tok/s;     22 s elapsed
Epoch  3,   200/  454; acc:  54.90; ppl:  14.04; 5517 src tok/s; 5745 tgt tok/s;     30 s elapsed
Epoch  3,   250/  454; acc:  56.36; ppl:  12.94; 5695 src tok/s; 5892 tgt tok/s;     37 s elapsed
Epoch  3,   300/  454; acc:  56.19; ppl:  12.77; 5599 src tok/s; 5816 tgt tok/s;     45 s elapsed
Epoch  3,   350/  454; acc:  58.51; ppl:  10.93; 5625 src tok/s; 5877 tgt tok/s;     52 s elapsed
Epoch  3,   400/  454; acc:  57.20; ppl:  12.07; 5779 src tok/s; 5970 tgt tok/s;     59 s elapsed
Epoch  3,   450/  454; acc:  59.10; ppl:  10.77; 5592 src tok/s; 5819 tgt tok/s;     67 s elapsed
Train perplexity: 13.275
Train accuracy: 55.7931
Validation perplexity: 10.6519
Validation accuracy: 59.465

Epoch  4,    50/  454; acc:  61.51; ppl:   8.53; 5590 src tok/s; 5861 tgt tok/s;      7 s elapsed
Epoch  4,   100/  454; acc:  60.31; ppl:   9.22; 5785 src tok/s; 5954 tgt tok/s;     15 s elapsed
Epoch  4,   150/  454; acc:  61.35; ppl:   8.69; 5784 src tok/s; 5972 tgt tok/s;     22 s elapsed
Epoch  4,   200/  454; acc:  62.16; ppl:   8.41; 5637 src tok/s; 5862 tgt tok/s;     29 s elapsed
Epoch  4,   250/  454; acc:  62.15; ppl:   8.31; 5602 src tok/s; 5807 tgt tok/s;     37 s elapsed
Epoch  4,   300/  454; acc:  61.56; ppl:   8.51; 5704 src tok/s; 5935 tgt tok/s;     44 s elapsed
Epoch  4,   350/  454; acc:  62.08; ppl:   8.23; 5562 src tok/s; 5823 tgt tok/s;     52 s elapsed
Epoch  4,   400/  454; acc:  61.80; ppl:   8.34; 5643 src tok/s; 5832 tgt tok/s;     59 s elapsed
Epoch  4,   450/  454; acc:  62.38; ppl:   7.95; 5445 src tok/s; 5626 tgt tok/s;     67 s elapsed
Train perplexity: 8.44336
Train accuracy: 61.7291
Validation perplexity: 8.5633
Validation accuracy: 62.4592

Epoch  5,    50/  454; acc:  64.74; ppl:   6.49; 5566 src tok/s; 5751 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  65.67; ppl:   6.16; 5612 src tok/s; 5810 tgt tok/s;     15 s elapsed
Epoch  5,   150/  454; acc:  64.65; ppl:   6.59; 5668 src tok/s; 5862 tgt tok/s;     23 s elapsed
Epoch  5,   200/  454; acc:  64.94; ppl:   6.31; 5586 src tok/s; 5830 tgt tok/s;     30 s elapsed
Epoch  5,   250/  454; acc:  66.06; ppl:   6.12; 5593 src tok/s; 5817 tgt tok/s;     37 s elapsed
Epoch  5,   300/  454; acc:  64.52; ppl:   6.55; 5634 src tok/s; 5820 tgt tok/s;     45 s elapsed
Epoch  5,   350/  454; acc:  65.37; ppl:   6.25; 5601 src tok/s; 5842 tgt tok/s;     52 s elapsed
Epoch  5,   400/  454; acc:  65.44; ppl:   6.22; 5560 src tok/s; 5778 tgt tok/s;     60 s elapsed
Epoch  5,   450/  454; acc:  65.10; ppl:   6.36; 5439 src tok/s; 5647 tgt tok/s;     68 s elapsed
Train perplexity: 6.34052
Train accuracy: 65.1635
Validation perplexity: 7.45267
Validation accuracy: 64.7581

Epoch  6,    50/  454; acc:  68.64; ppl:   4.87; 5497 src tok/s; 5707 tgt tok/s;      8 s elapsed
Epoch  6,   100/  454; acc:  67.87; ppl:   5.07; 5600 src tok/s; 5811 tgt tok/s;     15 s elapsed
Epoch  6,   150/  454; acc:  68.46; ppl:   5.05; 5687 src tok/s; 5905 tgt tok/s;     22 s elapsed
Epoch  6,   200/  454; acc:  67.39; ppl:   5.33; 5649 src tok/s; 5846 tgt tok/s;     30 s elapsed
Epoch  6,   250/  454; acc:  68.28; ppl:   5.01; 5482 src tok/s; 5695 tgt tok/s;     38 s elapsed
Epoch  6,   300/  454; acc:  67.57; ppl:   5.14; 5558 src tok/s; 5745 tgt tok/s;     45 s elapsed
Epoch  6,   350/  454; acc:  67.78; ppl:   5.10; 5392 src tok/s; 5643 tgt tok/s;     53 s elapsed
Epoch  6,   400/  454; acc:  67.67; ppl:   5.07; 5630 src tok/s; 5812 tgt tok/s;     60 s elapsed
Epoch  6,   450/  454; acc:  67.72; ppl:   5.08; 5497 src tok/s; 5728 tgt tok/s;     68 s elapsed
Train perplexity: 5.07562
Train accuracy: 67.9393
Validation perplexity: 6.99986
Validation accuracy: 66.0494

Epoch  7,    50/  454; acc:  71.25; ppl:   3.99; 5661 src tok/s; 5879 tgt tok/s;      7 s elapsed
Epoch  7,   100/  454; acc:  70.80; ppl:   4.09; 5711 src tok/s; 5920 tgt tok/s;     15 s elapsed
Epoch  7,   150/  454; acc:  70.66; ppl:   4.17; 5735 src tok/s; 5957 tgt tok/s;     22 s elapsed
Epoch  7,   200/  454; acc:  69.83; ppl:   4.31; 5719 src tok/s; 5942 tgt tok/s;     29 s elapsed
Epoch  7,   250/  454; acc:  69.49; ppl:   4.30; 5540 src tok/s; 5780 tgt tok/s;     37 s elapsed
Epoch  7,   300/  454; acc:  69.74; ppl:   4.35; 5750 src tok/s; 5963 tgt tok/s;     44 s elapsed
Epoch  7,   350/  454; acc:  69.69; ppl:   4.38; 5702 src tok/s; 5889 tgt tok/s;     52 s elapsed
Epoch  7,   400/  454; acc:  70.02; ppl:   4.27; 5654 src tok/s; 5870 tgt tok/s;     59 s elapsed
Epoch  7,   450/  454; acc:  69.46; ppl:   4.42; 5544 src tok/s; 5744 tgt tok/s;     67 s elapsed
Train perplexity: 4.25129
Train accuracy: 70.1139
Validation perplexity: 6.7924
Validation accuracy: 66.4964

Epoch  8,    50/  454; acc:  72.61; ppl:   3.55; 5687 src tok/s; 5889 tgt tok/s;      7 s elapsed
Epoch  8,   100/  454; acc:  73.48; ppl:   3.37; 5556 src tok/s; 5774 tgt tok/s;     15 s elapsed
Epoch  8,   150/  454; acc:  72.15; ppl:   3.59; 5717 src tok/s; 5957 tgt tok/s;     22 s elapsed
Epoch  8,   200/  454; acc:  72.02; ppl:   3.62; 5662 src tok/s; 5848 tgt tok/s;     30 s elapsed
Epoch  8,   250/  454; acc:  71.72; ppl:   3.71; 5580 src tok/s; 5787 tgt tok/s;     37 s elapsed
Epoch  8,   300/  454; acc:  71.50; ppl:   3.78; 5720 src tok/s; 5913 tgt tok/s;     45 s elapsed
Epoch  8,   350/  454; acc:  71.52; ppl:   3.75; 5715 src tok/s; 5951 tgt tok/s;     52 s elapsed
Epoch  8,   400/  454; acc:  71.23; ppl:   3.75; 5528 src tok/s; 5744 tgt tok/s;     59 s elapsed
Epoch  8,   450/  454; acc:  71.24; ppl:   3.86; 5349 src tok/s; 5565 tgt tok/s;     67 s elapsed
Train perplexity: 3.6622
Train accuracy: 71.9356
Validation perplexity: 6.67425
Validation accuracy: 66.9363
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.22; ppl:   2.74; 5754 src tok/s; 5969 tgt tok/s;      7 s elapsed
Epoch  9,   100/  454; acc:  76.77; ppl:   2.75; 5566 src tok/s; 5794 tgt tok/s;     15 s elapsed
Epoch  9,   150/  454; acc:  78.31; ppl:   2.56; 5533 src tok/s; 5789 tgt tok/s;     22 s elapsed
Epoch  9,   200/  454; acc:  75.75; ppl:   2.91; 5667 src tok/s; 5837 tgt tok/s;     30 s elapsed
Epoch  9,   250/  454; acc:  78.06; ppl:   2.60; 5536 src tok/s; 5740 tgt tok/s;     37 s elapsed
Epoch  9,   300/  454; acc:  77.15; ppl:   2.73; 5655 src tok/s; 5830 tgt tok/s;     45 s elapsed
Epoch  9,   350/  454; acc:  76.92; ppl:   2.68; 5590 src tok/s; 5843 tgt tok/s;     52 s elapsed
Epoch  9,   400/  454; acc:  76.32; ppl:   2.86; 5669 src tok/s; 5862 tgt tok/s;     60 s elapsed
Epoch  9,   450/  454; acc:  76.76; ppl:   2.79; 5651 src tok/s; 5876 tgt tok/s;     67 s elapsed
Train perplexity: 2.73648
Train accuracy: 77.0097
Validation perplexity: 6.24051
Validation accuracy: 68.9017
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.36; ppl:   2.20; 5677 src tok/s; 5906 tgt tok/s;      7 s elapsed
Epoch 10,   100/  454; acc:  80.62; ppl:   2.30; 5653 src tok/s; 5875 tgt tok/s;     15 s elapsed
Epoch 10,   150/  454; acc:  81.26; ppl:   2.17; 5594 src tok/s; 5829 tgt tok/s;     22 s elapsed
Epoch 10,   200/  454; acc:  80.36; ppl:   2.34; 5654 src tok/s; 5841 tgt tok/s;     30 s elapsed
Epoch 10,   250/  454; acc:  80.95; ppl:   2.26; 5650 src tok/s; 5834 tgt tok/s;     37 s elapsed
Epoch 10,   300/  454; acc:  80.76; ppl:   2.26; 5598 src tok/s; 5806 tgt tok/s;     45 s elapsed
Epoch 10,   350/  454; acc:  80.05; ppl:   2.31; 5680 src tok/s; 5887 tgt tok/s;     52 s elapsed
Epoch 10,   400/  454; acc:  81.47; ppl:   2.17; 5569 src tok/s; 5794 tgt tok/s;     60 s elapsed
Epoch 10,   450/  454; acc:  80.53; ppl:   2.26; 5462 src tok/s; 5691 tgt tok/s;     67 s elapsed
Train perplexity: 2.25092
Train accuracy: 80.8141
Validation perplexity: 6.32999
Validation accuracy: 69.3345
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  84.21; ppl:   1.92; 5719 src tok/s; 5959 tgt tok/s;      7 s elapsed
Epoch 11,   100/  454; acc:  82.35; ppl:   2.11; 5696 src tok/s; 5897 tgt tok/s;     15 s elapsed
Epoch 11,   150/  454; acc:  83.19; ppl:   2.01; 5622 src tok/s; 5829 tgt tok/s;     22 s elapsed
Epoch 11,   200/  454; acc:  83.19; ppl:   2.02; 5701 src tok/s; 5893 tgt tok/s;     30 s elapsed
Epoch 11,   250/  454; acc:  82.04; ppl:   2.12; 5649 src tok/s; 5820 tgt tok/s;     37 s elapsed
Epoch 11,   300/  454; acc:  83.43; ppl:   1.96; 5494 src tok/s; 5754 tgt tok/s;     45 s elapsed
Epoch 11,   350/  454; acc:  82.32; ppl:   2.12; 5658 src tok/s; 5849 tgt tok/s;     52 s elapsed
Epoch 11,   400/  454; acc:  83.70; ppl:   1.94; 5553 src tok/s; 5810 tgt tok/s;     59 s elapsed
Epoch 11,   450/  454; acc:  82.40; ppl:   2.09; 5508 src tok/s; 5719 tgt tok/s;     67 s elapsed
Train perplexity: 2.03493
Train accuracy: 82.9429
Validation perplexity: 6.44644
Validation accuracy: 69.5544
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.49; ppl:   1.89; 5604 src tok/s; 5847 tgt tok/s;      7 s elapsed
Epoch 12,   100/  454; acc:  83.86; ppl:   1.97; 5776 src tok/s; 5990 tgt tok/s;     15 s elapsed
Epoch 12,   150/  454; acc:  83.25; ppl:   2.00; 5763 src tok/s; 5931 tgt tok/s;     22 s elapsed
Epoch 12,   200/  454; acc:  85.62; ppl:   1.80; 5728 src tok/s; 5946 tgt tok/s;     29 s elapsed
Epoch 12,   250/  454; acc:  83.76; ppl:   1.97; 5632 src tok/s; 5844 tgt tok/s;     37 s elapsed
Epoch 12,   300/  454; acc:  84.12; ppl:   1.91; 5634 src tok/s; 5886 tgt tok/s;     44 s elapsed
Epoch 12,   350/  454; acc:  82.90; ppl:   2.05; 5736 src tok/s; 5893 tgt tok/s;     52 s elapsed
Epoch 12,   400/  454; acc:  85.41; ppl:   1.81; 5580 src tok/s; 5859 tgt tok/s;     59 s elapsed
Epoch 12,   450/  454; acc:  84.07; ppl:   1.92; 5586 src tok/s; 5806 tgt tok/s;     66 s elapsed
Train perplexity: 1.93115
Train accuracy: 84.0716
Validation perplexity: 6.57231
Validation accuracy: 69.6112
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  85.77; ppl:   1.78; 5571 src tok/s; 5826 tgt tok/s;      7 s elapsed
Epoch 13,   100/  454; acc:  83.27; ppl:   2.01; 5793 src tok/s; 5957 tgt tok/s;     15 s elapsed
Epoch 13,   150/  454; acc:  85.47; ppl:   1.82; 5547 src tok/s; 5788 tgt tok/s;     22 s elapsed
Epoch 13,   200/  454; acc:  84.37; ppl:   1.92; 5596 src tok/s; 5796 tgt tok/s;     30 s elapsed
Epoch 13,   250/  454; acc:  85.33; ppl:   1.81; 5432 src tok/s; 5681 tgt tok/s;     37 s elapsed
Epoch 13,   300/  454; acc:  83.49; ppl:   1.97; 5582 src tok/s; 5755 tgt tok/s;     45 s elapsed
Epoch 13,   350/  454; acc:  83.86; ppl:   1.96; 5659 src tok/s; 5829 tgt tok/s;     53 s elapsed
Epoch 13,   400/  454; acc:  85.94; ppl:   1.79; 5539 src tok/s; 5770 tgt tok/s;     60 s elapsed
Epoch 13,   450/  454; acc:  84.18; ppl:   1.91; 5628 src tok/s; 5848 tgt tok/s;     67 s elapsed
Train perplexity: 1.88578
Train accuracy: 84.6112
Validation perplexity: 6.61338
Validation accuracy: 69.4551
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.14; ppl:   1.83; 5477 src tok/s; 5688 tgt tok/s;      8 s elapsed
Epoch 14,   100/  454; acc:  84.48; ppl:   1.91; 5614 src tok/s; 5838 tgt tok/s;     15 s elapsed
Epoch 14,   150/  454; acc:  84.50; ppl:   1.90; 5573 src tok/s; 5765 tgt tok/s;     23 s elapsed
Epoch 14,   200/  454; acc:  85.41; ppl:   1.81; 5636 src tok/s; 5859 tgt tok/s;     30 s elapsed
Epoch 14,   250/  454; acc:  85.08; ppl:   1.82; 5645 src tok/s; 5878 tgt tok/s;     37 s elapsed
Epoch 14,   300/  454; acc:  84.93; ppl:   1.87; 5695 src tok/s; 5875 tgt tok/s;     45 s elapsed
Epoch 14,   350/  454; acc:  84.55; ppl:   1.90; 5560 src tok/s; 5760 tgt tok/s;     53 s elapsed
Epoch 14,   400/  454; acc:  85.01; ppl:   1.83; 5530 src tok/s; 5742 tgt tok/s;     60 s elapsed
Epoch 14,   450/  454; acc:  85.12; ppl:   1.83; 5462 src tok/s; 5705 tgt tok/s;     67 s elapsed
Train perplexity: 1.85815
Train accuracy: 84.8901
Validation perplexity: 6.65869
Validation accuracy: 69.597
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.70; ppl:   1.79; 5322 src tok/s; 5595 tgt tok/s;      7 s elapsed
Epoch 15,   100/  454; acc:  84.62; ppl:   1.87; 5765 src tok/s; 5928 tgt tok/s;     15 s elapsed
Epoch 15,   150/  454; acc:  84.13; ppl:   1.92; 5521 src tok/s; 5740 tgt tok/s;     23 s elapsed
Epoch 15,   200/  454; acc:  85.84; ppl:   1.79; 5671 src tok/s; 5897 tgt tok/s;     30 s elapsed
Epoch 15,   250/  454; acc:  85.64; ppl:   1.80; 5725 src tok/s; 5931 tgt tok/s;     37 s elapsed
Epoch 15,   300/  454; acc:  84.50; ppl:   1.90; 5729 src tok/s; 5920 tgt tok/s;     45 s elapsed
Epoch 15,   350/  454; acc:  85.59; ppl:   1.80; 5647 src tok/s; 5895 tgt tok/s;     52 s elapsed
Epoch 15,   400/  454; acc:  84.17; ppl:   1.92; 5670 src tok/s; 5852 tgt tok/s;     60 s elapsed
Epoch 15,   450/  454; acc:  85.15; ppl:   1.82; 5711 src tok/s; 5940 tgt tok/s;     67 s elapsed
Train perplexity: 1.84776
Train accuracy: 84.998
Validation perplexity: 6.66818
Validation accuracy: 69.6254
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.28; ppl:   1.81; 5839 src tok/s; 6021 tgt tok/s;      7 s elapsed
Epoch 16,   100/  454; acc:  85.42; ppl:   1.82; 5549 src tok/s; 5798 tgt tok/s;     15 s elapsed
Epoch 16,   150/  454; acc:  85.70; ppl:   1.81; 5643 src tok/s; 5878 tgt tok/s;     22 s elapsed
Epoch 16,   200/  454; acc:  84.68; ppl:   1.90; 5728 src tok/s; 5913 tgt tok/s;     29 s elapsed
Epoch 16,   250/  454; acc:  85.42; ppl:   1.82; 5561 src tok/s; 5772 tgt tok/s;     37 s elapsed
Epoch 16,   300/  454; acc:  84.41; ppl:   1.91; 5743 src tok/s; 5947 tgt tok/s;     44 s elapsed
Epoch 16,   350/  454; acc:  84.69; ppl:   1.86; 5625 src tok/s; 5836 tgt tok/s;     52 s elapsed
Epoch 16,   400/  454; acc:  85.32; ppl:   1.80; 5572 src tok/s; 5813 tgt tok/s;     59 s elapsed
Epoch 16,   450/  454; acc:  85.50; ppl:   1.82; 5419 src tok/s; 5632 tgt tok/s;     67 s elapsed
Train perplexity: 1.84065
Train accuracy: 85.1175
Validation perplexity: 6.67876
Validation accuracy: 69.597
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  84.73; ppl:   1.86; 5502 src tok/s; 5687 tgt tok/s;      8 s elapsed
Epoch 17,   100/  454; acc:  85.39; ppl:   1.84; 5571 src tok/s; 5763 tgt tok/s;     15 s elapsed
Epoch 17,   150/  454; acc:  86.27; ppl:   1.73; 5451 src tok/s; 5727 tgt tok/s;     22 s elapsed
Epoch 17,   200/  454; acc:  84.02; ppl:   1.95; 5480 src tok/s; 5642 tgt tok/s;     30 s elapsed
Epoch 17,   250/  454; acc:  84.37; ppl:   1.94; 5682 src tok/s; 5858 tgt tok/s;     38 s elapsed
Epoch 17,   300/  454; acc:  86.29; ppl:   1.74; 5555 src tok/s; 5813 tgt tok/s;     45 s elapsed
Epoch 17,   350/  454; acc:  86.05; ppl:   1.75; 5678 src tok/s; 5920 tgt tok/s;     52 s elapsed
Epoch 17,   400/  454; acc:  84.65; ppl:   1.90; 5658 src tok/s; 5852 tgt tok/s;     60 s elapsed
Epoch 17,   450/  454; acc:  85.33; ppl:   1.82; 5554 src tok/s; 5786 tgt tok/s;     68 s elapsed
Train perplexity: 1.83887
Train accuracy: 85.1958
Validation perplexity: 6.68353
Validation accuracy: 69.5828
Decaying learning rate to 0.000976562
