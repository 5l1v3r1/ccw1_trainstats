<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.5, kappa_enc=0.4, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/seeds/encoder0.4decoder0.5dropout0.3wdropTrueseed3', seed=3, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.4)
('Using Kappa L2 loss on decoder', 0.5)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.18; ppl: 47582.04; 4917 src tok/s; 5112 tgt tok/s;      9 s elapsed
Epoch  1,   100/  454; acc:  14.46; ppl: 1407.82; 6958 src tok/s; 7230 tgt tok/s;     15 s elapsed
Epoch  1,   150/  454; acc:  17.76; ppl: 531.41; 7154 src tok/s; 7417 tgt tok/s;     20 s elapsed
Epoch  1,   200/  454; acc:  20.49; ppl: 270.36; 7068 src tok/s; 7311 tgt tok/s;     26 s elapsed
Epoch  1,   250/  454; acc:  23.89; ppl: 181.61; 7048 src tok/s; 7267 tgt tok/s;     33 s elapsed
Epoch  1,   300/  454; acc:  28.00; ppl: 125.32; 6792 src tok/s; 7117 tgt tok/s;     39 s elapsed
Epoch  1,   350/  454; acc:  30.45; ppl:  98.35; 6976 src tok/s; 7305 tgt tok/s;     44 s elapsed
Epoch  1,   400/  454; acc:  30.41; ppl:  86.61; 6918 src tok/s; 7128 tgt tok/s;     51 s elapsed
Epoch  1,   450/  454; acc:  32.77; ppl:  71.18; 6845 src tok/s; 7085 tgt tok/s;     57 s elapsed
Train perplexity: 368.474
Train accuracy: 22.9817
Validation perplexity: 56.7494
Validation accuracy: 36.2566

Epoch  2,    50/  454; acc:  33.87; ppl:  60.54; 6813 src tok/s; 7026 tgt tok/s;      6 s elapsed
Epoch  2,   100/  454; acc:  36.94; ppl:  48.13; 7013 src tok/s; 7304 tgt tok/s;     12 s elapsed
Epoch  2,   150/  454; acc:  38.96; ppl:  42.59; 6977 src tok/s; 7227 tgt tok/s;     18 s elapsed
Epoch  2,   200/  454; acc:  41.62; ppl:  35.35; 6945 src tok/s; 7217 tgt tok/s;     24 s elapsed
Epoch  2,   250/  454; acc:  43.76; ppl:  30.54; 6936 src tok/s; 7176 tgt tok/s;     30 s elapsed
Epoch  2,   300/  454; acc:  46.93; ppl:  25.33; 6935 src tok/s; 7228 tgt tok/s;     36 s elapsed
Epoch  2,   350/  454; acc:  48.22; ppl:  23.46; 6738 src tok/s; 6991 tgt tok/s;     43 s elapsed
Epoch  2,   400/  454; acc:  50.28; ppl:  20.34; 6897 src tok/s; 7183 tgt tok/s;     49 s elapsed
Epoch  2,   450/  454; acc:  51.88; ppl:  18.70; 6849 src tok/s; 7101 tgt tok/s;     55 s elapsed
Train perplexity: 31.3699
Train accuracy: 43.6739
Validation perplexity: 16.6439
Validation accuracy: 52.4975

Epoch  3,    50/  454; acc:  53.47; ppl:  15.64; 6798 src tok/s; 7013 tgt tok/s;      6 s elapsed
Epoch  3,   100/  454; acc:  55.31; ppl:  13.94; 6867 src tok/s; 7155 tgt tok/s;     12 s elapsed
Epoch  3,   150/  454; acc:  54.73; ppl:  14.41; 6972 src tok/s; 7199 tgt tok/s;     18 s elapsed
Epoch  3,   200/  454; acc:  56.58; ppl:  12.92; 6928 src tok/s; 7235 tgt tok/s;     24 s elapsed
Epoch  3,   250/  454; acc:  56.87; ppl:  12.45; 7047 src tok/s; 7320 tgt tok/s;     30 s elapsed
Epoch  3,   300/  454; acc:  57.75; ppl:  11.78; 7029 src tok/s; 7289 tgt tok/s;     36 s elapsed
Epoch  3,   350/  454; acc:  57.66; ppl:  11.87; 6880 src tok/s; 7154 tgt tok/s;     42 s elapsed
Epoch  3,   400/  454; acc:  59.24; ppl:  10.89; 6972 src tok/s; 7208 tgt tok/s;     48 s elapsed
Epoch  3,   450/  454; acc:  58.65; ppl:  10.96; 6982 src tok/s; 7245 tgt tok/s;     55 s elapsed
Train perplexity: 12.6464
Train accuracy: 56.7313
Validation perplexity: 10.4544
Validation accuracy: 60.508

Epoch  4,    50/  454; acc:  62.08; ppl:   8.40; 6841 src tok/s; 7133 tgt tok/s;      6 s elapsed
Epoch  4,   100/  454; acc:  61.36; ppl:   8.82; 6973 src tok/s; 7212 tgt tok/s;     12 s elapsed
Epoch  4,   150/  454; acc:  61.15; ppl:   8.76; 7032 src tok/s; 7280 tgt tok/s;     18 s elapsed
Epoch  4,   200/  454; acc:  61.82; ppl:   8.46; 6853 src tok/s; 7142 tgt tok/s;     24 s elapsed
Epoch  4,   250/  454; acc:  62.52; ppl:   8.14; 7009 src tok/s; 7248 tgt tok/s;     30 s elapsed
Epoch  4,   300/  454; acc:  62.93; ppl:   7.91; 6876 src tok/s; 7152 tgt tok/s;     36 s elapsed
Epoch  4,   350/  454; acc:  62.89; ppl:   8.05; 6839 src tok/s; 7093 tgt tok/s;     42 s elapsed
Epoch  4,   400/  454; acc:  62.86; ppl:   7.78; 6907 src tok/s; 7173 tgt tok/s;     49 s elapsed
Epoch  4,   450/  454; acc:  62.60; ppl:   7.83; 6787 src tok/s; 7039 tgt tok/s;     55 s elapsed
Train perplexity: 8.2246
Train accuracy: 62.2646
Validation perplexity: 8.29383
Validation accuracy: 63.3106

Epoch  5,    50/  454; acc:  67.04; ppl:   5.74; 6595 src tok/s; 6902 tgt tok/s;      6 s elapsed
Epoch  5,   100/  454; acc:  64.68; ppl:   6.51; 6898 src tok/s; 7120 tgt tok/s;     12 s elapsed
Epoch  5,   150/  454; acc:  66.15; ppl:   5.98; 6943 src tok/s; 7219 tgt tok/s;     18 s elapsed
Epoch  5,   200/  454; acc:  65.04; ppl:   6.53; 7048 src tok/s; 7251 tgt tok/s;     24 s elapsed
Epoch  5,   250/  454; acc:  65.00; ppl:   6.60; 7035 src tok/s; 7275 tgt tok/s;     31 s elapsed
Epoch  5,   300/  454; acc:  65.96; ppl:   6.00; 6834 src tok/s; 7123 tgt tok/s;     37 s elapsed
Epoch  5,   350/  454; acc:  65.49; ppl:   6.23; 6988 src tok/s; 7230 tgt tok/s;     43 s elapsed
Epoch  5,   400/  454; acc:  66.09; ppl:   6.01; 6844 src tok/s; 7130 tgt tok/s;     49 s elapsed
Epoch  5,   450/  454; acc:  65.68; ppl:   6.16; 6864 src tok/s; 7138 tgt tok/s;     55 s elapsed
Train perplexity: 6.18682
Train accuracy: 65.6955
Validation perplexity: 7.42886
Validation accuracy: 64.7439

Epoch  6,    50/  454; acc:  69.58; ppl:   4.65; 6754 src tok/s; 7016 tgt tok/s;      6 s elapsed
Epoch  6,   100/  454; acc:  68.74; ppl:   4.92; 6894 src tok/s; 7169 tgt tok/s;     12 s elapsed
Epoch  6,   150/  454; acc:  68.46; ppl:   4.94; 6892 src tok/s; 7183 tgt tok/s;     18 s elapsed
Epoch  6,   200/  454; acc:  67.71; ppl:   5.10; 6946 src tok/s; 7167 tgt tok/s;     24 s elapsed
Epoch  6,   250/  454; acc:  69.23; ppl:   4.76; 6945 src tok/s; 7214 tgt tok/s;     30 s elapsed
Epoch  6,   300/  454; acc:  67.47; ppl:   5.17; 6903 src tok/s; 7146 tgt tok/s;     36 s elapsed
Epoch  6,   350/  454; acc:  68.16; ppl:   5.06; 6996 src tok/s; 7282 tgt tok/s;     42 s elapsed
Epoch  6,   400/  454; acc:  67.50; ppl:   5.29; 7013 src tok/s; 7277 tgt tok/s;     48 s elapsed
Epoch  6,   450/  454; acc:  67.94; ppl:   5.07; 6904 src tok/s; 7146 tgt tok/s;     55 s elapsed
Train perplexity: 4.99093
Train accuracy: 68.3113
Validation perplexity: 6.94366
Validation accuracy: 66.2339

Epoch  7,    50/  454; acc:  71.67; ppl:   3.91; 6482 src tok/s; 6736 tgt tok/s;      7 s elapsed
Epoch  7,   100/  454; acc:  71.22; ppl:   4.00; 6959 src tok/s; 7243 tgt tok/s;     13 s elapsed
Epoch  7,   150/  454; acc:  69.97; ppl:   4.25; 6919 src tok/s; 7153 tgt tok/s;     19 s elapsed
Epoch  7,   200/  454; acc:  71.07; ppl:   4.03; 6888 src tok/s; 7160 tgt tok/s;     25 s elapsed
Epoch  7,   250/  454; acc:  70.45; ppl:   4.13; 6868 src tok/s; 7157 tgt tok/s;     31 s elapsed
Epoch  7,   300/  454; acc:  69.75; ppl:   4.43; 6934 src tok/s; 7177 tgt tok/s;     37 s elapsed
Epoch  7,   350/  454; acc:  71.36; ppl:   3.94; 6821 src tok/s; 7165 tgt tok/s;     42 s elapsed
Epoch  7,   400/  454; acc:  68.87; ppl:   4.63; 7162 src tok/s; 7340 tgt tok/s;     49 s elapsed
Epoch  7,   450/  454; acc:  69.93; ppl:   4.31; 6774 src tok/s; 7027 tgt tok/s;     55 s elapsed
Train perplexity: 4.18364
Train accuracy: 70.4355
Validation perplexity: 6.84504
Validation accuracy: 66.8653

Epoch  8,    50/  454; acc:  73.43; ppl:   3.41; 6711 src tok/s; 6923 tgt tok/s;      6 s elapsed
Epoch  8,   100/  454; acc:  73.00; ppl:   3.48; 6850 src tok/s; 7119 tgt tok/s;     12 s elapsed
Epoch  8,   150/  454; acc:  73.41; ppl:   3.38; 6826 src tok/s; 7148 tgt tok/s;     18 s elapsed
Epoch  8,   200/  454; acc:  72.50; ppl:   3.58; 6917 src tok/s; 7169 tgt tok/s;     25 s elapsed
Epoch  8,   250/  454; acc:  70.97; ppl:   3.83; 7005 src tok/s; 7243 tgt tok/s;     31 s elapsed
Epoch  8,   300/  454; acc:  72.40; ppl:   3.58; 6683 src tok/s; 7003 tgt tok/s;     37 s elapsed
Epoch  8,   350/  454; acc:  70.84; ppl:   3.97; 7073 src tok/s; 7250 tgt tok/s;     43 s elapsed
Epoch  8,   400/  454; acc:  72.78; ppl:   3.48; 6772 src tok/s; 7099 tgt tok/s;     49 s elapsed
Epoch  8,   450/  454; acc:  71.62; ppl:   3.80; 6877 src tok/s; 7127 tgt tok/s;     55 s elapsed
Train perplexity: 3.62082
Train accuracy: 72.2632
Validation perplexity: 6.7923
Validation accuracy: 66.539
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.83; ppl:   2.59; 6606 src tok/s; 6901 tgt tok/s;      6 s elapsed
Epoch  9,   100/  454; acc:  76.48; ppl:   2.85; 7013 src tok/s; 7232 tgt tok/s;     12 s elapsed
Epoch  9,   150/  454; acc:  77.34; ppl:   2.69; 6967 src tok/s; 7223 tgt tok/s;     18 s elapsed
Epoch  9,   200/  454; acc:  76.97; ppl:   2.72; 6891 src tok/s; 7151 tgt tok/s;     24 s elapsed
Epoch  9,   250/  454; acc:  76.99; ppl:   2.73; 7015 src tok/s; 7263 tgt tok/s;     30 s elapsed
Epoch  9,   300/  454; acc:  77.44; ppl:   2.66; 6926 src tok/s; 7181 tgt tok/s;     36 s elapsed
Epoch  9,   350/  454; acc:  77.76; ppl:   2.62; 6917 src tok/s; 7195 tgt tok/s;     42 s elapsed
Epoch  9,   400/  454; acc:  77.36; ppl:   2.71; 6960 src tok/s; 7218 tgt tok/s;     49 s elapsed
Epoch  9,   450/  454; acc:  76.73; ppl:   2.77; 6871 src tok/s; 7133 tgt tok/s;     55 s elapsed
Train perplexity: 2.70081
Train accuracy: 77.2398
Validation perplexity: 6.34522
Validation accuracy: 68.9088
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.12; ppl:   2.22; 6948 src tok/s; 7259 tgt tok/s;      6 s elapsed
Epoch 10,   100/  454; acc:  81.25; ppl:   2.22; 6951 src tok/s; 7215 tgt tok/s;     12 s elapsed
Epoch 10,   150/  454; acc:  81.27; ppl:   2.21; 6814 src tok/s; 7071 tgt tok/s;     18 s elapsed
Epoch 10,   200/  454; acc:  81.34; ppl:   2.19; 6833 src tok/s; 7091 tgt tok/s;     24 s elapsed
Epoch 10,   250/  454; acc:  80.33; ppl:   2.32; 6985 src tok/s; 7205 tgt tok/s;     31 s elapsed
Epoch 10,   300/  454; acc:  81.75; ppl:   2.13; 6865 src tok/s; 7145 tgt tok/s;     36 s elapsed
Epoch 10,   350/  454; acc:  80.85; ppl:   2.24; 6955 src tok/s; 7203 tgt tok/s;     42 s elapsed
Epoch 10,   400/  454; acc:  80.80; ppl:   2.26; 6959 src tok/s; 7226 tgt tok/s;     49 s elapsed
Epoch 10,   450/  454; acc:  80.89; ppl:   2.25; 6914 src tok/s; 7164 tgt tok/s;     55 s elapsed
Train perplexity: 2.22581
Train accuracy: 81.0696
Validation perplexity: 6.33577
Validation accuracy: 69.1003
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.38; ppl:   2.00; 6843 src tok/s; 7099 tgt tok/s;      6 s elapsed
Epoch 11,   100/  454; acc:  83.43; ppl:   1.98; 6814 src tok/s; 7084 tgt tok/s;     12 s elapsed
Epoch 11,   150/  454; acc:  82.99; ppl:   2.03; 6845 src tok/s; 7079 tgt tok/s;     19 s elapsed
Epoch 11,   200/  454; acc:  82.86; ppl:   2.01; 6943 src tok/s; 7217 tgt tok/s;     25 s elapsed
Epoch 11,   250/  454; acc:  83.65; ppl:   1.97; 6952 src tok/s; 7244 tgt tok/s;     30 s elapsed
Epoch 11,   300/  454; acc:  83.08; ppl:   2.02; 7143 src tok/s; 7359 tgt tok/s;     36 s elapsed
Epoch 11,   350/  454; acc:  83.78; ppl:   1.94; 6855 src tok/s; 7138 tgt tok/s;     42 s elapsed
Epoch 11,   400/  454; acc:  82.17; ppl:   2.11; 6976 src tok/s; 7217 tgt tok/s;     49 s elapsed
Epoch 11,   450/  454; acc:  83.28; ppl:   1.98; 6831 src tok/s; 7129 tgt tok/s;     54 s elapsed
Train perplexity: 2.00548
Train accuracy: 83.1656
Validation perplexity: 6.45988
Validation accuracy: 69.3841
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.35; ppl:   1.89; 6787 src tok/s; 7047 tgt tok/s;      6 s elapsed
Epoch 12,   100/  454; acc:  84.15; ppl:   1.92; 6834 src tok/s; 7121 tgt tok/s;     12 s elapsed
Epoch 12,   150/  454; acc:  83.84; ppl:   1.96; 6905 src tok/s; 7150 tgt tok/s;     19 s elapsed
Epoch 12,   200/  454; acc:  85.23; ppl:   1.83; 6943 src tok/s; 7250 tgt tok/s;     24 s elapsed
Epoch 12,   250/  454; acc:  83.95; ppl:   1.94; 7141 src tok/s; 7333 tgt tok/s;     31 s elapsed
Epoch 12,   300/  454; acc:  84.84; ppl:   1.87; 6808 src tok/s; 7088 tgt tok/s;     36 s elapsed
Epoch 12,   350/  454; acc:  84.62; ppl:   1.89; 6902 src tok/s; 7167 tgt tok/s;     42 s elapsed
Epoch 12,   400/  454; acc:  83.87; ppl:   1.97; 6975 src tok/s; 7226 tgt tok/s;     49 s elapsed
Epoch 12,   450/  454; acc:  84.38; ppl:   1.90; 6779 src tok/s; 7042 tgt tok/s;     55 s elapsed
Train perplexity: 1.90624
Train accuracy: 84.3405
Validation perplexity: 6.5728
Validation accuracy: 69.4338
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  85.72; ppl:   1.81; 6536 src tok/s; 6802 tgt tok/s;      6 s elapsed
Epoch 13,   100/  454; acc:  84.74; ppl:   1.88; 7137 src tok/s; 7359 tgt tok/s;     12 s elapsed
Epoch 13,   150/  454; acc:  85.12; ppl:   1.84; 6956 src tok/s; 7216 tgt tok/s;     18 s elapsed
Epoch 13,   200/  454; acc:  84.80; ppl:   1.90; 6883 src tok/s; 7158 tgt tok/s;     24 s elapsed
Epoch 13,   250/  454; acc:  85.31; ppl:   1.81; 6967 src tok/s; 7238 tgt tok/s;     30 s elapsed
Epoch 13,   300/  454; acc:  84.00; ppl:   1.93; 6897 src tok/s; 7157 tgt tok/s;     36 s elapsed
Epoch 13,   350/  454; acc:  85.33; ppl:   1.80; 6867 src tok/s; 7180 tgt tok/s;     42 s elapsed
Epoch 13,   400/  454; acc:  84.22; ppl:   1.93; 6971 src tok/s; 7190 tgt tok/s;     49 s elapsed
Epoch 13,   450/  454; acc:  84.89; ppl:   1.85; 6762 src tok/s; 7031 tgt tok/s;     55 s elapsed
Train perplexity: 1.86168
Train accuracy: 84.8945
Validation perplexity: 6.61241
Validation accuracy: 69.3628
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.55; ppl:   1.80; 6728 src tok/s; 6994 tgt tok/s;      6 s elapsed
Epoch 14,   100/  454; acc:  85.59; ppl:   1.82; 6894 src tok/s; 7132 tgt tok/s;     12 s elapsed
Epoch 14,   150/  454; acc:  85.38; ppl:   1.84; 6992 src tok/s; 7222 tgt tok/s;     18 s elapsed
Epoch 14,   200/  454; acc:  84.98; ppl:   1.85; 6870 src tok/s; 7158 tgt tok/s;     24 s elapsed
Epoch 14,   250/  454; acc:  85.22; ppl:   1.83; 6923 src tok/s; 7184 tgt tok/s;     30 s elapsed
Epoch 14,   300/  454; acc:  85.41; ppl:   1.83; 6978 src tok/s; 7254 tgt tok/s;     36 s elapsed
Epoch 14,   350/  454; acc:  84.63; ppl:   1.88; 6925 src tok/s; 7173 tgt tok/s;     43 s elapsed
Epoch 14,   400/  454; acc:  85.50; ppl:   1.82; 6898 src tok/s; 7180 tgt tok/s;     49 s elapsed
Epoch 14,   450/  454; acc:  85.34; ppl:   1.83; 6850 src tok/s; 7122 tgt tok/s;     55 s elapsed
Train perplexity: 1.83736
Train accuracy: 85.2388
Validation perplexity: 6.67184
Validation accuracy: 69.2564
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.00; ppl:   1.86; 6610 src tok/s; 6847 tgt tok/s;      6 s elapsed
Epoch 15,   100/  454; acc:  85.76; ppl:   1.79; 6970 src tok/s; 7241 tgt tok/s;     12 s elapsed
Epoch 15,   150/  454; acc:  86.06; ppl:   1.77; 6975 src tok/s; 7255 tgt tok/s;     18 s elapsed
Epoch 15,   200/  454; acc:  84.66; ppl:   1.89; 7060 src tok/s; 7256 tgt tok/s;     24 s elapsed
Epoch 15,   250/  454; acc:  85.20; ppl:   1.83; 6844 src tok/s; 7115 tgt tok/s;     30 s elapsed
Epoch 15,   300/  454; acc:  85.32; ppl:   1.83; 6906 src tok/s; 7182 tgt tok/s;     37 s elapsed
Epoch 15,   350/  454; acc:  86.95; ppl:   1.69; 6752 src tok/s; 7095 tgt tok/s;     42 s elapsed
Epoch 15,   400/  454; acc:  84.01; ppl:   1.95; 7019 src tok/s; 7230 tgt tok/s;     49 s elapsed
Epoch 15,   450/  454; acc:  85.19; ppl:   1.84; 6717 src tok/s; 6989 tgt tok/s;     55 s elapsed
Train perplexity: 1.82703
Train accuracy: 85.3183
Validation perplexity: 6.68718
Validation accuracy: 69.3487
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.71; ppl:   1.79; 6676 src tok/s; 6913 tgt tok/s;      6 s elapsed
Epoch 16,   100/  454; acc:  85.58; ppl:   1.82; 6767 src tok/s; 7057 tgt tok/s;     13 s elapsed
Epoch 16,   150/  454; acc:  86.24; ppl:   1.75; 7058 src tok/s; 7332 tgt tok/s;     18 s elapsed
Epoch 16,   200/  454; acc:  84.86; ppl:   1.86; 6796 src tok/s; 7024 tgt tok/s;     25 s elapsed
Epoch 16,   250/  454; acc:  84.95; ppl:   1.87; 6926 src tok/s; 7191 tgt tok/s;     31 s elapsed
Epoch 16,   300/  454; acc:  86.07; ppl:   1.76; 6990 src tok/s; 7287 tgt tok/s;     37 s elapsed
Epoch 16,   350/  454; acc:  85.23; ppl:   1.83; 6915 src tok/s; 7156 tgt tok/s;     43 s elapsed
Epoch 16,   400/  454; acc:  85.23; ppl:   1.84; 6924 src tok/s; 7194 tgt tok/s;     49 s elapsed
Epoch 16,   450/  454; acc:  84.81; ppl:   1.85; 6836 src tok/s; 7078 tgt tok/s;     55 s elapsed
Train perplexity: 1.81867
Train accuracy: 85.4201
Validation perplexity: 6.69526
Validation accuracy: 69.377
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  84.67; ppl:   1.89; 6890 src tok/s; 7099 tgt tok/s;      6 s elapsed
Epoch 17,   100/  454; acc:  86.41; ppl:   1.74; 6751 src tok/s; 7104 tgt tok/s;     12 s elapsed
Epoch 17,   150/  454; acc:  85.17; ppl:   1.84; 7015 src tok/s; 7227 tgt tok/s;     18 s elapsed
Epoch 17,   200/  454; acc:  85.74; ppl:   1.78; 6980 src tok/s; 7236 tgt tok/s;     24 s elapsed
Epoch 17,   250/  454; acc:  85.88; ppl:   1.79; 6786 src tok/s; 7041 tgt tok/s;     30 s elapsed
Epoch 17,   300/  454; acc:  85.37; ppl:   1.84; 7090 src tok/s; 7360 tgt tok/s;     36 s elapsed
Epoch 17,   350/  454; acc:  85.28; ppl:   1.83; 6955 src tok/s; 7240 tgt tok/s;     42 s elapsed
Epoch 17,   400/  454; acc:  85.21; ppl:   1.83; 6868 src tok/s; 7111 tgt tok/s;     48 s elapsed
Epoch 17,   450/  454; acc:  85.53; ppl:   1.82; 6820 src tok/s; 7091 tgt tok/s;     55 s elapsed
Train perplexity: 1.81858
Train accuracy: 85.4498
Validation perplexity: 6.70038
Validation accuracy: 69.3983
Decaying learning rate to 0.000976562
