<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.4, kappa_enc=0.4, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/seeds/encoder0.4decoder0.4dropout0.3wdropTrueseed-1', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.4)
('Using Kappa L2 loss on decoder', 0.4)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.06; ppl: 27410.05; 2668 src tok/s; 2753 tgt tok/s;     16 s elapsed
Epoch  1,   100/  454; acc:  12.08; ppl: 4206.25; 3333 src tok/s; 3474 tgt tok/s;     28 s elapsed
Epoch  1,   150/  454; acc:  16.91; ppl: 817.21; 3348 src tok/s; 3467 tgt tok/s;     41 s elapsed
Epoch  1,   200/  454; acc:  19.23; ppl: 352.67; 3232 src tok/s; 3359 tgt tok/s;     54 s elapsed
Epoch  1,   250/  454; acc:  22.53; ppl: 221.58; 3146 src tok/s; 3263 tgt tok/s;     68 s elapsed
Epoch  1,   300/  454; acc:  26.64; ppl: 142.43; 3075 src tok/s; 3216 tgt tok/s;     81 s elapsed
Epoch  1,   350/  454; acc:  27.35; ppl: 116.42; 3184 src tok/s; 3288 tgt tok/s;     94 s elapsed
Epoch  1,   400/  454; acc:  31.15; ppl:  84.75; 3109 src tok/s; 3240 tgt tok/s;    107 s elapsed
Epoch  1,   450/  454; acc:  32.13; ppl:  75.53; 3074 src tok/s; 3178 tgt tok/s;    121 s elapsed
Train perplexity: 448.146
Train accuracy: 21.859
Validation perplexity: 57.187
Validation accuracy: 34.575

Epoch  2,    50/  454; acc:  34.84; ppl:  59.05; 3159 src tok/s; 3286 tgt tok/s;     13 s elapsed
Epoch  2,   100/  454; acc:  37.89; ppl:  49.70; 3111 src tok/s; 3233 tgt tok/s;     27 s elapsed
Epoch  2,   150/  454; acc:  41.24; ppl:  38.87; 3108 src tok/s; 3236 tgt tok/s;     40 s elapsed
Epoch  2,   200/  454; acc:  41.35; ppl:  37.46; 3185 src tok/s; 3307 tgt tok/s;     53 s elapsed
Epoch  2,   250/  454; acc:  43.68; ppl:  30.74; 3134 src tok/s; 3228 tgt tok/s;     67 s elapsed
Epoch  2,   300/  454; acc:  48.25; ppl:  23.76; 3156 src tok/s; 3282 tgt tok/s;     80 s elapsed
Epoch  2,   350/  454; acc:  47.87; ppl:  23.10; 3160 src tok/s; 3282 tgt tok/s;     94 s elapsed
Epoch  2,   400/  454; acc:  50.42; ppl:  20.51; 3173 src tok/s; 3284 tgt tok/s;    107 s elapsed
Epoch  2,   450/  454; acc:  50.84; ppl:  19.30; 3128 src tok/s; 3244 tgt tok/s;    120 s elapsed
Train perplexity: 31.1717
Train accuracy: 44.0863
Validation perplexity: 15.3908
Validation accuracy: 54.7609

Epoch  3,    50/  454; acc:  52.43; ppl:  16.70; 3188 src tok/s; 3284 tgt tok/s;     14 s elapsed
Epoch  3,   100/  454; acc:  55.43; ppl:  13.78; 3107 src tok/s; 3257 tgt tok/s;     27 s elapsed
Epoch  3,   150/  454; acc:  57.19; ppl:  12.31; 3128 src tok/s; 3271 tgt tok/s;     39 s elapsed
Epoch  3,   200/  454; acc:  54.83; ppl:  14.08; 3185 src tok/s; 3299 tgt tok/s;     53 s elapsed
Epoch  3,   250/  454; acc:  57.22; ppl:  12.65; 3221 src tok/s; 3333 tgt tok/s;     67 s elapsed
Epoch  3,   300/  454; acc:  57.85; ppl:  11.84; 3169 src tok/s; 3300 tgt tok/s;     79 s elapsed
Epoch  3,   350/  454; acc:  56.09; ppl:  13.27; 3151 src tok/s; 3255 tgt tok/s;     93 s elapsed
Epoch  3,   400/  454; acc:  59.32; ppl:  10.53; 3165 src tok/s; 3287 tgt tok/s;    106 s elapsed
Epoch  3,   450/  454; acc:  59.21; ppl:  10.69; 3069 src tok/s; 3184 tgt tok/s;    119 s elapsed
Train perplexity: 12.8056
Train accuracy: 56.5405
Validation perplexity: 10.86
Validation accuracy: 58.9896

Epoch  4,    50/  454; acc:  60.68; ppl:   9.08; 3176 src tok/s; 3289 tgt tok/s;     13 s elapsed
Epoch  4,   100/  454; acc:  62.43; ppl:   8.24; 3165 src tok/s; 3294 tgt tok/s;     26 s elapsed
Epoch  4,   150/  454; acc:  62.01; ppl:   8.34; 3192 src tok/s; 3307 tgt tok/s;     39 s elapsed
Epoch  4,   200/  454; acc:  61.20; ppl:   8.80; 3190 src tok/s; 3306 tgt tok/s;     53 s elapsed
Epoch  4,   250/  454; acc:  62.83; ppl:   8.02; 3220 src tok/s; 3330 tgt tok/s;     66 s elapsed
Epoch  4,   300/  454; acc:  62.36; ppl:   8.39; 3096 src tok/s; 3221 tgt tok/s;     79 s elapsed
Epoch  4,   350/  454; acc:  61.24; ppl:   8.40; 3211 src tok/s; 3316 tgt tok/s;     93 s elapsed
Epoch  4,   400/  454; acc:  63.90; ppl:   7.47; 3117 src tok/s; 3259 tgt tok/s;    106 s elapsed
Epoch  4,   450/  454; acc:  62.32; ppl:   8.11; 3115 src tok/s; 3243 tgt tok/s;    119 s elapsed
Train perplexity: 8.31283
Train accuracy: 62.0902
Validation perplexity: 8.10017
Validation accuracy: 63.8073

Epoch  5,    50/  454; acc:  65.84; ppl:   6.13; 3172 src tok/s; 3308 tgt tok/s;     13 s elapsed
Epoch  5,   100/  454; acc:  64.67; ppl:   6.54; 3132 src tok/s; 3255 tgt tok/s;     27 s elapsed
Epoch  5,   150/  454; acc:  66.09; ppl:   6.04; 3170 src tok/s; 3299 tgt tok/s;     39 s elapsed
Epoch  5,   200/  454; acc:  64.91; ppl:   6.57; 3216 src tok/s; 3313 tgt tok/s;     53 s elapsed
Epoch  5,   250/  454; acc:  66.60; ppl:   5.91; 3154 src tok/s; 3272 tgt tok/s;     66 s elapsed
Epoch  5,   300/  454; acc:  64.81; ppl:   6.45; 3216 src tok/s; 3318 tgt tok/s;     79 s elapsed
Epoch  5,   350/  454; acc:  65.74; ppl:   6.10; 3108 src tok/s; 3252 tgt tok/s;     92 s elapsed
Epoch  5,   400/  454; acc:  64.78; ppl:   6.54; 3233 src tok/s; 3337 tgt tok/s;    106 s elapsed
Epoch  5,   450/  454; acc:  65.77; ppl:   6.14; 3082 src tok/s; 3215 tgt tok/s;    119 s elapsed
Train perplexity: 6.27036
Train accuracy: 65.4471
Validation perplexity: 7.10791
Validation accuracy: 66.3545

Epoch  6,    50/  454; acc:  69.24; ppl:   4.72; 3203 src tok/s; 3327 tgt tok/s;     13 s elapsed
Epoch  6,   100/  454; acc:  67.96; ppl:   5.11; 3229 src tok/s; 3334 tgt tok/s;     26 s elapsed
Epoch  6,   150/  454; acc:  68.09; ppl:   5.01; 3169 src tok/s; 3282 tgt tok/s;     40 s elapsed
Epoch  6,   200/  454; acc:  69.12; ppl:   4.81; 3196 src tok/s; 3321 tgt tok/s;     52 s elapsed
Epoch  6,   250/  454; acc:  68.84; ppl:   4.89; 3123 src tok/s; 3250 tgt tok/s;     65 s elapsed
Epoch  6,   300/  454; acc:  67.36; ppl:   5.21; 3208 src tok/s; 3320 tgt tok/s;     79 s elapsed
Epoch  6,   350/  454; acc:  68.01; ppl:   5.09; 3197 src tok/s; 3318 tgt tok/s;     92 s elapsed
Epoch  6,   400/  454; acc:  67.72; ppl:   5.16; 3159 src tok/s; 3295 tgt tok/s;    105 s elapsed
Epoch  6,   450/  454; acc:  67.69; ppl:   5.22; 3126 src tok/s; 3245 tgt tok/s;    119 s elapsed
Train perplexity: 5.024
Train accuracy: 68.212
Validation perplexity: 6.88026
Validation accuracy: 65.8011

Epoch  7,    50/  454; acc:  72.32; ppl:   3.74; 3113 src tok/s; 3253 tgt tok/s;     13 s elapsed
Epoch  7,   100/  454; acc:  69.49; ppl:   4.39; 3152 src tok/s; 3260 tgt tok/s;     27 s elapsed
Epoch  7,   150/  454; acc:  70.05; ppl:   4.30; 3209 src tok/s; 3329 tgt tok/s;     40 s elapsed
Epoch  7,   200/  454; acc:  70.83; ppl:   4.11; 3167 src tok/s; 3292 tgt tok/s;     53 s elapsed
Epoch  7,   250/  454; acc:  69.49; ppl:   4.43; 3127 src tok/s; 3246 tgt tok/s;     66 s elapsed
Epoch  7,   300/  454; acc:  70.33; ppl:   4.15; 3203 src tok/s; 3325 tgt tok/s;     80 s elapsed
Epoch  7,   350/  454; acc:  69.17; ppl:   4.47; 3180 src tok/s; 3285 tgt tok/s;     93 s elapsed
Epoch  7,   400/  454; acc:  70.50; ppl:   4.14; 3184 src tok/s; 3298 tgt tok/s;    106 s elapsed
Epoch  7,   450/  454; acc:  69.62; ppl:   4.36; 3182 src tok/s; 3304 tgt tok/s;    119 s elapsed
Train perplexity: 4.22827
Train accuracy: 70.1846
Validation perplexity: 6.49405
Validation accuracy: 66.837

Epoch  8,    50/  454; acc:  74.32; ppl:   3.19; 3235 src tok/s; 3358 tgt tok/s;     13 s elapsed
Epoch  8,   100/  454; acc:  72.15; ppl:   3.63; 3216 src tok/s; 3320 tgt tok/s;     26 s elapsed
Epoch  8,   150/  454; acc:  71.51; ppl:   3.79; 3174 src tok/s; 3276 tgt tok/s;     40 s elapsed
Epoch  8,   200/  454; acc:  73.43; ppl:   3.35; 3142 src tok/s; 3275 tgt tok/s;     53 s elapsed
Epoch  8,   250/  454; acc:  71.79; ppl:   3.73; 3117 src tok/s; 3247 tgt tok/s;     66 s elapsed
Epoch  8,   300/  454; acc:  71.58; ppl:   3.75; 3179 src tok/s; 3299 tgt tok/s;     79 s elapsed
Epoch  8,   350/  454; acc:  71.90; ppl:   3.63; 3186 src tok/s; 3301 tgt tok/s;     92 s elapsed
Epoch  8,   400/  454; acc:  71.05; ppl:   3.92; 3131 src tok/s; 3260 tgt tok/s;    106 s elapsed
Epoch  8,   450/  454; acc:  71.03; ppl:   3.85; 3142 src tok/s; 3263 tgt tok/s;    119 s elapsed
Train perplexity: 3.64875
Train accuracy: 72.0671
Validation perplexity: 6.57163
Validation accuracy: 66.9221
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.14; ppl:   2.70; 3118 src tok/s; 3256 tgt tok/s;     13 s elapsed
Epoch  9,   100/  454; acc:  76.63; ppl:   2.78; 3190 src tok/s; 3284 tgt tok/s;     27 s elapsed
Epoch  9,   150/  454; acc:  77.32; ppl:   2.73; 3244 src tok/s; 3351 tgt tok/s;     40 s elapsed
Epoch  9,   200/  454; acc:  77.30; ppl:   2.73; 3011 src tok/s; 3148 tgt tok/s;     53 s elapsed
Epoch  9,   250/  454; acc:  77.38; ppl:   2.68; 3167 src tok/s; 3306 tgt tok/s;     66 s elapsed
Epoch  9,   300/  454; acc:  76.85; ppl:   2.74; 3184 src tok/s; 3305 tgt tok/s;     80 s elapsed
Epoch  9,   350/  454; acc:  76.55; ppl:   2.83; 3215 src tok/s; 3317 tgt tok/s;     94 s elapsed
Epoch  9,   400/  454; acc:  77.49; ppl:   2.66; 3196 src tok/s; 3318 tgt tok/s;    106 s elapsed
Epoch  9,   450/  454; acc:  77.12; ppl:   2.72; 3167 src tok/s; 3291 tgt tok/s;    119 s elapsed
Train perplexity: 2.73096
Train accuracy: 77.0799
Validation perplexity: 6.15769
Validation accuracy: 68.8875
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.66; ppl:   2.27; 3173 src tok/s; 3294 tgt tok/s;     14 s elapsed
Epoch 10,   100/  454; acc:  81.57; ppl:   2.18; 3217 src tok/s; 3351 tgt tok/s;     26 s elapsed
Epoch 10,   150/  454; acc:  80.43; ppl:   2.31; 3184 src tok/s; 3293 tgt tok/s;     40 s elapsed
Epoch 10,   200/  454; acc:  81.46; ppl:   2.16; 3164 src tok/s; 3283 tgt tok/s;     53 s elapsed
Epoch 10,   250/  454; acc:  81.37; ppl:   2.17; 3198 src tok/s; 3321 tgt tok/s;     66 s elapsed
Epoch 10,   300/  454; acc:  79.83; ppl:   2.35; 3106 src tok/s; 3222 tgt tok/s;     79 s elapsed
Epoch 10,   350/  454; acc:  80.27; ppl:   2.28; 3195 src tok/s; 3316 tgt tok/s;     93 s elapsed
Epoch 10,   400/  454; acc:  81.14; ppl:   2.19; 3171 src tok/s; 3293 tgt tok/s;    106 s elapsed
Epoch 10,   450/  454; acc:  81.44; ppl:   2.16; 3139 src tok/s; 3272 tgt tok/s;    118 s elapsed
Train perplexity: 2.24534
Train accuracy: 80.7872
Validation perplexity: 6.17715
Validation accuracy: 69.2919
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  82.84; ppl:   2.03; 3162 src tok/s; 3280 tgt tok/s;     13 s elapsed
Epoch 11,   100/  454; acc:  83.20; ppl:   2.03; 3101 src tok/s; 3227 tgt tok/s;     27 s elapsed
Epoch 11,   150/  454; acc:  82.89; ppl:   2.01; 3136 src tok/s; 3255 tgt tok/s;     40 s elapsed
Epoch 11,   200/  454; acc:  83.26; ppl:   2.01; 3178 src tok/s; 3277 tgt tok/s;     53 s elapsed
Epoch 11,   250/  454; acc:  83.65; ppl:   1.96; 3179 src tok/s; 3327 tgt tok/s;     66 s elapsed
Epoch 11,   300/  454; acc:  82.00; ppl:   2.12; 3187 src tok/s; 3308 tgt tok/s;     80 s elapsed
Epoch 11,   350/  454; acc:  82.49; ppl:   2.07; 3193 src tok/s; 3312 tgt tok/s;     93 s elapsed
Epoch 11,   400/  454; acc:  83.06; ppl:   1.99; 3192 src tok/s; 3314 tgt tok/s;    106 s elapsed
Epoch 11,   450/  454; acc:  83.21; ppl:   2.00; 3194 src tok/s; 3309 tgt tok/s;    119 s elapsed
Train perplexity: 2.02658
Train accuracy: 82.9155
Validation perplexity: 6.28848
Validation accuracy: 69.4551
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.94; ppl:   1.86; 3110 src tok/s; 3244 tgt tok/s;     13 s elapsed
Epoch 12,   100/  454; acc:  84.10; ppl:   1.95; 3194 src tok/s; 3287 tgt tok/s;     27 s elapsed
Epoch 12,   150/  454; acc:  84.87; ppl:   1.86; 3111 src tok/s; 3247 tgt tok/s;     39 s elapsed
Epoch 12,   200/  454; acc:  83.38; ppl:   2.00; 3274 src tok/s; 3374 tgt tok/s;     53 s elapsed
Epoch 12,   250/  454; acc:  84.10; ppl:   1.93; 3129 src tok/s; 3264 tgt tok/s;     66 s elapsed
Epoch 12,   300/  454; acc:  83.69; ppl:   1.96; 3234 src tok/s; 3346 tgt tok/s;     79 s elapsed
Epoch 12,   350/  454; acc:  83.16; ppl:   2.03; 3213 src tok/s; 3308 tgt tok/s;     93 s elapsed
Epoch 12,   400/  454; acc:  85.31; ppl:   1.82; 3154 src tok/s; 3311 tgt tok/s;    106 s elapsed
Epoch 12,   450/  454; acc:  84.55; ppl:   1.89; 3166 src tok/s; 3304 tgt tok/s;    118 s elapsed
Train perplexity: 1.92977
Train accuracy: 84.1444
Validation perplexity: 6.39801
Validation accuracy: 69.4977
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.28; ppl:   1.93; 3216 src tok/s; 3316 tgt tok/s;     13 s elapsed
Epoch 13,   100/  454; acc:  85.30; ppl:   1.82; 3176 src tok/s; 3309 tgt tok/s;     26 s elapsed
Epoch 13,   150/  454; acc:  84.70; ppl:   1.87; 3159 src tok/s; 3284 tgt tok/s;     39 s elapsed
Epoch 13,   200/  454; acc:  84.70; ppl:   1.87; 3211 src tok/s; 3309 tgt tok/s;     53 s elapsed
Epoch 13,   250/  454; acc:  84.65; ppl:   1.87; 3144 src tok/s; 3273 tgt tok/s;     66 s elapsed
Epoch 13,   300/  454; acc:  84.37; ppl:   1.92; 3194 src tok/s; 3321 tgt tok/s;     79 s elapsed
Epoch 13,   350/  454; acc:  83.72; ppl:   1.98; 3162 src tok/s; 3267 tgt tok/s;     93 s elapsed
Epoch 13,   400/  454; acc:  85.73; ppl:   1.78; 3187 src tok/s; 3334 tgt tok/s;    106 s elapsed
Epoch 13,   450/  454; acc:  84.80; ppl:   1.88; 3162 src tok/s; 3287 tgt tok/s;    119 s elapsed
Train perplexity: 1.87962
Train accuracy: 84.6925
Validation perplexity: 6.44092
Validation accuracy: 69.6254
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.70; ppl:   1.80; 3191 src tok/s; 3328 tgt tok/s;     13 s elapsed
Epoch 14,   100/  454; acc:  84.49; ppl:   1.90; 3183 src tok/s; 3289 tgt tok/s;     26 s elapsed
Epoch 14,   150/  454; acc:  85.14; ppl:   1.83; 3198 src tok/s; 3321 tgt tok/s;     39 s elapsed
Epoch 14,   200/  454; acc:  84.84; ppl:   1.88; 3112 src tok/s; 3219 tgt tok/s;     53 s elapsed
Epoch 14,   250/  454; acc:  85.41; ppl:   1.82; 3216 src tok/s; 3338 tgt tok/s;     66 s elapsed
Epoch 14,   300/  454; acc:  84.51; ppl:   1.90; 3176 src tok/s; 3283 tgt tok/s;     79 s elapsed
Epoch 14,   350/  454; acc:  84.43; ppl:   1.90; 3187 src tok/s; 3298 tgt tok/s;     93 s elapsed
Epoch 14,   400/  454; acc:  85.11; ppl:   1.83; 3100 src tok/s; 3236 tgt tok/s;    106 s elapsed
Epoch 14,   450/  454; acc:  84.56; ppl:   1.88; 3137 src tok/s; 3266 tgt tok/s;    119 s elapsed
Train perplexity: 1.8571
Train accuracy: 84.9181
Validation perplexity: 6.48906
Validation accuracy: 69.5615
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.19; ppl:   1.84; 3156 src tok/s; 3280 tgt tok/s;     14 s elapsed
Epoch 15,   100/  454; acc:  85.05; ppl:   1.85; 3181 src tok/s; 3306 tgt tok/s;     27 s elapsed
Epoch 15,   150/  454; acc:  85.25; ppl:   1.83; 3291 src tok/s; 3393 tgt tok/s;     39 s elapsed
Epoch 15,   200/  454; acc:  85.17; ppl:   1.83; 3171 src tok/s; 3293 tgt tok/s;     53 s elapsed
Epoch 15,   250/  454; acc:  85.32; ppl:   1.83; 3169 src tok/s; 3297 tgt tok/s;     66 s elapsed
Epoch 15,   300/  454; acc:  84.61; ppl:   1.87; 3170 src tok/s; 3285 tgt tok/s;     79 s elapsed
Epoch 15,   350/  454; acc:  84.96; ppl:   1.86; 3172 src tok/s; 3292 tgt tok/s;     92 s elapsed
Epoch 15,   400/  454; acc:  85.02; ppl:   1.86; 3205 src tok/s; 3335 tgt tok/s;    105 s elapsed
Epoch 15,   450/  454; acc:  85.62; ppl:   1.80; 3117 src tok/s; 3244 tgt tok/s;    118 s elapsed
Train perplexity: 1.84569
Train accuracy: 85.0691
Validation perplexity: 6.49865
Validation accuracy: 69.5686
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.75; ppl:   1.80; 3196 src tok/s; 3320 tgt tok/s;     13 s elapsed
Epoch 16,   100/  454; acc:  84.66; ppl:   1.89; 3167 src tok/s; 3273 tgt tok/s;     26 s elapsed
Epoch 16,   150/  454; acc:  86.22; ppl:   1.77; 3186 src tok/s; 3320 tgt tok/s;     39 s elapsed
Epoch 16,   200/  454; acc:  84.12; ppl:   1.92; 3161 src tok/s; 3264 tgt tok/s;     53 s elapsed
Epoch 16,   250/  454; acc:  85.19; ppl:   1.83; 3227 src tok/s; 3339 tgt tok/s;     66 s elapsed
Epoch 16,   300/  454; acc:  85.25; ppl:   1.83; 3120 src tok/s; 3260 tgt tok/s;     79 s elapsed
Epoch 16,   350/  454; acc:  84.24; ppl:   1.92; 3158 src tok/s; 3270 tgt tok/s;     93 s elapsed
Epoch 16,   400/  454; acc:  86.28; ppl:   1.71; 3218 src tok/s; 3342 tgt tok/s;    106 s elapsed
Epoch 16,   450/  454; acc:  84.96; ppl:   1.87; 3095 src tok/s; 3218 tgt tok/s;    119 s elapsed
Train perplexity: 1.83945
Train accuracy: 85.1767
Validation perplexity: 6.50681
Validation accuracy: 69.5189
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  84.70; ppl:   1.90; 3241 src tok/s; 3336 tgt tok/s;     13 s elapsed
Epoch 17,   100/  454; acc:  85.88; ppl:   1.77; 3159 src tok/s; 3297 tgt tok/s;     26 s elapsed
Epoch 17,   150/  454; acc:  84.99; ppl:   1.86; 3152 src tok/s; 3282 tgt tok/s;     39 s elapsed
Epoch 17,   200/  454; acc:  85.37; ppl:   1.82; 3169 src tok/s; 3298 tgt tok/s;     53 s elapsed
Epoch 17,   250/  454; acc:  85.70; ppl:   1.79; 3121 src tok/s; 3249 tgt tok/s;     65 s elapsed
Epoch 17,   300/  454; acc:  84.77; ppl:   1.87; 3272 src tok/s; 3366 tgt tok/s;     79 s elapsed
Epoch 17,   350/  454; acc:  84.36; ppl:   1.91; 3118 src tok/s; 3238 tgt tok/s;     93 s elapsed
Epoch 17,   400/  454; acc:  85.66; ppl:   1.78; 3159 src tok/s; 3271 tgt tok/s;    106 s elapsed
Epoch 17,   450/  454; acc:  85.38; ppl:   1.82; 3108 src tok/s; 3243 tgt tok/s;    119 s elapsed
Train perplexity: 1.83592
Train accuracy: 85.1888
Validation perplexity: 6.51045
Validation accuracy: 69.5615
Decaying learning rate to 0.000976562
