<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.2, kappa_enc=0.05, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.05decoder0.2dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.05)
('Using Kappa L2 loss on decoder', 0.2)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   9.65; ppl: 11734.55; 2780 src tok/s; 2891 tgt tok/s;     15 s elapsed
Epoch  1,   100/  454; acc:  15.73; ppl: 1170.00; 3300 src tok/s; 3448 tgt tok/s;     28 s elapsed
Epoch  1,   150/  454; acc:  18.31; ppl: 520.32; 3342 src tok/s; 3447 tgt tok/s;     41 s elapsed
Epoch  1,   200/  454; acc:  22.03; ppl: 240.38; 3322 src tok/s; 3450 tgt tok/s;     53 s elapsed
Epoch  1,   250/  454; acc:  23.89; ppl: 179.00; 3359 src tok/s; 3461 tgt tok/s;     66 s elapsed
Epoch  1,   300/  454; acc:  29.08; ppl: 109.04; 3351 src tok/s; 3497 tgt tok/s;     78 s elapsed
Epoch  1,   350/  454; acc:  29.91; ppl:  93.77; 3299 src tok/s; 3433 tgt tok/s;     91 s elapsed
Epoch  1,   400/  454; acc:  31.48; ppl:  76.45; 3387 src tok/s; 3495 tgt tok/s;    103 s elapsed
Epoch  1,   450/  454; acc:  33.01; ppl:  67.63; 3259 src tok/s; 3386 tgt tok/s;    116 s elapsed
Train perplexity: 293.699
Train accuracy: 23.7073
Validation perplexity: 74.543
Validation accuracy: 27.4301

Epoch  2,    50/  454; acc:  35.54; ppl:  53.54; 3281 src tok/s; 3400 tgt tok/s;     13 s elapsed
Epoch  2,   100/  454; acc:  38.20; ppl:  46.63; 3351 src tok/s; 3468 tgt tok/s;     25 s elapsed
Epoch  2,   150/  454; acc:  39.49; ppl:  41.62; 3381 src tok/s; 3493 tgt tok/s;     38 s elapsed
Epoch  2,   200/  454; acc:  43.95; ppl:  29.88; 3328 src tok/s; 3468 tgt tok/s;     50 s elapsed
Epoch  2,   250/  454; acc:  44.67; ppl:  29.26; 3328 src tok/s; 3462 tgt tok/s;     63 s elapsed
Epoch  2,   300/  454; acc:  47.90; ppl:  23.62; 3339 src tok/s; 3468 tgt tok/s;     75 s elapsed
Epoch  2,   350/  454; acc:  49.24; ppl:  21.52; 3329 src tok/s; 3470 tgt tok/s;     88 s elapsed
Epoch  2,   400/  454; acc:  49.27; ppl:  20.94; 3288 src tok/s; 3415 tgt tok/s;    101 s elapsed
Epoch  2,   450/  454; acc:  51.28; ppl:  19.14; 3281 src tok/s; 3397 tgt tok/s;    114 s elapsed
Train perplexity: 29.663
Train accuracy: 44.4647
Validation perplexity: 16.0851
Validation accuracy: 52.76

Epoch  3,    50/  454; acc:  54.47; ppl:  14.40; 3259 src tok/s; 3390 tgt tok/s;     13 s elapsed
Epoch  3,   100/  454; acc:  53.80; ppl:  15.12; 3400 src tok/s; 3507 tgt tok/s;     25 s elapsed
Epoch  3,   150/  454; acc:  55.73; ppl:  13.63; 3381 src tok/s; 3486 tgt tok/s;     38 s elapsed
Epoch  3,   200/  454; acc:  55.77; ppl:  13.37; 3290 src tok/s; 3426 tgt tok/s;     50 s elapsed
Epoch  3,   250/  454; acc:  56.42; ppl:  12.65; 3353 src tok/s; 3469 tgt tok/s;     63 s elapsed
Epoch  3,   300/  454; acc:  58.38; ppl:  11.36; 3262 src tok/s; 3414 tgt tok/s;     76 s elapsed
Epoch  3,   350/  454; acc:  57.78; ppl:  11.72; 3343 src tok/s; 3461 tgt tok/s;     88 s elapsed
Epoch  3,   400/  454; acc:  58.75; ppl:  10.87; 3333 src tok/s; 3463 tgt tok/s;    101 s elapsed
Epoch  3,   450/  454; acc:  58.36; ppl:  11.14; 3331 src tok/s; 3462 tgt tok/s;    113 s elapsed
Train perplexity: 12.5879
Train accuracy: 56.6388
Validation perplexity: 10.2453
Validation accuracy: 60.7138

Epoch  4,    50/  454; acc:  62.11; ppl:   8.31; 3296 src tok/s; 3441 tgt tok/s;     12 s elapsed
Epoch  4,   100/  454; acc:  61.14; ppl:   8.87; 3360 src tok/s; 3476 tgt tok/s;     25 s elapsed
Epoch  4,   150/  454; acc:  60.93; ppl:   8.78; 3310 src tok/s; 3421 tgt tok/s;     38 s elapsed
Epoch  4,   200/  454; acc:  62.36; ppl:   8.12; 3325 src tok/s; 3468 tgt tok/s;     50 s elapsed
Epoch  4,   250/  454; acc:  61.14; ppl:   8.73; 3285 src tok/s; 3399 tgt tok/s;     63 s elapsed
Epoch  4,   300/  454; acc:  62.64; ppl:   8.00; 3395 src tok/s; 3526 tgt tok/s;     75 s elapsed
Epoch  4,   350/  454; acc:  63.17; ppl:   7.72; 3395 src tok/s; 3519 tgt tok/s;     88 s elapsed
Epoch  4,   400/  454; acc:  62.26; ppl:   8.06; 3299 src tok/s; 3423 tgt tok/s;    101 s elapsed
Epoch  4,   450/  454; acc:  62.74; ppl:   7.84; 3271 src tok/s; 3398 tgt tok/s;    113 s elapsed
Train perplexity: 8.26786
Train accuracy: 62.0405
Validation perplexity: 8.28358
Validation accuracy: 63.4242

Epoch  5,    50/  454; acc:  65.42; ppl:   6.27; 3309 src tok/s; 3417 tgt tok/s;     13 s elapsed
Epoch  5,   100/  454; acc:  65.55; ppl:   6.21; 3330 src tok/s; 3459 tgt tok/s;     25 s elapsed
Epoch  5,   150/  454; acc:  65.40; ppl:   6.26; 3242 src tok/s; 3384 tgt tok/s;     38 s elapsed
Epoch  5,   200/  454; acc:  65.82; ppl:   6.22; 3350 src tok/s; 3477 tgt tok/s;     51 s elapsed
Epoch  5,   250/  454; acc:  65.19; ppl:   6.42; 3423 src tok/s; 3544 tgt tok/s;     63 s elapsed
Epoch  5,   300/  454; acc:  65.25; ppl:   6.28; 3320 src tok/s; 3465 tgt tok/s;     76 s elapsed
Epoch  5,   350/  454; acc:  65.15; ppl:   6.41; 3379 src tok/s; 3490 tgt tok/s;     88 s elapsed
Epoch  5,   400/  454; acc:  65.83; ppl:   6.06; 3332 src tok/s; 3452 tgt tok/s;    101 s elapsed
Epoch  5,   450/  454; acc:  65.97; ppl:   6.04; 3309 src tok/s; 3433 tgt tok/s;    113 s elapsed
Train perplexity: 6.23007
Train accuracy: 65.5373
Validation perplexity: 7.50624
Validation accuracy: 65.4889

Epoch  6,    50/  454; acc:  69.09; ppl:   4.77; 3274 src tok/s; 3415 tgt tok/s;     12 s elapsed
Epoch  6,   100/  454; acc:  68.46; ppl:   4.93; 3348 src tok/s; 3465 tgt tok/s;     25 s elapsed
Epoch  6,   150/  454; acc:  68.26; ppl:   5.01; 3325 src tok/s; 3457 tgt tok/s;     38 s elapsed
Epoch  6,   200/  454; acc:  68.31; ppl:   5.00; 3356 src tok/s; 3479 tgt tok/s;     51 s elapsed
Epoch  6,   250/  454; acc:  68.15; ppl:   5.03; 3348 src tok/s; 3491 tgt tok/s;     63 s elapsed
Epoch  6,   300/  454; acc:  67.65; ppl:   5.20; 3373 src tok/s; 3490 tgt tok/s;     76 s elapsed
Epoch  6,   350/  454; acc:  67.03; ppl:   5.38; 3390 src tok/s; 3498 tgt tok/s;     88 s elapsed
Epoch  6,   400/  454; acc:  68.53; ppl:   4.90; 3287 src tok/s; 3428 tgt tok/s;    101 s elapsed
Epoch  6,   450/  454; acc:  68.28; ppl:   4.96; 3284 src tok/s; 3412 tgt tok/s;    113 s elapsed
Train perplexity: 5.03338
Train accuracy: 68.1372
Validation perplexity: 7.85977
Validation accuracy: 64.2543
Decaying learning rate to 0.5

Epoch  7,    50/  454; acc:  72.56; ppl:   3.79; 3299 src tok/s; 3406 tgt tok/s;     13 s elapsed
Epoch  7,   100/  454; acc:  73.45; ppl:   3.56; 3285 src tok/s; 3419 tgt tok/s;     26 s elapsed
Epoch  7,   150/  454; acc:  73.58; ppl:   3.56; 3311 src tok/s; 3440 tgt tok/s;     38 s elapsed
Epoch  7,   200/  454; acc:  73.36; ppl:   3.54; 3371 src tok/s; 3494 tgt tok/s;     51 s elapsed
Epoch  7,   250/  454; acc:  74.14; ppl:   3.44; 3396 src tok/s; 3514 tgt tok/s;     63 s elapsed
Epoch  7,   300/  454; acc:  72.93; ppl:   3.72; 3320 src tok/s; 3455 tgt tok/s;     76 s elapsed
Epoch  7,   350/  454; acc:  73.40; ppl:   3.58; 3283 src tok/s; 3418 tgt tok/s;     88 s elapsed
Epoch  7,   400/  454; acc:  73.14; ppl:   3.64; 3293 src tok/s; 3425 tgt tok/s;    101 s elapsed
Epoch  7,   450/  454; acc:  73.60; ppl:   3.51; 3340 src tok/s; 3458 tgt tok/s;    114 s elapsed
Train perplexity: 3.59028
Train accuracy: 73.3499
Validation perplexity: 6.08753
Validation accuracy: 68.256
Decaying learning rate to 0.25

Epoch  8,    50/  454; acc:  77.78; ppl:   2.80; 3243 src tok/s; 3361 tgt tok/s;     12 s elapsed
Epoch  8,   100/  454; acc:  76.83; ppl:   2.95; 3369 src tok/s; 3475 tgt tok/s;     25 s elapsed
Epoch  8,   150/  454; acc:  78.71; ppl:   2.63; 3267 src tok/s; 3421 tgt tok/s;     37 s elapsed
Epoch  8,   200/  454; acc:  75.72; ppl:   3.12; 3342 src tok/s; 3443 tgt tok/s;     51 s elapsed
Epoch  8,   250/  454; acc:  77.18; ppl:   2.88; 3355 src tok/s; 3486 tgt tok/s;     63 s elapsed
Epoch  8,   300/  454; acc:  76.36; ppl:   2.99; 3349 src tok/s; 3494 tgt tok/s;     76 s elapsed
Epoch  8,   350/  454; acc:  76.07; ppl:   3.03; 3346 src tok/s; 3465 tgt tok/s;     89 s elapsed
Epoch  8,   400/  454; acc:  77.99; ppl:   2.71; 3379 src tok/s; 3521 tgt tok/s;    101 s elapsed
Epoch  8,   450/  454; acc:  76.52; ppl:   2.88; 3271 src tok/s; 3394 tgt tok/s;    113 s elapsed
Train perplexity: 2.89006
Train accuracy: 76.9758
Validation perplexity: 6.07628
Validation accuracy: 69.1287
Decaying learning rate to 0.125

Epoch  9,    50/  454; acc:  78.49; ppl:   2.68; 3306 src tok/s; 3401 tgt tok/s;     13 s elapsed
Epoch  9,   100/  454; acc:  80.37; ppl:   2.39; 3323 src tok/s; 3458 tgt tok/s;     25 s elapsed
Epoch  9,   150/  454; acc:  78.53; ppl:   2.64; 3271 src tok/s; 3397 tgt tok/s;     39 s elapsed
Epoch  9,   200/  454; acc:  79.14; ppl:   2.55; 3313 src tok/s; 3431 tgt tok/s;     51 s elapsed
Epoch  9,   250/  454; acc:  79.46; ppl:   2.51; 3346 src tok/s; 3474 tgt tok/s;     64 s elapsed
Epoch  9,   300/  454; acc:  79.01; ppl:   2.59; 3328 src tok/s; 3463 tgt tok/s;     76 s elapsed
Epoch  9,   350/  454; acc:  79.25; ppl:   2.52; 3332 src tok/s; 3461 tgt tok/s;     89 s elapsed
Epoch  9,   400/  454; acc:  78.26; ppl:   2.67; 3350 src tok/s; 3478 tgt tok/s;    101 s elapsed
Epoch  9,   450/  454; acc:  78.87; ppl:   2.57; 3251 src tok/s; 3393 tgt tok/s;    114 s elapsed
Train perplexity: 2.56998
Train accuracy: 79.0267
Validation perplexity: 6.14599
Validation accuracy: 69.4196
Decaying learning rate to 0.0625

Epoch 10,    50/  454; acc:  80.22; ppl:   2.42; 3264 src tok/s; 3386 tgt tok/s;     13 s elapsed
Epoch 10,   100/  454; acc:  80.59; ppl:   2.36; 3286 src tok/s; 3406 tgt tok/s;     26 s elapsed
Epoch 10,   150/  454; acc:  79.78; ppl:   2.44; 3305 src tok/s; 3447 tgt tok/s;     38 s elapsed
Epoch 10,   200/  454; acc:  80.58; ppl:   2.36; 3362 src tok/s; 3499 tgt tok/s;     51 s elapsed
Epoch 10,   250/  454; acc:  79.96; ppl:   2.46; 3284 src tok/s; 3409 tgt tok/s;     63 s elapsed
Epoch 10,   300/  454; acc:  80.39; ppl:   2.41; 3345 src tok/s; 3461 tgt tok/s;     76 s elapsed
Epoch 10,   350/  454; acc:  79.94; ppl:   2.44; 3322 src tok/s; 3438 tgt tok/s;     89 s elapsed
Epoch 10,   400/  454; acc:  80.35; ppl:   2.39; 3374 src tok/s; 3501 tgt tok/s;    101 s elapsed
Epoch 10,   450/  454; acc:  79.88; ppl:   2.47; 3263 src tok/s; 3389 tgt tok/s;    114 s elapsed
Train perplexity: 2.41517
Train accuracy: 80.1831
Validation perplexity: 6.2736
Validation accuracy: 69.3061
Decaying learning rate to 0.03125

Epoch 11,    50/  454; acc:  80.64; ppl:   2.37; 3362 src tok/s; 3478 tgt tok/s;     13 s elapsed
Epoch 11,   100/  454; acc:  81.56; ppl:   2.26; 3291 src tok/s; 3417 tgt tok/s;     25 s elapsed
Epoch 11,   150/  454; acc:  81.46; ppl:   2.25; 3307 src tok/s; 3451 tgt tok/s;     38 s elapsed
Epoch 11,   200/  454; acc:  80.40; ppl:   2.40; 3336 src tok/s; 3445 tgt tok/s;     51 s elapsed
Epoch 11,   250/  454; acc:  80.29; ppl:   2.41; 3325 src tok/s; 3438 tgt tok/s;     63 s elapsed
Epoch 11,   300/  454; acc:  80.82; ppl:   2.32; 3291 src tok/s; 3434 tgt tok/s;     76 s elapsed
Epoch 11,   350/  454; acc:  79.92; ppl:   2.46; 3356 src tok/s; 3441 tgt tok/s;     89 s elapsed
Epoch 11,   400/  454; acc:  81.21; ppl:   2.29; 3220 src tok/s; 3374 tgt tok/s;    101 s elapsed
Epoch 11,   450/  454; acc:  80.74; ppl:   2.35; 3288 src tok/s; 3420 tgt tok/s;    114 s elapsed
Train perplexity: 2.34353
Train accuracy: 80.771
Validation perplexity: 6.3561
Validation accuracy: 69.2564
Decaying learning rate to 0.015625

Epoch 12,    50/  454; acc:  81.61; ppl:   2.23; 3292 src tok/s; 3414 tgt tok/s;     12 s elapsed
Epoch 12,   100/  454; acc:  80.42; ppl:   2.40; 3306 src tok/s; 3425 tgt tok/s;     25 s elapsed
Epoch 12,   150/  454; acc:  81.71; ppl:   2.25; 3318 src tok/s; 3468 tgt tok/s;     38 s elapsed
Epoch 12,   200/  454; acc:  80.43; ppl:   2.43; 3333 src tok/s; 3453 tgt tok/s;     51 s elapsed
Epoch 12,   250/  454; acc:  80.08; ppl:   2.45; 3290 src tok/s; 3394 tgt tok/s;     64 s elapsed
Epoch 12,   300/  454; acc:  82.16; ppl:   2.15; 3348 src tok/s; 3487 tgt tok/s;     76 s elapsed
Epoch 12,   350/  454; acc:  81.54; ppl:   2.25; 3294 src tok/s; 3417 tgt tok/s;     89 s elapsed
Epoch 12,   400/  454; acc:  80.86; ppl:   2.34; 3338 src tok/s; 3454 tgt tok/s;    101 s elapsed
Epoch 12,   450/  454; acc:  81.68; ppl:   2.22; 3266 src tok/s; 3419 tgt tok/s;    113 s elapsed
Train perplexity: 2.30616
Train accuracy: 81.1244
Validation perplexity: 6.38639
Validation accuracy: 69.1855
Decaying learning rate to 0.0078125

Epoch 13,    50/  454; acc:  82.03; ppl:   2.19; 3292 src tok/s; 3434 tgt tok/s;     12 s elapsed
Epoch 13,   100/  454; acc:  80.59; ppl:   2.36; 3283 src tok/s; 3382 tgt tok/s;     26 s elapsed
Epoch 13,   150/  454; acc:  81.02; ppl:   2.35; 3307 src tok/s; 3423 tgt tok/s;     39 s elapsed
Epoch 13,   200/  454; acc:  81.55; ppl:   2.27; 3257 src tok/s; 3396 tgt tok/s;     51 s elapsed
Epoch 13,   250/  454; acc:  80.02; ppl:   2.47; 3322 src tok/s; 3423 tgt tok/s;     65 s elapsed
Epoch 13,   300/  454; acc:  83.01; ppl:   2.09; 3306 src tok/s; 3472 tgt tok/s;     76 s elapsed
Epoch 13,   350/  454; acc:  80.65; ppl:   2.36; 3365 src tok/s; 3476 tgt tok/s;     89 s elapsed
Epoch 13,   400/  454; acc:  81.55; ppl:   2.24; 3373 src tok/s; 3516 tgt tok/s;    101 s elapsed
Epoch 13,   450/  454; acc:  81.18; ppl:   2.30; 3333 src tok/s; 3445 tgt tok/s;    114 s elapsed
Train perplexity: 2.29091
Train accuracy: 81.2727
Validation perplexity: 6.38632
Validation accuracy: 69.2209
Decaying learning rate to 0.00390625

Epoch 14,    50/  454; acc:  81.70; ppl:   2.25; 3238 src tok/s; 3364 tgt tok/s;     13 s elapsed
Epoch 14,   100/  454; acc:  80.81; ppl:   2.33; 3335 src tok/s; 3479 tgt tok/s;     26 s elapsed
Epoch 14,   150/  454; acc:  81.49; ppl:   2.26; 3352 src tok/s; 3465 tgt tok/s;     38 s elapsed
Epoch 14,   200/  454; acc:  81.66; ppl:   2.25; 3222 src tok/s; 3351 tgt tok/s;     51 s elapsed
Epoch 14,   250/  454; acc:  81.11; ppl:   2.31; 3173 src tok/s; 3319 tgt tok/s;     64 s elapsed
Epoch 14,   300/  454; acc:  81.64; ppl:   2.24; 3265 src tok/s; 3367 tgt tok/s;     77 s elapsed
Epoch 14,   350/  454; acc:  81.72; ppl:   2.24; 3154 src tok/s; 3276 tgt tok/s;     90 s elapsed
Epoch 14,   400/  454; acc:  80.70; ppl:   2.36; 3314 src tok/s; 3412 tgt tok/s;    103 s elapsed
Epoch 14,   450/  454; acc:  81.42; ppl:   2.26; 3244 src tok/s; 3377 tgt tok/s;    116 s elapsed
Train perplexity: 2.27746
Train accuracy: 81.3564
Validation perplexity: 6.38979
Validation accuracy: 69.2209
Decaying learning rate to 0.00195312

Epoch 15,    50/  454; acc:  81.13; ppl:   2.33; 3281 src tok/s; 3391 tgt tok/s;     13 s elapsed
Epoch 15,   100/  454; acc:  81.68; ppl:   2.23; 3275 src tok/s; 3410 tgt tok/s;     26 s elapsed
Epoch 15,   150/  454; acc:  82.57; ppl:   2.16; 3221 src tok/s; 3367 tgt tok/s;     38 s elapsed
Epoch 15,   200/  454; acc:  80.24; ppl:   2.43; 3289 src tok/s; 3385 tgt tok/s;     51 s elapsed
Epoch 15,   250/  454; acc:  81.50; ppl:   2.26; 3270 src tok/s; 3394 tgt tok/s;     64 s elapsed
Epoch 15,   300/  454; acc:  81.32; ppl:   2.29; 3246 src tok/s; 3379 tgt tok/s;     77 s elapsed
Epoch 15,   350/  454; acc:  81.03; ppl:   2.31; 3372 src tok/s; 3485 tgt tok/s;     90 s elapsed
Epoch 15,   400/  454; acc:  82.07; ppl:   2.19; 3229 src tok/s; 3366 tgt tok/s;    103 s elapsed
Epoch 15,   450/  454; acc:  81.33; ppl:   2.28; 3312 src tok/s; 3441 tgt tok/s;    115 s elapsed
Train perplexity: 2.27662
Train accuracy: 81.4137
Validation perplexity: 6.39392
Validation accuracy: 69.2209
Decaying learning rate to 0.000976562

Epoch 16,    50/  454; acc:  81.06; ppl:   2.31; 3279 src tok/s; 3401 tgt tok/s;     13 s elapsed
Epoch 16,   100/  454; acc:  81.67; ppl:   2.23; 3323 src tok/s; 3446 tgt tok/s;     25 s elapsed
Epoch 16,   150/  454; acc:  81.97; ppl:   2.21; 3280 src tok/s; 3404 tgt tok/s;     38 s elapsed
Epoch 16,   200/  454; acc:  81.01; ppl:   2.34; 3239 src tok/s; 3355 tgt tok/s;     51 s elapsed
Epoch 16,   250/  454; acc:  82.85; ppl:   2.12; 3244 src tok/s; 3399 tgt tok/s;     63 s elapsed
Epoch 16,   300/  454; acc:  80.30; ppl:   2.42; 3256 src tok/s; 3340 tgt tok/s;     77 s elapsed
Epoch 16,   350/  454; acc:  81.98; ppl:   2.22; 3210 src tok/s; 3332 tgt tok/s;     90 s elapsed
Epoch 16,   400/  454; acc:  81.22; ppl:   2.29; 3197 src tok/s; 3339 tgt tok/s;    103 s elapsed
Epoch 16,   450/  454; acc:  81.57; ppl:   2.26; 3256 src tok/s; 3393 tgt tok/s;    116 s elapsed
Train perplexity: 2.27181
Train accuracy: 81.451
Validation perplexity: 6.3961
Validation accuracy: 69.1997
Decaying learning rate to 0.000488281

Epoch 17,    50/  454; acc:  81.43; ppl:   2.29; 3310 src tok/s; 3414 tgt tok/s;     13 s elapsed
Epoch 17,   100/  454; acc:  81.75; ppl:   2.23; 3255 src tok/s; 3396 tgt tok/s;     26 s elapsed
Epoch 17,   150/  454; acc:  81.30; ppl:   2.27; 3240 src tok/s; 3370 tgt tok/s;     39 s elapsed
Epoch 17,   200/  454; acc:  81.47; ppl:   2.25; 3217 src tok/s; 3342 tgt tok/s;     52 s elapsed
Epoch 17,   250/  454; acc:  80.65; ppl:   2.36; 3280 src tok/s; 3399 tgt tok/s;     65 s elapsed
Epoch 17,   300/  454; acc:  81.97; ppl:   2.20; 3259 src tok/s; 3391 tgt tok/s;     77 s elapsed
Epoch 17,   350/  454; acc:  82.86; ppl:   2.14; 3194 src tok/s; 3350 tgt tok/s;     89 s elapsed
Epoch 17,   400/  454; acc:  80.62; ppl:   2.40; 3262 src tok/s; 3349 tgt tok/s;    103 s elapsed
Epoch 17,   450/  454; acc:  81.04; ppl:   2.31; 3272 src tok/s; 3380 tgt tok/s;    116 s elapsed
Train perplexity: 2.2723
Train accuracy: 81.4505
Validation perplexity: 6.39694
Validation accuracy: 69.2209
Decaying learning rate to 0.000244141
