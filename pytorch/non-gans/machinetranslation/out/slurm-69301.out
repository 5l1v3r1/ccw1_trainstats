<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.1, kappa_enc=0.25, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.25decoder0.10dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.25)
('Using Kappa L2 loss on decoder', 0.1)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   9.36; ppl: 22833.12; 2881 src tok/s; 2979 tgt tok/s;     15 s elapsed
Epoch  1,   100/  454; acc:  14.94; ppl: 1278.95; 2990 src tok/s; 3109 tgt tok/s;     29 s elapsed
Epoch  1,   150/  454; acc:  18.80; ppl: 433.08; 3016 src tok/s; 3132 tgt tok/s;     42 s elapsed
Epoch  1,   200/  454; acc:  21.07; ppl: 264.89; 2977 src tok/s; 3083 tgt tok/s;     57 s elapsed
Epoch  1,   250/  454; acc:  24.92; ppl: 161.31; 2959 src tok/s; 3085 tgt tok/s;     70 s elapsed
Epoch  1,   300/  454; acc:  26.80; ppl: 125.58; 3032 src tok/s; 3134 tgt tok/s;     85 s elapsed
Epoch  1,   350/  454; acc:  30.17; ppl:  89.61; 3028 src tok/s; 3160 tgt tok/s;     98 s elapsed
Epoch  1,   400/  454; acc:  31.01; ppl:  81.31; 2942 src tok/s; 3061 tgt tok/s;    113 s elapsed
Epoch  1,   450/  454; acc:  32.77; ppl:  67.28; 2997 src tok/s; 3096 tgt tok/s;    127 s elapsed
Train perplexity: 312.648
Train accuracy: 23.4435
Validation perplexity: 52.4097
Validation accuracy: 35.3342

Epoch  2,    50/  454; acc:  34.99; ppl:  56.61; 2980 src tok/s; 3074 tgt tok/s;     15 s elapsed
Epoch  2,   100/  454; acc:  38.19; ppl:  43.49; 2944 src tok/s; 3078 tgt tok/s;     28 s elapsed
Epoch  2,   150/  454; acc:  42.15; ppl:  34.88; 3056 src tok/s; 3184 tgt tok/s;     42 s elapsed
Epoch  2,   200/  454; acc:  41.01; ppl:  36.65; 3011 src tok/s; 3116 tgt tok/s;     56 s elapsed
Epoch  2,   250/  454; acc:  45.51; ppl:  27.40; 2995 src tok/s; 3105 tgt tok/s;     70 s elapsed
Epoch  2,   300/  454; acc:  46.30; ppl:  25.97; 3010 src tok/s; 3118 tgt tok/s;     84 s elapsed
Epoch  2,   350/  454; acc:  49.87; ppl:  20.95; 3002 src tok/s; 3141 tgt tok/s;     97 s elapsed
Epoch  2,   400/  454; acc:  48.84; ppl:  21.92; 2988 src tok/s; 3084 tgt tok/s;    112 s elapsed
Epoch  2,   450/  454; acc:  51.09; ppl:  19.16; 2961 src tok/s; 3071 tgt tok/s;    126 s elapsed
Train perplexity: 29.9324
Train accuracy: 44.2485
Validation perplexity: 15.2532
Validation accuracy: 55.144

Epoch  3,    50/  454; acc:  52.41; ppl:  16.78; 2926 src tok/s; 3041 tgt tok/s;     15 s elapsed
Epoch  3,   100/  454; acc:  55.99; ppl:  13.20; 3007 src tok/s; 3143 tgt tok/s;     28 s elapsed
Epoch  3,   150/  454; acc:  55.92; ppl:  13.28; 2990 src tok/s; 3101 tgt tok/s;     42 s elapsed
Epoch  3,   200/  454; acc:  56.36; ppl:  12.76; 3027 src tok/s; 3143 tgt tok/s;     56 s elapsed
Epoch  3,   250/  454; acc:  57.22; ppl:  12.06; 3007 src tok/s; 3127 tgt tok/s;     70 s elapsed
Epoch  3,   300/  454; acc:  57.01; ppl:  12.24; 3012 src tok/s; 3113 tgt tok/s;     84 s elapsed
Epoch  3,   350/  454; acc:  59.47; ppl:  10.51; 2990 src tok/s; 3125 tgt tok/s;     97 s elapsed
Epoch  3,   400/  454; acc:  57.41; ppl:  12.05; 2993 src tok/s; 3068 tgt tok/s;    112 s elapsed
Epoch  3,   450/  454; acc:  58.85; ppl:  10.87; 2978 src tok/s; 3085 tgt tok/s;    126 s elapsed
Train perplexity: 12.5111
Train accuracy: 56.7603
Validation perplexity: 10.379
Validation accuracy: 60.579

Epoch  4,    50/  454; acc:  61.61; ppl:   8.54; 3020 src tok/s; 3120 tgt tok/s;     14 s elapsed
Epoch  4,   100/  454; acc:  61.10; ppl:   8.77; 2958 src tok/s; 3081 tgt tok/s;     28 s elapsed
Epoch  4,   150/  454; acc:  61.28; ppl:   8.83; 2972 src tok/s; 3079 tgt tok/s;     43 s elapsed
Epoch  4,   200/  454; acc:  62.95; ppl:   8.00; 3017 src tok/s; 3139 tgt tok/s;     56 s elapsed
Epoch  4,   250/  454; acc:  62.75; ppl:   7.95; 2843 src tok/s; 2950 tgt tok/s;     70 s elapsed
Epoch  4,   300/  454; acc:  63.04; ppl:   7.77; 2999 src tok/s; 3103 tgt tok/s;     85 s elapsed
Epoch  4,   350/  454; acc:  61.97; ppl:   8.18; 2996 src tok/s; 3110 tgt tok/s;     99 s elapsed
Epoch  4,   400/  454; acc:  63.24; ppl:   7.68; 3002 src tok/s; 3120 tgt tok/s;    113 s elapsed
Epoch  4,   450/  454; acc:  62.99; ppl:   7.72; 2993 src tok/s; 3118 tgt tok/s;    126 s elapsed
Train perplexity: 8.15521
Train accuracy: 62.3175
Validation perplexity: 8.52893
Validation accuracy: 62.4379

Epoch  5,    50/  454; acc:  65.93; ppl:   6.17; 3017 src tok/s; 3124 tgt tok/s;     14 s elapsed
Epoch  5,   100/  454; acc:  66.02; ppl:   6.17; 2943 src tok/s; 3072 tgt tok/s;     28 s elapsed
Epoch  5,   150/  454; acc:  64.98; ppl:   6.38; 2976 src tok/s; 3091 tgt tok/s;     42 s elapsed
Epoch  5,   200/  454; acc:  65.79; ppl:   6.24; 2983 src tok/s; 3092 tgt tok/s;     56 s elapsed
Epoch  5,   250/  454; acc:  65.90; ppl:   5.99; 3045 src tok/s; 3171 tgt tok/s;     70 s elapsed
Epoch  5,   300/  454; acc:  65.38; ppl:   6.28; 2977 src tok/s; 3080 tgt tok/s;     84 s elapsed
Epoch  5,   350/  454; acc:  66.03; ppl:   6.00; 3007 src tok/s; 3115 tgt tok/s;     98 s elapsed
Epoch  5,   400/  454; acc:  65.90; ppl:   6.16; 2958 src tok/s; 3074 tgt tok/s;    112 s elapsed
Epoch  5,   450/  454; acc:  66.17; ppl:   5.84; 3011 src tok/s; 3127 tgt tok/s;    126 s elapsed
Train perplexity: 6.15565
Train accuracy: 65.7238
Validation perplexity: 7.32851
Validation accuracy: 64.8716

Epoch  6,    50/  454; acc:  68.25; ppl:   4.96; 2937 src tok/s; 3055 tgt tok/s;     15 s elapsed
Epoch  6,   100/  454; acc:  69.13; ppl:   4.77; 3003 src tok/s; 3113 tgt tok/s;     28 s elapsed
Epoch  6,   150/  454; acc:  68.27; ppl:   4.96; 2994 src tok/s; 3096 tgt tok/s;     43 s elapsed
Epoch  6,   200/  454; acc:  68.58; ppl:   4.95; 2925 src tok/s; 3056 tgt tok/s;     57 s elapsed
Epoch  6,   250/  454; acc:  68.50; ppl:   4.94; 3002 src tok/s; 3100 tgt tok/s;     71 s elapsed
Epoch  6,   300/  454; acc:  68.81; ppl:   4.87; 2954 src tok/s; 3079 tgt tok/s;     85 s elapsed
Epoch  6,   350/  454; acc:  68.56; ppl:   4.90; 2994 src tok/s; 3129 tgt tok/s;     98 s elapsed
Epoch  6,   400/  454; acc:  67.37; ppl:   5.31; 2949 src tok/s; 3046 tgt tok/s;    113 s elapsed
Epoch  6,   450/  454; acc:  68.09; ppl:   5.02; 2993 src tok/s; 3097 tgt tok/s;    127 s elapsed
Train perplexity: 4.96163
Train accuracy: 68.3937
Validation perplexity: 6.98938
Validation accuracy: 65.7372

Epoch  7,    50/  454; acc:  71.15; ppl:   4.01; 2994 src tok/s; 3105 tgt tok/s;     14 s elapsed
Epoch  7,   100/  454; acc:  71.72; ppl:   3.95; 3018 src tok/s; 3137 tgt tok/s;     28 s elapsed
Epoch  7,   150/  454; acc:  70.69; ppl:   4.13; 2994 src tok/s; 3113 tgt tok/s;     42 s elapsed
Epoch  7,   200/  454; acc:  70.61; ppl:   4.14; 2992 src tok/s; 3118 tgt tok/s;     56 s elapsed
Epoch  7,   250/  454; acc:  70.73; ppl:   4.09; 2986 src tok/s; 3113 tgt tok/s;     70 s elapsed
Epoch  7,   300/  454; acc:  69.89; ppl:   4.27; 3002 src tok/s; 3101 tgt tok/s;     84 s elapsed
Epoch  7,   350/  454; acc:  69.77; ppl:   4.39; 3060 src tok/s; 3165 tgt tok/s;     98 s elapsed
Epoch  7,   400/  454; acc:  69.77; ppl:   4.30; 2936 src tok/s; 3032 tgt tok/s;    112 s elapsed
Epoch  7,   450/  454; acc:  69.18; ppl:   4.41; 2954 src tok/s; 3066 tgt tok/s;    126 s elapsed
Train perplexity: 4.18557
Train accuracy: 70.3831
Validation perplexity: 6.63303
Validation accuracy: 67.064

Epoch  8,    50/  454; acc:  73.81; ppl:   3.28; 2975 src tok/s; 3098 tgt tok/s;     14 s elapsed
Epoch  8,   100/  454; acc:  72.27; ppl:   3.60; 2978 src tok/s; 3078 tgt tok/s;     28 s elapsed
Epoch  8,   150/  454; acc:  72.91; ppl:   3.52; 3009 src tok/s; 3114 tgt tok/s;     42 s elapsed
Epoch  8,   200/  454; acc:  72.90; ppl:   3.47; 2925 src tok/s; 3044 tgt tok/s;     56 s elapsed
Epoch  8,   250/  454; acc:  71.95; ppl:   3.71; 3008 src tok/s; 3113 tgt tok/s;     71 s elapsed
Epoch  8,   300/  454; acc:  72.88; ppl:   3.54; 2998 src tok/s; 3130 tgt tok/s;     84 s elapsed
Epoch  8,   350/  454; acc:  71.53; ppl:   3.79; 2968 src tok/s; 3088 tgt tok/s;     98 s elapsed
Epoch  8,   400/  454; acc:  71.52; ppl:   3.79; 2978 src tok/s; 3077 tgt tok/s;    113 s elapsed
Epoch  8,   450/  454; acc:  71.81; ppl:   3.75; 2945 src tok/s; 3059 tgt tok/s;    126 s elapsed
Train perplexity: 3.61089
Train accuracy: 72.3512
Validation perplexity: 6.60199
Validation accuracy: 67.0498
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.89; ppl:   2.63; 2944 src tok/s; 3079 tgt tok/s;     14 s elapsed
Epoch  9,   100/  454; acc:  76.83; ppl:   2.76; 2940 src tok/s; 3032 tgt tok/s;     28 s elapsed
Epoch  9,   150/  454; acc:  77.60; ppl:   2.66; 3008 src tok/s; 3131 tgt tok/s;     42 s elapsed
Epoch  9,   200/  454; acc:  76.91; ppl:   2.80; 3013 src tok/s; 3118 tgt tok/s;     56 s elapsed
Epoch  9,   250/  454; acc:  77.32; ppl:   2.70; 2945 src tok/s; 3063 tgt tok/s;     70 s elapsed
Epoch  9,   300/  454; acc:  77.54; ppl:   2.64; 2975 src tok/s; 3083 tgt tok/s;     85 s elapsed
Epoch  9,   350/  454; acc:  76.88; ppl:   2.77; 2983 src tok/s; 3082 tgt tok/s;     99 s elapsed
Epoch  9,   400/  454; acc:  78.13; ppl:   2.58; 2982 src tok/s; 3096 tgt tok/s;    113 s elapsed
Epoch  9,   450/  454; acc:  77.17; ppl:   2.75; 2969 src tok/s; 3088 tgt tok/s;    127 s elapsed
Train perplexity: 2.70455
Train accuracy: 77.3348
Validation perplexity: 6.07861
Validation accuracy: 68.6179
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.67; ppl:   2.17; 2990 src tok/s; 3111 tgt tok/s;     14 s elapsed
Epoch 10,   100/  454; acc:  80.75; ppl:   2.26; 3015 src tok/s; 3112 tgt tok/s;     28 s elapsed
Epoch 10,   150/  454; acc:  81.09; ppl:   2.21; 3049 src tok/s; 3170 tgt tok/s;     42 s elapsed
Epoch 10,   200/  454; acc:  80.89; ppl:   2.27; 2953 src tok/s; 3067 tgt tok/s;     56 s elapsed
Epoch 10,   250/  454; acc:  81.62; ppl:   2.17; 2993 src tok/s; 3100 tgt tok/s;     70 s elapsed
Epoch 10,   300/  454; acc:  80.66; ppl:   2.27; 3034 src tok/s; 3141 tgt tok/s;     84 s elapsed
Epoch 10,   350/  454; acc:  81.33; ppl:   2.17; 2953 src tok/s; 3056 tgt tok/s;     98 s elapsed
Epoch 10,   400/  454; acc:  80.59; ppl:   2.27; 2950 src tok/s; 3071 tgt tok/s;    112 s elapsed
Epoch 10,   450/  454; acc:  80.39; ppl:   2.26; 2915 src tok/s; 3036 tgt tok/s;    126 s elapsed
Train perplexity: 2.22668
Train accuracy: 81.011
Validation perplexity: 6.27121
Validation accuracy: 69.0719
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  82.52; ppl:   2.09; 3046 src tok/s; 3128 tgt tok/s;     14 s elapsed
Epoch 11,   100/  454; acc:  84.20; ppl:   1.92; 3011 src tok/s; 3135 tgt tok/s;     28 s elapsed
Epoch 11,   150/  454; acc:  83.51; ppl:   1.98; 2965 src tok/s; 3082 tgt tok/s;     42 s elapsed
Epoch 11,   200/  454; acc:  83.31; ppl:   2.02; 2999 src tok/s; 3094 tgt tok/s;     56 s elapsed
Epoch 11,   250/  454; acc:  83.68; ppl:   1.94; 2937 src tok/s; 3066 tgt tok/s;     70 s elapsed
Epoch 11,   300/  454; acc:  82.48; ppl:   2.05; 3015 src tok/s; 3107 tgt tok/s;     84 s elapsed
Epoch 11,   350/  454; acc:  83.85; ppl:   1.95; 2982 src tok/s; 3117 tgt tok/s;     98 s elapsed
Epoch 11,   400/  454; acc:  82.34; ppl:   2.12; 2942 src tok/s; 3048 tgt tok/s;    113 s elapsed
Epoch 11,   450/  454; acc:  82.79; ppl:   2.03; 2956 src tok/s; 3095 tgt tok/s;    126 s elapsed
Train perplexity: 2.01144
Train accuracy: 83.1722
Validation perplexity: 6.40315
Validation accuracy: 69.1997
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.73; ppl:   1.88; 2936 src tok/s; 3044 tgt tok/s;     14 s elapsed
Epoch 12,   100/  454; acc:  84.23; ppl:   1.94; 2963 src tok/s; 3071 tgt tok/s;     29 s elapsed
Epoch 12,   150/  454; acc:  83.68; ppl:   1.99; 2987 src tok/s; 3084 tgt tok/s;     43 s elapsed
Epoch 12,   200/  454; acc:  84.96; ppl:   1.84; 2954 src tok/s; 3091 tgt tok/s;     57 s elapsed
Epoch 12,   250/  454; acc:  85.50; ppl:   1.83; 2906 src tok/s; 3053 tgt tok/s;     70 s elapsed
Epoch 12,   300/  454; acc:  83.27; ppl:   2.02; 3071 src tok/s; 3155 tgt tok/s;     85 s elapsed
Epoch 12,   350/  454; acc:  84.27; ppl:   1.89; 3013 src tok/s; 3130 tgt tok/s;     98 s elapsed
Epoch 12,   400/  454; acc:  83.89; ppl:   1.93; 3027 src tok/s; 3129 tgt tok/s;    113 s elapsed
Epoch 12,   450/  454; acc:  84.47; ppl:   1.88; 2934 src tok/s; 3051 tgt tok/s;    127 s elapsed
Train perplexity: 1.91168
Train accuracy: 84.3237
Validation perplexity: 6.51093
Validation accuracy: 69.2777
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  85.10; ppl:   1.84; 2913 src tok/s; 3032 tgt tok/s;     14 s elapsed
Epoch 13,   100/  454; acc:  84.82; ppl:   1.88; 3009 src tok/s; 3099 tgt tok/s;     28 s elapsed
Epoch 13,   150/  454; acc:  85.34; ppl:   1.83; 3005 src tok/s; 3099 tgt tok/s;     42 s elapsed
Epoch 13,   200/  454; acc:  84.55; ppl:   1.91; 2898 src tok/s; 3021 tgt tok/s;     57 s elapsed
Epoch 13,   250/  454; acc:  86.16; ppl:   1.74; 2980 src tok/s; 3125 tgt tok/s;     70 s elapsed
Epoch 13,   300/  454; acc:  83.80; ppl:   1.98; 3033 src tok/s; 3128 tgt tok/s;     85 s elapsed
Epoch 13,   350/  454; acc:  84.83; ppl:   1.85; 3024 src tok/s; 3150 tgt tok/s;     98 s elapsed
Epoch 13,   400/  454; acc:  84.61; ppl:   1.88; 3008 src tok/s; 3116 tgt tok/s;    113 s elapsed
Epoch 13,   450/  454; acc:  84.70; ppl:   1.88; 2941 src tok/s; 3055 tgt tok/s;    127 s elapsed
Train perplexity: 1.86521
Train accuracy: 84.8811
Validation perplexity: 6.60592
Validation accuracy: 69.3274
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  84.95; ppl:   1.87; 2953 src tok/s; 3071 tgt tok/s;     14 s elapsed
Epoch 14,   100/  454; acc:  85.95; ppl:   1.77; 2979 src tok/s; 3089 tgt tok/s;     28 s elapsed
Epoch 14,   150/  454; acc:  85.11; ppl:   1.84; 2965 src tok/s; 3084 tgt tok/s;     42 s elapsed
Epoch 14,   200/  454; acc:  85.39; ppl:   1.82; 2993 src tok/s; 3104 tgt tok/s;     56 s elapsed
Epoch 14,   250/  454; acc:  85.02; ppl:   1.84; 2993 src tok/s; 3099 tgt tok/s;     70 s elapsed
Epoch 14,   300/  454; acc:  85.41; ppl:   1.82; 2947 src tok/s; 3063 tgt tok/s;     84 s elapsed
Epoch 14,   350/  454; acc:  83.93; ppl:   1.94; 3040 src tok/s; 3134 tgt tok/s;     99 s elapsed
Epoch 14,   400/  454; acc:  85.88; ppl:   1.78; 2985 src tok/s; 3112 tgt tok/s;    113 s elapsed
Epoch 14,   450/  454; acc:  84.89; ppl:   1.85; 2985 src tok/s; 3099 tgt tok/s;    126 s elapsed
Train perplexity: 1.83728
Train accuracy: 85.161
Validation perplexity: 6.647
Validation accuracy: 69.2068
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.75; ppl:   1.78; 2983 src tok/s; 3113 tgt tok/s;     14 s elapsed
Epoch 15,   100/  454; acc:  84.77; ppl:   1.88; 3040 src tok/s; 3145 tgt tok/s;     28 s elapsed
Epoch 15,   150/  454; acc:  85.42; ppl:   1.83; 2908 src tok/s; 3023 tgt tok/s;     42 s elapsed
Epoch 15,   200/  454; acc:  85.35; ppl:   1.82; 3022 src tok/s; 3137 tgt tok/s;     56 s elapsed
Epoch 15,   250/  454; acc:  85.89; ppl:   1.79; 2967 src tok/s; 3089 tgt tok/s;     70 s elapsed
Epoch 15,   300/  454; acc:  84.87; ppl:   1.87; 3023 src tok/s; 3108 tgt tok/s;     84 s elapsed
Epoch 15,   350/  454; acc:  85.09; ppl:   1.85; 2936 src tok/s; 3074 tgt tok/s;     98 s elapsed
Epoch 15,   400/  454; acc:  85.22; ppl:   1.81; 2994 src tok/s; 3090 tgt tok/s;    112 s elapsed
Epoch 15,   450/  454; acc:  84.87; ppl:   1.85; 2961 src tok/s; 3064 tgt tok/s;    127 s elapsed
Train perplexity: 1.82999
Train accuracy: 85.2678
Validation perplexity: 6.67282
Validation accuracy: 69.1642
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.19; ppl:   1.84; 3062 src tok/s; 3172 tgt tok/s;     14 s elapsed
Epoch 16,   100/  454; acc:  85.27; ppl:   1.82; 2953 src tok/s; 3070 tgt tok/s;     28 s elapsed
Epoch 16,   150/  454; acc:  85.40; ppl:   1.83; 3061 src tok/s; 3158 tgt tok/s;     42 s elapsed
Epoch 16,   200/  454; acc:  85.42; ppl:   1.83; 2926 src tok/s; 3051 tgt tok/s;     56 s elapsed
Epoch 16,   250/  454; acc:  85.10; ppl:   1.86; 3022 src tok/s; 3124 tgt tok/s;     70 s elapsed
Epoch 16,   300/  454; acc:  85.89; ppl:   1.79; 2908 src tok/s; 3040 tgt tok/s;     84 s elapsed
Epoch 16,   350/  454; acc:  85.95; ppl:   1.78; 3030 src tok/s; 3144 tgt tok/s;     98 s elapsed
Epoch 16,   400/  454; acc:  84.93; ppl:   1.86; 2959 src tok/s; 3065 tgt tok/s;    112 s elapsed
Epoch 16,   450/  454; acc:  85.24; ppl:   1.81; 2942 src tok/s; 3055 tgt tok/s;    126 s elapsed
Train perplexity: 1.82295
Train accuracy: 85.3755
Validation perplexity: 6.67749
Validation accuracy: 69.2351
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.11; ppl:   1.85; 2927 src tok/s; 3061 tgt tok/s;     14 s elapsed
Epoch 17,   100/  454; acc:  85.66; ppl:   1.79; 2982 src tok/s; 3080 tgt tok/s;     28 s elapsed
Epoch 17,   150/  454; acc:  85.04; ppl:   1.83; 2988 src tok/s; 3107 tgt tok/s;     42 s elapsed
Epoch 17,   200/  454; acc:  85.23; ppl:   1.81; 3045 src tok/s; 3154 tgt tok/s;     56 s elapsed
Epoch 17,   250/  454; acc:  85.98; ppl:   1.79; 3003 src tok/s; 3117 tgt tok/s;     70 s elapsed
Epoch 17,   300/  454; acc:  85.20; ppl:   1.84; 2974 src tok/s; 3086 tgt tok/s;     84 s elapsed
Epoch 17,   350/  454; acc:  86.05; ppl:   1.76; 3011 src tok/s; 3133 tgt tok/s;     98 s elapsed
Epoch 17,   400/  454; acc:  84.54; ppl:   1.89; 2950 src tok/s; 3055 tgt tok/s;    113 s elapsed
Epoch 17,   450/  454; acc:  85.61; ppl:   1.81; 3011 src tok/s; 3120 tgt tok/s;    126 s elapsed
Train perplexity: 1.81775
Train accuracy: 85.3847
Validation perplexity: 6.67935
Validation accuracy: 69.2493
Decaying learning rate to 0.000976562
