<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.4, kappa_enc=0.4, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/seeds/encoder0.4decoder0.4dropout0.3wdropTrueseed3', seed=3, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.4)
('Using Kappa L2 loss on decoder', 0.4)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.41; ppl: 24883.84; 2786 src tok/s; 2880 tgt tok/s;     15 s elapsed
Epoch  1,   100/  454; acc:  14.61; ppl: 1247.59; 3395 src tok/s; 3537 tgt tok/s;     27 s elapsed
Epoch  1,   150/  454; acc:  17.73; ppl: 523.86; 3382 src tok/s; 3515 tgt tok/s;     40 s elapsed
Epoch  1,   200/  454; acc:  20.71; ppl: 281.53; 3335 src tok/s; 3475 tgt tok/s;     52 s elapsed
Epoch  1,   250/  454; acc:  25.41; ppl: 162.93; 3318 src tok/s; 3466 tgt tok/s;     65 s elapsed
Epoch  1,   300/  454; acc:  27.49; ppl: 123.43; 3464 src tok/s; 3570 tgt tok/s;     77 s elapsed
Epoch  1,   350/  454; acc:  30.07; ppl:  90.70; 3393 src tok/s; 3516 tgt tok/s;     89 s elapsed
Epoch  1,   400/  454; acc:  30.96; ppl:  79.32; 3386 src tok/s; 3497 tgt tok/s;    102 s elapsed
Epoch  1,   450/  454; acc:  32.57; ppl:  68.66; 3258 src tok/s; 3391 tgt tok/s;    115 s elapsed
Train perplexity: 325.001
Train accuracy: 23.2204
Validation perplexity: 53.9459
Validation accuracy: 36.8242

Epoch  2,    50/  454; acc:  34.66; ppl:  58.86; 3308 src tok/s; 3443 tgt tok/s;     13 s elapsed
Epoch  2,   100/  454; acc:  38.50; ppl:  44.15; 3324 src tok/s; 3491 tgt tok/s;     25 s elapsed
Epoch  2,   150/  454; acc:  40.94; ppl:  37.93; 3332 src tok/s; 3456 tgt tok/s;     38 s elapsed
Epoch  2,   200/  454; acc:  42.61; ppl:  32.67; 3400 src tok/s; 3519 tgt tok/s;     50 s elapsed
Epoch  2,   250/  454; acc:  45.91; ppl:  27.62; 3306 src tok/s; 3423 tgt tok/s;     63 s elapsed
Epoch  2,   300/  454; acc:  46.71; ppl:  25.42; 3336 src tok/s; 3455 tgt tok/s;     76 s elapsed
Epoch  2,   350/  454; acc:  48.69; ppl:  22.39; 3311 src tok/s; 3418 tgt tok/s;     88 s elapsed
Epoch  2,   400/  454; acc:  51.19; ppl:  19.00; 3285 src tok/s; 3406 tgt tok/s;    101 s elapsed
Epoch  2,   450/  454; acc:  50.69; ppl:  19.38; 3244 src tok/s; 3363 tgt tok/s;    114 s elapsed
Train perplexity: 29.7104
Train accuracy: 44.491
Validation perplexity: 15.7509
Validation accuracy: 54.5764

Epoch  3,    50/  454; acc:  54.58; ppl:  14.58; 3346 src tok/s; 3480 tgt tok/s;     12 s elapsed
Epoch  3,   100/  454; acc:  53.74; ppl:  15.18; 3333 src tok/s; 3449 tgt tok/s;     25 s elapsed
Epoch  3,   150/  454; acc:  56.50; ppl:  12.49; 3280 src tok/s; 3443 tgt tok/s;     37 s elapsed
Epoch  3,   200/  454; acc:  54.64; ppl:  14.05; 3382 src tok/s; 3485 tgt tok/s;     50 s elapsed
Epoch  3,   250/  454; acc:  56.03; ppl:  13.29; 3302 src tok/s; 3421 tgt tok/s;     63 s elapsed
Epoch  3,   300/  454; acc:  58.07; ppl:  11.57; 3286 src tok/s; 3419 tgt tok/s;     76 s elapsed
Epoch  3,   350/  454; acc:  58.28; ppl:  11.51; 3267 src tok/s; 3381 tgt tok/s;     89 s elapsed
Epoch  3,   400/  454; acc:  58.69; ppl:  11.08; 3213 src tok/s; 3349 tgt tok/s;    102 s elapsed
Epoch  3,   450/  454; acc:  59.62; ppl:  10.21; 3267 src tok/s; 3383 tgt tok/s;    114 s elapsed
Train perplexity: 12.5829
Train accuracy: 56.6382
Validation perplexity: 10.3962
Validation accuracy: 60.5577

Epoch  4,    50/  454; acc:  61.75; ppl:   8.25; 3301 src tok/s; 3436 tgt tok/s;     13 s elapsed
Epoch  4,   100/  454; acc:  61.13; ppl:   8.64; 3344 src tok/s; 3476 tgt tok/s;     25 s elapsed
Epoch  4,   150/  454; acc:  62.57; ppl:   8.09; 3389 src tok/s; 3536 tgt tok/s;     37 s elapsed
Epoch  4,   200/  454; acc:  60.39; ppl:   9.17; 3302 src tok/s; 3414 tgt tok/s;     50 s elapsed
Epoch  4,   250/  454; acc:  62.01; ppl:   8.24; 3315 src tok/s; 3445 tgt tok/s;     63 s elapsed
Epoch  4,   300/  454; acc:  62.67; ppl:   7.95; 3240 src tok/s; 3347 tgt tok/s;     76 s elapsed
Epoch  4,   350/  454; acc:  63.05; ppl:   7.80; 3206 src tok/s; 3349 tgt tok/s;     89 s elapsed
Epoch  4,   400/  454; acc:  62.93; ppl:   7.70; 3281 src tok/s; 3387 tgt tok/s;    102 s elapsed
Epoch  4,   450/  454; acc:  62.06; ppl:   8.17; 3253 src tok/s; 3365 tgt tok/s;    115 s elapsed
Train perplexity: 8.20327
Train accuracy: 62.0867
Validation perplexity: 8.42827
Validation accuracy: 63.1191

Epoch  5,    50/  454; acc:  66.87; ppl:   5.75; 3330 src tok/s; 3483 tgt tok/s;     12 s elapsed
Epoch  5,   100/  454; acc:  65.87; ppl:   6.12; 3465 src tok/s; 3578 tgt tok/s;     24 s elapsed
Epoch  5,   150/  454; acc:  64.97; ppl:   6.46; 3285 src tok/s; 3387 tgt tok/s;     38 s elapsed
Epoch  5,   200/  454; acc:  66.21; ppl:   6.06; 3294 src tok/s; 3430 tgt tok/s;     50 s elapsed
Epoch  5,   250/  454; acc:  65.12; ppl:   6.33; 3309 src tok/s; 3402 tgt tok/s;     63 s elapsed
Epoch  5,   300/  454; acc:  65.98; ppl:   6.06; 3143 src tok/s; 3285 tgt tok/s;     76 s elapsed
Epoch  5,   350/  454; acc:  65.61; ppl:   6.26; 3237 src tok/s; 3362 tgt tok/s;     89 s elapsed
Epoch  5,   400/  454; acc:  65.55; ppl:   6.01; 3242 src tok/s; 3369 tgt tok/s;    102 s elapsed
Epoch  5,   450/  454; acc:  65.34; ppl:   6.29; 3185 src tok/s; 3314 tgt tok/s;    115 s elapsed
Train perplexity: 6.1571
Train accuracy: 65.7013
Validation perplexity: 7.19385
Validation accuracy: 65.5101

Epoch  6,    50/  454; acc:  69.24; ppl:   4.67; 3317 src tok/s; 3474 tgt tok/s;     12 s elapsed
Epoch  6,   100/  454; acc:  67.62; ppl:   5.20; 3411 src tok/s; 3520 tgt tok/s;     25 s elapsed
Epoch  6,   150/  454; acc:  68.84; ppl:   4.80; 3354 src tok/s; 3477 tgt tok/s;     38 s elapsed
Epoch  6,   200/  454; acc:  68.28; ppl:   5.02; 3306 src tok/s; 3440 tgt tok/s;     50 s elapsed
Epoch  6,   250/  454; acc:  68.47; ppl:   4.89; 3241 src tok/s; 3367 tgt tok/s;     63 s elapsed
Epoch  6,   300/  454; acc:  67.93; ppl:   5.07; 3263 src tok/s; 3393 tgt tok/s;     76 s elapsed
Epoch  6,   350/  454; acc:  69.37; ppl:   4.61; 3174 src tok/s; 3302 tgt tok/s;     89 s elapsed
Epoch  6,   400/  454; acc:  66.93; ppl:   5.34; 3237 src tok/s; 3333 tgt tok/s;    102 s elapsed
Epoch  6,   450/  454; acc:  67.85; ppl:   5.14; 3232 src tok/s; 3346 tgt tok/s;    115 s elapsed
Train perplexity: 4.95824
Train accuracy: 68.3004
Validation perplexity: 6.79533
Validation accuracy: 66.2197

Epoch  7,    50/  454; acc:  70.94; ppl:   4.09; 3336 src tok/s; 3443 tgt tok/s;     13 s elapsed
Epoch  7,   100/  454; acc:  71.69; ppl:   3.88; 3375 src tok/s; 3513 tgt tok/s;     25 s elapsed
Epoch  7,   150/  454; acc:  69.88; ppl:   4.27; 3271 src tok/s; 3380 tgt tok/s;     38 s elapsed
Epoch  7,   200/  454; acc:  71.06; ppl:   4.02; 3312 src tok/s; 3463 tgt tok/s;     51 s elapsed
Epoch  7,   250/  454; acc:  69.92; ppl:   4.31; 3294 src tok/s; 3396 tgt tok/s;     64 s elapsed
Epoch  7,   300/  454; acc:  70.40; ppl:   4.19; 3249 src tok/s; 3375 tgt tok/s;     76 s elapsed
Epoch  7,   350/  454; acc:  70.67; ppl:   4.15; 3168 src tok/s; 3304 tgt tok/s;     89 s elapsed
Epoch  7,   400/  454; acc:  70.10; ppl:   4.36; 3200 src tok/s; 3321 tgt tok/s;    102 s elapsed
Epoch  7,   450/  454; acc:  69.99; ppl:   4.25; 3242 src tok/s; 3372 tgt tok/s;    115 s elapsed
Train perplexity: 4.17103
Train accuracy: 70.5012
Validation perplexity: 6.66207
Validation accuracy: 66.9079

Epoch  8,    50/  454; acc:  72.60; ppl:   3.56; 3339 src tok/s; 3444 tgt tok/s;     13 s elapsed
Epoch  8,   100/  454; acc:  74.39; ppl:   3.21; 3317 src tok/s; 3458 tgt tok/s;     25 s elapsed
Epoch  8,   150/  454; acc:  73.41; ppl:   3.41; 3271 src tok/s; 3407 tgt tok/s;     37 s elapsed
Epoch  8,   200/  454; acc:  71.84; ppl:   3.67; 3368 src tok/s; 3488 tgt tok/s;     50 s elapsed
Epoch  8,   250/  454; acc:  72.91; ppl:   3.51; 3222 src tok/s; 3336 tgt tok/s;     63 s elapsed
Epoch  8,   300/  454; acc:  71.69; ppl:   3.76; 3233 src tok/s; 3359 tgt tok/s;     76 s elapsed
Epoch  8,   350/  454; acc:  71.22; ppl:   3.81; 3223 src tok/s; 3337 tgt tok/s;     90 s elapsed
Epoch  8,   400/  454; acc:  71.56; ppl:   3.73; 3192 src tok/s; 3325 tgt tok/s;    103 s elapsed
Epoch  8,   450/  454; acc:  71.73; ppl:   3.73; 3245 src tok/s; 3372 tgt tok/s;    115 s elapsed
Train perplexity: 3.60114
Train accuracy: 72.3314
Validation perplexity: 6.51243
Validation accuracy: 67.4471
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  78.60; ppl:   2.52; 3339 src tok/s; 3497 tgt tok/s;     12 s elapsed
Epoch  9,   100/  454; acc:  76.20; ppl:   2.88; 3377 src tok/s; 3479 tgt tok/s;     25 s elapsed
Epoch  9,   150/  454; acc:  77.18; ppl:   2.72; 3309 src tok/s; 3436 tgt tok/s;     38 s elapsed
Epoch  9,   200/  454; acc:  77.26; ppl:   2.68; 3278 src tok/s; 3412 tgt tok/s;     50 s elapsed
Epoch  9,   250/  454; acc:  77.31; ppl:   2.70; 3236 src tok/s; 3364 tgt tok/s;     63 s elapsed
Epoch  9,   300/  454; acc:  77.44; ppl:   2.67; 3264 src tok/s; 3374 tgt tok/s;     76 s elapsed
Epoch  9,   350/  454; acc:  77.55; ppl:   2.66; 3254 src tok/s; 3379 tgt tok/s;     89 s elapsed
Epoch  9,   400/  454; acc:  76.85; ppl:   2.78; 3189 src tok/s; 3300 tgt tok/s;    102 s elapsed
Epoch  9,   450/  454; acc:  77.03; ppl:   2.73; 3188 src tok/s; 3311 tgt tok/s;    115 s elapsed
Train perplexity: 2.70005
Train accuracy: 77.2763
Validation perplexity: 6.21061
Validation accuracy: 68.5185
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.32; ppl:   2.23; 3342 src tok/s; 3471 tgt tok/s;     12 s elapsed
Epoch 10,   100/  454; acc:  81.67; ppl:   2.18; 3402 src tok/s; 3528 tgt tok/s;     25 s elapsed
Epoch 10,   150/  454; acc:  81.55; ppl:   2.15; 3371 src tok/s; 3499 tgt tok/s;     37 s elapsed
Epoch 10,   200/  454; acc:  80.86; ppl:   2.24; 3279 src tok/s; 3387 tgt tok/s;     50 s elapsed
Epoch 10,   250/  454; acc:  80.15; ppl:   2.33; 3319 src tok/s; 3414 tgt tok/s;     64 s elapsed
Epoch 10,   300/  454; acc:  82.11; ppl:   2.09; 3157 src tok/s; 3315 tgt tok/s;     76 s elapsed
Epoch 10,   350/  454; acc:  80.96; ppl:   2.20; 3229 src tok/s; 3363 tgt tok/s;     89 s elapsed
Epoch 10,   400/  454; acc:  80.56; ppl:   2.28; 3199 src tok/s; 3313 tgt tok/s;    102 s elapsed
Epoch 10,   450/  454; acc:  80.40; ppl:   2.27; 3191 src tok/s; 3314 tgt tok/s;    115 s elapsed
Train perplexity: 2.21848
Train accuracy: 81.0536
Validation perplexity: 6.36008
Validation accuracy: 68.8662
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  84.23; ppl:   1.93; 3357 src tok/s; 3502 tgt tok/s;     12 s elapsed
Epoch 11,   100/  454; acc:  82.81; ppl:   2.06; 3393 src tok/s; 3491 tgt tok/s;     25 s elapsed
Epoch 11,   150/  454; acc:  83.33; ppl:   2.00; 3419 src tok/s; 3548 tgt tok/s;     37 s elapsed
Epoch 11,   200/  454; acc:  83.34; ppl:   1.99; 3362 src tok/s; 3482 tgt tok/s;     50 s elapsed
Epoch 11,   250/  454; acc:  82.39; ppl:   2.11; 3226 src tok/s; 3333 tgt tok/s;     63 s elapsed
Epoch 11,   300/  454; acc:  84.45; ppl:   1.89; 3184 src tok/s; 3333 tgt tok/s;     76 s elapsed
Epoch 11,   350/  454; acc:  82.60; ppl:   2.07; 3234 src tok/s; 3343 tgt tok/s;     89 s elapsed
Epoch 11,   400/  454; acc:  83.45; ppl:   1.98; 3200 src tok/s; 3339 tgt tok/s;    102 s elapsed
Epoch 11,   450/  454; acc:  83.08; ppl:   2.01; 3123 src tok/s; 3253 tgt tok/s;    115 s elapsed
Train perplexity: 2.00767
Train accuracy: 83.2505
Validation perplexity: 6.4689
Validation accuracy: 69.2068
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.50; ppl:   1.91; 3302 src tok/s; 3438 tgt tok/s;     13 s elapsed
Epoch 12,   100/  454; acc:  84.48; ppl:   1.90; 3318 src tok/s; 3445 tgt tok/s;     25 s elapsed
Epoch 12,   150/  454; acc:  85.79; ppl:   1.81; 3344 src tok/s; 3479 tgt tok/s;     37 s elapsed
Epoch 12,   200/  454; acc:  83.12; ppl:   2.00; 3301 src tok/s; 3417 tgt tok/s;     51 s elapsed
Epoch 12,   250/  454; acc:  84.20; ppl:   1.93; 3269 src tok/s; 3399 tgt tok/s;     63 s elapsed
Epoch 12,   300/  454; acc:  84.39; ppl:   1.90; 3214 src tok/s; 3351 tgt tok/s;     76 s elapsed
Epoch 12,   350/  454; acc:  84.80; ppl:   1.86; 3283 src tok/s; 3406 tgt tok/s;     89 s elapsed
Epoch 12,   400/  454; acc:  83.94; ppl:   1.95; 3210 src tok/s; 3322 tgt tok/s;    102 s elapsed
Epoch 12,   450/  454; acc:  84.27; ppl:   1.92; 3263 src tok/s; 3363 tgt tok/s;    115 s elapsed
Train perplexity: 1.90775
Train accuracy: 84.3922
Validation perplexity: 6.60792
Validation accuracy: 69.2138
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  85.70; ppl:   1.81; 3382 src tok/s; 3500 tgt tok/s;     12 s elapsed
Epoch 13,   100/  454; acc:  84.30; ppl:   1.93; 3324 src tok/s; 3442 tgt tok/s;     25 s elapsed
Epoch 13,   150/  454; acc:  85.25; ppl:   1.84; 3325 src tok/s; 3459 tgt tok/s;     37 s elapsed
Epoch 13,   200/  454; acc:  84.28; ppl:   1.90; 3326 src tok/s; 3437 tgt tok/s;     50 s elapsed
Epoch 13,   250/  454; acc:  86.21; ppl:   1.76; 3130 src tok/s; 3297 tgt tok/s;     63 s elapsed
Epoch 13,   300/  454; acc:  84.19; ppl:   1.91; 3267 src tok/s; 3359 tgt tok/s;     76 s elapsed
Epoch 13,   350/  454; acc:  83.93; ppl:   1.94; 3240 src tok/s; 3367 tgt tok/s;     89 s elapsed
Epoch 13,   400/  454; acc:  85.71; ppl:   1.78; 3288 src tok/s; 3424 tgt tok/s;    102 s elapsed
Epoch 13,   450/  454; acc:  84.91; ppl:   1.88; 3286 src tok/s; 3410 tgt tok/s;    115 s elapsed
Train perplexity: 1.86016
Train accuracy: 84.91
Validation perplexity: 6.68186
Validation accuracy: 69.1642
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  86.32; ppl:   1.75; 3262 src tok/s; 3405 tgt tok/s;     12 s elapsed
Epoch 14,   100/  454; acc:  84.43; ppl:   1.90; 3451 src tok/s; 3570 tgt tok/s;     25 s elapsed
Epoch 14,   150/  454; acc:  85.06; ppl:   1.84; 3284 src tok/s; 3415 tgt tok/s;     38 s elapsed
Epoch 14,   200/  454; acc:  85.17; ppl:   1.85; 3389 src tok/s; 3509 tgt tok/s;     50 s elapsed
Epoch 14,   250/  454; acc:  86.32; ppl:   1.73; 3283 src tok/s; 3427 tgt tok/s;     62 s elapsed
Epoch 14,   300/  454; acc:  84.35; ppl:   1.90; 3253 src tok/s; 3362 tgt tok/s;     76 s elapsed
Epoch 14,   350/  454; acc:  85.48; ppl:   1.83; 3196 src tok/s; 3328 tgt tok/s;     89 s elapsed
Epoch 14,   400/  454; acc:  85.01; ppl:   1.88; 3158 src tok/s; 3273 tgt tok/s;    102 s elapsed
Epoch 14,   450/  454; acc:  85.46; ppl:   1.80; 3274 src tok/s; 3389 tgt tok/s;    115 s elapsed
Train perplexity: 1.83661
Train accuracy: 85.2167
Validation perplexity: 6.70625
Validation accuracy: 69.0719
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.77; ppl:   1.78; 3370 src tok/s; 3507 tgt tok/s;     12 s elapsed
Epoch 15,   100/  454; acc:  85.60; ppl:   1.82; 3273 src tok/s; 3392 tgt tok/s;     25 s elapsed
Epoch 15,   150/  454; acc:  84.96; ppl:   1.89; 3341 src tok/s; 3454 tgt tok/s;     38 s elapsed
Epoch 15,   200/  454; acc:  86.33; ppl:   1.73; 3359 src tok/s; 3485 tgt tok/s;     50 s elapsed
Epoch 15,   250/  454; acc:  86.11; ppl:   1.76; 3264 src tok/s; 3405 tgt tok/s;     63 s elapsed
Epoch 15,   300/  454; acc:  84.56; ppl:   1.92; 3275 src tok/s; 3387 tgt tok/s;     76 s elapsed
Epoch 15,   350/  454; acc:  84.86; ppl:   1.85; 3233 src tok/s; 3353 tgt tok/s;     89 s elapsed
Epoch 15,   400/  454; acc:  85.48; ppl:   1.81; 3201 src tok/s; 3326 tgt tok/s;    102 s elapsed
Epoch 15,   450/  454; acc:  85.12; ppl:   1.86; 3191 src tok/s; 3312 tgt tok/s;    115 s elapsed
Train perplexity: 1.82233
Train accuracy: 85.419
Validation perplexity: 6.72242
Validation accuracy: 69.1003
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.79; ppl:   1.79; 3385 src tok/s; 3508 tgt tok/s;     13 s elapsed
Epoch 16,   100/  454; acc:  85.58; ppl:   1.81; 3363 src tok/s; 3490 tgt tok/s;     25 s elapsed
Epoch 16,   150/  454; acc:  86.40; ppl:   1.73; 3335 src tok/s; 3473 tgt tok/s;     37 s elapsed
Epoch 16,   200/  454; acc:  84.59; ppl:   1.90; 3326 src tok/s; 3436 tgt tok/s;     50 s elapsed
Epoch 16,   250/  454; acc:  86.43; ppl:   1.72; 3266 src tok/s; 3432 tgt tok/s;     62 s elapsed
Epoch 16,   300/  454; acc:  84.07; ppl:   1.95; 3330 src tok/s; 3434 tgt tok/s;     76 s elapsed
Epoch 16,   350/  454; acc:  85.47; ppl:   1.84; 3154 src tok/s; 3287 tgt tok/s;     88 s elapsed
Epoch 16,   400/  454; acc:  85.40; ppl:   1.82; 3295 src tok/s; 3408 tgt tok/s;    102 s elapsed
Epoch 16,   450/  454; acc:  85.33; ppl:   1.83; 3177 src tok/s; 3292 tgt tok/s;    115 s elapsed
Train perplexity: 1.81993
Train accuracy: 85.4402
Validation perplexity: 6.7302
Validation accuracy: 69.1216
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.70; ppl:   1.81; 3281 src tok/s; 3426 tgt tok/s;     12 s elapsed
Epoch 17,   100/  454; acc:  85.55; ppl:   1.81; 3378 src tok/s; 3499 tgt tok/s;     25 s elapsed
Epoch 17,   150/  454; acc:  87.55; ppl:   1.65; 3269 src tok/s; 3436 tgt tok/s;     37 s elapsed
Epoch 17,   200/  454; acc:  83.84; ppl:   1.97; 3374 src tok/s; 3469 tgt tok/s;     50 s elapsed
Epoch 17,   250/  454; acc:  85.68; ppl:   1.79; 3254 src tok/s; 3361 tgt tok/s;     64 s elapsed
Epoch 17,   300/  454; acc:  85.46; ppl:   1.84; 3245 src tok/s; 3360 tgt tok/s;     76 s elapsed
Epoch 17,   350/  454; acc:  85.05; ppl:   1.84; 3243 src tok/s; 3358 tgt tok/s;     90 s elapsed
Epoch 17,   400/  454; acc:  85.71; ppl:   1.79; 3202 src tok/s; 3344 tgt tok/s;    102 s elapsed
Epoch 17,   450/  454; acc:  85.23; ppl:   1.83; 3231 src tok/s; 3350 tgt tok/s;    115 s elapsed
Train perplexity: 1.81603
Train accuracy: 85.4853
Validation perplexity: 6.73345
Validation accuracy: 69.0932
Decaying learning rate to 0.000976562
