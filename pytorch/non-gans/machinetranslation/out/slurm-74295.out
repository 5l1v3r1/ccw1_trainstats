<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.4, kappa_enc=0.3, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/seeds/encoder0.3decoder0.4dropout0.3wdropTrueseed-1', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.3)
('Using Kappa L2 loss on decoder', 0.4)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   7.16; ppl: 112864.93; 2710 src tok/s; 2820 tgt tok/s;     15 s elapsed
Epoch  1,   100/  454; acc:  12.74; ppl: 3424.19; 3409 src tok/s; 3536 tgt tok/s;     28 s elapsed
Epoch  1,   150/  454; acc:  17.16; ppl: 675.52; 3343 src tok/s; 3457 tgt tok/s;     40 s elapsed
Epoch  1,   200/  454; acc:  20.01; ppl: 316.97; 3293 src tok/s; 3413 tgt tok/s;     53 s elapsed
Epoch  1,   250/  454; acc:  22.44; ppl: 212.98; 3279 src tok/s; 3399 tgt tok/s;     66 s elapsed
Epoch  1,   300/  454; acc:  26.86; ppl: 134.68; 3345 src tok/s; 3478 tgt tok/s;     78 s elapsed
Epoch  1,   350/  454; acc:  28.28; ppl: 105.90; 3341 src tok/s; 3462 tgt tok/s;     91 s elapsed
Epoch  1,   400/  454; acc:  31.06; ppl:  81.92; 3296 src tok/s; 3428 tgt tok/s;    104 s elapsed
Epoch  1,   450/  454; acc:  32.03; ppl:  75.49; 3258 src tok/s; 3386 tgt tok/s;    116 s elapsed
Train perplexity: 478.165
Train accuracy: 22.0443
Validation perplexity: 66.6704
Validation accuracy: 33.8158

Epoch  2,    50/  454; acc:  34.07; ppl:  60.68; 3201 src tok/s; 3325 tgt tok/s;     13 s elapsed
Epoch  2,   100/  454; acc:  37.10; ppl:  49.92; 3319 src tok/s; 3436 tgt tok/s;     26 s elapsed
Epoch  2,   150/  454; acc:  39.35; ppl:  44.01; 3218 src tok/s; 3348 tgt tok/s;     39 s elapsed
Epoch  2,   200/  454; acc:  40.92; ppl:  38.83; 3267 src tok/s; 3385 tgt tok/s;     52 s elapsed
Epoch  2,   250/  454; acc:  42.82; ppl:  31.65; 3256 src tok/s; 3369 tgt tok/s;     65 s elapsed
Epoch  2,   300/  454; acc:  46.34; ppl:  25.69; 3155 src tok/s; 3300 tgt tok/s;     78 s elapsed
Epoch  2,   350/  454; acc:  48.15; ppl:  23.33; 3250 src tok/s; 3379 tgt tok/s;     90 s elapsed
Epoch  2,   400/  454; acc:  48.67; ppl:  22.49; 3244 src tok/s; 3340 tgt tok/s;    104 s elapsed
Epoch  2,   450/  454; acc:  50.11; ppl:  19.96; 3210 src tok/s; 3333 tgt tok/s;    117 s elapsed
Train perplexity: 32.683
Train accuracy: 43.107
Validation perplexity: 17.1917
Validation accuracy: 51.7454

Epoch  3,    50/  454; acc:  52.42; ppl:  16.61; 3264 src tok/s; 3383 tgt tok/s;     13 s elapsed
Epoch  3,   100/  454; acc:  54.52; ppl:  14.44; 3172 src tok/s; 3298 tgt tok/s;     26 s elapsed
Epoch  3,   150/  454; acc:  55.89; ppl:  13.27; 3203 src tok/s; 3357 tgt tok/s;     38 s elapsed
Epoch  3,   200/  454; acc:  54.51; ppl:  14.27; 3200 src tok/s; 3293 tgt tok/s;     52 s elapsed
Epoch  3,   250/  454; acc:  55.36; ppl:  13.63; 3245 src tok/s; 3350 tgt tok/s;     66 s elapsed
Epoch  3,   300/  454; acc:  57.35; ppl:  12.09; 3201 src tok/s; 3338 tgt tok/s;     78 s elapsed
Epoch  3,   350/  454; acc:  57.36; ppl:  12.34; 3199 src tok/s; 3316 tgt tok/s;     92 s elapsed
Epoch  3,   400/  454; acc:  57.76; ppl:  11.68; 3215 src tok/s; 3354 tgt tok/s;    104 s elapsed
Epoch  3,   450/  454; acc:  58.63; ppl:  11.09; 3237 src tok/s; 3346 tgt tok/s;    117 s elapsed
Train perplexity: 13.1654
Train accuracy: 55.9968
Validation perplexity: 10.6296
Validation accuracy: 59.0961

Epoch  4,    50/  454; acc:  60.12; ppl:   9.43; 3209 src tok/s; 3305 tgt tok/s;     13 s elapsed
Epoch  4,   100/  454; acc:  62.17; ppl:   8.34; 3199 src tok/s; 3333 tgt tok/s;     26 s elapsed
Epoch  4,   150/  454; acc:  61.35; ppl:   8.81; 3217 src tok/s; 3345 tgt tok/s;     39 s elapsed
Epoch  4,   200/  454; acc:  61.62; ppl:   8.63; 3176 src tok/s; 3285 tgt tok/s;     52 s elapsed
Epoch  4,   250/  454; acc:  61.56; ppl:   8.51; 3202 src tok/s; 3322 tgt tok/s;     65 s elapsed
Epoch  4,   300/  454; acc:  61.86; ppl:   8.39; 3180 src tok/s; 3308 tgt tok/s;     79 s elapsed
Epoch  4,   350/  454; acc:  62.19; ppl:   8.17; 3169 src tok/s; 3307 tgt tok/s;     92 s elapsed
Epoch  4,   400/  454; acc:  62.86; ppl:   7.74; 3278 src tok/s; 3390 tgt tok/s;    105 s elapsed
Epoch  4,   450/  454; acc:  62.24; ppl:   8.21; 3210 src tok/s; 3330 tgt tok/s;    118 s elapsed
Train perplexity: 8.44739
Train accuracy: 61.7962
Validation perplexity: 8.13703
Validation accuracy: 63.637

Epoch  5,    50/  454; acc:  65.89; ppl:   6.17; 3187 src tok/s; 3297 tgt tok/s;     13 s elapsed
Epoch  5,   100/  454; acc:  65.25; ppl:   6.25; 3212 src tok/s; 3338 tgt tok/s;     26 s elapsed
Epoch  5,   150/  454; acc:  66.67; ppl:   5.82; 3192 src tok/s; 3342 tgt tok/s;     38 s elapsed
Epoch  5,   200/  454; acc:  64.01; ppl:   6.77; 3244 src tok/s; 3341 tgt tok/s;     52 s elapsed
Epoch  5,   250/  454; acc:  65.29; ppl:   6.39; 3153 src tok/s; 3283 tgt tok/s;     66 s elapsed
Epoch  5,   300/  454; acc:  64.40; ppl:   6.66; 3135 src tok/s; 3266 tgt tok/s;     79 s elapsed
Epoch  5,   350/  454; acc:  64.73; ppl:   6.55; 3230 src tok/s; 3328 tgt tok/s;     92 s elapsed
Epoch  5,   400/  454; acc:  66.06; ppl:   6.11; 3189 src tok/s; 3321 tgt tok/s;    105 s elapsed
Epoch  5,   450/  454; acc:  65.27; ppl:   6.23; 3201 src tok/s; 3317 tgt tok/s;    118 s elapsed
Train perplexity: 6.3155
Train accuracy: 65.2993
Validation perplexity: 7.38777
Validation accuracy: 65.3115

Epoch  6,    50/  454; acc:  68.35; ppl:   4.96; 3247 src tok/s; 3364 tgt tok/s;     13 s elapsed
Epoch  6,   100/  454; acc:  68.58; ppl:   4.82; 3164 src tok/s; 3312 tgt tok/s;     26 s elapsed
Epoch  6,   150/  454; acc:  67.96; ppl:   5.13; 3254 src tok/s; 3349 tgt tok/s;     39 s elapsed
Epoch  6,   200/  454; acc:  68.09; ppl:   4.95; 3172 src tok/s; 3299 tgt tok/s;     52 s elapsed
Epoch  6,   250/  454; acc:  66.74; ppl:   5.42; 3181 src tok/s; 3303 tgt tok/s;     66 s elapsed
Epoch  6,   300/  454; acc:  68.59; ppl:   4.79; 3204 src tok/s; 3335 tgt tok/s;     79 s elapsed
Epoch  6,   350/  454; acc:  66.82; ppl:   5.46; 3169 src tok/s; 3280 tgt tok/s;     92 s elapsed
Epoch  6,   400/  454; acc:  68.44; ppl:   4.95; 3223 src tok/s; 3360 tgt tok/s;    105 s elapsed
Epoch  6,   450/  454; acc:  67.94; ppl:   5.16; 3147 src tok/s; 3256 tgt tok/s;    118 s elapsed
Train perplexity: 5.07173
Train accuracy: 67.9411
Validation perplexity: 6.94912
Validation accuracy: 65.7443

Epoch  7,    50/  454; acc:  70.38; ppl:   4.26; 3211 src tok/s; 3302 tgt tok/s;     14 s elapsed
Epoch  7,   100/  454; acc:  72.03; ppl:   3.83; 3252 src tok/s; 3388 tgt tok/s;     26 s elapsed
Epoch  7,   150/  454; acc:  68.89; ppl:   4.65; 3170 src tok/s; 3264 tgt tok/s;     40 s elapsed
Epoch  7,   200/  454; acc:  71.92; ppl:   3.87; 3193 src tok/s; 3348 tgt tok/s;     52 s elapsed
Epoch  7,   250/  454; acc:  71.10; ppl:   4.08; 3174 src tok/s; 3310 tgt tok/s;     65 s elapsed
Epoch  7,   300/  454; acc:  68.82; ppl:   4.60; 3186 src tok/s; 3295 tgt tok/s;     79 s elapsed
Epoch  7,   350/  454; acc:  70.90; ppl:   4.02; 3218 src tok/s; 3357 tgt tok/s;     91 s elapsed
Epoch  7,   400/  454; acc:  69.06; ppl:   4.50; 3230 src tok/s; 3355 tgt tok/s;    105 s elapsed
Epoch  7,   450/  454; acc:  69.25; ppl:   4.48; 3115 src tok/s; 3227 tgt tok/s;    118 s elapsed
Train perplexity: 4.25661
Train accuracy: 70.2034
Validation perplexity: 6.59783
Validation accuracy: 66.8086

Epoch  8,    50/  454; acc:  73.22; ppl:   3.46; 3210 src tok/s; 3328 tgt tok/s;     13 s elapsed
Epoch  8,   100/  454; acc:  72.86; ppl:   3.49; 3176 src tok/s; 3302 tgt tok/s;     26 s elapsed
Epoch  8,   150/  454; acc:  71.63; ppl:   3.78; 3211 src tok/s; 3322 tgt tok/s;     40 s elapsed
Epoch  8,   200/  454; acc:  73.16; ppl:   3.42; 3165 src tok/s; 3294 tgt tok/s;     53 s elapsed
Epoch  8,   250/  454; acc:  71.66; ppl:   3.74; 3169 src tok/s; 3288 tgt tok/s;     66 s elapsed
Epoch  8,   300/  454; acc:  71.40; ppl:   3.77; 3256 src tok/s; 3392 tgt tok/s;     79 s elapsed
Epoch  8,   350/  454; acc:  71.29; ppl:   3.86; 3213 src tok/s; 3325 tgt tok/s;     92 s elapsed
Epoch  8,   400/  454; acc:  71.41; ppl:   3.79; 3179 src tok/s; 3306 tgt tok/s;    105 s elapsed
Epoch  8,   450/  454; acc:  71.66; ppl:   3.76; 3155 src tok/s; 3265 tgt tok/s;    118 s elapsed
Train perplexity: 3.67255
Train accuracy: 72.0152
Validation perplexity: 6.47041
Validation accuracy: 66.9079
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.83; ppl:   2.81; 3149 src tok/s; 3277 tgt tok/s;     13 s elapsed
Epoch  9,   100/  454; acc:  76.85; ppl:   2.74; 3189 src tok/s; 3326 tgt tok/s;     26 s elapsed
Epoch  9,   150/  454; acc:  76.48; ppl:   2.83; 3117 src tok/s; 3229 tgt tok/s;     40 s elapsed
Epoch  9,   200/  454; acc:  78.27; ppl:   2.53; 3227 src tok/s; 3335 tgt tok/s;     53 s elapsed
Epoch  9,   250/  454; acc:  75.76; ppl:   2.94; 3225 src tok/s; 3308 tgt tok/s;     67 s elapsed
Epoch  9,   300/  454; acc:  78.21; ppl:   2.55; 3126 src tok/s; 3295 tgt tok/s;     79 s elapsed
Epoch  9,   350/  454; acc:  76.87; ppl:   2.75; 3158 src tok/s; 3295 tgt tok/s;     92 s elapsed
Epoch  9,   400/  454; acc:  76.89; ppl:   2.73; 3250 src tok/s; 3359 tgt tok/s;    105 s elapsed
Epoch  9,   450/  454; acc:  77.24; ppl:   2.70; 3081 src tok/s; 3196 tgt tok/s;    119 s elapsed
Train perplexity: 2.73904
Train accuracy: 76.9795
Validation perplexity: 5.98255
Validation accuracy: 68.6675
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.01; ppl:   2.38; 3222 src tok/s; 3330 tgt tok/s;     13 s elapsed
Epoch 10,   100/  454; acc:  81.92; ppl:   2.13; 3214 src tok/s; 3328 tgt tok/s;     26 s elapsed
Epoch 10,   150/  454; acc:  81.84; ppl:   2.14; 3170 src tok/s; 3302 tgt tok/s;     39 s elapsed
Epoch 10,   200/  454; acc:  80.46; ppl:   2.30; 3205 src tok/s; 3329 tgt tok/s;     52 s elapsed
Epoch 10,   250/  454; acc:  79.98; ppl:   2.37; 3163 src tok/s; 3271 tgt tok/s;     66 s elapsed
Epoch 10,   300/  454; acc:  81.72; ppl:   2.16; 3166 src tok/s; 3303 tgt tok/s;     79 s elapsed
Epoch 10,   350/  454; acc:  81.25; ppl:   2.21; 3213 src tok/s; 3359 tgt tok/s;     91 s elapsed
Epoch 10,   400/  454; acc:  79.90; ppl:   2.32; 3202 src tok/s; 3302 tgt tok/s;    105 s elapsed
Epoch 10,   450/  454; acc:  80.40; ppl:   2.31; 3130 src tok/s; 3244 tgt tok/s;    118 s elapsed
Train perplexity: 2.25604
Train accuracy: 80.8156
Validation perplexity: 6.13726
Validation accuracy: 69.3132
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.64; ppl:   1.98; 3188 src tok/s; 3309 tgt tok/s;     13 s elapsed
Epoch 11,   100/  454; acc:  83.00; ppl:   2.07; 3219 src tok/s; 3324 tgt tok/s;     26 s elapsed
Epoch 11,   150/  454; acc:  82.61; ppl:   2.08; 3229 src tok/s; 3326 tgt tok/s;     40 s elapsed
Epoch 11,   200/  454; acc:  83.10; ppl:   2.00; 3106 src tok/s; 3239 tgt tok/s;     53 s elapsed
Epoch 11,   250/  454; acc:  82.65; ppl:   2.06; 3193 src tok/s; 3307 tgt tok/s;     66 s elapsed
Epoch 11,   300/  454; acc:  83.23; ppl:   2.00; 3228 src tok/s; 3353 tgt tok/s;     79 s elapsed
Epoch 11,   350/  454; acc:  81.75; ppl:   2.16; 3172 src tok/s; 3279 tgt tok/s;     93 s elapsed
Epoch 11,   400/  454; acc:  83.81; ppl:   1.94; 3143 src tok/s; 3285 tgt tok/s;    105 s elapsed
Epoch 11,   450/  454; acc:  82.61; ppl:   2.06; 3167 src tok/s; 3307 tgt tok/s;    118 s elapsed
Train perplexity: 2.03873
Train accuracy: 82.9236
Validation perplexity: 6.29665
Validation accuracy: 69.3416
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.04; ppl:   1.93; 3184 src tok/s; 3303 tgt tok/s;     13 s elapsed
Epoch 12,   100/  454; acc:  84.20; ppl:   1.92; 3232 src tok/s; 3362 tgt tok/s;     26 s elapsed
Epoch 12,   150/  454; acc:  85.40; ppl:   1.80; 3087 src tok/s; 3252 tgt tok/s;     39 s elapsed
Epoch 12,   200/  454; acc:  82.83; ppl:   2.05; 3201 src tok/s; 3290 tgt tok/s;     53 s elapsed
Epoch 12,   250/  454; acc:  84.35; ppl:   1.90; 3177 src tok/s; 3302 tgt tok/s;     66 s elapsed
Epoch 12,   300/  454; acc:  83.73; ppl:   1.95; 3220 src tok/s; 3318 tgt tok/s;     79 s elapsed
Epoch 12,   350/  454; acc:  83.30; ppl:   2.01; 3217 src tok/s; 3307 tgt tok/s;     93 s elapsed
Epoch 12,   400/  454; acc:  84.63; ppl:   1.85; 3167 src tok/s; 3309 tgt tok/s;    105 s elapsed
Epoch 12,   450/  454; acc:  83.82; ppl:   1.95; 3162 src tok/s; 3304 tgt tok/s;    118 s elapsed
Train perplexity: 1.93244
Train accuracy: 83.9974
Validation perplexity: 6.3762
Validation accuracy: 69.4196
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.80; ppl:   1.87; 3192 src tok/s; 3295 tgt tok/s;     14 s elapsed
Epoch 13,   100/  454; acc:  85.05; ppl:   1.85; 3078 src tok/s; 3218 tgt tok/s;     27 s elapsed
Epoch 13,   150/  454; acc:  85.29; ppl:   1.82; 3134 src tok/s; 3263 tgt tok/s;     40 s elapsed
Epoch 13,   200/  454; acc:  83.68; ppl:   1.95; 3245 src tok/s; 3364 tgt tok/s;     53 s elapsed
Epoch 13,   250/  454; acc:  84.82; ppl:   1.86; 3176 src tok/s; 3298 tgt tok/s;     66 s elapsed
Epoch 13,   300/  454; acc:  84.19; ppl:   1.92; 3184 src tok/s; 3298 tgt tok/s;     79 s elapsed
Epoch 13,   350/  454; acc:  83.44; ppl:   2.00; 3189 src tok/s; 3299 tgt tok/s;     93 s elapsed
Epoch 13,   400/  454; acc:  85.40; ppl:   1.81; 3175 src tok/s; 3295 tgt tok/s;    106 s elapsed
Epoch 13,   450/  454; acc:  84.52; ppl:   1.90; 3206 src tok/s; 3324 tgt tok/s;    119 s elapsed
Train perplexity: 1.88602
Train accuracy: 84.584
Validation perplexity: 6.42726
Validation accuracy: 69.4196
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  84.91; ppl:   1.86; 3145 src tok/s; 3282 tgt tok/s;     13 s elapsed
Epoch 14,   100/  454; acc:  84.94; ppl:   1.84; 3180 src tok/s; 3292 tgt tok/s;     26 s elapsed
Epoch 14,   150/  454; acc:  85.62; ppl:   1.80; 3180 src tok/s; 3317 tgt tok/s;     39 s elapsed
Epoch 14,   200/  454; acc:  84.44; ppl:   1.91; 3153 src tok/s; 3260 tgt tok/s;     53 s elapsed
Epoch 14,   250/  454; acc:  84.59; ppl:   1.89; 3218 src tok/s; 3337 tgt tok/s;     66 s elapsed
Epoch 14,   300/  454; acc:  84.91; ppl:   1.85; 3192 src tok/s; 3318 tgt tok/s;     79 s elapsed
Epoch 14,   350/  454; acc:  84.78; ppl:   1.88; 3191 src tok/s; 3309 tgt tok/s;     92 s elapsed
Epoch 14,   400/  454; acc:  85.04; ppl:   1.84; 3232 src tok/s; 3341 tgt tok/s;    105 s elapsed
Epoch 14,   450/  454; acc:  84.99; ppl:   1.83; 3142 src tok/s; 3266 tgt tok/s;    118 s elapsed
Train perplexity: 1.86123
Train accuracy: 84.8596
Validation perplexity: 6.45938
Validation accuracy: 69.2635
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.56; ppl:   1.82; 3212 src tok/s; 3343 tgt tok/s;     13 s elapsed
Epoch 15,   100/  454; acc:  85.11; ppl:   1.82; 3170 src tok/s; 3292 tgt tok/s;     26 s elapsed
Epoch 15,   150/  454; acc:  84.50; ppl:   1.91; 3160 src tok/s; 3268 tgt tok/s;     40 s elapsed
Epoch 15,   200/  454; acc:  85.57; ppl:   1.80; 3198 src tok/s; 3330 tgt tok/s;     52 s elapsed
Epoch 15,   250/  454; acc:  84.80; ppl:   1.88; 3199 src tok/s; 3291 tgt tok/s;     66 s elapsed
Epoch 15,   300/  454; acc:  85.09; ppl:   1.85; 3165 src tok/s; 3301 tgt tok/s;     79 s elapsed
Epoch 15,   350/  454; acc:  85.25; ppl:   1.83; 3113 src tok/s; 3254 tgt tok/s;     92 s elapsed
Epoch 15,   400/  454; acc:  84.95; ppl:   1.86; 3266 src tok/s; 3368 tgt tok/s;    105 s elapsed
Epoch 15,   450/  454; acc:  84.53; ppl:   1.88; 3178 src tok/s; 3298 tgt tok/s;    118 s elapsed
Train perplexity: 1.84986
Train accuracy: 85.0484
Validation perplexity: 6.47458
Validation accuracy: 69.2209
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.32; ppl:   1.83; 3244 src tok/s; 3363 tgt tok/s;     13 s elapsed
Epoch 16,   100/  454; acc:  85.28; ppl:   1.83; 3151 src tok/s; 3270 tgt tok/s;     26 s elapsed
Epoch 16,   150/  454; acc:  85.53; ppl:   1.82; 3146 src tok/s; 3288 tgt tok/s;     39 s elapsed
Epoch 16,   200/  454; acc:  84.97; ppl:   1.85; 3212 src tok/s; 3322 tgt tok/s;     53 s elapsed
Epoch 16,   250/  454; acc:  85.99; ppl:   1.78; 3217 src tok/s; 3355 tgt tok/s;     65 s elapsed
Epoch 16,   300/  454; acc:  84.39; ppl:   1.92; 3167 src tok/s; 3274 tgt tok/s;     79 s elapsed
Epoch 16,   350/  454; acc:  84.39; ppl:   1.93; 3157 src tok/s; 3264 tgt tok/s;     92 s elapsed
Epoch 16,   400/  454; acc:  85.31; ppl:   1.81; 3136 src tok/s; 3250 tgt tok/s;    106 s elapsed
Epoch 16,   450/  454; acc:  85.12; ppl:   1.84; 3123 src tok/s; 3245 tgt tok/s;    119 s elapsed
Train perplexity: 1.84396
Train accuracy: 85.1545
Validation perplexity: 6.4865
Validation accuracy: 69.2209
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  86.52; ppl:   1.76; 3202 src tok/s; 3348 tgt tok/s;     12 s elapsed
Epoch 17,   100/  454; acc:  84.35; ppl:   1.91; 3219 src tok/s; 3328 tgt tok/s;     26 s elapsed
Epoch 17,   150/  454; acc:  84.33; ppl:   1.92; 3196 src tok/s; 3301 tgt tok/s;     40 s elapsed
Epoch 17,   200/  454; acc:  85.90; ppl:   1.77; 3199 src tok/s; 3337 tgt tok/s;     52 s elapsed
Epoch 17,   250/  454; acc:  85.83; ppl:   1.81; 3180 src tok/s; 3309 tgt tok/s;     65 s elapsed
Epoch 17,   300/  454; acc:  84.80; ppl:   1.87; 3235 src tok/s; 3337 tgt tok/s;     79 s elapsed
Epoch 17,   350/  454; acc:  86.29; ppl:   1.72; 3121 src tok/s; 3274 tgt tok/s;     91 s elapsed
Epoch 17,   400/  454; acc:  84.00; ppl:   1.94; 3158 src tok/s; 3241 tgt tok/s;    105 s elapsed
Epoch 17,   450/  454; acc:  85.64; ppl:   1.80; 3167 src tok/s; 3306 tgt tok/s;    118 s elapsed
Train perplexity: 1.8417
Train accuracy: 85.1937
Validation perplexity: 6.4908
Validation accuracy: 69.2351
Decaying learning rate to 0.000976562
