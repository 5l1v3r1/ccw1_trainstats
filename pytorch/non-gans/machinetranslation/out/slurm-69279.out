<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.05, kappa_enc=0.1, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.1decoder0.05dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.1)
('Using Kappa L2 loss on decoder', 0.05)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   9.04; ppl: 14687.70; 2940 src tok/s; 3043 tgt tok/s;     14 s elapsed
Epoch  1,   100/  454; acc:  13.24; ppl: 2962.11; 3076 src tok/s; 3206 tgt tok/s;     28 s elapsed
Epoch  1,   150/  454; acc:  17.70; ppl: 537.54; 3111 src tok/s; 3216 tgt tok/s;     42 s elapsed
Epoch  1,   200/  454; acc:  20.89; ppl: 279.77; 3038 src tok/s; 3173 tgt tok/s;     55 s elapsed
Epoch  1,   250/  454; acc:  24.41; ppl: 183.92; 3095 src tok/s; 3221 tgt tok/s;     68 s elapsed
Epoch  1,   300/  454; acc:  27.02; ppl: 134.81; 3068 src tok/s; 3170 tgt tok/s;     82 s elapsed
Epoch  1,   350/  454; acc:  29.98; ppl:  98.30; 3075 src tok/s; 3220 tgt tok/s;     95 s elapsed
Epoch  1,   400/  454; acc:  30.96; ppl:  84.42; 3078 src tok/s; 3173 tgt tok/s;    110 s elapsed
Epoch  1,   450/  454; acc:  34.04; ppl:  66.86; 3086 src tok/s; 3191 tgt tok/s;    123 s elapsed
Train perplexity: 351.308
Train accuracy: 23.0745
Validation perplexity: 70.9299
Validation accuracy: 34.7169

Epoch  2,    50/  454; acc:  36.71; ppl:  53.38; 3012 src tok/s; 3142 tgt tok/s;     13 s elapsed
Epoch  2,   100/  454; acc:  37.45; ppl:  48.93; 3134 src tok/s; 3241 tgt tok/s;     27 s elapsed
Epoch  2,   150/  454; acc:  41.26; ppl:  37.77; 2971 src tok/s; 3090 tgt tok/s;     41 s elapsed
Epoch  2,   200/  454; acc:  43.20; ppl:  32.46; 3081 src tok/s; 3187 tgt tok/s;     55 s elapsed
Epoch  2,   250/  454; acc:  45.15; ppl:  28.49; 3093 src tok/s; 3212 tgt tok/s;     69 s elapsed
Epoch  2,   300/  454; acc:  47.13; ppl:  25.02; 3082 src tok/s; 3200 tgt tok/s;     82 s elapsed
Epoch  2,   350/  454; acc:  48.68; ppl:  22.43; 3122 src tok/s; 3238 tgt tok/s;     96 s elapsed
Epoch  2,   400/  454; acc:  50.66; ppl:  19.32; 3050 src tok/s; 3175 tgt tok/s;    109 s elapsed
Epoch  2,   450/  454; acc:  52.19; ppl:  17.86; 3051 src tok/s; 3165 tgt tok/s;    123 s elapsed
Train perplexity: 29.6168
Train accuracy: 44.7095
Validation perplexity: 16.5207
Validation accuracy: 53.6824

Epoch  3,    50/  454; acc:  52.64; ppl:  16.17; 3128 src tok/s; 3216 tgt tok/s;     14 s elapsed
Epoch  3,   100/  454; acc:  54.60; ppl:  14.46; 3076 src tok/s; 3216 tgt tok/s;     27 s elapsed
Epoch  3,   150/  454; acc:  54.96; ppl:  14.13; 3111 src tok/s; 3206 tgt tok/s;     41 s elapsed
Epoch  3,   200/  454; acc:  57.36; ppl:  12.02; 3053 src tok/s; 3182 tgt tok/s;     54 s elapsed
Epoch  3,   250/  454; acc:  56.11; ppl:  13.02; 3075 src tok/s; 3195 tgt tok/s;     68 s elapsed
Epoch  3,   300/  454; acc:  57.48; ppl:  11.73; 3114 src tok/s; 3244 tgt tok/s;     81 s elapsed
Epoch  3,   350/  454; acc:  57.37; ppl:  12.01; 3092 src tok/s; 3200 tgt tok/s;     95 s elapsed
Epoch  3,   400/  454; acc:  59.57; ppl:  10.39; 3085 src tok/s; 3215 tgt tok/s;    109 s elapsed
Epoch  3,   450/  454; acc:  58.04; ppl:  11.23; 2999 src tok/s; 3107 tgt tok/s;    122 s elapsed
Train perplexity: 12.6666
Train accuracy: 56.4852
Validation perplexity: 10.4481
Validation accuracy: 60.1887

Epoch  4,    50/  454; acc:  60.97; ppl:   8.91; 3093 src tok/s; 3215 tgt tok/s;     14 s elapsed
Epoch  4,   100/  454; acc:  62.06; ppl:   8.26; 3095 src tok/s; 3217 tgt tok/s;     27 s elapsed
Epoch  4,   150/  454; acc:  62.64; ppl:   8.00; 3134 src tok/s; 3244 tgt tok/s;     40 s elapsed
Epoch  4,   200/  454; acc:  60.89; ppl:   9.04; 3086 src tok/s; 3205 tgt tok/s;     54 s elapsed
Epoch  4,   250/  454; acc:  61.74; ppl:   8.42; 3102 src tok/s; 3200 tgt tok/s;     68 s elapsed
Epoch  4,   300/  454; acc:  62.88; ppl:   7.87; 3069 src tok/s; 3193 tgt tok/s;     81 s elapsed
Epoch  4,   350/  454; acc:  62.34; ppl:   8.12; 3009 src tok/s; 3150 tgt tok/s;     95 s elapsed
Epoch  4,   400/  454; acc:  62.95; ppl:   7.76; 3113 src tok/s; 3221 tgt tok/s;    109 s elapsed
Epoch  4,   450/  454; acc:  62.98; ppl:   7.92; 3031 src tok/s; 3137 tgt tok/s;    122 s elapsed
Train perplexity: 8.26184
Train accuracy: 62.1287
Validation perplexity: 8.53028
Validation accuracy: 62.5656

Epoch  5,    50/  454; acc:  65.28; ppl:   6.39; 3095 src tok/s; 3208 tgt tok/s;     14 s elapsed
Epoch  5,   100/  454; acc:  66.06; ppl:   6.03; 3072 src tok/s; 3186 tgt tok/s;     27 s elapsed
Epoch  5,   150/  454; acc:  65.38; ppl:   6.25; 3085 src tok/s; 3215 tgt tok/s;     41 s elapsed
Epoch  5,   200/  454; acc:  65.09; ppl:   6.43; 3033 src tok/s; 3156 tgt tok/s;     55 s elapsed
Epoch  5,   250/  454; acc:  65.47; ppl:   6.35; 3109 src tok/s; 3202 tgt tok/s;     68 s elapsed
Epoch  5,   300/  454; acc:  65.94; ppl:   6.12; 3123 src tok/s; 3242 tgt tok/s;     82 s elapsed
Epoch  5,   350/  454; acc:  65.69; ppl:   6.13; 3026 src tok/s; 3159 tgt tok/s;     95 s elapsed
Epoch  5,   400/  454; acc:  65.72; ppl:   6.14; 3050 src tok/s; 3167 tgt tok/s;    109 s elapsed
Epoch  5,   450/  454; acc:  65.46; ppl:   6.20; 3051 src tok/s; 3149 tgt tok/s;    123 s elapsed
Train perplexity: 6.22303
Train accuracy: 65.5761
Validation perplexity: 7.53433
Validation accuracy: 64.4317

Epoch  6,    50/  454; acc:  68.97; ppl:   4.80; 3121 src tok/s; 3224 tgt tok/s;     14 s elapsed
Epoch  6,   100/  454; acc:  68.61; ppl:   4.87; 3041 src tok/s; 3158 tgt tok/s;     27 s elapsed
Epoch  6,   150/  454; acc:  68.53; ppl:   4.85; 3076 src tok/s; 3198 tgt tok/s;     41 s elapsed
Epoch  6,   200/  454; acc:  67.74; ppl:   5.12; 3081 src tok/s; 3190 tgt tok/s;     55 s elapsed
Epoch  6,   250/  454; acc:  68.85; ppl:   4.89; 3060 src tok/s; 3176 tgt tok/s;     68 s elapsed
Epoch  6,   300/  454; acc:  67.83; ppl:   5.10; 3111 src tok/s; 3218 tgt tok/s;     82 s elapsed
Epoch  6,   350/  454; acc:  67.79; ppl:   5.14; 3067 src tok/s; 3177 tgt tok/s;     96 s elapsed
Epoch  6,   400/  454; acc:  67.45; ppl:   5.27; 3098 src tok/s; 3240 tgt tok/s;    109 s elapsed
Epoch  6,   450/  454; acc:  67.80; ppl:   5.17; 3073 src tok/s; 3191 tgt tok/s;    122 s elapsed
Train perplexity: 5.02297
Train accuracy: 68.174
Validation perplexity: 6.91588
Validation accuracy: 66.0565

Epoch  7,    50/  454; acc:  71.13; ppl:   4.01; 3093 src tok/s; 3206 tgt tok/s;     14 s elapsed
Epoch  7,   100/  454; acc:  71.39; ppl:   3.94; 3019 src tok/s; 3161 tgt tok/s;     27 s elapsed
Epoch  7,   150/  454; acc:  69.48; ppl:   4.47; 3097 src tok/s; 3187 tgt tok/s;     42 s elapsed
Epoch  7,   200/  454; acc:  71.76; ppl:   3.87; 3120 src tok/s; 3267 tgt tok/s;     54 s elapsed
Epoch  7,   250/  454; acc:  70.79; ppl:   4.12; 3081 src tok/s; 3206 tgt tok/s;     67 s elapsed
Epoch  7,   300/  454; acc:  69.29; ppl:   4.49; 3105 src tok/s; 3206 tgt tok/s;     82 s elapsed
Epoch  7,   350/  454; acc:  70.20; ppl:   4.23; 3004 src tok/s; 3129 tgt tok/s;     95 s elapsed
Epoch  7,   400/  454; acc:  69.46; ppl:   4.30; 3088 src tok/s; 3194 tgt tok/s;    109 s elapsed
Epoch  7,   450/  454; acc:  69.15; ppl:   4.53; 3023 src tok/s; 3119 tgt tok/s;    123 s elapsed
Train perplexity: 4.2122
Train accuracy: 70.2972
Validation perplexity: 6.67711
Validation accuracy: 66.9647

Epoch  8,    50/  454; acc:  73.48; ppl:   3.42; 3076 src tok/s; 3206 tgt tok/s;     14 s elapsed
Epoch  8,   100/  454; acc:  73.08; ppl:   3.52; 3074 src tok/s; 3198 tgt tok/s;     27 s elapsed
Epoch  8,   150/  454; acc:  72.28; ppl:   3.59; 3057 src tok/s; 3178 tgt tok/s;     41 s elapsed
Epoch  8,   200/  454; acc:  72.43; ppl:   3.58; 3107 src tok/s; 3217 tgt tok/s;     54 s elapsed
Epoch  8,   250/  454; acc:  70.93; ppl:   3.95; 3045 src tok/s; 3157 tgt tok/s;     68 s elapsed
Epoch  8,   300/  454; acc:  72.58; ppl:   3.53; 3054 src tok/s; 3190 tgt tok/s;     82 s elapsed
Epoch  8,   350/  454; acc:  71.62; ppl:   3.78; 3039 src tok/s; 3147 tgt tok/s;     96 s elapsed
Epoch  8,   400/  454; acc:  72.00; ppl:   3.66; 3126 src tok/s; 3228 tgt tok/s;    109 s elapsed
Epoch  8,   450/  454; acc:  71.73; ppl:   3.77; 3023 src tok/s; 3120 tgt tok/s;    123 s elapsed
Train perplexity: 3.64084
Train accuracy: 72.2359
Validation perplexity: 6.59832
Validation accuracy: 66.986
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.15; ppl:   2.72; 3031 src tok/s; 3142 tgt tok/s;     14 s elapsed
Epoch  9,   100/  454; acc:  76.88; ppl:   2.76; 3115 src tok/s; 3237 tgt tok/s;     27 s elapsed
Epoch  9,   150/  454; acc:  77.60; ppl:   2.67; 3121 src tok/s; 3237 tgt tok/s;     41 s elapsed
Epoch  9,   200/  454; acc:  77.27; ppl:   2.72; 3033 src tok/s; 3164 tgt tok/s;     55 s elapsed
Epoch  9,   250/  454; acc:  76.18; ppl:   2.85; 3044 src tok/s; 3153 tgt tok/s;     69 s elapsed
Epoch  9,   300/  454; acc:  78.16; ppl:   2.58; 3068 src tok/s; 3199 tgt tok/s;     82 s elapsed
Epoch  9,   350/  454; acc:  77.09; ppl:   2.70; 3067 src tok/s; 3174 tgt tok/s;     96 s elapsed
Epoch  9,   400/  454; acc:  77.19; ppl:   2.70; 3117 src tok/s; 3228 tgt tok/s;    109 s elapsed
Epoch  9,   450/  454; acc:  76.53; ppl:   2.84; 3057 src tok/s; 3164 tgt tok/s;    123 s elapsed
Train perplexity: 2.72272
Train accuracy: 77.1231
Validation perplexity: 6.26832
Validation accuracy: 68.8946
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.20; ppl:   2.25; 3062 src tok/s; 3164 tgt tok/s;     14 s elapsed
Epoch 10,   100/  454; acc:  81.60; ppl:   2.20; 3088 src tok/s; 3199 tgt tok/s;     27 s elapsed
Epoch 10,   150/  454; acc:  80.16; ppl:   2.32; 3084 src tok/s; 3171 tgt tok/s;     42 s elapsed
Epoch 10,   200/  454; acc:  82.31; ppl:   2.06; 3045 src tok/s; 3199 tgt tok/s;     54 s elapsed
Epoch 10,   250/  454; acc:  81.98; ppl:   2.12; 3064 src tok/s; 3199 tgt tok/s;     68 s elapsed
Epoch 10,   300/  454; acc:  79.90; ppl:   2.38; 3140 src tok/s; 3238 tgt tok/s;     82 s elapsed
Epoch 10,   350/  454; acc:  80.49; ppl:   2.28; 3102 src tok/s; 3231 tgt tok/s;     95 s elapsed
Epoch 10,   400/  454; acc:  80.61; ppl:   2.28; 3069 src tok/s; 3200 tgt tok/s;    109 s elapsed
Epoch 10,   450/  454; acc:  80.41; ppl:   2.27; 3045 src tok/s; 3149 tgt tok/s;    122 s elapsed
Train perplexity: 2.2389
Train accuracy: 80.9445
Validation perplexity: 6.28053
Validation accuracy: 69.3628
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.69; ppl:   1.97; 3071 src tok/s; 3201 tgt tok/s;     14 s elapsed
Epoch 11,   100/  454; acc:  82.97; ppl:   2.05; 3112 src tok/s; 3210 tgt tok/s;     27 s elapsed
Epoch 11,   150/  454; acc:  83.37; ppl:   2.00; 3111 src tok/s; 3235 tgt tok/s;     40 s elapsed
Epoch 11,   200/  454; acc:  82.47; ppl:   2.08; 3044 src tok/s; 3166 tgt tok/s;     54 s elapsed
Epoch 11,   250/  454; acc:  82.84; ppl:   2.03; 3035 src tok/s; 3148 tgt tok/s;     68 s elapsed
Epoch 11,   300/  454; acc:  83.28; ppl:   2.00; 3063 src tok/s; 3192 tgt tok/s;     82 s elapsed
Epoch 11,   350/  454; acc:  83.58; ppl:   1.96; 3062 src tok/s; 3187 tgt tok/s;     95 s elapsed
Epoch 11,   400/  454; acc:  82.78; ppl:   2.06; 3078 src tok/s; 3178 tgt tok/s;    109 s elapsed
Epoch 11,   450/  454; acc:  82.86; ppl:   2.03; 3065 src tok/s; 3176 tgt tok/s;    123 s elapsed
Train perplexity: 2.02234
Train accuracy: 83.0681
Validation perplexity: 6.40458
Validation accuracy: 69.448
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  83.32; ppl:   1.99; 3048 src tok/s; 3154 tgt tok/s;     14 s elapsed
Epoch 12,   100/  454; acc:  85.31; ppl:   1.82; 3119 src tok/s; 3236 tgt tok/s;     27 s elapsed
Epoch 12,   150/  454; acc:  84.63; ppl:   1.87; 3060 src tok/s; 3187 tgt tok/s;     41 s elapsed
Epoch 12,   200/  454; acc:  83.62; ppl:   1.98; 3094 src tok/s; 3204 tgt tok/s;     55 s elapsed
Epoch 12,   250/  454; acc:  84.14; ppl:   1.93; 3081 src tok/s; 3195 tgt tok/s;     68 s elapsed
Epoch 12,   300/  454; acc:  84.51; ppl:   1.91; 3084 src tok/s; 3211 tgt tok/s;     82 s elapsed
Epoch 12,   350/  454; acc:  84.11; ppl:   1.93; 3113 src tok/s; 3214 tgt tok/s;     95 s elapsed
Epoch 12,   400/  454; acc:  83.98; ppl:   1.93; 3124 src tok/s; 3257 tgt tok/s;    109 s elapsed
Epoch 12,   450/  454; acc:  83.98; ppl:   1.92; 3039 src tok/s; 3153 tgt tok/s;    122 s elapsed
Train perplexity: 1.91947
Train accuracy: 84.1827
Validation perplexity: 6.54562
Validation accuracy: 69.4693
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.24; ppl:   1.93; 3132 src tok/s; 3225 tgt tok/s;     14 s elapsed
Epoch 13,   100/  454; acc:  85.35; ppl:   1.82; 3043 src tok/s; 3177 tgt tok/s;     27 s elapsed
Epoch 13,   150/  454; acc:  85.34; ppl:   1.81; 3085 src tok/s; 3212 tgt tok/s;     40 s elapsed
Epoch 13,   200/  454; acc:  84.11; ppl:   1.95; 3073 src tok/s; 3172 tgt tok/s;     54 s elapsed
Epoch 13,   250/  454; acc:  84.63; ppl:   1.88; 3060 src tok/s; 3191 tgt tok/s;     68 s elapsed
Epoch 13,   300/  454; acc:  84.85; ppl:   1.85; 3124 src tok/s; 3226 tgt tok/s;     82 s elapsed
Epoch 13,   350/  454; acc:  85.31; ppl:   1.80; 3085 src tok/s; 3219 tgt tok/s;     95 s elapsed
Epoch 13,   400/  454; acc:  84.33; ppl:   1.92; 3042 src tok/s; 3163 tgt tok/s;    109 s elapsed
Epoch 13,   450/  454; acc:  84.76; ppl:   1.87; 3068 src tok/s; 3178 tgt tok/s;    122 s elapsed
Train perplexity: 1.86981
Train accuracy: 84.7665
Validation perplexity: 6.60613
Validation accuracy: 69.3558
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.50; ppl:   1.80; 3093 src tok/s; 3210 tgt tok/s;     13 s elapsed
Epoch 14,   100/  454; acc:  84.89; ppl:   1.89; 3062 src tok/s; 3170 tgt tok/s;     27 s elapsed
Epoch 14,   150/  454; acc:  85.50; ppl:   1.82; 3055 src tok/s; 3170 tgt tok/s;     41 s elapsed
Epoch 14,   200/  454; acc:  84.95; ppl:   1.88; 3041 src tok/s; 3167 tgt tok/s;     55 s elapsed
Epoch 14,   250/  454; acc:  85.23; ppl:   1.82; 3042 src tok/s; 3161 tgt tok/s;     68 s elapsed
Epoch 14,   300/  454; acc:  85.05; ppl:   1.84; 3097 src tok/s; 3202 tgt tok/s;     82 s elapsed
Epoch 14,   350/  454; acc:  85.57; ppl:   1.78; 3066 src tok/s; 3195 tgt tok/s;     95 s elapsed
Epoch 14,   400/  454; acc:  84.50; ppl:   1.91; 3054 src tok/s; 3162 tgt tok/s;    109 s elapsed
Epoch 14,   450/  454; acc:  85.36; ppl:   1.81; 3100 src tok/s; 3232 tgt tok/s;    123 s elapsed
Train perplexity: 1.8474
Train accuracy: 85.0923
Validation perplexity: 6.6365
Validation accuracy: 69.3487
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  84.58; ppl:   1.88; 3021 src tok/s; 3127 tgt tok/s;     14 s elapsed
Epoch 15,   100/  454; acc:  85.36; ppl:   1.81; 3077 src tok/s; 3209 tgt tok/s;     28 s elapsed
Epoch 15,   150/  454; acc:  84.82; ppl:   1.88; 3089 src tok/s; 3185 tgt tok/s;     42 s elapsed
Epoch 15,   200/  454; acc:  85.33; ppl:   1.82; 3073 src tok/s; 3205 tgt tok/s;     55 s elapsed
Epoch 15,   250/  454; acc:  85.91; ppl:   1.79; 3062 src tok/s; 3186 tgt tok/s;     68 s elapsed
Epoch 15,   300/  454; acc:  84.80; ppl:   1.88; 3041 src tok/s; 3151 tgt tok/s;     82 s elapsed
Epoch 15,   350/  454; acc:  84.81; ppl:   1.88; 3123 src tok/s; 3234 tgt tok/s;     96 s elapsed
Epoch 15,   400/  454; acc:  85.71; ppl:   1.80; 3152 src tok/s; 3264 tgt tok/s;    109 s elapsed
Epoch 15,   450/  454; acc:  86.28; ppl:   1.74; 3017 src tok/s; 3152 tgt tok/s;    122 s elapsed
Train perplexity: 1.83852
Train accuracy: 85.1941
Validation perplexity: 6.64992
Validation accuracy: 69.3416
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.38; ppl:   1.83; 3085 src tok/s; 3212 tgt tok/s;     14 s elapsed
Epoch 16,   100/  454; acc:  85.06; ppl:   1.87; 3114 src tok/s; 3234 tgt tok/s;     27 s elapsed
Epoch 16,   150/  454; acc:  85.36; ppl:   1.83; 3109 src tok/s; 3218 tgt tok/s;     41 s elapsed
Epoch 16,   200/  454; acc:  85.63; ppl:   1.81; 3108 src tok/s; 3222 tgt tok/s;     54 s elapsed
Epoch 16,   250/  454; acc:  85.51; ppl:   1.83; 3058 src tok/s; 3174 tgt tok/s;     68 s elapsed
Epoch 16,   300/  454; acc:  84.97; ppl:   1.84; 3102 src tok/s; 3230 tgt tok/s;     81 s elapsed
Epoch 16,   350/  454; acc:  84.80; ppl:   1.87; 3075 src tok/s; 3192 tgt tok/s;     95 s elapsed
Epoch 16,   400/  454; acc:  86.07; ppl:   1.76; 3113 src tok/s; 3222 tgt tok/s;    108 s elapsed
Epoch 16,   450/  454; acc:  85.56; ppl:   1.82; 3017 src tok/s; 3132 tgt tok/s;    122 s elapsed
Train perplexity: 1.82999
Train accuracy: 85.3479
Validation perplexity: 6.66293
Validation accuracy: 69.3983
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  84.52; ppl:   1.90; 3088 src tok/s; 3183 tgt tok/s;     14 s elapsed
Epoch 17,   100/  454; acc:  85.60; ppl:   1.78; 3088 src tok/s; 3230 tgt tok/s;     27 s elapsed
Epoch 17,   150/  454; acc:  85.49; ppl:   1.82; 3046 src tok/s; 3174 tgt tok/s;     41 s elapsed
Epoch 17,   200/  454; acc:  85.77; ppl:   1.81; 3026 src tok/s; 3122 tgt tok/s;     55 s elapsed
Epoch 17,   250/  454; acc:  84.99; ppl:   1.85; 3114 src tok/s; 3230 tgt tok/s;     68 s elapsed
Epoch 17,   300/  454; acc:  85.48; ppl:   1.81; 3102 src tok/s; 3215 tgt tok/s;     82 s elapsed
Epoch 17,   350/  454; acc:  86.14; ppl:   1.77; 3056 src tok/s; 3182 tgt tok/s;     96 s elapsed
Epoch 17,   400/  454; acc:  84.93; ppl:   1.87; 3034 src tok/s; 3143 tgt tok/s;    109 s elapsed
Epoch 17,   450/  454; acc:  85.99; ppl:   1.78; 3061 src tok/s; 3188 tgt tok/s;    123 s elapsed
Train perplexity: 1.82752
Train accuracy: 85.376
Validation perplexity: 6.66598
Validation accuracy: 69.3841
Decaying learning rate to 0.000976562
