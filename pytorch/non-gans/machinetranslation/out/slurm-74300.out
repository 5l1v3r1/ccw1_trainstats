<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.4, kappa_enc=0.4, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/seeds/encoder0.4decoder0.4dropout0.3wdropTrueseed1', seed=1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.4)
('Using Kappa L2 loss on decoder', 0.4)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.64; ppl: 15805.23; 4996 src tok/s; 5165 tgt tok/s;      9 s elapsed
Epoch  1,   100/  454; acc:  14.91; ppl: 1210.97; 6992 src tok/s; 7319 tgt tok/s;     14 s elapsed
Epoch  1,   150/  454; acc:  18.53; ppl: 429.78; 7050 src tok/s; 7222 tgt tok/s;     21 s elapsed
Epoch  1,   200/  454; acc:  22.90; ppl: 220.93; 6821 src tok/s; 7165 tgt tok/s;     27 s elapsed
Epoch  1,   250/  454; acc:  24.69; ppl: 162.88; 6914 src tok/s; 7193 tgt tok/s;     32 s elapsed
Epoch  1,   300/  454; acc:  27.24; ppl: 121.88; 7046 src tok/s; 7290 tgt tok/s;     39 s elapsed
Epoch  1,   350/  454; acc:  29.32; ppl:  98.79; 6958 src tok/s; 7215 tgt tok/s;     45 s elapsed
Epoch  1,   400/  454; acc:  32.68; ppl:  71.07; 6957 src tok/s; 7248 tgt tok/s;     51 s elapsed
Epoch  1,   450/  454; acc:  33.90; ppl:  63.99; 6796 src tok/s; 7056 tgt tok/s;     57 s elapsed
Train perplexity: 294.687
Train accuracy: 23.6241
Validation perplexity: 56.4599
Validation accuracy: 36.0792

Epoch  2,    50/  454; acc:  35.06; ppl:  56.47; 6460 src tok/s; 6678 tgt tok/s;      7 s elapsed
Epoch  2,   100/  454; acc:  36.90; ppl:  48.09; 6877 src tok/s; 7142 tgt tok/s;     13 s elapsed
Epoch  2,   150/  454; acc:  39.23; ppl:  43.01; 6700 src tok/s; 6981 tgt tok/s;     19 s elapsed
Epoch  2,   200/  454; acc:  40.63; ppl:  37.61; 6970 src tok/s; 7224 tgt tok/s;     25 s elapsed
Epoch  2,   250/  454; acc:  42.37; ppl:  33.02; 6863 src tok/s; 7067 tgt tok/s;     31 s elapsed
Epoch  2,   300/  454; acc:  47.62; ppl:  24.44; 6655 src tok/s; 6966 tgt tok/s;     37 s elapsed
Epoch  2,   350/  454; acc:  47.12; ppl:  25.39; 6926 src tok/s; 7141 tgt tok/s;     44 s elapsed
Epoch  2,   400/  454; acc:  50.48; ppl:  19.89; 6684 src tok/s; 6999 tgt tok/s;     50 s elapsed
Epoch  2,   450/  454; acc:  50.22; ppl:  20.04; 6677 src tok/s; 6919 tgt tok/s;     56 s elapsed
Train perplexity: 31.9968
Train accuracy: 43.3329
Validation perplexity: 17.4588
Validation accuracy: 52.462

Epoch  3,    50/  454; acc:  52.12; ppl:  16.78; 6658 src tok/s; 6867 tgt tok/s;      6 s elapsed
Epoch  3,   100/  454; acc:  54.67; ppl:  14.14; 6833 src tok/s; 7118 tgt tok/s;     12 s elapsed
Epoch  3,   150/  454; acc:  54.82; ppl:  13.93; 6924 src tok/s; 7150 tgt tok/s;     19 s elapsed
Epoch  3,   200/  454; acc:  55.58; ppl:  13.61; 6656 src tok/s; 6923 tgt tok/s;     25 s elapsed
Epoch  3,   250/  454; acc:  57.21; ppl:  12.14; 6732 src tok/s; 6998 tgt tok/s;     31 s elapsed
Epoch  3,   300/  454; acc:  56.62; ppl:  12.19; 6802 src tok/s; 7064 tgt tok/s;     37 s elapsed
Epoch  3,   350/  454; acc:  56.86; ppl:  12.28; 6851 src tok/s; 7090 tgt tok/s;     44 s elapsed
Epoch  3,   400/  454; acc:  59.02; ppl:  10.75; 6726 src tok/s; 7001 tgt tok/s;     50 s elapsed
Epoch  3,   450/  454; acc:  58.72; ppl:  11.04; 6720 src tok/s; 7008 tgt tok/s;     56 s elapsed
Train perplexity: 12.891
Train accuracy: 56.1479
Validation perplexity: 10.8445
Validation accuracy: 59.7134

Epoch  4,    50/  454; acc:  60.96; ppl:   8.94; 6422 src tok/s; 6604 tgt tok/s;      7 s elapsed
Epoch  4,   100/  454; acc:  61.89; ppl:   8.41; 6828 src tok/s; 7134 tgt tok/s;     13 s elapsed
Epoch  4,   150/  454; acc:  61.39; ppl:   8.53; 6877 src tok/s; 7140 tgt tok/s;     19 s elapsed
Epoch  4,   200/  454; acc:  61.77; ppl:   8.38; 6814 src tok/s; 7042 tgt tok/s;     25 s elapsed
Epoch  4,   250/  454; acc:  61.44; ppl:   8.56; 6890 src tok/s; 7105 tgt tok/s;     31 s elapsed
Epoch  4,   300/  454; acc:  62.68; ppl:   8.05; 6740 src tok/s; 7069 tgt tok/s;     37 s elapsed
Epoch  4,   350/  454; acc:  62.28; ppl:   8.27; 6615 src tok/s; 6883 tgt tok/s;     44 s elapsed
Epoch  4,   400/  454; acc:  62.99; ppl:   7.84; 6831 src tok/s; 7104 tgt tok/s;     50 s elapsed
Epoch  4,   450/  454; acc:  62.61; ppl:   7.83; 6770 src tok/s; 7005 tgt tok/s;     56 s elapsed
Train perplexity: 8.29681
Train accuracy: 62.0213
Validation perplexity: 8.30414
Validation accuracy: 63.3958

Epoch  5,    50/  454; acc:  66.02; ppl:   6.06; 6556 src tok/s; 6800 tgt tok/s;      6 s elapsed
Epoch  5,   100/  454; acc:  65.33; ppl:   6.33; 6696 src tok/s; 6922 tgt tok/s;     13 s elapsed
Epoch  5,   150/  454; acc:  66.55; ppl:   5.83; 6601 src tok/s; 6959 tgt tok/s;     19 s elapsed
Epoch  5,   200/  454; acc:  63.87; ppl:   6.84; 7012 src tok/s; 7216 tgt tok/s;     25 s elapsed
Epoch  5,   250/  454; acc:  65.82; ppl:   6.23; 6846 src tok/s; 7065 tgt tok/s;     31 s elapsed
Epoch  5,   300/  454; acc:  65.46; ppl:   6.37; 6829 src tok/s; 7077 tgt tok/s;     37 s elapsed
Epoch  5,   350/  454; acc:  66.93; ppl:   5.75; 6723 src tok/s; 7061 tgt tok/s;     43 s elapsed
Epoch  5,   400/  454; acc:  64.72; ppl:   6.44; 6845 src tok/s; 7057 tgt tok/s;     50 s elapsed
Epoch  5,   450/  454; acc:  65.86; ppl:   6.17; 6718 src tok/s; 6984 tgt tok/s;     56 s elapsed
Train perplexity: 6.2346
Train accuracy: 65.5719
Validation perplexity: 7.25337
Validation accuracy: 65.5385

Epoch  6,    50/  454; acc:  69.38; ppl:   4.70; 6675 src tok/s; 6919 tgt tok/s;      6 s elapsed
Epoch  6,   100/  454; acc:  68.42; ppl:   4.91; 6840 src tok/s; 7084 tgt tok/s;     12 s elapsed
Epoch  6,   150/  454; acc:  67.32; ppl:   5.17; 6773 src tok/s; 7021 tgt tok/s;     19 s elapsed
Epoch  6,   200/  454; acc:  69.20; ppl:   4.77; 6886 src tok/s; 7138 tgt tok/s;     25 s elapsed
Epoch  6,   250/  454; acc:  67.92; ppl:   5.09; 6627 src tok/s; 6947 tgt tok/s;     31 s elapsed
Epoch  6,   300/  454; acc:  67.48; ppl:   5.19; 6878 src tok/s; 7123 tgt tok/s;     37 s elapsed
Epoch  6,   350/  454; acc:  69.03; ppl:   4.78; 6702 src tok/s; 6979 tgt tok/s;     43 s elapsed
Epoch  6,   400/  454; acc:  67.23; ppl:   5.28; 6785 src tok/s; 7011 tgt tok/s;     50 s elapsed
Epoch  6,   450/  454; acc:  67.32; ppl:   5.29; 6804 src tok/s; 7051 tgt tok/s;     56 s elapsed
Train perplexity: 5.01788
Train accuracy: 68.1253
Validation perplexity: 6.99104
Validation accuracy: 65.7301

Epoch  7,    50/  454; acc:  72.00; ppl:   3.85; 6700 src tok/s; 6952 tgt tok/s;      6 s elapsed
Epoch  7,   100/  454; acc:  70.17; ppl:   4.24; 6872 src tok/s; 7132 tgt tok/s;     12 s elapsed
Epoch  7,   150/  454; acc:  70.62; ppl:   4.14; 6655 src tok/s; 6866 tgt tok/s;     19 s elapsed
Epoch  7,   200/  454; acc:  70.60; ppl:   4.10; 6753 src tok/s; 7033 tgt tok/s;     25 s elapsed
Epoch  7,   250/  454; acc:  70.37; ppl:   4.13; 6851 src tok/s; 7079 tgt tok/s;     31 s elapsed
Epoch  7,   300/  454; acc:  69.47; ppl:   4.34; 6774 src tok/s; 7038 tgt tok/s;     37 s elapsed
Epoch  7,   350/  454; acc:  69.02; ppl:   4.47; 6903 src tok/s; 7131 tgt tok/s;     44 s elapsed
Epoch  7,   400/  454; acc:  70.57; ppl:   4.16; 6675 src tok/s; 6991 tgt tok/s;     50 s elapsed
Epoch  7,   450/  454; acc:  69.69; ppl:   4.38; 6684 src tok/s; 6954 tgt tok/s;     56 s elapsed
Train perplexity: 4.2016
Train accuracy: 70.262
Validation perplexity: 6.50567
Validation accuracy: 67.0569

Epoch  8,    50/  454; acc:  73.46; ppl:   3.33; 6641 src tok/s; 6918 tgt tok/s;      6 s elapsed
Epoch  8,   100/  454; acc:  72.71; ppl:   3.53; 6774 src tok/s; 7020 tgt tok/s;     13 s elapsed
Epoch  8,   150/  454; acc:  71.39; ppl:   3.76; 6842 src tok/s; 7073 tgt tok/s;     19 s elapsed
Epoch  8,   200/  454; acc:  72.64; ppl:   3.51; 6679 src tok/s; 6955 tgt tok/s;     25 s elapsed
Epoch  8,   250/  454; acc:  71.73; ppl:   3.72; 6949 src tok/s; 7171 tgt tok/s;     31 s elapsed
Epoch  8,   300/  454; acc:  72.10; ppl:   3.60; 6691 src tok/s; 7003 tgt tok/s;     37 s elapsed
Epoch  8,   350/  454; acc:  71.44; ppl:   3.84; 6755 src tok/s; 6990 tgt tok/s;     44 s elapsed
Epoch  8,   400/  454; acc:  72.03; ppl:   3.64; 6717 src tok/s; 6973 tgt tok/s;     50 s elapsed
Epoch  8,   450/  454; acc:  71.08; ppl:   3.78; 6736 src tok/s; 6967 tgt tok/s;     56 s elapsed
Train perplexity: 3.63016
Train accuracy: 72.0744
Validation perplexity: 6.76348
Validation accuracy: 66.0494
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.25; ppl:   2.89; 6393 src tok/s; 6638 tgt tok/s;      7 s elapsed
Epoch  9,   100/  454; acc:  77.64; ppl:   2.66; 6885 src tok/s; 7130 tgt tok/s;     13 s elapsed
Epoch  9,   150/  454; acc:  78.11; ppl:   2.58; 6858 src tok/s; 7135 tgt tok/s;     19 s elapsed
Epoch  9,   200/  454; acc:  77.02; ppl:   2.74; 6757 src tok/s; 6986 tgt tok/s;     25 s elapsed
Epoch  9,   250/  454; acc:  78.54; ppl:   2.49; 6724 src tok/s; 7032 tgt tok/s;     31 s elapsed
Epoch  9,   300/  454; acc:  76.06; ppl:   2.87; 6957 src tok/s; 7154 tgt tok/s;     37 s elapsed
Epoch  9,   350/  454; acc:  77.30; ppl:   2.66; 6800 src tok/s; 7038 tgt tok/s;     44 s elapsed
Epoch  9,   400/  454; acc:  76.81; ppl:   2.76; 6646 src tok/s; 6926 tgt tok/s;     50 s elapsed
Epoch  9,   450/  454; acc:  76.92; ppl:   2.75; 6713 src tok/s; 6981 tgt tok/s;     56 s elapsed
Train perplexity: 2.71228
Train accuracy: 77.1605
Validation perplexity: 6.15457
Validation accuracy: 68.9371
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.58; ppl:   2.27; 6592 src tok/s; 6819 tgt tok/s;      6 s elapsed
Epoch 10,   100/  454; acc:  81.57; ppl:   2.17; 6662 src tok/s; 6942 tgt tok/s;     13 s elapsed
Epoch 10,   150/  454; acc:  80.93; ppl:   2.26; 6578 src tok/s; 6851 tgt tok/s;     19 s elapsed
Epoch 10,   200/  454; acc:  81.14; ppl:   2.22; 6897 src tok/s; 7154 tgt tok/s;     25 s elapsed
Epoch 10,   250/  454; acc:  81.49; ppl:   2.15; 6918 src tok/s; 7165 tgt tok/s;     31 s elapsed
Epoch 10,   300/  454; acc:  80.46; ppl:   2.29; 6959 src tok/s; 7212 tgt tok/s;     37 s elapsed
Epoch 10,   350/  454; acc:  80.86; ppl:   2.21; 6721 src tok/s; 7012 tgt tok/s;     43 s elapsed
Epoch 10,   400/  454; acc:  80.20; ppl:   2.31; 6795 src tok/s; 7003 tgt tok/s;     50 s elapsed
Epoch 10,   450/  454; acc:  80.86; ppl:   2.27; 6618 src tok/s; 6883 tgt tok/s;     56 s elapsed
Train perplexity: 2.23532
Train accuracy: 80.9089
Validation perplexity: 6.34559
Validation accuracy: 69.4125
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  82.64; ppl:   2.07; 6497 src tok/s; 6741 tgt tok/s;      7 s elapsed
Epoch 11,   100/  454; acc:  84.09; ppl:   1.93; 6883 src tok/s; 7162 tgt tok/s;     13 s elapsed
Epoch 11,   150/  454; acc:  82.83; ppl:   2.04; 6662 src tok/s; 6921 tgt tok/s;     19 s elapsed
Epoch 11,   200/  454; acc:  82.95; ppl:   2.02; 6867 src tok/s; 7142 tgt tok/s;     25 s elapsed
Epoch 11,   250/  454; acc:  82.86; ppl:   2.04; 6991 src tok/s; 7163 tgt tok/s;     31 s elapsed
Epoch 11,   300/  454; acc:  83.39; ppl:   1.99; 6650 src tok/s; 6948 tgt tok/s;     37 s elapsed
Epoch 11,   350/  454; acc:  82.41; ppl:   2.06; 6837 src tok/s; 7102 tgt tok/s;     44 s elapsed
Epoch 11,   400/  454; acc:  83.86; ppl:   1.94; 6905 src tok/s; 7168 tgt tok/s;     49 s elapsed
Epoch 11,   450/  454; acc:  83.37; ppl:   1.99; 6733 src tok/s; 7003 tgt tok/s;     56 s elapsed
Train perplexity: 2.01426
Train accuracy: 83.0924
Validation perplexity: 6.47641
Validation accuracy: 69.2422
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.54; ppl:   1.90; 6928 src tok/s; 7165 tgt tok/s;      6 s elapsed
Epoch 12,   100/  454; acc:  84.19; ppl:   1.93; 6767 src tok/s; 7064 tgt tok/s;     12 s elapsed
Epoch 12,   150/  454; acc:  84.63; ppl:   1.88; 6618 src tok/s; 6916 tgt tok/s;     18 s elapsed
Epoch 12,   200/  454; acc:  83.55; ppl:   1.98; 6802 src tok/s; 7038 tgt tok/s;     25 s elapsed
Epoch 12,   250/  454; acc:  84.99; ppl:   1.84; 6867 src tok/s; 7167 tgt tok/s;     31 s elapsed
Epoch 12,   300/  454; acc:  83.43; ppl:   1.98; 6904 src tok/s; 7122 tgt tok/s;     37 s elapsed
Epoch 12,   350/  454; acc:  83.91; ppl:   1.95; 6817 src tok/s; 7053 tgt tok/s;     43 s elapsed
Epoch 12,   400/  454; acc:  84.50; ppl:   1.89; 6759 src tok/s; 7052 tgt tok/s;     49 s elapsed
Epoch 12,   450/  454; acc:  84.18; ppl:   1.92; 6855 src tok/s; 7055 tgt tok/s;     55 s elapsed
Train perplexity: 1.91722
Train accuracy: 84.2123
Validation perplexity: 6.5989
Validation accuracy: 69.2068
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  85.34; ppl:   1.81; 6238 src tok/s; 6521 tgt tok/s;      6 s elapsed
Epoch 13,   100/  454; acc:  83.69; ppl:   1.97; 6990 src tok/s; 7145 tgt tok/s;     13 s elapsed
Epoch 13,   150/  454; acc:  84.30; ppl:   1.92; 6842 src tok/s; 7078 tgt tok/s;     19 s elapsed
Epoch 13,   200/  454; acc:  85.75; ppl:   1.79; 6519 src tok/s; 6835 tgt tok/s;     25 s elapsed
Epoch 13,   250/  454; acc:  85.14; ppl:   1.84; 6845 src tok/s; 7089 tgt tok/s;     31 s elapsed
Epoch 13,   300/  454; acc:  84.62; ppl:   1.88; 6713 src tok/s; 6973 tgt tok/s;     38 s elapsed
Epoch 13,   350/  454; acc:  84.93; ppl:   1.84; 6671 src tok/s; 6952 tgt tok/s;     44 s elapsed
Epoch 13,   400/  454; acc:  85.24; ppl:   1.83; 6863 src tok/s; 7145 tgt tok/s;     50 s elapsed
Epoch 13,   450/  454; acc:  85.15; ppl:   1.80; 6850 src tok/s; 7120 tgt tok/s;     56 s elapsed
Train perplexity: 1.86568
Train accuracy: 84.7911
Validation perplexity: 6.62962
Validation accuracy: 69.3274
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  84.79; ppl:   1.87; 6296 src tok/s; 6559 tgt tok/s;      7 s elapsed
Epoch 14,   100/  454; acc:  84.82; ppl:   1.85; 6677 src tok/s; 6925 tgt tok/s;     13 s elapsed
Epoch 14,   150/  454; acc:  86.01; ppl:   1.77; 6957 src tok/s; 7234 tgt tok/s;     19 s elapsed
Epoch 14,   200/  454; acc:  84.25; ppl:   1.92; 6754 src tok/s; 6985 tgt tok/s;     25 s elapsed
Epoch 14,   250/  454; acc:  84.03; ppl:   1.95; 6920 src tok/s; 7125 tgt tok/s;     32 s elapsed
Epoch 14,   300/  454; acc:  86.31; ppl:   1.75; 6773 src tok/s; 7098 tgt tok/s;     37 s elapsed
Epoch 14,   350/  454; acc:  85.46; ppl:   1.80; 6791 src tok/s; 7028 tgt tok/s;     44 s elapsed
Epoch 14,   400/  454; acc:  84.84; ppl:   1.87; 6715 src tok/s; 6972 tgt tok/s;     50 s elapsed
Epoch 14,   450/  454; acc:  85.09; ppl:   1.86; 6765 src tok/s; 6994 tgt tok/s;     56 s elapsed
Train perplexity: 1.84634
Train accuracy: 85.0839
Validation perplexity: 6.67752
Validation accuracy: 69.1855
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  84.07; ppl:   1.93; 6664 src tok/s; 6849 tgt tok/s;      7 s elapsed
Epoch 15,   100/  454; acc:  86.67; ppl:   1.72; 6768 src tok/s; 7089 tgt tok/s;     13 s elapsed
Epoch 15,   150/  454; acc:  85.72; ppl:   1.80; 6876 src tok/s; 7149 tgt tok/s;     19 s elapsed
Epoch 15,   200/  454; acc:  84.76; ppl:   1.89; 6904 src tok/s; 7118 tgt tok/s;     25 s elapsed
Epoch 15,   250/  454; acc:  85.33; ppl:   1.82; 6774 src tok/s; 7046 tgt tok/s;     31 s elapsed
Epoch 15,   300/  454; acc:  85.07; ppl:   1.84; 6816 src tok/s; 7045 tgt tok/s;     37 s elapsed
Epoch 15,   350/  454; acc:  85.20; ppl:   1.83; 6774 src tok/s; 7000 tgt tok/s;     43 s elapsed
Epoch 15,   400/  454; acc:  85.66; ppl:   1.78; 6677 src tok/s; 7021 tgt tok/s;     49 s elapsed
Epoch 15,   450/  454; acc:  84.75; ppl:   1.88; 6694 src tok/s; 6951 tgt tok/s;     56 s elapsed
Train perplexity: 1.83279
Train accuracy: 85.2288
Validation perplexity: 6.6949
Validation accuracy: 69.1571
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  86.42; ppl:   1.74; 6530 src tok/s; 6821 tgt tok/s;      6 s elapsed
Epoch 16,   100/  454; acc:  84.08; ppl:   1.94; 6926 src tok/s; 7133 tgt tok/s;     12 s elapsed
Epoch 16,   150/  454; acc:  84.97; ppl:   1.84; 6825 src tok/s; 7073 tgt tok/s;     19 s elapsed
Epoch 16,   200/  454; acc:  85.75; ppl:   1.78; 6688 src tok/s; 6948 tgt tok/s;     25 s elapsed
Epoch 16,   250/  454; acc:  85.11; ppl:   1.84; 6847 src tok/s; 7080 tgt tok/s;     31 s elapsed
Epoch 16,   300/  454; acc:  85.26; ppl:   1.83; 6783 src tok/s; 7046 tgt tok/s;     37 s elapsed
Epoch 16,   350/  454; acc:  85.45; ppl:   1.82; 6849 src tok/s; 7032 tgt tok/s;     44 s elapsed
Epoch 16,   400/  454; acc:  85.76; ppl:   1.80; 6781 src tok/s; 7116 tgt tok/s;     50 s elapsed
Epoch 16,   450/  454; acc:  84.89; ppl:   1.86; 6698 src tok/s; 6983 tgt tok/s;     56 s elapsed
Train perplexity: 1.8279
Train accuracy: 85.2944
Validation perplexity: 6.70205
Validation accuracy: 69.1784
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  84.54; ppl:   1.90; 6638 src tok/s; 6851 tgt tok/s;      7 s elapsed
Epoch 17,   100/  454; acc:  86.53; ppl:   1.73; 6701 src tok/s; 6982 tgt tok/s;     13 s elapsed
Epoch 17,   150/  454; acc:  84.75; ppl:   1.90; 6770 src tok/s; 6996 tgt tok/s;     19 s elapsed
Epoch 17,   200/  454; acc:  86.08; ppl:   1.76; 6876 src tok/s; 7127 tgt tok/s;     25 s elapsed
Epoch 17,   250/  454; acc:  85.44; ppl:   1.80; 6719 src tok/s; 7012 tgt tok/s;     31 s elapsed
Epoch 17,   300/  454; acc:  85.08; ppl:   1.84; 6787 src tok/s; 7066 tgt tok/s;     37 s elapsed
Epoch 17,   350/  454; acc:  85.08; ppl:   1.85; 6735 src tok/s; 6979 tgt tok/s;     43 s elapsed
Epoch 17,   400/  454; acc:  85.24; ppl:   1.81; 6881 src tok/s; 7153 tgt tok/s;     50 s elapsed
Epoch 17,   450/  454; acc:  85.37; ppl:   1.83; 6667 src tok/s; 6916 tgt tok/s;     56 s elapsed
Train perplexity: 1.82358
Train accuracy: 85.3319
Validation perplexity: 6.70715
Validation accuracy: 69.1855
Decaying learning rate to 0.000976562
