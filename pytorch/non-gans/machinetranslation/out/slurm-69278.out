<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.0, kappa_enc=0.1, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.1decoder0dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.1)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   9.24; ppl: 8445.50; 4592 src tok/s; 4776 tgt tok/s;      9 s elapsed
Epoch  1,   100/  454; acc:  14.29; ppl: 1726.77; 6737 src tok/s; 7002 tgt tok/s;     15 s elapsed
Epoch  1,   150/  454; acc:  18.13; ppl: 522.01; 6723 src tok/s; 6917 tgt tok/s;     22 s elapsed
Epoch  1,   200/  454; acc:  21.86; ppl: 261.19; 6538 src tok/s; 6818 tgt tok/s;     28 s elapsed
Epoch  1,   250/  454; acc:  24.01; ppl: 182.68; 6595 src tok/s; 6823 tgt tok/s;     35 s elapsed
Epoch  1,   300/  454; acc:  28.79; ppl: 113.66; 6731 src tok/s; 6993 tgt tok/s;     41 s elapsed
Epoch  1,   350/  454; acc:  29.90; ppl:  96.55; 6845 src tok/s; 7056 tgt tok/s;     47 s elapsed
Epoch  1,   400/  454; acc:  31.70; ppl:  80.01; 6568 src tok/s; 6877 tgt tok/s;     53 s elapsed
Epoch  1,   450/  454; acc:  33.63; ppl:  66.16; 6531 src tok/s; 6791 tgt tok/s;     59 s elapsed
Train perplexity: 300.014
Train accuracy: 23.5717
Validation perplexity: 56.0261
Validation accuracy: 35.5258

Epoch  2,    50/  454; acc:  37.59; ppl:  49.05; 6339 src tok/s; 6629 tgt tok/s;      6 s elapsed
Epoch  2,   100/  454; acc:  37.74; ppl:  46.68; 6915 src tok/s; 7116 tgt tok/s;     13 s elapsed
Epoch  2,   150/  454; acc:  42.08; ppl:  35.64; 6654 src tok/s; 6904 tgt tok/s;     19 s elapsed
Epoch  2,   200/  454; acc:  43.68; ppl:  31.10; 6572 src tok/s; 6826 tgt tok/s;     25 s elapsed
Epoch  2,   250/  454; acc:  47.13; ppl:  25.82; 6564 src tok/s; 6875 tgt tok/s;     31 s elapsed
Epoch  2,   300/  454; acc:  46.61; ppl:  25.39; 6732 src tok/s; 6928 tgt tok/s;     38 s elapsed
Epoch  2,   350/  454; acc:  49.07; ppl:  21.61; 6618 src tok/s; 6862 tgt tok/s;     44 s elapsed
Epoch  2,   400/  454; acc:  51.27; ppl:  19.34; 6535 src tok/s; 6796 tgt tok/s;     51 s elapsed
Epoch  2,   450/  454; acc:  51.16; ppl:  19.45; 6575 src tok/s; 6828 tgt tok/s;     57 s elapsed
Train perplexity: 28.6464
Train accuracy: 45.2037
Validation perplexity: 16.1189
Validation accuracy: 53.0226

Epoch  3,    50/  454; acc:  52.75; ppl:  15.76; 6357 src tok/s; 6619 tgt tok/s;      7 s elapsed
Epoch  3,   100/  454; acc:  55.39; ppl:  13.61; 6643 src tok/s; 6943 tgt tok/s;     13 s elapsed
Epoch  3,   150/  454; acc:  56.63; ppl:  12.97; 6594 src tok/s; 6829 tgt tok/s;     19 s elapsed
Epoch  3,   200/  454; acc:  55.75; ppl:  13.32; 6687 src tok/s; 6893 tgt tok/s;     26 s elapsed
Epoch  3,   250/  454; acc:  56.69; ppl:  12.57; 6649 src tok/s; 6856 tgt tok/s;     32 s elapsed
Epoch  3,   300/  454; acc:  58.94; ppl:  10.94; 6633 src tok/s; 6926 tgt tok/s;     38 s elapsed
Epoch  3,   350/  454; acc:  56.56; ppl:  12.38; 6679 src tok/s; 6904 tgt tok/s;     45 s elapsed
Epoch  3,   400/  454; acc:  59.59; ppl:  10.33; 6662 src tok/s; 6937 tgt tok/s;     51 s elapsed
Epoch  3,   450/  454; acc:  58.65; ppl:  10.89; 6589 src tok/s; 6842 tgt tok/s;     57 s elapsed
Train perplexity: 12.4407
Train accuracy: 56.7462
Validation perplexity: 10.4512
Validation accuracy: 60.0184

Epoch  4,    50/  454; acc:  61.96; ppl:   8.22; 6310 src tok/s; 6566 tgt tok/s;      7 s elapsed
Epoch  4,   100/  454; acc:  61.56; ppl:   8.50; 6678 src tok/s; 6906 tgt tok/s;     13 s elapsed
Epoch  4,   150/  454; acc:  60.50; ppl:   9.06; 6794 src tok/s; 6960 tgt tok/s;     20 s elapsed
Epoch  4,   200/  454; acc:  63.73; ppl:   7.46; 6611 src tok/s; 6919 tgt tok/s;     25 s elapsed
Epoch  4,   250/  454; acc:  61.68; ppl:   8.42; 6719 src tok/s; 6976 tgt tok/s;     32 s elapsed
Epoch  4,   300/  454; acc:  61.73; ppl:   8.40; 6537 src tok/s; 6815 tgt tok/s;     38 s elapsed
Epoch  4,   350/  454; acc:  62.71; ppl:   8.01; 6561 src tok/s; 6835 tgt tok/s;     44 s elapsed
Epoch  4,   400/  454; acc:  62.53; ppl:   8.18; 6624 src tok/s; 6851 tgt tok/s;     51 s elapsed
Epoch  4,   450/  454; acc:  63.71; ppl:   7.41; 6567 src tok/s; 6836 tgt tok/s;     57 s elapsed
Train perplexity: 8.18988
Train accuracy: 62.1956
Validation perplexity: 8.17136
Validation accuracy: 63.3603

Epoch  5,    50/  454; acc:  64.38; ppl:   6.66; 6396 src tok/s; 6606 tgt tok/s;      7 s elapsed
Epoch  5,   100/  454; acc:  65.61; ppl:   6.11; 6541 src tok/s; 6830 tgt tok/s;     13 s elapsed
Epoch  5,   150/  454; acc:  66.32; ppl:   5.93; 6772 src tok/s; 7016 tgt tok/s;     19 s elapsed
Epoch  5,   200/  454; acc:  65.15; ppl:   6.42; 6547 src tok/s; 6773 tgt tok/s;     26 s elapsed
Epoch  5,   250/  454; acc:  64.88; ppl:   6.54; 6651 src tok/s; 6899 tgt tok/s;     32 s elapsed
Epoch  5,   300/  454; acc:  65.95; ppl:   6.03; 6603 src tok/s; 6879 tgt tok/s;     38 s elapsed
Epoch  5,   350/  454; acc:  65.05; ppl:   6.29; 6690 src tok/s; 6913 tgt tok/s;     45 s elapsed
Epoch  5,   400/  454; acc:  66.60; ppl:   5.82; 6595 src tok/s; 6867 tgt tok/s;     51 s elapsed
Epoch  5,   450/  454; acc:  65.74; ppl:   6.02; 6453 src tok/s; 6698 tgt tok/s;     57 s elapsed
Train perplexity: 6.19175
Train accuracy: 65.5395
Validation perplexity: 7.25537
Validation accuracy: 65.0206

Epoch  6,    50/  454; acc:  68.97; ppl:   4.77; 6333 src tok/s; 6568 tgt tok/s;      7 s elapsed
Epoch  6,   100/  454; acc:  68.32; ppl:   4.99; 6675 src tok/s; 6908 tgt tok/s;     13 s elapsed
Epoch  6,   150/  454; acc:  68.86; ppl:   4.82; 6571 src tok/s; 6818 tgt tok/s;     19 s elapsed
Epoch  6,   200/  454; acc:  68.34; ppl:   5.01; 6586 src tok/s; 6839 tgt tok/s;     26 s elapsed
Epoch  6,   250/  454; acc:  67.45; ppl:   5.22; 6714 src tok/s; 6941 tgt tok/s;     32 s elapsed
Epoch  6,   300/  454; acc:  68.48; ppl:   4.93; 6579 src tok/s; 6859 tgt tok/s;     38 s elapsed
Epoch  6,   350/  454; acc:  67.05; ppl:   5.32; 6749 src tok/s; 6964 tgt tok/s;     45 s elapsed
Epoch  6,   400/  454; acc:  68.11; ppl:   5.02; 6542 src tok/s; 6821 tgt tok/s;     51 s elapsed
Epoch  6,   450/  454; acc:  68.86; ppl:   4.76; 6443 src tok/s; 6733 tgt tok/s;     57 s elapsed
Train perplexity: 4.99191
Train accuracy: 68.2391
Validation perplexity: 6.89634
Validation accuracy: 66.1132

Epoch  7,    50/  454; acc:  71.93; ppl:   3.83; 6400 src tok/s; 6680 tgt tok/s;      6 s elapsed
Epoch  7,   100/  454; acc:  70.07; ppl:   4.19; 6623 src tok/s; 6880 tgt tok/s;     13 s elapsed
Epoch  7,   150/  454; acc:  70.10; ppl:   4.24; 6624 src tok/s; 6867 tgt tok/s;     19 s elapsed
Epoch  7,   200/  454; acc:  71.19; ppl:   4.01; 6720 src tok/s; 7002 tgt tok/s;     25 s elapsed
Epoch  7,   250/  454; acc:  71.01; ppl:   4.01; 6441 src tok/s; 6716 tgt tok/s;     32 s elapsed
Epoch  7,   300/  454; acc:  70.01; ppl:   4.31; 6749 src tok/s; 6956 tgt tok/s;     38 s elapsed
Epoch  7,   350/  454; acc:  69.46; ppl:   4.41; 6555 src tok/s; 6779 tgt tok/s;     45 s elapsed
Epoch  7,   400/  454; acc:  69.49; ppl:   4.41; 6585 src tok/s; 6823 tgt tok/s;     51 s elapsed
Epoch  7,   450/  454; acc:  69.21; ppl:   4.42; 6636 src tok/s; 6876 tgt tok/s;     57 s elapsed
Train perplexity: 4.19848
Train accuracy: 70.2708
Validation perplexity: 6.69136
Validation accuracy: 66.7589

Epoch  8,    50/  454; acc:  73.09; ppl:   3.46; 6328 src tok/s; 6584 tgt tok/s;      7 s elapsed
Epoch  8,   100/  454; acc:  73.14; ppl:   3.40; 6592 src tok/s; 6870 tgt tok/s;     13 s elapsed
Epoch  8,   150/  454; acc:  74.00; ppl:   3.31; 6482 src tok/s; 6790 tgt tok/s;     19 s elapsed
Epoch  8,   200/  454; acc:  71.20; ppl:   3.86; 6756 src tok/s; 6982 tgt tok/s;     26 s elapsed
Epoch  8,   250/  454; acc:  71.49; ppl:   3.76; 6611 src tok/s; 6867 tgt tok/s;     32 s elapsed
Epoch  8,   300/  454; acc:  71.93; ppl:   3.66; 6484 src tok/s; 6725 tgt tok/s;     39 s elapsed
Epoch  8,   350/  454; acc:  72.61; ppl:   3.53; 6749 src tok/s; 6988 tgt tok/s;     45 s elapsed
Epoch  8,   400/  454; acc:  71.23; ppl:   3.85; 6724 src tok/s; 6953 tgt tok/s;     51 s elapsed
Epoch  8,   450/  454; acc:  71.71; ppl:   3.74; 6520 src tok/s; 6747 tgt tok/s;     57 s elapsed
Train perplexity: 3.62309
Train accuracy: 72.2275
Validation perplexity: 6.69039
Validation accuracy: 66.5673
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.64; ppl:   2.82; 6321 src tok/s; 6564 tgt tok/s;      7 s elapsed
Epoch  9,   100/  454; acc:  77.45; ppl:   2.66; 6686 src tok/s; 6934 tgt tok/s;     13 s elapsed
Epoch  9,   150/  454; acc:  78.09; ppl:   2.61; 6543 src tok/s; 6784 tgt tok/s;     19 s elapsed
Epoch  9,   200/  454; acc:  76.35; ppl:   2.81; 6499 src tok/s; 6725 tgt tok/s;     26 s elapsed
Epoch  9,   250/  454; acc:  77.59; ppl:   2.64; 6546 src tok/s; 6837 tgt tok/s;     32 s elapsed
Epoch  9,   300/  454; acc:  76.85; ppl:   2.79; 6785 src tok/s; 7003 tgt tok/s;     38 s elapsed
Epoch  9,   350/  454; acc:  76.78; ppl:   2.78; 6629 src tok/s; 6872 tgt tok/s;     45 s elapsed
Epoch  9,   400/  454; acc:  77.69; ppl:   2.61; 6685 src tok/s; 6962 tgt tok/s;     51 s elapsed
Epoch  9,   450/  454; acc:  76.99; ppl:   2.74; 6571 src tok/s; 6831 tgt tok/s;     57 s elapsed
Train perplexity: 2.71455
Train accuracy: 77.1823
Validation perplexity: 6.24066
Validation accuracy: 68.6179
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.62; ppl:   2.16; 6395 src tok/s; 6633 tgt tok/s;      6 s elapsed
Epoch 10,   100/  454; acc:  81.08; ppl:   2.23; 6707 src tok/s; 6945 tgt tok/s;     13 s elapsed
Epoch 10,   150/  454; acc:  81.67; ppl:   2.15; 6699 src tok/s; 6962 tgt tok/s;     19 s elapsed
Epoch 10,   200/  454; acc:  80.65; ppl:   2.31; 6784 src tok/s; 7020 tgt tok/s;     25 s elapsed
Epoch 10,   250/  454; acc:  80.09; ppl:   2.35; 6521 src tok/s; 6766 tgt tok/s;     32 s elapsed
Epoch 10,   300/  454; acc:  81.08; ppl:   2.19; 6482 src tok/s; 6768 tgt tok/s;     38 s elapsed
Epoch 10,   350/  454; acc:  80.23; ppl:   2.33; 6584 src tok/s; 6804 tgt tok/s;     45 s elapsed
Epoch 10,   400/  454; acc:  81.85; ppl:   2.14; 6627 src tok/s; 6895 tgt tok/s;     51 s elapsed
Epoch 10,   450/  454; acc:  80.80; ppl:   2.25; 6669 src tok/s; 6927 tgt tok/s;     57 s elapsed
Train perplexity: 2.23428
Train accuracy: 81.0072
Validation perplexity: 6.27677
Validation accuracy: 69.3628
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  82.88; ppl:   2.05; 6492 src tok/s; 6750 tgt tok/s;      7 s elapsed
Epoch 11,   100/  454; acc:  83.63; ppl:   1.96; 6535 src tok/s; 6781 tgt tok/s;     13 s elapsed
Epoch 11,   150/  454; acc:  83.17; ppl:   2.03; 6617 src tok/s; 6872 tgt tok/s;     19 s elapsed
Epoch 11,   200/  454; acc:  83.21; ppl:   2.03; 6617 src tok/s; 6854 tgt tok/s;     26 s elapsed
Epoch 11,   250/  454; acc:  82.64; ppl:   2.08; 6584 src tok/s; 6827 tgt tok/s;     32 s elapsed
Epoch 11,   300/  454; acc:  83.31; ppl:   1.99; 6662 src tok/s; 6924 tgt tok/s;     38 s elapsed
Epoch 11,   350/  454; acc:  83.00; ppl:   2.03; 6622 src tok/s; 6854 tgt tok/s;     45 s elapsed
Epoch 11,   400/  454; acc:  83.20; ppl:   1.98; 6516 src tok/s; 6797 tgt tok/s;     51 s elapsed
Epoch 11,   450/  454; acc:  82.87; ppl:   2.04; 6602 src tok/s; 6826 tgt tok/s;     57 s elapsed
Train perplexity: 2.01919
Train accuracy: 83.1124
Validation perplexity: 6.42464
Validation accuracy: 69.3558
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  83.97; ppl:   1.94; 6539 src tok/s; 6781 tgt tok/s;      6 s elapsed
Epoch 12,   100/  454; acc:  84.56; ppl:   1.88; 6606 src tok/s; 6905 tgt tok/s;     13 s elapsed
Epoch 12,   150/  454; acc:  83.54; ppl:   2.00; 6629 src tok/s; 6862 tgt tok/s;     19 s elapsed
Epoch 12,   200/  454; acc:  84.68; ppl:   1.85; 6629 src tok/s; 6898 tgt tok/s;     25 s elapsed
Epoch 12,   250/  454; acc:  84.54; ppl:   1.87; 6499 src tok/s; 6781 tgt tok/s;     32 s elapsed
Epoch 12,   300/  454; acc:  84.70; ppl:   1.90; 6678 src tok/s; 6889 tgt tok/s;     38 s elapsed
Epoch 12,   350/  454; acc:  84.26; ppl:   1.91; 6594 src tok/s; 6824 tgt tok/s;     45 s elapsed
Epoch 12,   400/  454; acc:  84.09; ppl:   1.94; 6557 src tok/s; 6798 tgt tok/s;     51 s elapsed
Epoch 12,   450/  454; acc:  84.01; ppl:   1.95; 6611 src tok/s; 6841 tgt tok/s;     57 s elapsed
Train perplexity: 1.91501
Train accuracy: 84.265
Validation perplexity: 6.54315
Validation accuracy: 69.2422
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  86.10; ppl:   1.76; 6351 src tok/s; 6619 tgt tok/s;      6 s elapsed
Epoch 13,   100/  454; acc:  84.19; ppl:   1.92; 6045 src tok/s; 6268 tgt tok/s;     14 s elapsed
Epoch 13,   150/  454; acc:  84.28; ppl:   1.91; 6186 src tok/s; 6384 tgt tok/s;     21 s elapsed
Epoch 13,   200/  454; acc:  85.73; ppl:   1.80; 6662 src tok/s; 6927 tgt tok/s;     27 s elapsed
Epoch 13,   250/  454; acc:  84.64; ppl:   1.89; 6650 src tok/s; 6873 tgt tok/s;     33 s elapsed
Epoch 13,   300/  454; acc:  84.18; ppl:   1.92; 6537 src tok/s; 6785 tgt tok/s;     39 s elapsed
Epoch 13,   350/  454; acc:  84.62; ppl:   1.91; 6524 src tok/s; 6796 tgt tok/s;     46 s elapsed
Epoch 13,   400/  454; acc:  84.53; ppl:   1.87; 6532 src tok/s; 6788 tgt tok/s;     52 s elapsed
Epoch 13,   450/  454; acc:  84.63; ppl:   1.88; 6487 src tok/s; 6720 tgt tok/s;     59 s elapsed
Train perplexity: 1.86945
Train accuracy: 84.7727
Validation perplexity: 6.62732
Validation accuracy: 69.2848
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  84.57; ppl:   1.89; 6300 src tok/s; 6556 tgt tok/s;      7 s elapsed
Epoch 14,   100/  454; acc:  85.80; ppl:   1.77; 6719 src tok/s; 6995 tgt tok/s;     13 s elapsed
Epoch 14,   150/  454; acc:  84.45; ppl:   1.91; 6623 src tok/s; 6858 tgt tok/s;     19 s elapsed
Epoch 14,   200/  454; acc:  85.89; ppl:   1.79; 6523 src tok/s; 6784 tgt tok/s;     26 s elapsed
Epoch 14,   250/  454; acc:  84.89; ppl:   1.87; 6409 src tok/s; 6638 tgt tok/s;     32 s elapsed
Epoch 14,   300/  454; acc:  85.51; ppl:   1.81; 6616 src tok/s; 6868 tgt tok/s;     39 s elapsed
Epoch 14,   350/  454; acc:  83.92; ppl:   1.97; 6788 src tok/s; 6974 tgt tok/s;     45 s elapsed
Epoch 14,   400/  454; acc:  86.12; ppl:   1.74; 6686 src tok/s; 6975 tgt tok/s;     51 s elapsed
Epoch 14,   450/  454; acc:  84.83; ppl:   1.85; 6512 src tok/s; 6762 tgt tok/s;     57 s elapsed
Train perplexity: 1.84531
Train accuracy: 85.086
Validation perplexity: 6.65591
Validation accuracy: 69.2635
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.88; ppl:   1.77; 6260 src tok/s; 6496 tgt tok/s;      7 s elapsed
Epoch 15,   100/  454; acc:  85.26; ppl:   1.85; 6659 src tok/s; 6885 tgt tok/s;     13 s elapsed
Epoch 15,   150/  454; acc:  85.08; ppl:   1.84; 6837 src tok/s; 7071 tgt tok/s;     19 s elapsed
Epoch 15,   200/  454; acc:  85.11; ppl:   1.84; 6559 src tok/s; 6846 tgt tok/s;     25 s elapsed
Epoch 15,   250/  454; acc:  86.66; ppl:   1.71; 6593 src tok/s; 6896 tgt tok/s;     32 s elapsed
Epoch 15,   300/  454; acc:  83.87; ppl:   1.96; 6553 src tok/s; 6754 tgt tok/s;     38 s elapsed
Epoch 15,   350/  454; acc:  85.59; ppl:   1.79; 6290 src tok/s; 6607 tgt tok/s;     45 s elapsed
Epoch 15,   400/  454; acc:  84.89; ppl:   1.89; 6804 src tok/s; 7014 tgt tok/s;     51 s elapsed
Epoch 15,   450/  454; acc:  84.88; ppl:   1.87; 6613 src tok/s; 6828 tgt tok/s;     57 s elapsed
Train perplexity: 1.83293
Train accuracy: 85.2544
Validation perplexity: 6.66739
Validation accuracy: 69.2564
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.50; ppl:   1.82; 6342 src tok/s; 6613 tgt tok/s;      6 s elapsed
Epoch 16,   100/  454; acc:  85.22; ppl:   1.85; 6635 src tok/s; 6844 tgt tok/s;     13 s elapsed
Epoch 16,   150/  454; acc:  85.44; ppl:   1.84; 6583 src tok/s; 6842 tgt tok/s;     19 s elapsed
Epoch 16,   200/  454; acc:  85.36; ppl:   1.84; 6604 src tok/s; 6838 tgt tok/s;     26 s elapsed
Epoch 16,   250/  454; acc:  85.34; ppl:   1.82; 6640 src tok/s; 6915 tgt tok/s;     32 s elapsed
Epoch 16,   300/  454; acc:  85.52; ppl:   1.80; 6690 src tok/s; 6961 tgt tok/s;     38 s elapsed
Epoch 16,   350/  454; acc:  85.71; ppl:   1.79; 6707 src tok/s; 6942 tgt tok/s;     45 s elapsed
Epoch 16,   400/  454; acc:  85.00; ppl:   1.86; 6616 src tok/s; 6865 tgt tok/s;     51 s elapsed
Epoch 16,   450/  454; acc:  85.04; ppl:   1.86; 6578 src tok/s; 6798 tgt tok/s;     57 s elapsed
Train perplexity: 1.82857
Train accuracy: 85.375
Validation perplexity: 6.67582
Validation accuracy: 69.2848
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  86.11; ppl:   1.75; 6392 src tok/s; 6644 tgt tok/s;      6 s elapsed
Epoch 17,   100/  454; acc:  85.39; ppl:   1.84; 6659 src tok/s; 6864 tgt tok/s;     13 s elapsed
Epoch 17,   150/  454; acc:  86.36; ppl:   1.75; 6429 src tok/s; 6744 tgt tok/s;     19 s elapsed
Epoch 17,   200/  454; acc:  84.66; ppl:   1.89; 6740 src tok/s; 6971 tgt tok/s;     25 s elapsed
Epoch 17,   250/  454; acc:  84.93; ppl:   1.86; 6662 src tok/s; 6902 tgt tok/s;     32 s elapsed
Epoch 17,   300/  454; acc:  85.52; ppl:   1.81; 6486 src tok/s; 6803 tgt tok/s;     38 s elapsed
Epoch 17,   350/  454; acc:  84.63; ppl:   1.89; 6572 src tok/s; 6806 tgt tok/s;     45 s elapsed
Epoch 17,   400/  454; acc:  85.94; ppl:   1.80; 6738 src tok/s; 6968 tgt tok/s;     51 s elapsed
Epoch 17,   450/  454; acc:  85.34; ppl:   1.83; 6597 src tok/s; 6818 tgt tok/s;     57 s elapsed
Train perplexity: 1.82438
Train accuracy: 85.4249
Validation perplexity: 6.68178
Validation accuracy: 69.2635
Decaying learning rate to 0.000976562
