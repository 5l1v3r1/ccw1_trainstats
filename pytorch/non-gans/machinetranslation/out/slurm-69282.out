<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.2, kappa_enc=0.1, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.1decoder0.20dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.1)
('Using Kappa L2 loss on decoder', 0.2)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.25; ppl: 35416.68; 2724 src tok/s; 2834 tgt tok/s;     15 s elapsed
Epoch  1,   100/  454; acc:  14.50; ppl: 1605.40; 3362 src tok/s; 3492 tgt tok/s;     28 s elapsed
Epoch  1,   150/  454; acc:  18.55; ppl: 474.74; 3366 src tok/s; 3472 tgt tok/s;     40 s elapsed
Epoch  1,   200/  454; acc:  20.82; ppl: 289.63; 3276 src tok/s; 3413 tgt tok/s;     53 s elapsed
Epoch  1,   250/  454; acc:  24.29; ppl: 186.37; 3130 src tok/s; 3244 tgt tok/s;     67 s elapsed
Epoch  1,   300/  454; acc:  27.85; ppl: 118.24; 3075 src tok/s; 3197 tgt tok/s;     80 s elapsed
Epoch  1,   350/  454; acc:  30.20; ppl:  93.01; 3118 src tok/s; 3260 tgt tok/s;     93 s elapsed
Epoch  1,   400/  454; acc:  31.26; ppl:  82.59; 3077 src tok/s; 3154 tgt tok/s;    107 s elapsed
Epoch  1,   450/  454; acc:  32.74; ppl:  68.94; 3043 src tok/s; 3171 tgt tok/s;    121 s elapsed
Train perplexity: 349.16
Train accuracy: 23.2457
Validation perplexity: 54.7983
Validation accuracy: 36.1218

Epoch  2,    50/  454; acc:  35.43; ppl:  54.16; 3123 src tok/s; 3246 tgt tok/s;     14 s elapsed
Epoch  2,   100/  454; acc:  38.34; ppl:  45.38; 3092 src tok/s; 3211 tgt tok/s;     27 s elapsed
Epoch  2,   150/  454; acc:  40.08; ppl:  40.42; 3118 src tok/s; 3216 tgt tok/s;     41 s elapsed
Epoch  2,   200/  454; acc:  44.57; ppl:  30.15; 3069 src tok/s; 3212 tgt tok/s;     54 s elapsed
Epoch  2,   250/  454; acc:  45.74; ppl:  27.55; 3146 src tok/s; 3252 tgt tok/s;     67 s elapsed
Epoch  2,   300/  454; acc:  47.42; ppl:  24.63; 3048 src tok/s; 3168 tgt tok/s;     81 s elapsed
Epoch  2,   350/  454; acc:  49.49; ppl:  22.06; 3052 src tok/s; 3175 tgt tok/s;     95 s elapsed
Epoch  2,   400/  454; acc:  51.26; ppl:  19.53; 3104 src tok/s; 3206 tgt tok/s;    109 s elapsed
Epoch  2,   450/  454; acc:  52.09; ppl:  18.45; 3029 src tok/s; 3154 tgt tok/s;    122 s elapsed
Train perplexity: 29.2896
Train accuracy: 44.9568
Validation perplexity: 15.905
Validation accuracy: 53.576

Epoch  3,    50/  454; acc:  53.93; ppl:  14.99; 3079 src tok/s; 3197 tgt tok/s;     14 s elapsed
Epoch  3,   100/  454; acc:  55.00; ppl:  14.24; 3038 src tok/s; 3159 tgt tok/s;     27 s elapsed
Epoch  3,   150/  454; acc:  56.29; ppl:  13.08; 3093 src tok/s; 3214 tgt tok/s;     41 s elapsed
Epoch  3,   200/  454; acc:  56.60; ppl:  12.86; 3096 src tok/s; 3197 tgt tok/s;     55 s elapsed
Epoch  3,   250/  454; acc:  56.87; ppl:  12.66; 3099 src tok/s; 3217 tgt tok/s;     68 s elapsed
Epoch  3,   300/  454; acc:  58.37; ppl:  11.00; 3156 src tok/s; 3288 tgt tok/s;     81 s elapsed
Epoch  3,   350/  454; acc:  57.50; ppl:  11.69; 3067 src tok/s; 3175 tgt tok/s;     95 s elapsed
Epoch  3,   400/  454; acc:  59.13; ppl:  10.74; 3145 src tok/s; 3262 tgt tok/s;    109 s elapsed
Epoch  3,   450/  454; acc:  59.21; ppl:  10.69; 3089 src tok/s; 3197 tgt tok/s;    122 s elapsed
Train perplexity: 12.3273
Train accuracy: 57.0374
Validation perplexity: 9.68956
Validation accuracy: 61.3098

Epoch  4,    50/  454; acc:  61.29; ppl:   8.63; 3177 src tok/s; 3272 tgt tok/s;     13 s elapsed
Epoch  4,   100/  454; acc:  62.24; ppl:   8.42; 3137 src tok/s; 3268 tgt tok/s;     27 s elapsed
Epoch  4,   150/  454; acc:  62.37; ppl:   8.15; 3101 src tok/s; 3234 tgt tok/s;     40 s elapsed
Epoch  4,   200/  454; acc:  61.33; ppl:   8.69; 3135 src tok/s; 3248 tgt tok/s;     54 s elapsed
Epoch  4,   250/  454; acc:  62.44; ppl:   8.19; 3113 src tok/s; 3225 tgt tok/s;     67 s elapsed
Epoch  4,   300/  454; acc:  61.80; ppl:   8.42; 3103 src tok/s; 3232 tgt tok/s;     80 s elapsed
Epoch  4,   350/  454; acc:  63.04; ppl:   7.70; 3063 src tok/s; 3166 tgt tok/s;     94 s elapsed
Epoch  4,   400/  454; acc:  63.34; ppl:   7.64; 3079 src tok/s; 3209 tgt tok/s;    108 s elapsed
Epoch  4,   450/  454; acc:  63.00; ppl:   7.67; 3121 src tok/s; 3225 tgt tok/s;    121 s elapsed
Train perplexity: 8.14132
Train accuracy: 62.3605
Validation perplexity: 7.98712
Validation accuracy: 64.1053

Epoch  5,    50/  454; acc:  66.97; ppl:   5.88; 3202 src tok/s; 3329 tgt tok/s;     13 s elapsed
Epoch  5,   100/  454; acc:  65.11; ppl:   6.35; 3166 src tok/s; 3271 tgt tok/s;     26 s elapsed
Epoch  5,   150/  454; acc:  65.27; ppl:   6.26; 3109 src tok/s; 3220 tgt tok/s;     40 s elapsed
Epoch  5,   200/  454; acc:  65.85; ppl:   6.09; 3081 src tok/s; 3213 tgt tok/s;     54 s elapsed
Epoch  5,   250/  454; acc:  66.02; ppl:   6.04; 3121 src tok/s; 3248 tgt tok/s;     67 s elapsed
Epoch  5,   300/  454; acc:  64.86; ppl:   6.48; 3130 src tok/s; 3233 tgt tok/s;     80 s elapsed
Epoch  5,   350/  454; acc:  65.81; ppl:   6.09; 3105 src tok/s; 3223 tgt tok/s;     94 s elapsed
Epoch  5,   400/  454; acc:  66.11; ppl:   6.05; 3090 src tok/s; 3221 tgt tok/s;    107 s elapsed
Epoch  5,   450/  454; acc:  65.96; ppl:   6.13; 3108 src tok/s; 3222 tgt tok/s;    121 s elapsed
Train perplexity: 6.15448
Train accuracy: 65.7593
Validation perplexity: 7.36947
Validation accuracy: 64.8716

Epoch  6,    50/  454; acc:  68.18; ppl:   4.95; 3192 src tok/s; 3288 tgt tok/s;     13 s elapsed
Epoch  6,   100/  454; acc:  68.88; ppl:   4.74; 3157 src tok/s; 3273 tgt tok/s;     27 s elapsed
Epoch  6,   150/  454; acc:  68.95; ppl:   4.82; 3113 src tok/s; 3227 tgt tok/s;     40 s elapsed
Epoch  6,   200/  454; acc:  67.48; ppl:   5.15; 3112 src tok/s; 3212 tgt tok/s;     54 s elapsed
Epoch  6,   250/  454; acc:  67.22; ppl:   5.28; 3114 src tok/s; 3219 tgt tok/s;     68 s elapsed
Epoch  6,   300/  454; acc:  68.77; ppl:   4.84; 3119 src tok/s; 3264 tgt tok/s;     80 s elapsed
Epoch  6,   350/  454; acc:  69.23; ppl:   4.69; 3126 src tok/s; 3274 tgt tok/s;     94 s elapsed
Epoch  6,   400/  454; acc:  67.74; ppl:   5.12; 3133 src tok/s; 3253 tgt tok/s;    107 s elapsed
Epoch  6,   450/  454; acc:  67.69; ppl:   5.19; 3065 src tok/s; 3182 tgt tok/s;    121 s elapsed
Train perplexity: 4.9724
Train accuracy: 68.2376
Validation perplexity: 6.92546
Validation accuracy: 66.0494

Epoch  7,    50/  454; acc:  70.79; ppl:   4.08; 3191 src tok/s; 3302 tgt tok/s;     14 s elapsed
Epoch  7,   100/  454; acc:  71.42; ppl:   3.95; 3018 src tok/s; 3163 tgt tok/s;     27 s elapsed
Epoch  7,   150/  454; acc:  70.91; ppl:   4.10; 3097 src tok/s; 3228 tgt tok/s;     40 s elapsed
Epoch  7,   200/  454; acc:  69.99; ppl:   4.26; 3066 src tok/s; 3178 tgt tok/s;     54 s elapsed
Epoch  7,   250/  454; acc:  71.35; ppl:   3.89; 3077 src tok/s; 3229 tgt tok/s;     67 s elapsed
Epoch  7,   300/  454; acc:  69.13; ppl:   4.54; 3115 src tok/s; 3216 tgt tok/s;     81 s elapsed
Epoch  7,   350/  454; acc:  70.09; ppl:   4.21; 3063 src tok/s; 3177 tgt tok/s;     95 s elapsed
Epoch  7,   400/  454; acc:  70.43; ppl:   4.27; 3226 src tok/s; 3317 tgt tok/s;    108 s elapsed
Epoch  7,   450/  454; acc:  69.51; ppl:   4.35; 3189 src tok/s; 3292 tgt tok/s;    121 s elapsed
Train perplexity: 4.17673
Train accuracy: 70.4148
Validation perplexity: 6.8078
Validation accuracy: 66.0068

Epoch  8,    50/  454; acc:  74.17; ppl:   3.21; 3209 src tok/s; 3353 tgt tok/s;     12 s elapsed
Epoch  8,   100/  454; acc:  71.94; ppl:   3.65; 3194 src tok/s; 3291 tgt tok/s;     26 s elapsed
Epoch  8,   150/  454; acc:  71.77; ppl:   3.70; 3119 src tok/s; 3218 tgt tok/s;     40 s elapsed
Epoch  8,   200/  454; acc:  73.41; ppl:   3.41; 3193 src tok/s; 3323 tgt tok/s;     53 s elapsed
Epoch  8,   250/  454; acc:  71.73; ppl:   3.72; 3159 src tok/s; 3287 tgt tok/s;     66 s elapsed
Epoch  8,   300/  454; acc:  72.39; ppl:   3.56; 3072 src tok/s; 3197 tgt tok/s;     80 s elapsed
Epoch  8,   350/  454; acc:  71.88; ppl:   3.69; 3124 src tok/s; 3255 tgt tok/s;     93 s elapsed
Epoch  8,   400/  454; acc:  71.35; ppl:   3.80; 3087 src tok/s; 3199 tgt tok/s;    107 s elapsed
Epoch  8,   450/  454; acc:  71.32; ppl:   3.83; 3129 src tok/s; 3231 tgt tok/s;    120 s elapsed
Train perplexity: 3.61208
Train accuracy: 72.2189
Validation perplexity: 6.77274
Validation accuracy: 66.7305
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.63; ppl:   2.80; 3147 src tok/s; 3263 tgt tok/s;     13 s elapsed
Epoch  9,   100/  454; acc:  77.96; ppl:   2.63; 3154 src tok/s; 3283 tgt tok/s;     26 s elapsed
Epoch  9,   150/  454; acc:  76.54; ppl:   2.85; 3116 src tok/s; 3218 tgt tok/s;     40 s elapsed
Epoch  9,   200/  454; acc:  77.73; ppl:   2.64; 3153 src tok/s; 3284 tgt tok/s;     53 s elapsed
Epoch  9,   250/  454; acc:  77.40; ppl:   2.68; 3116 src tok/s; 3243 tgt tok/s;     67 s elapsed
Epoch  9,   300/  454; acc:  77.12; ppl:   2.74; 3100 src tok/s; 3208 tgt tok/s;     80 s elapsed
Epoch  9,   350/  454; acc:  78.04; ppl:   2.59; 3117 src tok/s; 3252 tgt tok/s;     94 s elapsed
Epoch  9,   400/  454; acc:  76.71; ppl:   2.73; 3094 src tok/s; 3206 tgt tok/s;    107 s elapsed
Epoch  9,   450/  454; acc:  76.81; ppl:   2.76; 3138 src tok/s; 3244 tgt tok/s;    120 s elapsed
Train perplexity: 2.71392
Train accuracy: 77.2089
Validation perplexity: 6.13875
Validation accuracy: 68.8023
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.78; ppl:   2.27; 3149 src tok/s; 3281 tgt tok/s;     13 s elapsed
Epoch 10,   100/  454; acc:  81.91; ppl:   2.13; 3116 src tok/s; 3222 tgt tok/s;     27 s elapsed
Epoch 10,   150/  454; acc:  81.01; ppl:   2.24; 3122 src tok/s; 3248 tgt tok/s;     40 s elapsed
Epoch 10,   200/  454; acc:  80.59; ppl:   2.26; 3136 src tok/s; 3240 tgt tok/s;     53 s elapsed
Epoch 10,   250/  454; acc:  81.39; ppl:   2.18; 3128 src tok/s; 3240 tgt tok/s;     67 s elapsed
Epoch 10,   300/  454; acc:  80.50; ppl:   2.31; 3151 src tok/s; 3264 tgt tok/s;     80 s elapsed
Epoch 10,   350/  454; acc:  80.46; ppl:   2.29; 3114 src tok/s; 3234 tgt tok/s;     94 s elapsed
Epoch 10,   400/  454; acc:  81.32; ppl:   2.20; 3137 src tok/s; 3272 tgt tok/s;    107 s elapsed
Epoch 10,   450/  454; acc:  80.77; ppl:   2.23; 3152 src tok/s; 3272 tgt tok/s;    121 s elapsed
Train perplexity: 2.23428
Train accuracy: 80.9698
Validation perplexity: 6.14862
Validation accuracy: 69.5118
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  82.48; ppl:   2.09; 3174 src tok/s; 3277 tgt tok/s;     14 s elapsed
Epoch 11,   100/  454; acc:  84.22; ppl:   1.91; 3171 src tok/s; 3304 tgt tok/s;     26 s elapsed
Epoch 11,   150/  454; acc:  82.61; ppl:   2.09; 3113 src tok/s; 3228 tgt tok/s;     40 s elapsed
Epoch 11,   200/  454; acc:  83.73; ppl:   1.93; 3102 src tok/s; 3241 tgt tok/s;     53 s elapsed
Epoch 11,   250/  454; acc:  83.41; ppl:   1.98; 3128 src tok/s; 3247 tgt tok/s;     67 s elapsed
Epoch 11,   300/  454; acc:  82.96; ppl:   2.05; 3157 src tok/s; 3271 tgt tok/s;     80 s elapsed
Epoch 11,   350/  454; acc:  82.78; ppl:   2.04; 3173 src tok/s; 3285 tgt tok/s;     93 s elapsed
Epoch 11,   400/  454; acc:  83.22; ppl:   2.01; 3144 src tok/s; 3259 tgt tok/s;    107 s elapsed
Epoch 11,   450/  454; acc:  82.70; ppl:   2.06; 3115 src tok/s; 3235 tgt tok/s;    120 s elapsed
Train perplexity: 2.01492
Train accuracy: 83.1416
Validation perplexity: 6.27496
Validation accuracy: 69.6608
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  83.95; ppl:   1.95; 3173 src tok/s; 3300 tgt tok/s;     13 s elapsed
Epoch 12,   100/  454; acc:  84.76; ppl:   1.86; 3117 src tok/s; 3233 tgt tok/s;     27 s elapsed
Epoch 12,   150/  454; acc:  84.18; ppl:   1.91; 3184 src tok/s; 3298 tgt tok/s;     40 s elapsed
Epoch 12,   200/  454; acc:  84.14; ppl:   1.91; 3133 src tok/s; 3251 tgt tok/s;     53 s elapsed
Epoch 12,   250/  454; acc:  83.63; ppl:   1.99; 3122 src tok/s; 3250 tgt tok/s;     67 s elapsed
Epoch 12,   300/  454; acc:  84.82; ppl:   1.87; 3155 src tok/s; 3273 tgt tok/s;     80 s elapsed
Epoch 12,   350/  454; acc:  85.48; ppl:   1.82; 3143 src tok/s; 3274 tgt tok/s;     93 s elapsed
Epoch 12,   400/  454; acc:  82.99; ppl:   2.02; 3153 src tok/s; 3252 tgt tok/s;    107 s elapsed
Epoch 12,   450/  454; acc:  84.23; ppl:   1.92; 3076 src tok/s; 3206 tgt tok/s;    120 s elapsed
Train perplexity: 1.91886
Train accuracy: 84.1906
Validation perplexity: 6.41282
Validation accuracy: 69.5331
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.63; ppl:   1.90; 3190 src tok/s; 3320 tgt tok/s;     13 s elapsed
Epoch 13,   100/  454; acc:  85.14; ppl:   1.83; 3145 src tok/s; 3274 tgt tok/s;     27 s elapsed
Epoch 13,   150/  454; acc:  84.00; ppl:   1.95; 3128 src tok/s; 3233 tgt tok/s;     40 s elapsed
Epoch 13,   200/  454; acc:  85.55; ppl:   1.80; 3148 src tok/s; 3276 tgt tok/s;     53 s elapsed
Epoch 13,   250/  454; acc:  84.69; ppl:   1.88; 3100 src tok/s; 3210 tgt tok/s;     67 s elapsed
Epoch 13,   300/  454; acc:  85.04; ppl:   1.84; 3163 src tok/s; 3281 tgt tok/s;     80 s elapsed
Epoch 13,   350/  454; acc:  85.58; ppl:   1.82; 3201 src tok/s; 3320 tgt tok/s;     93 s elapsed
Epoch 13,   400/  454; acc:  84.17; ppl:   1.95; 3128 src tok/s; 3231 tgt tok/s;    107 s elapsed
Epoch 13,   450/  454; acc:  84.37; ppl:   1.90; 3049 src tok/s; 3172 tgt tok/s;    120 s elapsed
Train perplexity: 1.87146
Train accuracy: 84.8068
Validation perplexity: 6.46795
Validation accuracy: 69.6538
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.57; ppl:   1.81; 3127 src tok/s; 3245 tgt tok/s;     13 s elapsed
Epoch 14,   100/  454; acc:  85.02; ppl:   1.87; 3133 src tok/s; 3255 tgt tok/s;     27 s elapsed
Epoch 14,   150/  454; acc:  84.37; ppl:   1.92; 3158 src tok/s; 3246 tgt tok/s;     41 s elapsed
Epoch 14,   200/  454; acc:  86.16; ppl:   1.75; 3088 src tok/s; 3228 tgt tok/s;     54 s elapsed
Epoch 14,   250/  454; acc:  84.44; ppl:   1.88; 3125 src tok/s; 3239 tgt tok/s;     67 s elapsed
Epoch 14,   300/  454; acc:  84.96; ppl:   1.85; 3107 src tok/s; 3219 tgt tok/s;     81 s elapsed
Epoch 14,   350/  454; acc:  85.62; ppl:   1.79; 3099 src tok/s; 3246 tgt tok/s;     94 s elapsed
Epoch 14,   400/  454; acc:  84.67; ppl:   1.89; 3115 src tok/s; 3217 tgt tok/s;    108 s elapsed
Epoch 14,   450/  454; acc:  84.31; ppl:   1.89; 3091 src tok/s; 3208 tgt tok/s;    121 s elapsed
Train perplexity: 1.84807
Train accuracy: 85.025
Validation perplexity: 6.50555
Validation accuracy: 69.6254
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  84.43; ppl:   1.90; 3192 src tok/s; 3292 tgt tok/s;     14 s elapsed
Epoch 15,   100/  454; acc:  86.37; ppl:   1.76; 3144 src tok/s; 3284 tgt tok/s;     27 s elapsed
Epoch 15,   150/  454; acc:  84.48; ppl:   1.92; 3109 src tok/s; 3217 tgt tok/s;     41 s elapsed
Epoch 15,   200/  454; acc:  85.99; ppl:   1.76; 3094 src tok/s; 3221 tgt tok/s;     54 s elapsed
Epoch 15,   250/  454; acc:  84.59; ppl:   1.89; 3135 src tok/s; 3244 tgt tok/s;     67 s elapsed
Epoch 15,   300/  454; acc:  85.88; ppl:   1.78; 3114 src tok/s; 3235 tgt tok/s;     81 s elapsed
Epoch 15,   350/  454; acc:  85.53; ppl:   1.83; 3066 src tok/s; 3195 tgt tok/s;     94 s elapsed
Epoch 15,   400/  454; acc:  84.75; ppl:   1.85; 3173 src tok/s; 3295 tgt tok/s;    107 s elapsed
Epoch 15,   450/  454; acc:  85.61; ppl:   1.79; 3070 src tok/s; 3192 tgt tok/s;    120 s elapsed
Train perplexity: 1.83586
Train accuracy: 85.2337
Validation perplexity: 6.52222
Validation accuracy: 69.6112
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.02; ppl:   1.86; 3105 src tok/s; 3229 tgt tok/s;     14 s elapsed
Epoch 16,   100/  454; acc:  85.54; ppl:   1.80; 3105 src tok/s; 3235 tgt tok/s;     27 s elapsed
Epoch 16,   150/  454; acc:  86.01; ppl:   1.76; 3103 src tok/s; 3236 tgt tok/s;     40 s elapsed
Epoch 16,   200/  454; acc:  84.46; ppl:   1.89; 3166 src tok/s; 3270 tgt tok/s;     54 s elapsed
Epoch 16,   250/  454; acc:  84.46; ppl:   1.91; 3159 src tok/s; 3256 tgt tok/s;     68 s elapsed
Epoch 16,   300/  454; acc:  85.74; ppl:   1.78; 3158 src tok/s; 3290 tgt tok/s;     81 s elapsed
Epoch 16,   350/  454; acc:  85.48; ppl:   1.82; 3146 src tok/s; 3257 tgt tok/s;     94 s elapsed
Epoch 16,   400/  454; acc:  85.44; ppl:   1.81; 3129 src tok/s; 3259 tgt tok/s;    107 s elapsed
Epoch 16,   450/  454; acc:  84.98; ppl:   1.85; 3130 src tok/s; 3231 tgt tok/s;    120 s elapsed
Train perplexity: 1.82974
Train accuracy: 85.2526
Validation perplexity: 6.5311
Validation accuracy: 69.5899
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.16; ppl:   1.83; 3170 src tok/s; 3296 tgt tok/s;     13 s elapsed
Epoch 17,   100/  454; acc:  85.67; ppl:   1.81; 3064 src tok/s; 3179 tgt tok/s;     27 s elapsed
Epoch 17,   150/  454; acc:  84.92; ppl:   1.85; 3241 src tok/s; 3346 tgt tok/s;     40 s elapsed
Epoch 17,   200/  454; acc:  85.43; ppl:   1.81; 3122 src tok/s; 3251 tgt tok/s;     53 s elapsed
Epoch 17,   250/  454; acc:  85.44; ppl:   1.82; 3117 src tok/s; 3247 tgt tok/s;     67 s elapsed
Epoch 17,   300/  454; acc:  85.15; ppl:   1.83; 3102 src tok/s; 3211 tgt tok/s;     80 s elapsed
Epoch 17,   350/  454; acc:  84.65; ppl:   1.90; 3157 src tok/s; 3262 tgt tok/s;     94 s elapsed
Epoch 17,   400/  454; acc:  85.87; ppl:   1.77; 3071 src tok/s; 3210 tgt tok/s;    107 s elapsed
Epoch 17,   450/  454; acc:  85.02; ppl:   1.85; 3098 src tok/s; 3202 tgt tok/s;    121 s elapsed
Train perplexity: 1.8279
Train accuracy: 85.2766
Validation perplexity: 6.53407
Validation accuracy: 69.5899
Decaying learning rate to 0.000976562
