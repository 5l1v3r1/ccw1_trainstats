<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.5, kappa_enc=0.4, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/seeds/encoder0.4decoder0.5dropout0.3wdropTrueseed-1', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.4)
('Using Kappa L2 loss on decoder', 0.5)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.73; ppl: 28194.10; 4802 src tok/s; 4945 tgt tok/s;      9 s elapsed
Epoch  1,   100/  454; acc:  15.31; ppl: 1300.20; 5518 src tok/s; 5756 tgt tok/s;     16 s elapsed
Epoch  1,   150/  454; acc:  17.86; ppl: 518.41; 5718 src tok/s; 5915 tgt tok/s;     24 s elapsed
Epoch  1,   200/  454; acc:  22.09; ppl: 268.92; 5530 src tok/s; 5748 tgt tok/s;     31 s elapsed
Epoch  1,   250/  454; acc:  24.81; ppl: 173.85; 5702 src tok/s; 5872 tgt tok/s;     39 s elapsed
Epoch  1,   300/  454; acc:  27.99; ppl: 122.74; 5582 src tok/s; 5853 tgt tok/s;     46 s elapsed
Epoch  1,   350/  454; acc:  29.78; ppl:  96.26; 5548 src tok/s; 5742 tgt tok/s;     54 s elapsed
Epoch  1,   400/  454; acc:  31.05; ppl:  81.15; 5190 src tok/s; 5390 tgt tok/s;     62 s elapsed
Epoch  1,   450/  454; acc:  32.42; ppl:  71.02; 5408 src tok/s; 5626 tgt tok/s;     70 s elapsed
Train perplexity: 339.596
Train accuracy: 23.396
Validation perplexity: 83.8273
Validation accuracy: 34.057

Epoch  2,    50/  454; acc:  34.77; ppl:  58.27; 5428 src tok/s; 5612 tgt tok/s;      8 s elapsed
Epoch  2,   100/  454; acc:  39.62; ppl:  42.82; 5424 src tok/s; 5663 tgt tok/s;     15 s elapsed
Epoch  2,   150/  454; acc:  41.19; ppl:  36.93; 5439 src tok/s; 5655 tgt tok/s;     23 s elapsed
Epoch  2,   200/  454; acc:  43.15; ppl:  33.05; 5542 src tok/s; 5740 tgt tok/s;     31 s elapsed
Epoch  2,   250/  454; acc:  46.15; ppl:  26.06; 5421 src tok/s; 5654 tgt tok/s;     38 s elapsed
Epoch  2,   300/  454; acc:  46.26; ppl:  25.99; 5406 src tok/s; 5579 tgt tok/s;     46 s elapsed
Epoch  2,   350/  454; acc:  48.05; ppl:  23.41; 5483 src tok/s; 5665 tgt tok/s;     54 s elapsed
Epoch  2,   400/  454; acc:  50.87; ppl:  19.54; 5491 src tok/s; 5712 tgt tok/s;     62 s elapsed
Epoch  2,   450/  454; acc:  51.17; ppl:  18.68; 5505 src tok/s; 5702 tgt tok/s;     69 s elapsed
Train perplexity: 29.509
Train accuracy: 44.6454
Validation perplexity: 15.9293
Validation accuracy: 53.8456

Epoch  3,    50/  454; acc:  54.36; ppl:  14.59; 5415 src tok/s; 5608 tgt tok/s;      8 s elapsed
Epoch  3,   100/  454; acc:  54.51; ppl:  14.52; 5412 src tok/s; 5628 tgt tok/s;     15 s elapsed
Epoch  3,   150/  454; acc:  56.18; ppl:  13.08; 5432 src tok/s; 5624 tgt tok/s;     23 s elapsed
Epoch  3,   200/  454; acc:  55.60; ppl:  13.59; 5414 src tok/s; 5592 tgt tok/s;     31 s elapsed
Epoch  3,   250/  454; acc:  56.31; ppl:  12.61; 5470 src tok/s; 5649 tgt tok/s;     39 s elapsed
Epoch  3,   300/  454; acc:  58.29; ppl:  11.43; 5515 src tok/s; 5740 tgt tok/s;     46 s elapsed
Epoch  3,   350/  454; acc:  58.28; ppl:  11.32; 5453 src tok/s; 5700 tgt tok/s;     54 s elapsed
Epoch  3,   400/  454; acc:  57.80; ppl:  11.30; 5442 src tok/s; 5642 tgt tok/s;     62 s elapsed
Epoch  3,   450/  454; acc:  58.46; ppl:  11.08; 5346 src tok/s; 5559 tgt tok/s;     69 s elapsed
Train perplexity: 12.5106
Train accuracy: 56.6819
Validation perplexity: 10.4047
Validation accuracy: 59.9759

Epoch  4,    50/  454; acc:  62.11; ppl:   8.18; 5378 src tok/s; 5590 tgt tok/s;      8 s elapsed
Epoch  4,   100/  454; acc:  60.39; ppl:   9.05; 5442 src tok/s; 5636 tgt tok/s;     16 s elapsed
Epoch  4,   150/  454; acc:  62.06; ppl:   8.21; 5511 src tok/s; 5718 tgt tok/s;     23 s elapsed
Epoch  4,   200/  454; acc:  61.92; ppl:   8.30; 5446 src tok/s; 5647 tgt tok/s;     31 s elapsed
Epoch  4,   250/  454; acc:  62.57; ppl:   8.12; 5476 src tok/s; 5668 tgt tok/s;     39 s elapsed
Epoch  4,   300/  454; acc:  62.62; ppl:   7.94; 5452 src tok/s; 5672 tgt tok/s;     46 s elapsed
Epoch  4,   350/  454; acc:  62.32; ppl:   8.06; 5481 src tok/s; 5710 tgt tok/s;     54 s elapsed
Epoch  4,   400/  454; acc:  62.00; ppl:   8.41; 5527 src tok/s; 5730 tgt tok/s;     62 s elapsed
Epoch  4,   450/  454; acc:  63.37; ppl:   7.62; 5283 src tok/s; 5488 tgt tok/s;     69 s elapsed
Train perplexity: 8.19601
Train accuracy: 62.1591
Validation perplexity: 8.3329
Validation accuracy: 63.261

Epoch  5,    50/  454; acc:  65.32; ppl:   6.33; 5501 src tok/s; 5715 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  65.74; ppl:   6.11; 5706 src tok/s; 5920 tgt tok/s;     15 s elapsed
Epoch  5,   150/  454; acc:  65.06; ppl:   6.32; 5624 src tok/s; 5794 tgt tok/s;     23 s elapsed
Epoch  5,   200/  454; acc:  66.39; ppl:   5.98; 5052 src tok/s; 5277 tgt tok/s;     31 s elapsed
Epoch  5,   250/  454; acc:  65.95; ppl:   6.11; 5416 src tok/s; 5622 tgt tok/s;     39 s elapsed
Epoch  5,   300/  454; acc:  65.98; ppl:   6.20; 5365 src tok/s; 5592 tgt tok/s;     46 s elapsed
Epoch  5,   350/  454; acc:  65.27; ppl:   6.24; 5502 src tok/s; 5708 tgt tok/s;     54 s elapsed
Epoch  5,   400/  454; acc:  65.69; ppl:   6.28; 5425 src tok/s; 5626 tgt tok/s;     62 s elapsed
Epoch  5,   450/  454; acc:  65.52; ppl:   6.25; 5316 src tok/s; 5495 tgt tok/s;     70 s elapsed
Train perplexity: 6.19154
Train accuracy: 65.6813
Validation perplexity: 7.42786
Validation accuracy: 65.2263

Epoch  6,    50/  454; acc:  68.92; ppl:   4.78; 5440 src tok/s; 5613 tgt tok/s;      8 s elapsed
Epoch  6,   100/  454; acc:  69.07; ppl:   4.77; 5319 src tok/s; 5547 tgt tok/s;     16 s elapsed
Epoch  6,   150/  454; acc:  67.50; ppl:   5.22; 5424 src tok/s; 5579 tgt tok/s;     24 s elapsed
Epoch  6,   200/  454; acc:  68.58; ppl:   4.92; 5343 src tok/s; 5584 tgt tok/s;     31 s elapsed
Epoch  6,   250/  454; acc:  69.18; ppl:   4.76; 5367 src tok/s; 5557 tgt tok/s;     39 s elapsed
Epoch  6,   300/  454; acc:  68.11; ppl:   5.08; 5332 src tok/s; 5524 tgt tok/s;     47 s elapsed
Epoch  6,   350/  454; acc:  67.74; ppl:   5.16; 5337 src tok/s; 5540 tgt tok/s;     55 s elapsed
Epoch  6,   400/  454; acc:  67.93; ppl:   5.05; 5229 src tok/s; 5469 tgt tok/s;     63 s elapsed
Epoch  6,   450/  454; acc:  67.56; ppl:   5.09; 5284 src tok/s; 5486 tgt tok/s;     71 s elapsed
Train perplexity: 4.97883
Train accuracy: 68.2781
Validation perplexity: 6.827
Validation accuracy: 66.397

Epoch  7,    50/  454; acc:  71.61; ppl:   3.93; 5336 src tok/s; 5526 tgt tok/s;      8 s elapsed
Epoch  7,   100/  454; acc:  70.79; ppl:   4.06; 5356 src tok/s; 5548 tgt tok/s;     16 s elapsed
Epoch  7,   150/  454; acc:  70.56; ppl:   4.07; 5239 src tok/s; 5465 tgt tok/s;     24 s elapsed
Epoch  7,   200/  454; acc:  70.14; ppl:   4.23; 5287 src tok/s; 5472 tgt tok/s;     32 s elapsed
Epoch  7,   250/  454; acc:  69.94; ppl:   4.36; 5302 src tok/s; 5493 tgt tok/s;     40 s elapsed
Epoch  7,   300/  454; acc:  71.08; ppl:   3.95; 5429 src tok/s; 5619 tgt tok/s;     47 s elapsed
Epoch  7,   350/  454; acc:  70.76; ppl:   4.10; 5254 src tok/s; 5490 tgt tok/s;     55 s elapsed
Epoch  7,   400/  454; acc:  69.23; ppl:   4.46; 5341 src tok/s; 5527 tgt tok/s;     63 s elapsed
Epoch  7,   450/  454; acc:  69.59; ppl:   4.38; 5311 src tok/s; 5518 tgt tok/s;     71 s elapsed
Train perplexity: 4.16601
Train accuracy: 70.4216
Validation perplexity: 6.58225
Validation accuracy: 67.291

Epoch  8,    50/  454; acc:  74.25; ppl:   3.18; 5280 src tok/s; 5510 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  71.93; ppl:   3.63; 5357 src tok/s; 5547 tgt tok/s;     16 s elapsed
Epoch  8,   150/  454; acc:  73.09; ppl:   3.43; 5257 src tok/s; 5481 tgt tok/s;     24 s elapsed
Epoch  8,   200/  454; acc:  71.44; ppl:   3.81; 5427 src tok/s; 5611 tgt tok/s;     32 s elapsed
Epoch  8,   250/  454; acc:  71.25; ppl:   3.77; 5324 src tok/s; 5483 tgt tok/s;     40 s elapsed
Epoch  8,   300/  454; acc:  72.98; ppl:   3.43; 5392 src tok/s; 5623 tgt tok/s;     47 s elapsed
Epoch  8,   350/  454; acc:  71.72; ppl:   3.75; 5190 src tok/s; 5402 tgt tok/s;     55 s elapsed
Epoch  8,   400/  454; acc:  71.75; ppl:   3.72; 5338 src tok/s; 5524 tgt tok/s;     63 s elapsed
Epoch  8,   450/  454; acc:  72.18; ppl:   3.66; 5194 src tok/s; 5401 tgt tok/s;     71 s elapsed
Train perplexity: 3.60438
Train accuracy: 72.2326
Validation perplexity: 6.61448
Validation accuracy: 67.4755
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.70; ppl:   2.81; 5376 src tok/s; 5558 tgt tok/s;      8 s elapsed
Epoch  9,   100/  454; acc:  77.52; ppl:   2.65; 5317 src tok/s; 5542 tgt tok/s;     16 s elapsed
Epoch  9,   150/  454; acc:  77.85; ppl:   2.62; 5388 src tok/s; 5587 tgt tok/s;     23 s elapsed
Epoch  9,   200/  454; acc:  77.58; ppl:   2.65; 5275 src tok/s; 5487 tgt tok/s;     31 s elapsed
Epoch  9,   250/  454; acc:  77.87; ppl:   2.61; 5176 src tok/s; 5410 tgt tok/s;     39 s elapsed
Epoch  9,   300/  454; acc:  76.62; ppl:   2.79; 5356 src tok/s; 5543 tgt tok/s;     47 s elapsed
Epoch  9,   350/  454; acc:  76.93; ppl:   2.74; 5413 src tok/s; 5616 tgt tok/s;     55 s elapsed
Epoch  9,   400/  454; acc:  77.07; ppl:   2.70; 5327 src tok/s; 5516 tgt tok/s;     63 s elapsed
Epoch  9,   450/  454; acc:  77.19; ppl:   2.70; 5246 src tok/s; 5435 tgt tok/s;     71 s elapsed
Train perplexity: 2.69694
Train accuracy: 77.2413
Validation perplexity: 6.25733
Validation accuracy: 68.6108
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.41; ppl:   2.17; 5368 src tok/s; 5597 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  80.95; ppl:   2.23; 5434 src tok/s; 5630 tgt tok/s;     15 s elapsed
Epoch 10,   150/  454; acc:  80.20; ppl:   2.30; 5444 src tok/s; 5591 tgt tok/s;     24 s elapsed
Epoch 10,   200/  454; acc:  82.23; ppl:   2.08; 5451 src tok/s; 5687 tgt tok/s;     31 s elapsed
Epoch 10,   250/  454; acc:  80.88; ppl:   2.25; 5339 src tok/s; 5570 tgt tok/s;     39 s elapsed
Epoch 10,   300/  454; acc:  80.93; ppl:   2.21; 5346 src tok/s; 5548 tgt tok/s;     47 s elapsed
Epoch 10,   350/  454; acc:  80.44; ppl:   2.29; 5382 src tok/s; 5582 tgt tok/s;     54 s elapsed
Epoch 10,   400/  454; acc:  81.22; ppl:   2.20; 5429 src tok/s; 5625 tgt tok/s;     62 s elapsed
Epoch 10,   450/  454; acc:  81.19; ppl:   2.20; 5362 src tok/s; 5574 tgt tok/s;     70 s elapsed
Train perplexity: 2.21826
Train accuracy: 81.0222
Validation perplexity: 6.41141
Validation accuracy: 68.6108
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.31; ppl:   1.98; 5336 src tok/s; 5516 tgt tok/s;      8 s elapsed
Epoch 11,   100/  454; acc:  83.06; ppl:   2.02; 5402 src tok/s; 5625 tgt tok/s;     16 s elapsed
Epoch 11,   150/  454; acc:  82.12; ppl:   2.13; 5436 src tok/s; 5606 tgt tok/s;     24 s elapsed
Epoch 11,   200/  454; acc:  84.23; ppl:   1.90; 5428 src tok/s; 5660 tgt tok/s;     31 s elapsed
Epoch 11,   250/  454; acc:  83.13; ppl:   2.01; 5371 src tok/s; 5588 tgt tok/s;     39 s elapsed
Epoch 11,   300/  454; acc:  83.15; ppl:   2.02; 5375 src tok/s; 5607 tgt tok/s;     47 s elapsed
Epoch 11,   350/  454; acc:  83.17; ppl:   2.02; 5450 src tok/s; 5648 tgt tok/s;     54 s elapsed
Epoch 11,   400/  454; acc:  83.50; ppl:   1.98; 5509 src tok/s; 5724 tgt tok/s;     62 s elapsed
Epoch 11,   450/  454; acc:  83.22; ppl:   2.02; 5382 src tok/s; 5556 tgt tok/s;     70 s elapsed
Train perplexity: 2.00634
Train accuracy: 83.2326
Validation perplexity: 6.53134
Validation accuracy: 68.9513
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  85.22; ppl:   1.82; 5449 src tok/s; 5658 tgt tok/s;      8 s elapsed
Epoch 12,   100/  454; acc:  83.50; ppl:   1.98; 5515 src tok/s; 5690 tgt tok/s;     15 s elapsed
Epoch 12,   150/  454; acc:  83.41; ppl:   2.01; 5437 src tok/s; 5611 tgt tok/s;     24 s elapsed
Epoch 12,   200/  454; acc:  85.78; ppl:   1.78; 5337 src tok/s; 5564 tgt tok/s;     31 s elapsed
Epoch 12,   250/  454; acc:  84.56; ppl:   1.91; 5304 src tok/s; 5540 tgt tok/s;     39 s elapsed
Epoch 12,   300/  454; acc:  84.21; ppl:   1.91; 5394 src tok/s; 5591 tgt tok/s;     47 s elapsed
Epoch 12,   350/  454; acc:  84.81; ppl:   1.85; 5370 src tok/s; 5585 tgt tok/s;     54 s elapsed
Epoch 12,   400/  454; acc:  83.57; ppl:   1.96; 5403 src tok/s; 5604 tgt tok/s;     62 s elapsed
Epoch 12,   450/  454; acc:  84.05; ppl:   1.95; 5410 src tok/s; 5614 tgt tok/s;     70 s elapsed
Train perplexity: 1.90584
Train accuracy: 84.3417
Validation perplexity: 6.6322
Validation accuracy: 69.0507
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.86; ppl:   1.86; 5301 src tok/s; 5505 tgt tok/s;      8 s elapsed
Epoch 13,   100/  454; acc:  84.96; ppl:   1.87; 5483 src tok/s; 5666 tgt tok/s;     16 s elapsed
Epoch 13,   150/  454; acc:  86.11; ppl:   1.74; 5285 src tok/s; 5525 tgt tok/s;     23 s elapsed
Epoch 13,   200/  454; acc:  83.65; ppl:   1.97; 5576 src tok/s; 5748 tgt tok/s;     31 s elapsed
Epoch 13,   250/  454; acc:  85.09; ppl:   1.85; 5391 src tok/s; 5614 tgt tok/s;     39 s elapsed
Epoch 13,   300/  454; acc:  84.87; ppl:   1.86; 5452 src tok/s; 5654 tgt tok/s;     47 s elapsed
Epoch 13,   350/  454; acc:  84.93; ppl:   1.85; 5420 src tok/s; 5634 tgt tok/s;     54 s elapsed
Epoch 13,   400/  454; acc:  84.95; ppl:   1.85; 5487 src tok/s; 5689 tgt tok/s;     62 s elapsed
Epoch 13,   450/  454; acc:  85.22; ppl:   1.82; 5309 src tok/s; 5535 tgt tok/s;     69 s elapsed
Train perplexity: 1.85706
Train accuracy: 84.9067
Validation perplexity: 6.68818
Validation accuracy: 68.9655
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.76; ppl:   1.78; 5505 src tok/s; 5700 tgt tok/s;      8 s elapsed
Epoch 14,   100/  454; acc:  84.66; ppl:   1.87; 5390 src tok/s; 5621 tgt tok/s;     15 s elapsed
Epoch 14,   150/  454; acc:  85.25; ppl:   1.82; 5450 src tok/s; 5655 tgt tok/s;     23 s elapsed
Epoch 14,   200/  454; acc:  84.80; ppl:   1.87; 5553 src tok/s; 5738 tgt tok/s;     31 s elapsed
Epoch 14,   250/  454; acc:  84.85; ppl:   1.88; 5468 src tok/s; 5660 tgt tok/s;     39 s elapsed
Epoch 14,   300/  454; acc:  86.04; ppl:   1.76; 5448 src tok/s; 5686 tgt tok/s;     46 s elapsed
Epoch 14,   350/  454; acc:  84.53; ppl:   1.89; 5357 src tok/s; 5540 tgt tok/s;     54 s elapsed
Epoch 14,   400/  454; acc:  85.58; ppl:   1.80; 5326 src tok/s; 5538 tgt tok/s;     62 s elapsed
Epoch 14,   450/  454; acc:  85.12; ppl:   1.83; 5370 src tok/s; 5577 tgt tok/s;     69 s elapsed
Train perplexity: 1.83475
Train accuracy: 85.161
Validation perplexity: 6.72791
Validation accuracy: 68.8946
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.35; ppl:   1.83; 5327 src tok/s; 5564 tgt tok/s;      8 s elapsed
Epoch 15,   100/  454; acc:  85.47; ppl:   1.80; 5437 src tok/s; 5631 tgt tok/s;     16 s elapsed
Epoch 15,   150/  454; acc:  85.77; ppl:   1.81; 5544 src tok/s; 5721 tgt tok/s;     23 s elapsed
Epoch 15,   200/  454; acc:  85.10; ppl:   1.85; 5443 src tok/s; 5639 tgt tok/s;     31 s elapsed
Epoch 15,   250/  454; acc:  85.95; ppl:   1.76; 5391 src tok/s; 5608 tgt tok/s;     39 s elapsed
Epoch 15,   300/  454; acc:  84.84; ppl:   1.84; 5459 src tok/s; 5665 tgt tok/s;     46 s elapsed
Epoch 15,   350/  454; acc:  85.21; ppl:   1.84; 5417 src tok/s; 5605 tgt tok/s;     54 s elapsed
Epoch 15,   400/  454; acc:  85.46; ppl:   1.83; 5503 src tok/s; 5715 tgt tok/s;     62 s elapsed
Epoch 15,   450/  454; acc:  85.47; ppl:   1.81; 5266 src tok/s; 5485 tgt tok/s;     69 s elapsed
Train perplexity: 1.82245
Train accuracy: 85.3781
Validation perplexity: 6.75353
Validation accuracy: 68.9017
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  84.70; ppl:   1.87; 5348 src tok/s; 5531 tgt tok/s;      8 s elapsed
Epoch 16,   100/  454; acc:  86.02; ppl:   1.78; 5468 src tok/s; 5665 tgt tok/s;     16 s elapsed
Epoch 16,   150/  454; acc:  85.91; ppl:   1.79; 5386 src tok/s; 5608 tgt tok/s;     23 s elapsed
Epoch 16,   200/  454; acc:  84.99; ppl:   1.85; 5557 src tok/s; 5753 tgt tok/s;     31 s elapsed
Epoch 16,   250/  454; acc:  85.14; ppl:   1.82; 5371 src tok/s; 5576 tgt tok/s;     39 s elapsed
Epoch 16,   300/  454; acc:  85.58; ppl:   1.81; 5416 src tok/s; 5625 tgt tok/s;     47 s elapsed
Epoch 16,   350/  454; acc:  86.22; ppl:   1.74; 5368 src tok/s; 5614 tgt tok/s;     54 s elapsed
Epoch 16,   400/  454; acc:  84.48; ppl:   1.90; 5493 src tok/s; 5668 tgt tok/s;     62 s elapsed
Epoch 16,   450/  454; acc:  85.28; ppl:   1.82; 5400 src tok/s; 5606 tgt tok/s;     70 s elapsed
Train perplexity: 1.81895
Train accuracy: 85.3745
Validation perplexity: 6.7624
Validation accuracy: 68.9726
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.59; ppl:   1.79; 5521 src tok/s; 5712 tgt tok/s;      8 s elapsed
Epoch 17,   100/  454; acc:  85.79; ppl:   1.82; 5550 src tok/s; 5777 tgt tok/s;     15 s elapsed
Epoch 17,   150/  454; acc:  85.89; ppl:   1.77; 5450 src tok/s; 5670 tgt tok/s;     23 s elapsed
Epoch 17,   200/  454; acc:  85.03; ppl:   1.87; 5468 src tok/s; 5677 tgt tok/s;     31 s elapsed
Epoch 17,   250/  454; acc:  84.59; ppl:   1.87; 5186 src tok/s; 5378 tgt tok/s;     39 s elapsed
Epoch 17,   300/  454; acc:  86.17; ppl:   1.77; 5632 src tok/s; 5871 tgt tok/s;     46 s elapsed
Epoch 17,   350/  454; acc:  86.46; ppl:   1.72; 5528 src tok/s; 5759 tgt tok/s;     53 s elapsed
Epoch 17,   400/  454; acc:  84.51; ppl:   1.91; 5558 src tok/s; 5729 tgt tok/s;     61 s elapsed
Epoch 17,   450/  454; acc:  85.51; ppl:   1.81; 5113 src tok/s; 5280 tgt tok/s;     70 s elapsed
Train perplexity: 1.81176
Train accuracy: 85.504
Validation perplexity: 6.76676
Validation accuracy: 68.9513
Decaying learning rate to 0.000976562
