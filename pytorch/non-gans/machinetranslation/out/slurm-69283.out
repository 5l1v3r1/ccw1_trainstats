<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.25, kappa_enc=0.1, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.1decoder0.25dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.1)
('Using Kappa L2 loss on decoder', 0.25)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   7.38; ppl: 26039.26; 2533 src tok/s; 2604 tgt tok/s;     18 s elapsed
Epoch  1,   100/  454; acc:  13.04; ppl: 2191.71; 2994 src tok/s; 3129 tgt tok/s;     31 s elapsed
Epoch  1,   150/  454; acc:  17.30; ppl: 600.32; 2950 src tok/s; 3060 tgt tok/s;     45 s elapsed
Epoch  1,   200/  454; acc:  20.70; ppl: 279.94; 2930 src tok/s; 3059 tgt tok/s;     59 s elapsed
Epoch  1,   250/  454; acc:  22.27; ppl: 211.71; 3021 src tok/s; 3116 tgt tok/s;     73 s elapsed
Epoch  1,   300/  454; acc:  28.29; ppl: 122.03; 2961 src tok/s; 3066 tgt tok/s;     87 s elapsed
Epoch  1,   350/  454; acc:  29.21; ppl: 103.21; 2922 src tok/s; 3056 tgt tok/s;    101 s elapsed
Epoch  1,   400/  454; acc:  31.55; ppl:  81.45; 2952 src tok/s; 3058 tgt tok/s;    116 s elapsed
Epoch  1,   450/  454; acc:  32.61; ppl:  72.95; 2901 src tok/s; 3015 tgt tok/s;    130 s elapsed
Train perplexity: 377.411
Train accuracy: 22.5232
Validation perplexity: 68.2268
Validation accuracy: 33.8442

Epoch  2,    50/  454; acc:  34.53; ppl:  57.02; 2972 src tok/s; 3055 tgt tok/s;     15 s elapsed
Epoch  2,   100/  454; acc:  36.68; ppl:  50.78; 2951 src tok/s; 3084 tgt tok/s;     28 s elapsed
Epoch  2,   150/  454; acc:  38.34; ppl:  46.03; 2907 src tok/s; 3027 tgt tok/s;     43 s elapsed
Epoch  2,   200/  454; acc:  40.31; ppl:  40.28; 2989 src tok/s; 3094 tgt tok/s;     57 s elapsed
Epoch  2,   250/  454; acc:  42.01; ppl:  35.73; 2950 src tok/s; 3055 tgt tok/s;     71 s elapsed
Epoch  2,   300/  454; acc:  45.42; ppl:  27.97; 2961 src tok/s; 3089 tgt tok/s;     85 s elapsed
Epoch  2,   350/  454; acc:  46.97; ppl:  24.91; 2945 src tok/s; 3038 tgt tok/s;    100 s elapsed
Epoch  2,   400/  454; acc:  49.14; ppl:  21.41; 2926 src tok/s; 3065 tgt tok/s;    114 s elapsed
Epoch  2,   450/  454; acc:  50.99; ppl:  19.32; 2935 src tok/s; 3034 tgt tok/s;    128 s elapsed
Train perplexity: 33.5449
Train accuracy: 42.7457
Validation perplexity: 18.3003
Validation accuracy: 50.5392

Epoch  3,    50/  454; acc:  53.16; ppl:  16.06; 2997 src tok/s; 3101 tgt tok/s;     14 s elapsed
Epoch  3,   100/  454; acc:  53.76; ppl:  15.58; 2919 src tok/s; 3038 tgt tok/s;     28 s elapsed
Epoch  3,   150/  454; acc:  55.30; ppl:  13.87; 2943 src tok/s; 3058 tgt tok/s;     42 s elapsed
Epoch  3,   200/  454; acc:  54.72; ppl:  14.25; 3003 src tok/s; 3102 tgt tok/s;     57 s elapsed
Epoch  3,   250/  454; acc:  56.82; ppl:  12.88; 2891 src tok/s; 3022 tgt tok/s;     70 s elapsed
Epoch  3,   300/  454; acc:  56.47; ppl:  12.64; 2931 src tok/s; 3043 tgt tok/s;     85 s elapsed
Epoch  3,   350/  454; acc:  57.94; ppl:  11.55; 2922 src tok/s; 3026 tgt tok/s;    100 s elapsed
Epoch  3,   400/  454; acc:  57.70; ppl:  11.97; 2962 src tok/s; 3068 tgt tok/s;    114 s elapsed
Epoch  3,   450/  454; acc:  58.54; ppl:  10.94; 2921 src tok/s; 3038 tgt tok/s;    128 s elapsed
Train perplexity: 13.2003
Train accuracy: 56.0597
Validation perplexity: 10.7952
Validation accuracy: 59.4224

Epoch  4,    50/  454; acc:  61.70; ppl:   8.44; 2916 src tok/s; 3046 tgt tok/s;     14 s elapsed
Epoch  4,   100/  454; acc:  60.25; ppl:   9.31; 2997 src tok/s; 3102 tgt tok/s;     28 s elapsed
Epoch  4,   150/  454; acc:  60.59; ppl:   8.98; 2948 src tok/s; 3054 tgt tok/s;     43 s elapsed
Epoch  4,   200/  454; acc:  61.86; ppl:   8.58; 2979 src tok/s; 3090 tgt tok/s;     57 s elapsed
Epoch  4,   250/  454; acc:  61.22; ppl:   8.69; 2942 src tok/s; 3048 tgt tok/s;     71 s elapsed
Epoch  4,   300/  454; acc:  62.49; ppl:   8.09; 2955 src tok/s; 3080 tgt tok/s;     85 s elapsed
Epoch  4,   350/  454; acc:  63.21; ppl:   7.76; 2943 src tok/s; 3056 tgt tok/s;    100 s elapsed
Epoch  4,   400/  454; acc:  62.16; ppl:   8.26; 2940 src tok/s; 3047 tgt tok/s;    114 s elapsed
Epoch  4,   450/  454; acc:  62.17; ppl:   8.07; 2957 src tok/s; 3059 tgt tok/s;    128 s elapsed
Train perplexity: 8.45493
Train accuracy: 61.7359
Validation perplexity: 8.31133
Validation accuracy: 64.1195

Epoch  5,    50/  454; acc:  65.28; ppl:   6.33; 2950 src tok/s; 3073 tgt tok/s;     14 s elapsed
Epoch  5,   100/  454; acc:  65.45; ppl:   6.36; 2951 src tok/s; 3065 tgt tok/s;     29 s elapsed
Epoch  5,   150/  454; acc:  65.80; ppl:   6.15; 2937 src tok/s; 3072 tgt tok/s;     42 s elapsed
Epoch  5,   200/  454; acc:  64.12; ppl:   6.80; 2977 src tok/s; 3073 tgt tok/s;     57 s elapsed
Epoch  5,   250/  454; acc:  63.74; ppl:   6.95; 2953 src tok/s; 3044 tgt tok/s;     72 s elapsed
Epoch  5,   300/  454; acc:  66.79; ppl:   5.61; 2972 src tok/s; 3099 tgt tok/s;     85 s elapsed
Epoch  5,   350/  454; acc:  66.22; ppl:   6.13; 2980 src tok/s; 3087 tgt tok/s;     99 s elapsed
Epoch  5,   400/  454; acc:  65.12; ppl:   6.46; 2903 src tok/s; 3018 tgt tok/s;    114 s elapsed
Epoch  5,   450/  454; acc:  65.17; ppl:   6.40; 2951 src tok/s; 3055 tgt tok/s;    128 s elapsed
Train perplexity: 6.35212
Train accuracy: 65.2738
Validation perplexity: 7.65023
Validation accuracy: 64.2685

Epoch  6,    50/  454; acc:  68.49; ppl:   4.93; 2928 src tok/s; 3054 tgt tok/s;     14 s elapsed
Epoch  6,   100/  454; acc:  67.66; ppl:   5.15; 2912 src tok/s; 3014 tgt tok/s;     29 s elapsed
Epoch  6,   150/  454; acc:  67.67; ppl:   5.07; 2966 src tok/s; 3079 tgt tok/s;     43 s elapsed
Epoch  6,   200/  454; acc:  68.25; ppl:   4.94; 2978 src tok/s; 3080 tgt tok/s;     57 s elapsed
Epoch  6,   250/  454; acc:  68.27; ppl:   4.95; 2934 src tok/s; 3054 tgt tok/s;     71 s elapsed
Epoch  6,   300/  454; acc:  67.14; ppl:   5.43; 2982 src tok/s; 3081 tgt tok/s;     86 s elapsed
Epoch  6,   350/  454; acc:  68.25; ppl:   5.10; 2878 src tok/s; 2980 tgt tok/s;    100 s elapsed
Epoch  6,   400/  454; acc:  67.80; ppl:   5.14; 2954 src tok/s; 3076 tgt tok/s;    114 s elapsed
Epoch  6,   450/  454; acc:  68.08; ppl:   4.97; 2898 src tok/s; 3026 tgt tok/s;    128 s elapsed
Train perplexity: 5.09073
Train accuracy: 67.8901
Validation perplexity: 6.92619
Validation accuracy: 65.0915

Epoch  7,    50/  454; acc:  71.40; ppl:   3.93; 2903 src tok/s; 3048 tgt tok/s;     14 s elapsed
Epoch  7,   100/  454; acc:  69.79; ppl:   4.42; 3039 src tok/s; 3125 tgt tok/s;     28 s elapsed
Epoch  7,   150/  454; acc:  69.74; ppl:   4.37; 2898 src tok/s; 3001 tgt tok/s;     43 s elapsed
Epoch  7,   200/  454; acc:  70.83; ppl:   4.12; 2944 src tok/s; 3057 tgt tok/s;     57 s elapsed
Epoch  7,   250/  454; acc:  69.25; ppl:   4.45; 2986 src tok/s; 3059 tgt tok/s;     72 s elapsed
Epoch  7,   300/  454; acc:  70.87; ppl:   4.03; 2933 src tok/s; 3062 tgt tok/s;     85 s elapsed
Epoch  7,   350/  454; acc:  70.82; ppl:   4.14; 2923 src tok/s; 3064 tgt tok/s;     99 s elapsed
Epoch  7,   400/  454; acc:  69.16; ppl:   4.42; 2929 src tok/s; 3024 tgt tok/s;    114 s elapsed
Epoch  7,   450/  454; acc:  69.10; ppl:   4.51; 2924 src tok/s; 3047 tgt tok/s;    128 s elapsed
Train perplexity: 4.26676
Train accuracy: 70.0934
Validation perplexity: 6.65375
Validation accuracy: 67.1208

Epoch  8,    50/  454; acc:  73.10; ppl:   3.48; 2939 src tok/s; 3056 tgt tok/s;     14 s elapsed
Epoch  8,   100/  454; acc:  72.42; ppl:   3.53; 2920 src tok/s; 3039 tgt tok/s;     29 s elapsed
Epoch  8,   150/  454; acc:  72.16; ppl:   3.63; 2908 src tok/s; 3026 tgt tok/s;     43 s elapsed
Epoch  8,   200/  454; acc:  72.00; ppl:   3.64; 2938 src tok/s; 3039 tgt tok/s;     57 s elapsed
Epoch  8,   250/  454; acc:  72.33; ppl:   3.59; 2916 src tok/s; 3042 tgt tok/s;     71 s elapsed
Epoch  8,   300/  454; acc:  71.03; ppl:   3.87; 3000 src tok/s; 3103 tgt tok/s;     86 s elapsed
Epoch  8,   350/  454; acc:  70.96; ppl:   3.90; 2957 src tok/s; 3049 tgt tok/s;    101 s elapsed
Epoch  8,   400/  454; acc:  72.62; ppl:   3.59; 2953 src tok/s; 3076 tgt tok/s;    114 s elapsed
Epoch  8,   450/  454; acc:  71.26; ppl:   3.83; 2954 src tok/s; 3056 tgt tok/s;    128 s elapsed
Train perplexity: 3.6685
Train accuracy: 71.9944
Validation perplexity: 6.64268
Validation accuracy: 67.3478
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.81; ppl:   2.79; 2901 src tok/s; 3040 tgt tok/s;     14 s elapsed
Epoch  9,   100/  454; acc:  77.09; ppl:   2.77; 2992 src tok/s; 3094 tgt tok/s;     29 s elapsed
Epoch  9,   150/  454; acc:  77.63; ppl:   2.64; 2976 src tok/s; 3088 tgt tok/s;     43 s elapsed
Epoch  9,   200/  454; acc:  76.73; ppl:   2.81; 2997 src tok/s; 3097 tgt tok/s;     57 s elapsed
Epoch  9,   250/  454; acc:  76.89; ppl:   2.75; 2940 src tok/s; 3043 tgt tok/s;     71 s elapsed
Epoch  9,   300/  454; acc:  76.97; ppl:   2.75; 2889 src tok/s; 3008 tgt tok/s;     85 s elapsed
Epoch  9,   350/  454; acc:  76.49; ppl:   2.82; 2939 src tok/s; 3037 tgt tok/s;    100 s elapsed
Epoch  9,   400/  454; acc:  77.64; ppl:   2.62; 2931 src tok/s; 3050 tgt tok/s;    114 s elapsed
Epoch  9,   450/  454; acc:  76.83; ppl:   2.75; 2914 src tok/s; 3022 tgt tok/s;    128 s elapsed
Train perplexity: 2.74628
Train accuracy: 76.9904
Validation perplexity: 6.08526
Validation accuracy: 68.781
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.68; ppl:   2.27; 2944 src tok/s; 3059 tgt tok/s;     15 s elapsed
Epoch 10,   100/  454; acc:  81.28; ppl:   2.22; 2910 src tok/s; 3048 tgt tok/s;     29 s elapsed
Epoch 10,   150/  454; acc:  80.89; ppl:   2.26; 2945 src tok/s; 3057 tgt tok/s;     43 s elapsed
Epoch 10,   200/  454; acc:  80.68; ppl:   2.28; 2971 src tok/s; 3058 tgt tok/s;     57 s elapsed
Epoch 10,   250/  454; acc:  80.82; ppl:   2.25; 2908 src tok/s; 3027 tgt tok/s;     71 s elapsed
Epoch 10,   300/  454; acc:  81.18; ppl:   2.19; 2995 src tok/s; 3099 tgt tok/s;     85 s elapsed
Epoch 10,   350/  454; acc:  80.11; ppl:   2.32; 2958 src tok/s; 3063 tgt tok/s;    100 s elapsed
Epoch 10,   400/  454; acc:  80.94; ppl:   2.23; 2964 src tok/s; 3085 tgt tok/s;    114 s elapsed
Epoch 10,   450/  454; acc:  80.36; ppl:   2.28; 2893 src tok/s; 2999 tgt tok/s;    128 s elapsed
Train perplexity: 2.25589
Train accuracy: 80.7685
Validation perplexity: 6.17039
Validation accuracy: 69.2777
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  82.29; ppl:   2.10; 2932 src tok/s; 3016 tgt tok/s;     15 s elapsed
Epoch 11,   100/  454; acc:  83.97; ppl:   1.95; 2923 src tok/s; 3042 tgt tok/s;     29 s elapsed
Epoch 11,   150/  454; acc:  81.26; ppl:   2.18; 2972 src tok/s; 3061 tgt tok/s;     44 s elapsed
Epoch 11,   200/  454; acc:  84.74; ppl:   1.85; 2948 src tok/s; 3094 tgt tok/s;     57 s elapsed
Epoch 11,   250/  454; acc:  82.77; ppl:   2.03; 2988 src tok/s; 3096 tgt tok/s;     71 s elapsed
Epoch 11,   300/  454; acc:  83.15; ppl:   2.00; 2894 src tok/s; 3020 tgt tok/s;     85 s elapsed
Epoch 11,   350/  454; acc:  82.76; ppl:   2.05; 2950 src tok/s; 3054 tgt tok/s;    100 s elapsed
Epoch 11,   400/  454; acc:  82.56; ppl:   2.08; 2978 src tok/s; 3090 tgt tok/s;    114 s elapsed
Epoch 11,   450/  454; acc:  82.79; ppl:   2.05; 2860 src tok/s; 2976 tgt tok/s;    128 s elapsed
Train perplexity: 2.03736
Train accuracy: 82.8547
Validation perplexity: 6.35252
Validation accuracy: 69.6608
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.16; ppl:   1.94; 2926 src tok/s; 3035 tgt tok/s;     14 s elapsed
Epoch 12,   100/  454; acc:  84.50; ppl:   1.89; 2924 src tok/s; 3036 tgt tok/s;     29 s elapsed
Epoch 12,   150/  454; acc:  84.20; ppl:   1.93; 2930 src tok/s; 3042 tgt tok/s;     43 s elapsed
Epoch 12,   200/  454; acc:  83.82; ppl:   1.96; 2942 src tok/s; 3051 tgt tok/s;     57 s elapsed
Epoch 12,   250/  454; acc:  83.93; ppl:   1.95; 2890 src tok/s; 2993 tgt tok/s;     72 s elapsed
Epoch 12,   300/  454; acc:  84.17; ppl:   1.92; 2977 src tok/s; 3096 tgt tok/s;     86 s elapsed
Epoch 12,   350/  454; acc:  85.58; ppl:   1.78; 2943 src tok/s; 3088 tgt tok/s;     99 s elapsed
Epoch 12,   400/  454; acc:  82.50; ppl:   2.08; 2953 src tok/s; 3045 tgt tok/s;    114 s elapsed
Epoch 12,   450/  454; acc:  84.28; ppl:   1.89; 2982 src tok/s; 3104 tgt tok/s;    128 s elapsed
Train perplexity: 1.93415
Train accuracy: 84.0321
Validation perplexity: 6.45626
Validation accuracy: 69.4054
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.67; ppl:   1.86; 2911 src tok/s; 3028 tgt tok/s;     14 s elapsed
Epoch 13,   100/  454; acc:  84.86; ppl:   1.89; 2967 src tok/s; 3070 tgt tok/s;     28 s elapsed
Epoch 13,   150/  454; acc:  84.20; ppl:   1.92; 2984 src tok/s; 3091 tgt tok/s;     43 s elapsed
Epoch 13,   200/  454; acc:  85.10; ppl:   1.85; 2944 src tok/s; 3074 tgt tok/s;     57 s elapsed
Epoch 13,   250/  454; acc:  84.42; ppl:   1.90; 2975 src tok/s; 3072 tgt tok/s;     71 s elapsed
Epoch 13,   300/  454; acc:  84.82; ppl:   1.87; 2916 src tok/s; 3034 tgt tok/s;     85 s elapsed
Epoch 13,   350/  454; acc:  83.99; ppl:   1.95; 2961 src tok/s; 3057 tgt tok/s;    100 s elapsed
Epoch 13,   400/  454; acc:  85.15; ppl:   1.83; 2930 src tok/s; 3057 tgt tok/s;    114 s elapsed
Epoch 13,   450/  454; acc:  84.13; ppl:   1.90; 2909 src tok/s; 3014 tgt tok/s;    128 s elapsed
Train perplexity: 1.88471
Train accuracy: 84.5884
Validation perplexity: 6.5264
Validation accuracy: 69.6041
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  84.99; ppl:   1.83; 2968 src tok/s; 3091 tgt tok/s;     14 s elapsed
Epoch 14,   100/  454; acc:  84.59; ppl:   1.88; 2938 src tok/s; 3044 tgt tok/s;     28 s elapsed
Epoch 14,   150/  454; acc:  84.89; ppl:   1.86; 2940 src tok/s; 3058 tgt tok/s;     42 s elapsed
Epoch 14,   200/  454; acc:  84.31; ppl:   1.91; 2975 src tok/s; 3076 tgt tok/s;     57 s elapsed
Epoch 14,   250/  454; acc:  84.49; ppl:   1.91; 2924 src tok/s; 3012 tgt tok/s;     72 s elapsed
Epoch 14,   300/  454; acc:  85.04; ppl:   1.84; 2957 src tok/s; 3075 tgt tok/s;     86 s elapsed
Epoch 14,   350/  454; acc:  85.35; ppl:   1.81; 2915 src tok/s; 3041 tgt tok/s;    100 s elapsed
Epoch 14,   400/  454; acc:  85.02; ppl:   1.86; 2995 src tok/s; 3109 tgt tok/s;    114 s elapsed
Epoch 14,   450/  454; acc:  85.16; ppl:   1.85; 2913 src tok/s; 3025 tgt tok/s;    128 s elapsed
Train perplexity: 1.8609
Train accuracy: 84.8666
Validation perplexity: 6.56451
Validation accuracy: 69.5828
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.09; ppl:   1.83; 2936 src tok/s; 3070 tgt tok/s;     14 s elapsed
Epoch 15,   100/  454; acc:  84.67; ppl:   1.89; 2971 src tok/s; 3050 tgt tok/s;     28 s elapsed
Epoch 15,   150/  454; acc:  85.55; ppl:   1.79; 2962 src tok/s; 3078 tgt tok/s;     42 s elapsed
Epoch 15,   200/  454; acc:  84.74; ppl:   1.90; 2979 src tok/s; 3083 tgt tok/s;     57 s elapsed
Epoch 15,   250/  454; acc:  85.73; ppl:   1.82; 2960 src tok/s; 3078 tgt tok/s;     70 s elapsed
Epoch 15,   300/  454; acc:  84.68; ppl:   1.89; 2933 src tok/s; 3041 tgt tok/s;     85 s elapsed
Epoch 15,   350/  454; acc:  84.67; ppl:   1.89; 2856 src tok/s; 2959 tgt tok/s;    100 s elapsed
Epoch 15,   400/  454; acc:  85.24; ppl:   1.83; 2954 src tok/s; 3079 tgt tok/s;    114 s elapsed
Epoch 15,   450/  454; acc:  84.96; ppl:   1.85; 2939 src tok/s; 3047 tgt tok/s;    128 s elapsed
Train perplexity: 1.85218
Train accuracy: 85.0414
Validation perplexity: 6.57485
Validation accuracy: 69.5544
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.17; ppl:   1.84; 3012 src tok/s; 3100 tgt tok/s;     14 s elapsed
Epoch 16,   100/  454; acc:  85.44; ppl:   1.83; 2911 src tok/s; 3038 tgt tok/s;     28 s elapsed
Epoch 16,   150/  454; acc:  84.96; ppl:   1.86; 2998 src tok/s; 3103 tgt tok/s;     42 s elapsed
Epoch 16,   200/  454; acc:  85.43; ppl:   1.80; 2895 src tok/s; 3015 tgt tok/s;     57 s elapsed
Epoch 16,   250/  454; acc:  84.56; ppl:   1.90; 2969 src tok/s; 3072 tgt tok/s;     71 s elapsed
Epoch 16,   300/  454; acc:  85.19; ppl:   1.82; 2981 src tok/s; 3089 tgt tok/s;     85 s elapsed
Epoch 16,   350/  454; acc:  85.57; ppl:   1.80; 2908 src tok/s; 3048 tgt tok/s;     99 s elapsed
Epoch 16,   400/  454; acc:  84.55; ppl:   1.88; 2959 src tok/s; 3067 tgt tok/s;    114 s elapsed
Epoch 16,   450/  454; acc:  84.72; ppl:   1.87; 2869 src tok/s; 2975 tgt tok/s;    128 s elapsed
Train perplexity: 1.84409
Train accuracy: 85.0784
Validation perplexity: 6.58414
Validation accuracy: 69.5828
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.21; ppl:   1.83; 2936 src tok/s; 3044 tgt tok/s;     14 s elapsed
Epoch 17,   100/  454; acc:  84.98; ppl:   1.85; 2959 src tok/s; 3074 tgt tok/s;     29 s elapsed
Epoch 17,   150/  454; acc:  86.26; ppl:   1.74; 2989 src tok/s; 3102 tgt tok/s;     42 s elapsed
Epoch 17,   200/  454; acc:  84.25; ppl:   1.93; 2936 src tok/s; 3034 tgt tok/s;     57 s elapsed
Epoch 17,   250/  454; acc:  85.11; ppl:   1.86; 2934 src tok/s; 3034 tgt tok/s;     72 s elapsed
Epoch 17,   300/  454; acc:  85.15; ppl:   1.81; 2972 src tok/s; 3106 tgt tok/s;     85 s elapsed
Epoch 17,   350/  454; acc:  85.35; ppl:   1.81; 2904 src tok/s; 3035 tgt tok/s;     99 s elapsed
Epoch 17,   400/  454; acc:  84.87; ppl:   1.86; 2959 src tok/s; 3067 tgt tok/s;    114 s elapsed
Epoch 17,   450/  454; acc:  85.08; ppl:   1.85; 2953 src tok/s; 3053 tgt tok/s;    128 s elapsed
Train perplexity: 1.83943
Train accuracy: 85.1398
Validation perplexity: 6.58816
Validation accuracy: 69.5544
Decaying learning rate to 0.000976562
