<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.25, kappa_enc=0.15, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.15decoder0.25dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.15)
('Using Kappa L2 loss on decoder', 0.25)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   9.00; ppl: 12943.56; 3593 src tok/s; 3721 tgt tok/s;     12 s elapsed
Epoch  1,   100/  454; acc:  16.19; ppl: 892.42; 5610 src tok/s; 5821 tgt tok/s;     19 s elapsed
Epoch  1,   150/  454; acc:  18.88; ppl: 482.36; 5431 src tok/s; 5662 tgt tok/s;     26 s elapsed
Epoch  1,   200/  454; acc:  20.88; ppl: 269.14; 5520 src tok/s; 5686 tgt tok/s;     35 s elapsed
Epoch  1,   250/  454; acc:  25.17; ppl: 151.85; 5587 src tok/s; 5791 tgt tok/s;     42 s elapsed
Epoch  1,   300/  454; acc:  28.02; ppl: 118.20; 5416 src tok/s; 5634 tgt tok/s;     50 s elapsed
Epoch  1,   350/  454; acc:  31.24; ppl:  85.05; 5046 src tok/s; 5301 tgt tok/s;     58 s elapsed
Epoch  1,   400/  454; acc:  30.68; ppl:  84.31; 5203 src tok/s; 5369 tgt tok/s;     66 s elapsed
Epoch  1,   450/  454; acc:  32.70; ppl:  69.36; 5077 src tok/s; 5265 tgt tok/s;     74 s elapsed
Train perplexity: 284.222
Train accuracy: 23.7163
Validation perplexity: 58.534
Validation accuracy: 34.5679

Epoch  2,    50/  454; acc:  34.71; ppl:  58.76; 5227 src tok/s; 5393 tgt tok/s;      8 s elapsed
Epoch  2,   100/  454; acc:  38.97; ppl:  44.28; 5180 src tok/s; 5397 tgt tok/s;     16 s elapsed
Epoch  2,   150/  454; acc:  41.17; ppl:  36.74; 5241 src tok/s; 5448 tgt tok/s;     24 s elapsed
Epoch  2,   200/  454; acc:  41.87; ppl:  34.14; 5260 src tok/s; 5439 tgt tok/s;     32 s elapsed
Epoch  2,   250/  454; acc:  44.92; ppl:  29.05; 5114 src tok/s; 5363 tgt tok/s;     40 s elapsed
Epoch  2,   300/  454; acc:  45.65; ppl:  27.04; 5345 src tok/s; 5511 tgt tok/s;     48 s elapsed
Epoch  2,   350/  454; acc:  49.27; ppl:  21.55; 5182 src tok/s; 5430 tgt tok/s;     56 s elapsed
Epoch  2,   400/  454; acc:  49.00; ppl:  22.18; 5281 src tok/s; 5436 tgt tok/s;     64 s elapsed
Epoch  2,   450/  454; acc:  50.48; ppl:  19.51; 5180 src tok/s; 5368 tgt tok/s;     72 s elapsed
Train perplexity: 30.4634
Train accuracy: 44.096
Validation perplexity: 15.2609
Validation accuracy: 54.9383

Epoch  3,    50/  454; acc:  52.79; ppl:  16.20; 5282 src tok/s; 5463 tgt tok/s;      8 s elapsed
Epoch  3,   100/  454; acc:  55.63; ppl:  13.79; 5328 src tok/s; 5540 tgt tok/s;     16 s elapsed
Epoch  3,   150/  454; acc:  55.03; ppl:  13.91; 5198 src tok/s; 5412 tgt tok/s;     24 s elapsed
Epoch  3,   200/  454; acc:  55.57; ppl:  13.27; 5205 src tok/s; 5413 tgt tok/s;     32 s elapsed
Epoch  3,   250/  454; acc:  57.33; ppl:  11.93; 5240 src tok/s; 5457 tgt tok/s;     40 s elapsed
Epoch  3,   300/  454; acc:  56.42; ppl:  12.71; 5209 src tok/s; 5398 tgt tok/s;     48 s elapsed
Epoch  3,   350/  454; acc:  57.25; ppl:  11.83; 5319 src tok/s; 5472 tgt tok/s;     56 s elapsed
Epoch  3,   400/  454; acc:  58.79; ppl:  10.89; 5163 src tok/s; 5362 tgt tok/s;     64 s elapsed
Epoch  3,   450/  454; acc:  59.18; ppl:  10.69; 5087 src tok/s; 5305 tgt tok/s;     72 s elapsed
Train perplexity: 12.7235
Train accuracy: 56.4046
Validation perplexity: 10.5377
Validation accuracy: 59.9546

Epoch  4,    50/  454; acc:  62.03; ppl:   8.42; 5128 src tok/s; 5366 tgt tok/s;      8 s elapsed
Epoch  4,   100/  454; acc:  60.95; ppl:   8.93; 5146 src tok/s; 5318 tgt tok/s;     16 s elapsed
Epoch  4,   150/  454; acc:  61.83; ppl:   8.25; 5302 src tok/s; 5499 tgt tok/s;     24 s elapsed
Epoch  4,   200/  454; acc:  61.09; ppl:   8.81; 5276 src tok/s; 5474 tgt tok/s;     32 s elapsed
Epoch  4,   250/  454; acc:  61.98; ppl:   8.39; 5301 src tok/s; 5466 tgt tok/s;     40 s elapsed
Epoch  4,   300/  454; acc:  62.37; ppl:   7.98; 5280 src tok/s; 5503 tgt tok/s;     48 s elapsed
Epoch  4,   350/  454; acc:  62.12; ppl:   8.28; 5305 src tok/s; 5507 tgt tok/s;     56 s elapsed
Epoch  4,   400/  454; acc:  62.95; ppl:   7.72; 5376 src tok/s; 5569 tgt tok/s;     64 s elapsed
Epoch  4,   450/  454; acc:  62.76; ppl:   7.90; 5115 src tok/s; 5315 tgt tok/s;     72 s elapsed
Train perplexity: 8.28421
Train accuracy: 62.0158
Validation perplexity: 8.2575
Validation accuracy: 63.1829

Epoch  5,    50/  454; acc:  65.57; ppl:   6.22; 5336 src tok/s; 5539 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  65.96; ppl:   6.08; 5301 src tok/s; 5500 tgt tok/s;     16 s elapsed
Epoch  5,   150/  454; acc:  65.20; ppl:   6.39; 5289 src tok/s; 5477 tgt tok/s;     24 s elapsed
Epoch  5,   200/  454; acc:  65.91; ppl:   6.16; 5246 src tok/s; 5469 tgt tok/s;     32 s elapsed
Epoch  5,   250/  454; acc:  66.24; ppl:   5.98; 5261 src tok/s; 5500 tgt tok/s;     39 s elapsed
Epoch  5,   300/  454; acc:  64.39; ppl:   6.59; 5409 src tok/s; 5578 tgt tok/s;     47 s elapsed
Epoch  5,   350/  454; acc:  65.74; ppl:   6.09; 5290 src tok/s; 5494 tgt tok/s;     55 s elapsed
Epoch  5,   400/  454; acc:  65.31; ppl:   6.22; 5293 src tok/s; 5469 tgt tok/s;     63 s elapsed
Epoch  5,   450/  454; acc:  65.39; ppl:   6.18; 5215 src tok/s; 5407 tgt tok/s;     71 s elapsed
Train perplexity: 6.20976
Train accuracy: 65.5254
Validation perplexity: 7.1551
Validation accuracy: 65.6237

Epoch  6,    50/  454; acc:  69.97; ppl:   4.51; 5358 src tok/s; 5582 tgt tok/s;      7 s elapsed
Epoch  6,   100/  454; acc:  67.02; ppl:   5.29; 5385 src tok/s; 5519 tgt tok/s;     16 s elapsed
Epoch  6,   150/  454; acc:  68.78; ppl:   4.79; 5312 src tok/s; 5511 tgt tok/s;     23 s elapsed
Epoch  6,   200/  454; acc:  68.15; ppl:   5.07; 5101 src tok/s; 5323 tgt tok/s;     32 s elapsed
Epoch  6,   250/  454; acc:  68.61; ppl:   4.89; 5304 src tok/s; 5531 tgt tok/s;     39 s elapsed
Epoch  6,   300/  454; acc:  67.38; ppl:   5.24; 5199 src tok/s; 5396 tgt tok/s;     48 s elapsed
Epoch  6,   350/  454; acc:  66.97; ppl:   5.35; 5265 src tok/s; 5450 tgt tok/s;     56 s elapsed
Epoch  6,   400/  454; acc:  68.66; ppl:   4.88; 5303 src tok/s; 5512 tgt tok/s;     64 s elapsed
Epoch  6,   450/  454; acc:  67.78; ppl:   5.13; 5272 src tok/s; 5470 tgt tok/s;     72 s elapsed
Train perplexity: 5.01002
Train accuracy: 68.1422
Validation perplexity: 6.93254
Validation accuracy: 66.4822

Epoch  7,    50/  454; acc:  71.08; ppl:   4.03; 5363 src tok/s; 5542 tgt tok/s;      8 s elapsed
Epoch  7,   100/  454; acc:  71.41; ppl:   3.89; 5336 src tok/s; 5568 tgt tok/s;     16 s elapsed
Epoch  7,   150/  454; acc:  70.15; ppl:   4.19; 5332 src tok/s; 5533 tgt tok/s;     24 s elapsed
Epoch  7,   200/  454; acc:  71.00; ppl:   4.09; 5249 src tok/s; 5446 tgt tok/s;     32 s elapsed
Epoch  7,   250/  454; acc:  69.39; ppl:   4.53; 5259 src tok/s; 5416 tgt tok/s;     40 s elapsed
Epoch  7,   300/  454; acc:  71.31; ppl:   3.93; 5400 src tok/s; 5646 tgt tok/s;     47 s elapsed
Epoch  7,   350/  454; acc:  71.22; ppl:   4.03; 5207 src tok/s; 5443 tgt tok/s;     55 s elapsed
Epoch  7,   400/  454; acc:  68.25; ppl:   4.81; 5377 src tok/s; 5519 tgt tok/s;     63 s elapsed
Epoch  7,   450/  454; acc:  69.72; ppl:   4.34; 5225 src tok/s; 5449 tgt tok/s;     71 s elapsed
Train perplexity: 4.20683
Train accuracy: 70.3479
Validation perplexity: 6.40194
Validation accuracy: 67.6955

Epoch  8,    50/  454; acc:  72.82; ppl:   3.48; 5527 src tok/s; 5688 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  73.98; ppl:   3.26; 5260 src tok/s; 5487 tgt tok/s;     16 s elapsed
Epoch  8,   150/  454; acc:  72.56; ppl:   3.56; 5391 src tok/s; 5613 tgt tok/s;     23 s elapsed
Epoch  8,   200/  454; acc:  72.12; ppl:   3.68; 5202 src tok/s; 5403 tgt tok/s;     31 s elapsed
Epoch  8,   250/  454; acc:  73.06; ppl:   3.47; 5268 src tok/s; 5523 tgt tok/s;     39 s elapsed
Epoch  8,   300/  454; acc:  70.92; ppl:   3.90; 5363 src tok/s; 5530 tgt tok/s;     47 s elapsed
Epoch  8,   350/  454; acc:  71.60; ppl:   3.78; 5221 src tok/s; 5426 tgt tok/s;     55 s elapsed
Epoch  8,   400/  454; acc:  71.64; ppl:   3.72; 5267 src tok/s; 5457 tgt tok/s;     63 s elapsed
Epoch  8,   450/  454; acc:  71.82; ppl:   3.79; 5202 src tok/s; 5382 tgt tok/s;     71 s elapsed
Train perplexity: 3.62929
Train accuracy: 72.2584
Validation perplexity: 6.67937
Validation accuracy: 66.695
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.41; ppl:   2.71; 5481 src tok/s; 5714 tgt tok/s;      7 s elapsed
Epoch  9,   100/  454; acc:  77.01; ppl:   2.79; 5263 src tok/s; 5437 tgt tok/s;     16 s elapsed
Epoch  9,   150/  454; acc:  78.04; ppl:   2.61; 5269 src tok/s; 5528 tgt tok/s;     23 s elapsed
Epoch  9,   200/  454; acc:  76.99; ppl:   2.75; 5322 src tok/s; 5508 tgt tok/s;     31 s elapsed
Epoch  9,   250/  454; acc:  77.55; ppl:   2.69; 5273 src tok/s; 5463 tgt tok/s;     39 s elapsed
Epoch  9,   300/  454; acc:  77.45; ppl:   2.68; 5396 src tok/s; 5593 tgt tok/s;     47 s elapsed
Epoch  9,   350/  454; acc:  77.30; ppl:   2.65; 5304 src tok/s; 5502 tgt tok/s;     55 s elapsed
Epoch  9,   400/  454; acc:  76.45; ppl:   2.79; 5203 src tok/s; 5392 tgt tok/s;     63 s elapsed
Epoch  9,   450/  454; acc:  77.10; ppl:   2.78; 5210 src tok/s; 5404 tgt tok/s;     71 s elapsed
Train perplexity: 2.71679
Train accuracy: 77.2418
Validation perplexity: 6.09501
Validation accuracy: 69.1571
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.49; ppl:   2.31; 5446 src tok/s; 5652 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  82.18; ppl:   2.10; 5360 src tok/s; 5580 tgt tok/s;     15 s elapsed
Epoch 10,   150/  454; acc:  80.24; ppl:   2.35; 5274 src tok/s; 5435 tgt tok/s;     24 s elapsed
Epoch 10,   200/  454; acc:  81.98; ppl:   2.11; 5201 src tok/s; 5447 tgt tok/s;     31 s elapsed
Epoch 10,   250/  454; acc:  80.34; ppl:   2.32; 5339 src tok/s; 5544 tgt tok/s;     40 s elapsed
Epoch 10,   300/  454; acc:  81.41; ppl:   2.19; 5358 src tok/s; 5557 tgt tok/s;     47 s elapsed
Epoch 10,   350/  454; acc:  80.94; ppl:   2.23; 5371 src tok/s; 5622 tgt tok/s;     55 s elapsed
Epoch 10,   400/  454; acc:  80.50; ppl:   2.27; 5213 src tok/s; 5373 tgt tok/s;     63 s elapsed
Epoch 10,   450/  454; acc:  80.83; ppl:   2.25; 5246 src tok/s; 5415 tgt tok/s;     71 s elapsed
Train perplexity: 2.23608
Train accuracy: 80.9713
Validation perplexity: 6.23706
Validation accuracy: 69.2138
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  82.39; ppl:   2.11; 5455 src tok/s; 5653 tgt tok/s;      8 s elapsed
Epoch 11,   100/  454; acc:  83.73; ppl:   1.94; 5432 src tok/s; 5670 tgt tok/s;     15 s elapsed
Epoch 11,   150/  454; acc:  82.97; ppl:   2.04; 5306 src tok/s; 5485 tgt tok/s;     23 s elapsed
Epoch 11,   200/  454; acc:  83.15; ppl:   2.00; 5281 src tok/s; 5505 tgt tok/s;     31 s elapsed
Epoch 11,   250/  454; acc:  83.10; ppl:   2.01; 5442 src tok/s; 5613 tgt tok/s;     39 s elapsed
Epoch 11,   300/  454; acc:  83.81; ppl:   1.97; 5174 src tok/s; 5378 tgt tok/s;     47 s elapsed
Epoch 11,   350/  454; acc:  83.35; ppl:   1.99; 5359 src tok/s; 5580 tgt tok/s;     55 s elapsed
Epoch 11,   400/  454; acc:  82.56; ppl:   2.06; 5286 src tok/s; 5479 tgt tok/s;     63 s elapsed
Epoch 11,   450/  454; acc:  83.10; ppl:   2.04; 5179 src tok/s; 5373 tgt tok/s;     71 s elapsed
Train perplexity: 2.0194
Train accuracy: 83.1134
Validation perplexity: 6.36127
Validation accuracy: 69.3487
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.47; ppl:   1.92; 5398 src tok/s; 5603 tgt tok/s;      8 s elapsed
Epoch 12,   100/  454; acc:  84.20; ppl:   1.94; 5285 src tok/s; 5464 tgt tok/s;     16 s elapsed
Epoch 12,   150/  454; acc:  85.09; ppl:   1.86; 5289 src tok/s; 5490 tgt tok/s;     24 s elapsed
Epoch 12,   200/  454; acc:  83.33; ppl:   2.02; 5252 src tok/s; 5440 tgt tok/s;     32 s elapsed
Epoch 12,   250/  454; acc:  83.50; ppl:   1.97; 5405 src tok/s; 5572 tgt tok/s;     40 s elapsed
Epoch 12,   300/  454; acc:  85.36; ppl:   1.80; 5324 src tok/s; 5569 tgt tok/s;     47 s elapsed
Epoch 12,   350/  454; acc:  84.96; ppl:   1.82; 5301 src tok/s; 5561 tgt tok/s;     55 s elapsed
Epoch 12,   400/  454; acc:  83.53; ppl:   2.00; 5315 src tok/s; 5499 tgt tok/s;     63 s elapsed
Epoch 12,   450/  454; acc:  84.23; ppl:   1.93; 5208 src tok/s; 5396 tgt tok/s;     71 s elapsed
Train perplexity: 1.9194
Train accuracy: 84.2683
Validation perplexity: 6.4608
Validation accuracy: 69.4551
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  83.97; ppl:   1.95; 5377 src tok/s; 5552 tgt tok/s;      8 s elapsed
Epoch 13,   100/  454; acc:  85.93; ppl:   1.77; 5245 src tok/s; 5500 tgt tok/s;     16 s elapsed
Epoch 13,   150/  454; acc:  85.42; ppl:   1.82; 5198 src tok/s; 5443 tgt tok/s;     24 s elapsed
Epoch 13,   200/  454; acc:  84.03; ppl:   1.95; 5344 src tok/s; 5534 tgt tok/s;     32 s elapsed
Epoch 13,   250/  454; acc:  84.40; ppl:   1.92; 5333 src tok/s; 5501 tgt tok/s;     40 s elapsed
Epoch 13,   300/  454; acc:  85.18; ppl:   1.84; 5204 src tok/s; 5437 tgt tok/s;     48 s elapsed
Epoch 13,   350/  454; acc:  85.56; ppl:   1.79; 5254 src tok/s; 5455 tgt tok/s;     55 s elapsed
Epoch 13,   400/  454; acc:  84.19; ppl:   1.92; 5210 src tok/s; 5357 tgt tok/s;     64 s elapsed
Epoch 13,   450/  454; acc:  84.60; ppl:   1.88; 5346 src tok/s; 5538 tgt tok/s;     71 s elapsed
Train perplexity: 1.87053
Train accuracy: 84.7976
Validation perplexity: 6.53881
Validation accuracy: 69.3274
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  84.89; ppl:   1.88; 5454 src tok/s; 5641 tgt tok/s;      8 s elapsed
Epoch 14,   100/  454; acc:  85.68; ppl:   1.78; 5185 src tok/s; 5410 tgt tok/s;     16 s elapsed
Epoch 14,   150/  454; acc:  85.31; ppl:   1.83; 5223 src tok/s; 5441 tgt tok/s;     24 s elapsed
Epoch 14,   200/  454; acc:  84.73; ppl:   1.89; 5413 src tok/s; 5614 tgt tok/s;     32 s elapsed
Epoch 14,   250/  454; acc:  85.07; ppl:   1.86; 5416 src tok/s; 5606 tgt tok/s;     39 s elapsed
Epoch 14,   300/  454; acc:  85.62; ppl:   1.81; 5382 src tok/s; 5582 tgt tok/s;     47 s elapsed
Epoch 14,   350/  454; acc:  84.50; ppl:   1.88; 5286 src tok/s; 5492 tgt tok/s;     55 s elapsed
Epoch 14,   400/  454; acc:  84.86; ppl:   1.87; 5327 src tok/s; 5522 tgt tok/s;     63 s elapsed
Epoch 14,   450/  454; acc:  84.99; ppl:   1.85; 5245 src tok/s; 5437 tgt tok/s;     71 s elapsed
Train perplexity: 1.84822
Train accuracy: 85.0632
Validation perplexity: 6.57107
Validation accuracy: 69.3487
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  84.62; ppl:   1.91; 5349 src tok/s; 5503 tgt tok/s;      8 s elapsed
Epoch 15,   100/  454; acc:  86.00; ppl:   1.78; 5446 src tok/s; 5673 tgt tok/s;     16 s elapsed
Epoch 15,   150/  454; acc:  85.10; ppl:   1.86; 5366 src tok/s; 5550 tgt tok/s;     24 s elapsed
Epoch 15,   200/  454; acc:  85.06; ppl:   1.84; 5259 src tok/s; 5486 tgt tok/s;     31 s elapsed
Epoch 15,   250/  454; acc:  85.11; ppl:   1.83; 5256 src tok/s; 5485 tgt tok/s;     39 s elapsed
Epoch 15,   300/  454; acc:  85.16; ppl:   1.84; 5403 src tok/s; 5623 tgt tok/s;     47 s elapsed
Epoch 15,   350/  454; acc:  85.01; ppl:   1.84; 5382 src tok/s; 5528 tgt tok/s;     55 s elapsed
Epoch 15,   400/  454; acc:  85.69; ppl:   1.80; 5388 src tok/s; 5624 tgt tok/s;     63 s elapsed
Epoch 15,   450/  454; acc:  85.03; ppl:   1.84; 5162 src tok/s; 5362 tgt tok/s;     71 s elapsed
Train perplexity: 1.83735
Train accuracy: 85.1927
Validation perplexity: 6.58888
Validation accuracy: 69.2919
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  84.56; ppl:   1.90; 5389 src tok/s; 5510 tgt tok/s;      8 s elapsed
Epoch 16,   100/  454; acc:  86.58; ppl:   1.72; 5199 src tok/s; 5458 tgt tok/s;     16 s elapsed
Epoch 16,   150/  454; acc:  85.55; ppl:   1.81; 5267 src tok/s; 5495 tgt tok/s;     23 s elapsed
Epoch 16,   200/  454; acc:  84.82; ppl:   1.87; 5376 src tok/s; 5546 tgt tok/s;     32 s elapsed
Epoch 16,   250/  454; acc:  84.89; ppl:   1.84; 5293 src tok/s; 5507 tgt tok/s;     40 s elapsed
Epoch 16,   300/  454; acc:  86.05; ppl:   1.79; 5335 src tok/s; 5553 tgt tok/s;     47 s elapsed
Epoch 16,   350/  454; acc:  84.57; ppl:   1.89; 5211 src tok/s; 5412 tgt tok/s;     56 s elapsed
Epoch 16,   400/  454; acc:  85.48; ppl:   1.80; 5354 src tok/s; 5562 tgt tok/s;     63 s elapsed
Epoch 16,   450/  454; acc:  85.11; ppl:   1.85; 5280 src tok/s; 5471 tgt tok/s;     71 s elapsed
Train perplexity: 1.82976
Train accuracy: 85.2898
Validation perplexity: 6.59623
Validation accuracy: 69.299
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  86.42; ppl:   1.72; 5401 src tok/s; 5638 tgt tok/s;      7 s elapsed
Epoch 17,   100/  454; acc:  84.66; ppl:   1.90; 5287 src tok/s; 5470 tgt tok/s;     16 s elapsed
Epoch 17,   150/  454; acc:  84.82; ppl:   1.88; 5200 src tok/s; 5415 tgt tok/s;     24 s elapsed
Epoch 17,   200/  454; acc:  85.42; ppl:   1.80; 5307 src tok/s; 5480 tgt tok/s;     32 s elapsed
Epoch 17,   250/  454; acc:  85.66; ppl:   1.81; 5259 src tok/s; 5494 tgt tok/s;     39 s elapsed
Epoch 17,   300/  454; acc:  85.11; ppl:   1.86; 5334 src tok/s; 5507 tgt tok/s;     48 s elapsed
Epoch 17,   350/  454; acc:  85.32; ppl:   1.84; 5387 src tok/s; 5557 tgt tok/s;     56 s elapsed
Epoch 17,   400/  454; acc:  85.65; ppl:   1.80; 5189 src tok/s; 5401 tgt tok/s;     63 s elapsed
Epoch 17,   450/  454; acc:  85.24; ppl:   1.84; 5338 src tok/s; 5555 tgt tok/s;     71 s elapsed
Train perplexity: 1.82703
Train accuracy: 85.3649
Validation perplexity: 6.60164
Validation accuracy: 69.3132
Decaying learning rate to 0.000976562
