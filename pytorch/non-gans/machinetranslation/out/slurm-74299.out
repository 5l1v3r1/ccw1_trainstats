<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.4, kappa_enc=0.3, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/seeds/encoder0.3decoder0.4dropout0.3wdropTrueseed4', seed=4, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.3)
('Using Kappa L2 loss on decoder', 0.4)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   9.93; ppl: 14991.80; 4192 src tok/s; 4340 tgt tok/s;     10 s elapsed
Epoch  1,   100/  454; acc:  14.35; ppl: 1288.55; 5329 src tok/s; 5530 tgt tok/s;     18 s elapsed
Epoch  1,   150/  454; acc:  18.87; ppl: 452.05; 5331 src tok/s; 5588 tgt tok/s;     25 s elapsed
Epoch  1,   200/  454; acc:  21.05; ppl: 269.57; 5318 src tok/s; 5459 tgt tok/s;     34 s elapsed
Epoch  1,   250/  454; acc:  24.82; ppl: 163.54; 5256 src tok/s; 5484 tgt tok/s;     41 s elapsed
Epoch  1,   300/  454; acc:  26.50; ppl: 132.54; 5390 src tok/s; 5574 tgt tok/s;     49 s elapsed
Epoch  1,   350/  454; acc:  30.22; ppl:  90.57; 5298 src tok/s; 5501 tgt tok/s;     57 s elapsed
Epoch  1,   400/  454; acc:  31.56; ppl:  78.92; 5342 src tok/s; 5559 tgt tok/s;     65 s elapsed
Epoch  1,   450/  454; acc:  33.23; ppl:  66.49; 5283 src tok/s; 5484 tgt tok/s;     73 s elapsed
Train perplexity: 302.045
Train accuracy: 23.4538
Validation perplexity: 63.2961
Validation accuracy: 30.3037

Epoch  2,    50/  454; acc:  36.31; ppl:  50.59; 5220 src tok/s; 5436 tgt tok/s;      8 s elapsed
Epoch  2,   100/  454; acc:  36.15; ppl:  52.33; 5467 src tok/s; 5629 tgt tok/s;     16 s elapsed
Epoch  2,   150/  454; acc:  40.41; ppl:  38.78; 5376 src tok/s; 5590 tgt tok/s;     24 s elapsed
Epoch  2,   200/  454; acc:  42.57; ppl:  34.48; 5255 src tok/s; 5458 tgt tok/s;     32 s elapsed
Epoch  2,   250/  454; acc:  44.25; ppl:  29.22; 5421 src tok/s; 5602 tgt tok/s;     39 s elapsed
Epoch  2,   300/  454; acc:  47.24; ppl:  24.70; 5336 src tok/s; 5583 tgt tok/s;     47 s elapsed
Epoch  2,   350/  454; acc:  46.75; ppl:  24.85; 5437 src tok/s; 5622 tgt tok/s;     55 s elapsed
Epoch  2,   400/  454; acc:  51.06; ppl:  18.75; 5217 src tok/s; 5445 tgt tok/s;     63 s elapsed
Epoch  2,   450/  454; acc:  51.20; ppl:  18.62; 5269 src tok/s; 5449 tgt tok/s;     71 s elapsed
Train perplexity: 30.3449
Train accuracy: 44.0262
Validation perplexity: 16.3566
Validation accuracy: 53.5547

Epoch  3,    50/  454; acc:  55.38; ppl:  13.87; 5229 src tok/s; 5473 tgt tok/s;      7 s elapsed
Epoch  3,   100/  454; acc:  53.74; ppl:  15.16; 5451 src tok/s; 5603 tgt tok/s;     16 s elapsed
Epoch  3,   150/  454; acc:  54.64; ppl:  14.47; 5305 src tok/s; 5503 tgt tok/s;     24 s elapsed
Epoch  3,   200/  454; acc:  56.54; ppl:  12.68; 5342 src tok/s; 5547 tgt tok/s;     31 s elapsed
Epoch  3,   250/  454; acc:  55.39; ppl:  13.18; 5408 src tok/s; 5592 tgt tok/s;     39 s elapsed
Epoch  3,   300/  454; acc:  58.63; ppl:  11.37; 5208 src tok/s; 5435 tgt tok/s;     47 s elapsed
Epoch  3,   350/  454; acc:  57.45; ppl:  11.93; 5353 src tok/s; 5520 tgt tok/s;     55 s elapsed
Epoch  3,   400/  454; acc:  57.93; ppl:  11.41; 5335 src tok/s; 5553 tgt tok/s;     63 s elapsed
Epoch  3,   450/  454; acc:  58.31; ppl:  11.13; 5204 src tok/s; 5414 tgt tok/s;     71 s elapsed
Train perplexity: 12.7143
Train accuracy: 56.4527
Validation perplexity: 10.231
Validation accuracy: 60.0823

Epoch  4,    50/  454; acc:  60.29; ppl:   9.24; 5431 src tok/s; 5563 tgt tok/s;      8 s elapsed
Epoch  4,   100/  454; acc:  63.24; ppl:   7.77; 5291 src tok/s; 5529 tgt tok/s;     16 s elapsed
Epoch  4,   150/  454; acc:  62.43; ppl:   8.25; 5211 src tok/s; 5435 tgt tok/s;     23 s elapsed
Epoch  4,   200/  454; acc:  60.73; ppl:   8.73; 5333 src tok/s; 5527 tgt tok/s;     31 s elapsed
Epoch  4,   250/  454; acc:  61.81; ppl:   8.44; 5419 src tok/s; 5611 tgt tok/s;     39 s elapsed
Epoch  4,   300/  454; acc:  62.32; ppl:   8.27; 5354 src tok/s; 5567 tgt tok/s;     47 s elapsed
Epoch  4,   350/  454; acc:  63.17; ppl:   7.80; 5169 src tok/s; 5429 tgt tok/s;     55 s elapsed
Epoch  4,   400/  454; acc:  61.97; ppl:   8.22; 5442 src tok/s; 5625 tgt tok/s;     63 s elapsed
Epoch  4,   450/  454; acc:  62.44; ppl:   7.92; 5250 src tok/s; 5430 tgt tok/s;     71 s elapsed
Train perplexity: 8.28098
Train accuracy: 62.0448
Validation perplexity: 8.46263
Validation accuracy: 62.7146

Epoch  5,    50/  454; acc:  65.98; ppl:   6.06; 5298 src tok/s; 5514 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  65.19; ppl:   6.45; 5358 src tok/s; 5534 tgt tok/s;     16 s elapsed
Epoch  5,   150/  454; acc:  66.17; ppl:   6.10; 5272 src tok/s; 5494 tgt tok/s;     24 s elapsed
Epoch  5,   200/  454; acc:  64.60; ppl:   6.60; 5322 src tok/s; 5520 tgt tok/s;     32 s elapsed
Epoch  5,   250/  454; acc:  65.24; ppl:   6.33; 5366 src tok/s; 5547 tgt tok/s;     39 s elapsed
Epoch  5,   300/  454; acc:  65.75; ppl:   6.15; 5247 src tok/s; 5453 tgt tok/s;     48 s elapsed
Epoch  5,   350/  454; acc:  65.66; ppl:   6.13; 5280 src tok/s; 5487 tgt tok/s;     55 s elapsed
Epoch  5,   400/  454; acc:  65.48; ppl:   6.16; 5377 src tok/s; 5580 tgt tok/s;     63 s elapsed
Epoch  5,   450/  454; acc:  65.82; ppl:   6.14; 5264 src tok/s; 5463 tgt tok/s;     71 s elapsed
Train perplexity: 6.22906
Train accuracy: 65.5525
Validation perplexity: 7.28177
Validation accuracy: 65.2334

Epoch  6,    50/  454; acc:  68.87; ppl:   4.85; 5210 src tok/s; 5455 tgt tok/s;      8 s elapsed
Epoch  6,   100/  454; acc:  68.22; ppl:   4.94; 5437 src tok/s; 5593 tgt tok/s;     16 s elapsed
Epoch  6,   150/  454; acc:  68.52; ppl:   4.85; 5269 src tok/s; 5484 tgt tok/s;     23 s elapsed
Epoch  6,   200/  454; acc:  67.56; ppl:   5.15; 5297 src tok/s; 5462 tgt tok/s;     32 s elapsed
Epoch  6,   250/  454; acc:  68.82; ppl:   4.82; 5345 src tok/s; 5546 tgt tok/s;     39 s elapsed
Epoch  6,   300/  454; acc:  67.98; ppl:   5.13; 5228 src tok/s; 5463 tgt tok/s;     47 s elapsed
Epoch  6,   350/  454; acc:  68.03; ppl:   5.10; 5348 src tok/s; 5551 tgt tok/s;     55 s elapsed
Epoch  6,   400/  454; acc:  67.76; ppl:   5.10; 5372 src tok/s; 5572 tgt tok/s;     63 s elapsed
Epoch  6,   450/  454; acc:  67.66; ppl:   5.21; 5298 src tok/s; 5478 tgt tok/s;     71 s elapsed
Train perplexity: 5.00707
Train accuracy: 68.1831
Validation perplexity: 6.91649
Validation accuracy: 65.9075

Epoch  7,    50/  454; acc:  70.69; ppl:   4.12; 5392 src tok/s; 5545 tgt tok/s;      8 s elapsed
Epoch  7,   100/  454; acc:  72.00; ppl:   3.82; 5349 src tok/s; 5595 tgt tok/s;     16 s elapsed
Epoch  7,   150/  454; acc:  70.70; ppl:   4.16; 5221 src tok/s; 5462 tgt tok/s;     23 s elapsed
Epoch  7,   200/  454; acc:  70.48; ppl:   4.16; 5471 src tok/s; 5647 tgt tok/s;     31 s elapsed
Epoch  7,   250/  454; acc:  70.65; ppl:   4.05; 5321 src tok/s; 5519 tgt tok/s;     39 s elapsed
Epoch  7,   300/  454; acc:  69.30; ppl:   4.43; 5410 src tok/s; 5598 tgt tok/s;     47 s elapsed
Epoch  7,   350/  454; acc:  70.13; ppl:   4.24; 5314 src tok/s; 5508 tgt tok/s;     55 s elapsed
Epoch  7,   400/  454; acc:  70.04; ppl:   4.29; 5376 src tok/s; 5586 tgt tok/s;     63 s elapsed
Epoch  7,   450/  454; acc:  69.29; ppl:   4.51; 5271 src tok/s; 5475 tgt tok/s;     71 s elapsed
Train perplexity: 4.19568
Train accuracy: 70.3516
Validation perplexity: 6.56161
Validation accuracy: 66.5035

Epoch  8,    50/  454; acc:  72.14; ppl:   3.60; 5315 src tok/s; 5511 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  74.06; ppl:   3.31; 5338 src tok/s; 5568 tgt tok/s;     16 s elapsed
Epoch  8,   150/  454; acc:  71.69; ppl:   3.72; 5376 src tok/s; 5558 tgt tok/s;     24 s elapsed
Epoch  8,   200/  454; acc:  72.53; ppl:   3.51; 5399 src tok/s; 5607 tgt tok/s;     31 s elapsed
Epoch  8,   250/  454; acc:  73.40; ppl:   3.39; 5339 src tok/s; 5572 tgt tok/s;     39 s elapsed
Epoch  8,   300/  454; acc:  71.05; ppl:   3.92; 5486 src tok/s; 5661 tgt tok/s;     47 s elapsed
Epoch  8,   350/  454; acc:  71.53; ppl:   3.75; 5431 src tok/s; 5606 tgt tok/s;     55 s elapsed
Epoch  8,   400/  454; acc:  72.03; ppl:   3.66; 5201 src tok/s; 5421 tgt tok/s;     63 s elapsed
Epoch  8,   450/  454; acc:  71.41; ppl:   3.78; 5262 src tok/s; 5471 tgt tok/s;     70 s elapsed
Train perplexity: 3.63644
Train accuracy: 72.1558
Validation perplexity: 6.68988
Validation accuracy: 66.8795
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.47; ppl:   2.70; 5297 src tok/s; 5500 tgt tok/s;      8 s elapsed
Epoch  9,   100/  454; acc:  76.94; ppl:   2.75; 5203 src tok/s; 5412 tgt tok/s;     16 s elapsed
Epoch  9,   150/  454; acc:  78.31; ppl:   2.56; 5288 src tok/s; 5480 tgt tok/s;     24 s elapsed
Epoch  9,   200/  454; acc:  76.35; ppl:   2.87; 5248 src tok/s; 5412 tgt tok/s;     32 s elapsed
Epoch  9,   250/  454; acc:  77.40; ppl:   2.68; 5269 src tok/s; 5477 tgt tok/s;     40 s elapsed
Epoch  9,   300/  454; acc:  77.44; ppl:   2.70; 5255 src tok/s; 5488 tgt tok/s;     48 s elapsed
Epoch  9,   350/  454; acc:  76.92; ppl:   2.75; 5315 src tok/s; 5507 tgt tok/s;     56 s elapsed
Epoch  9,   400/  454; acc:  77.23; ppl:   2.71; 5292 src tok/s; 5494 tgt tok/s;     64 s elapsed
Epoch  9,   450/  454; acc:  77.41; ppl:   2.67; 5060 src tok/s; 5270 tgt tok/s;     72 s elapsed
Train perplexity: 2.71776
Train accuracy: 77.2144
Validation perplexity: 6.11244
Validation accuracy: 69.2635
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.31; ppl:   2.24; 5124 src tok/s; 5335 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  81.03; ppl:   2.23; 5278 src tok/s; 5462 tgt tok/s;     16 s elapsed
Epoch 10,   150/  454; acc:  81.68; ppl:   2.17; 5218 src tok/s; 5415 tgt tok/s;     24 s elapsed
Epoch 10,   200/  454; acc:  80.60; ppl:   2.30; 5290 src tok/s; 5468 tgt tok/s;     32 s elapsed
Epoch 10,   250/  454; acc:  80.54; ppl:   2.27; 5234 src tok/s; 5421 tgt tok/s;     40 s elapsed
Epoch 10,   300/  454; acc:  81.41; ppl:   2.17; 5388 src tok/s; 5609 tgt tok/s;     48 s elapsed
Epoch 10,   350/  454; acc:  80.35; ppl:   2.31; 5252 src tok/s; 5449 tgt tok/s;     56 s elapsed
Epoch 10,   400/  454; acc:  81.17; ppl:   2.18; 5190 src tok/s; 5418 tgt tok/s;     64 s elapsed
Epoch 10,   450/  454; acc:  80.78; ppl:   2.26; 5223 src tok/s; 5412 tgt tok/s;     72 s elapsed
Train perplexity: 2.23544
Train accuracy: 80.989
Validation perplexity: 6.27917
Validation accuracy: 68.9229
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  84.24; ppl:   1.92; 5212 src tok/s; 5421 tgt tok/s;      8 s elapsed
Epoch 11,   100/  454; acc:  82.61; ppl:   2.09; 5336 src tok/s; 5509 tgt tok/s;     16 s elapsed
Epoch 11,   150/  454; acc:  82.78; ppl:   2.05; 5376 src tok/s; 5579 tgt tok/s;     24 s elapsed
Epoch 11,   200/  454; acc:  83.70; ppl:   1.96; 5111 src tok/s; 5342 tgt tok/s;     32 s elapsed
Epoch 11,   250/  454; acc:  83.46; ppl:   1.99; 5170 src tok/s; 5381 tgt tok/s;     40 s elapsed
Epoch 11,   300/  454; acc:  82.92; ppl:   2.03; 5295 src tok/s; 5459 tgt tok/s;     48 s elapsed
Epoch 11,   350/  454; acc:  84.34; ppl:   1.89; 5301 src tok/s; 5515 tgt tok/s;     55 s elapsed
Epoch 11,   400/  454; acc:  81.96; ppl:   2.14; 5247 src tok/s; 5422 tgt tok/s;     64 s elapsed
Epoch 11,   450/  454; acc:  82.84; ppl:   2.07; 5110 src tok/s; 5312 tgt tok/s;     72 s elapsed
Train perplexity: 2.01505
Train accuracy: 83.1862
Validation perplexity: 6.35543
Validation accuracy: 69.4054
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  85.68; ppl:   1.76; 5230 src tok/s; 5455 tgt tok/s;      8 s elapsed
Epoch 12,   100/  454; acc:  83.15; ppl:   2.05; 5355 src tok/s; 5521 tgt tok/s;     16 s elapsed
Epoch 12,   150/  454; acc:  84.38; ppl:   1.90; 5239 src tok/s; 5430 tgt tok/s;     24 s elapsed
Epoch 12,   200/  454; acc:  83.44; ppl:   1.98; 5298 src tok/s; 5497 tgt tok/s;     32 s elapsed
Epoch 12,   250/  454; acc:  84.01; ppl:   1.96; 5337 src tok/s; 5563 tgt tok/s;     40 s elapsed
Epoch 12,   300/  454; acc:  84.41; ppl:   1.92; 5418 src tok/s; 5637 tgt tok/s;     48 s elapsed
Epoch 12,   350/  454; acc:  83.80; ppl:   1.94; 5193 src tok/s; 5388 tgt tok/s;     56 s elapsed
Epoch 12,   400/  454; acc:  84.64; ppl:   1.86; 5442 src tok/s; 5642 tgt tok/s;     63 s elapsed
Epoch 12,   450/  454; acc:  84.47; ppl:   1.90; 5249 src tok/s; 5446 tgt tok/s;     71 s elapsed
Train perplexity: 1.91896
Train accuracy: 84.193
Validation perplexity: 6.46492
Validation accuracy: 69.6325
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  85.49; ppl:   1.81; 5372 src tok/s; 5589 tgt tok/s;      8 s elapsed
Epoch 13,   100/  454; acc:  84.58; ppl:   1.91; 5568 src tok/s; 5767 tgt tok/s;     15 s elapsed
Epoch 13,   150/  454; acc:  85.87; ppl:   1.79; 5456 src tok/s; 5702 tgt tok/s;     23 s elapsed
Epoch 13,   200/  454; acc:  84.08; ppl:   1.95; 5525 src tok/s; 5730 tgt tok/s;     31 s elapsed
Epoch 13,   250/  454; acc:  85.80; ppl:   1.77; 5537 src tok/s; 5782 tgt tok/s;     38 s elapsed
Epoch 13,   300/  454; acc:  83.93; ppl:   1.97; 5639 src tok/s; 5786 tgt tok/s;     46 s elapsed
Epoch 13,   350/  454; acc:  84.28; ppl:   1.93; 5156 src tok/s; 5344 tgt tok/s;     54 s elapsed
Epoch 13,   400/  454; acc:  85.03; ppl:   1.85; 5452 src tok/s; 5668 tgt tok/s;     61 s elapsed
Epoch 13,   450/  454; acc:  84.11; ppl:   1.90; 5516 src tok/s; 5713 tgt tok/s;     69 s elapsed
Train perplexity: 1.87182
Train accuracy: 84.8078
Validation perplexity: 6.55575
Validation accuracy: 69.3983
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.96; ppl:   1.76; 5089 src tok/s; 5295 tgt tok/s;      8 s elapsed
Epoch 14,   100/  454; acc:  84.63; ppl:   1.92; 5365 src tok/s; 5565 tgt tok/s;     16 s elapsed
Epoch 14,   150/  454; acc:  85.16; ppl:   1.83; 5555 src tok/s; 5778 tgt tok/s;     24 s elapsed
Epoch 14,   200/  454; acc:  84.71; ppl:   1.88; 5562 src tok/s; 5761 tgt tok/s;     31 s elapsed
Epoch 14,   250/  454; acc:  84.71; ppl:   1.87; 5544 src tok/s; 5716 tgt tok/s;     39 s elapsed
Epoch 14,   300/  454; acc:  85.24; ppl:   1.83; 5581 src tok/s; 5792 tgt tok/s;     46 s elapsed
Epoch 14,   350/  454; acc:  85.63; ppl:   1.79; 5469 src tok/s; 5699 tgt tok/s;     54 s elapsed
Epoch 14,   400/  454; acc:  84.82; ppl:   1.86; 5471 src tok/s; 5671 tgt tok/s;     62 s elapsed
Epoch 14,   450/  454; acc:  84.73; ppl:   1.87; 5046 src tok/s; 5238 tgt tok/s;     70 s elapsed
Train perplexity: 1.84554
Train accuracy: 85.0728
Validation perplexity: 6.56564
Validation accuracy: 69.3487
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  84.87; ppl:   1.89; 5389 src tok/s; 5583 tgt tok/s;      8 s elapsed
Epoch 15,   100/  454; acc:  85.81; ppl:   1.79; 5545 src tok/s; 5718 tgt tok/s;     15 s elapsed
Epoch 15,   150/  454; acc:  85.20; ppl:   1.85; 5299 src tok/s; 5530 tgt tok/s;     23 s elapsed
Epoch 15,   200/  454; acc:  85.52; ppl:   1.82; 5372 src tok/s; 5583 tgt tok/s;     31 s elapsed
Epoch 15,   250/  454; acc:  84.55; ppl:   1.89; 5410 src tok/s; 5585 tgt tok/s;     39 s elapsed
Epoch 15,   300/  454; acc:  85.53; ppl:   1.80; 5289 src tok/s; 5516 tgt tok/s;     47 s elapsed
Epoch 15,   350/  454; acc:  86.13; ppl:   1.76; 5284 src tok/s; 5511 tgt tok/s;     55 s elapsed
Epoch 15,   400/  454; acc:  84.59; ppl:   1.91; 5444 src tok/s; 5619 tgt tok/s;     62 s elapsed
Epoch 15,   450/  454; acc:  85.70; ppl:   1.80; 5254 src tok/s; 5466 tgt tok/s;     70 s elapsed
Train perplexity: 1.8352
Train accuracy: 85.2778
Validation perplexity: 6.58979
Validation accuracy: 69.3274
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  83.97; ppl:   1.96; 5470 src tok/s; 5656 tgt tok/s;      8 s elapsed
Epoch 16,   100/  454; acc:  86.29; ppl:   1.74; 5204 src tok/s; 5429 tgt tok/s;     16 s elapsed
Epoch 16,   150/  454; acc:  85.65; ppl:   1.81; 5378 src tok/s; 5606 tgt tok/s;     24 s elapsed
Epoch 16,   200/  454; acc:  84.99; ppl:   1.85; 5385 src tok/s; 5598 tgt tok/s;     31 s elapsed
Epoch 16,   250/  454; acc:  85.36; ppl:   1.81; 5381 src tok/s; 5586 tgt tok/s;     39 s elapsed
Epoch 16,   300/  454; acc:  85.17; ppl:   1.84; 5376 src tok/s; 5548 tgt tok/s;     47 s elapsed
Epoch 16,   350/  454; acc:  84.43; ppl:   1.91; 5469 src tok/s; 5627 tgt tok/s;     55 s elapsed
Epoch 16,   400/  454; acc:  86.63; ppl:   1.71; 5285 src tok/s; 5542 tgt tok/s;     62 s elapsed
Epoch 16,   450/  454; acc:  85.35; ppl:   1.83; 5304 src tok/s; 5498 tgt tok/s;     70 s elapsed
Train perplexity: 1.82828
Train accuracy: 85.2933
Validation perplexity: 6.59605
Validation accuracy: 69.3345
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  84.99; ppl:   1.85; 5428 src tok/s; 5626 tgt tok/s;      8 s elapsed
Epoch 17,   100/  454; acc:  85.02; ppl:   1.89; 5456 src tok/s; 5659 tgt tok/s;     15 s elapsed
Epoch 17,   150/  454; acc:  85.77; ppl:   1.80; 5425 src tok/s; 5626 tgt tok/s;     23 s elapsed
Epoch 17,   200/  454; acc:  85.41; ppl:   1.82; 5258 src tok/s; 5468 tgt tok/s;     31 s elapsed
Epoch 17,   250/  454; acc:  86.10; ppl:   1.75; 5417 src tok/s; 5646 tgt tok/s;     39 s elapsed
Epoch 17,   300/  454; acc:  84.62; ppl:   1.91; 5354 src tok/s; 5554 tgt tok/s;     47 s elapsed
Epoch 17,   350/  454; acc:  84.52; ppl:   1.91; 5477 src tok/s; 5645 tgt tok/s;     55 s elapsed
Epoch 17,   400/  454; acc:  86.71; ppl:   1.71; 5316 src tok/s; 5527 tgt tok/s;     62 s elapsed
Epoch 17,   450/  454; acc:  85.25; ppl:   1.83; 5336 src tok/s; 5554 tgt tok/s;     70 s elapsed
Train perplexity: 1.8275
Train accuracy: 85.3784
Validation perplexity: 6.59941
Validation accuracy: 69.3132
Decaying learning rate to 0.000976562
