<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.15, kappa_enc=0.1, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.1decoder0.15dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.1)
('Using Kappa L2 loss on decoder', 0.15)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.62; ppl: 14250.40; 2929 src tok/s; 3040 tgt tok/s;     14 s elapsed
Epoch  1,   100/  454; acc:  14.78; ppl: 2334.03; 3327 src tok/s; 3455 tgt tok/s;     27 s elapsed
Epoch  1,   150/  454; acc:  17.51; ppl: 555.50; 3094 src tok/s; 3220 tgt tok/s;     40 s elapsed
Epoch  1,   200/  454; acc:  20.60; ppl: 274.36; 3097 src tok/s; 3203 tgt tok/s;     54 s elapsed
Epoch  1,   250/  454; acc:  24.35; ppl: 167.94; 3071 src tok/s; 3217 tgt tok/s;     67 s elapsed
Epoch  1,   300/  454; acc:  25.65; ppl: 139.84; 3157 src tok/s; 3263 tgt tok/s;     81 s elapsed
Epoch  1,   350/  454; acc:  30.89; ppl:  88.21; 3016 src tok/s; 3155 tgt tok/s;     94 s elapsed
Epoch  1,   400/  454; acc:  30.01; ppl:  89.06; 3103 src tok/s; 3193 tgt tok/s;    108 s elapsed
Epoch  1,   450/  454; acc:  32.45; ppl:  71.67; 3071 src tok/s; 3176 tgt tok/s;    122 s elapsed
Train perplexity: 338.969
Train accuracy: 22.8623
Validation perplexity: 65.7512
Validation accuracy: 33.7378

Epoch  2,    50/  454; acc:  35.44; ppl:  57.53; 3109 src tok/s; 3223 tgt tok/s;     13 s elapsed
Epoch  2,   100/  454; acc:  37.91; ppl:  47.20; 3102 src tok/s; 3210 tgt tok/s;     27 s elapsed
Epoch  2,   150/  454; acc:  39.73; ppl:  41.16; 3067 src tok/s; 3164 tgt tok/s;     42 s elapsed
Epoch  2,   200/  454; acc:  44.28; ppl:  30.71; 3054 src tok/s; 3190 tgt tok/s;     55 s elapsed
Epoch  2,   250/  454; acc:  44.84; ppl:  28.79; 3076 src tok/s; 3197 tgt tok/s;     68 s elapsed
Epoch  2,   300/  454; acc:  46.78; ppl:  24.79; 3072 src tok/s; 3198 tgt tok/s;     82 s elapsed
Epoch  2,   350/  454; acc:  48.54; ppl:  22.33; 3126 src tok/s; 3238 tgt tok/s;     95 s elapsed
Epoch  2,   400/  454; acc:  50.47; ppl:  20.19; 3044 src tok/s; 3169 tgt tok/s;    109 s elapsed
Epoch  2,   450/  454; acc:  51.79; ppl:  18.18; 3090 src tok/s; 3211 tgt tok/s;    122 s elapsed
Train perplexity: 30.1262
Train accuracy: 44.379
Validation perplexity: 16.6366
Validation accuracy: 53.6611

Epoch  3,    50/  454; acc:  53.70; ppl:  15.60; 3028 src tok/s; 3143 tgt tok/s;     13 s elapsed
Epoch  3,   100/  454; acc:  54.38; ppl:  14.12; 3079 src tok/s; 3183 tgt tok/s;     27 s elapsed
Epoch  3,   150/  454; acc:  54.36; ppl:  14.83; 3108 src tok/s; 3220 tgt tok/s;     41 s elapsed
Epoch  3,   200/  454; acc:  56.31; ppl:  12.94; 3094 src tok/s; 3212 tgt tok/s;     55 s elapsed
Epoch  3,   250/  454; acc:  56.96; ppl:  12.39; 3086 src tok/s; 3201 tgt tok/s;     68 s elapsed
Epoch  3,   300/  454; acc:  56.92; ppl:  12.29; 3033 src tok/s; 3147 tgt tok/s;     82 s elapsed
Epoch  3,   350/  454; acc:  57.94; ppl:  11.71; 3038 src tok/s; 3173 tgt tok/s;     96 s elapsed
Epoch  3,   400/  454; acc:  58.21; ppl:  11.24; 3119 src tok/s; 3229 tgt tok/s;    109 s elapsed
Epoch  3,   450/  454; acc:  58.71; ppl:  10.95; 3086 src tok/s; 3214 tgt tok/s;    123 s elapsed
Train perplexity: 12.7891
Train accuracy: 56.4162
Validation perplexity: 10.4328
Validation accuracy: 60.3306

Epoch  4,    50/  454; acc:  62.66; ppl:   8.06; 3035 src tok/s; 3173 tgt tok/s;     13 s elapsed
Epoch  4,   100/  454; acc:  60.86; ppl:   8.90; 3058 src tok/s; 3159 tgt tok/s;     27 s elapsed
Epoch  4,   150/  454; acc:  62.68; ppl:   8.09; 3098 src tok/s; 3228 tgt tok/s;     40 s elapsed
Epoch  4,   200/  454; acc:  60.95; ppl:   8.86; 3097 src tok/s; 3202 tgt tok/s;     54 s elapsed
Epoch  4,   250/  454; acc:  61.76; ppl:   8.44; 3123 src tok/s; 3235 tgt tok/s;     68 s elapsed
Epoch  4,   300/  454; acc:  62.46; ppl:   8.28; 3052 src tok/s; 3178 tgt tok/s;     82 s elapsed
Epoch  4,   350/  454; acc:  61.79; ppl:   8.42; 3143 src tok/s; 3249 tgt tok/s;     95 s elapsed
Epoch  4,   400/  454; acc:  62.32; ppl:   8.10; 3071 src tok/s; 3190 tgt tok/s;    109 s elapsed
Epoch  4,   450/  454; acc:  61.96; ppl:   8.18; 3005 src tok/s; 3115 tgt tok/s;    123 s elapsed
Train perplexity: 8.35683
Train accuracy: 61.9488
Validation perplexity: 8.26163
Validation accuracy: 63.9279

Epoch  5,    50/  454; acc:  66.33; ppl:   5.89; 3108 src tok/s; 3229 tgt tok/s;     13 s elapsed
Epoch  5,   100/  454; acc:  64.75; ppl:   6.60; 3129 src tok/s; 3240 tgt tok/s;     27 s elapsed
Epoch  5,   150/  454; acc:  66.07; ppl:   6.02; 3037 src tok/s; 3171 tgt tok/s;     40 s elapsed
Epoch  5,   200/  454; acc:  63.99; ppl:   6.86; 3105 src tok/s; 3209 tgt tok/s;     54 s elapsed
Epoch  5,   250/  454; acc:  65.23; ppl:   6.29; 3077 src tok/s; 3174 tgt tok/s;     68 s elapsed
Epoch  5,   300/  454; acc:  65.23; ppl:   6.33; 3114 src tok/s; 3230 tgt tok/s;     81 s elapsed
Epoch  5,   350/  454; acc:  66.16; ppl:   5.97; 3091 src tok/s; 3218 tgt tok/s;     95 s elapsed
Epoch  5,   400/  454; acc:  64.70; ppl:   6.62; 3026 src tok/s; 3146 tgt tok/s;    109 s elapsed
Epoch  5,   450/  454; acc:  66.09; ppl:   5.96; 3009 src tok/s; 3144 tgt tok/s;    122 s elapsed
Train perplexity: 6.30007
Train accuracy: 65.3188
Validation perplexity: 7.51354
Validation accuracy: 64.5097

Epoch  6,    50/  454; acc:  68.54; ppl:   5.00; 3101 src tok/s; 3198 tgt tok/s;     14 s elapsed
Epoch  6,   100/  454; acc:  68.48; ppl:   4.89; 3075 src tok/s; 3204 tgt tok/s;     27 s elapsed
Epoch  6,   150/  454; acc:  67.43; ppl:   5.22; 3125 src tok/s; 3240 tgt tok/s;     41 s elapsed
Epoch  6,   200/  454; acc:  68.78; ppl:   4.86; 3012 src tok/s; 3156 tgt tok/s;     54 s elapsed
Epoch  6,   250/  454; acc:  67.70; ppl:   5.20; 3055 src tok/s; 3183 tgt tok/s;     68 s elapsed
Epoch  6,   300/  454; acc:  68.21; ppl:   5.03; 3090 src tok/s; 3196 tgt tok/s;     82 s elapsed
Epoch  6,   350/  454; acc:  67.97; ppl:   5.14; 3090 src tok/s; 3199 tgt tok/s;     95 s elapsed
Epoch  6,   400/  454; acc:  67.84; ppl:   5.10; 3123 src tok/s; 3232 tgt tok/s;    109 s elapsed
Epoch  6,   450/  454; acc:  67.68; ppl:   5.20; 3027 src tok/s; 3135 tgt tok/s;    123 s elapsed
Train perplexity: 5.06509
Train accuracy: 68.0868
Validation perplexity: 6.97786
Validation accuracy: 65.8294

Epoch  7,    50/  454; acc:  71.74; ppl:   3.89; 3087 src tok/s; 3211 tgt tok/s;     13 s elapsed
Epoch  7,   100/  454; acc:  70.20; ppl:   4.27; 3123 src tok/s; 3235 tgt tok/s;     27 s elapsed
Epoch  7,   150/  454; acc:  70.06; ppl:   4.32; 3123 src tok/s; 3231 tgt tok/s;     41 s elapsed
Epoch  7,   200/  454; acc:  70.92; ppl:   4.03; 3051 src tok/s; 3181 tgt tok/s;     54 s elapsed
Epoch  7,   250/  454; acc:  70.33; ppl:   4.23; 3108 src tok/s; 3215 tgt tok/s;     68 s elapsed
Epoch  7,   300/  454; acc:  69.97; ppl:   4.31; 3054 src tok/s; 3171 tgt tok/s;     82 s elapsed
Epoch  7,   350/  454; acc:  69.80; ppl:   4.39; 2991 src tok/s; 3131 tgt tok/s;     95 s elapsed
Epoch  7,   400/  454; acc:  69.48; ppl:   4.42; 3139 src tok/s; 3249 tgt tok/s;    109 s elapsed
Epoch  7,   450/  454; acc:  69.44; ppl:   4.37; 3050 src tok/s; 3156 tgt tok/s;    122 s elapsed
Train perplexity: 4.24937
Train accuracy: 70.1829
Validation perplexity: 6.59455
Validation accuracy: 67.1988

Epoch  8,    50/  454; acc:  73.68; ppl:   3.32; 3067 src tok/s; 3175 tgt tok/s;     14 s elapsed
Epoch  8,   100/  454; acc:  72.26; ppl:   3.55; 3065 src tok/s; 3193 tgt tok/s;     27 s elapsed
Epoch  8,   150/  454; acc:  72.53; ppl:   3.57; 3092 src tok/s; 3213 tgt tok/s;     41 s elapsed
Epoch  8,   200/  454; acc:  71.52; ppl:   3.75; 3067 src tok/s; 3176 tgt tok/s;     55 s elapsed
Epoch  8,   250/  454; acc:  72.12; ppl:   3.62; 3047 src tok/s; 3161 tgt tok/s;     69 s elapsed
Epoch  8,   300/  454; acc:  71.88; ppl:   3.70; 3087 src tok/s; 3219 tgt tok/s;     82 s elapsed
Epoch  8,   350/  454; acc:  70.77; ppl:   3.93; 3058 src tok/s; 3152 tgt tok/s;     96 s elapsed
Epoch  8,   400/  454; acc:  72.09; ppl:   3.64; 3076 src tok/s; 3197 tgt tok/s;    109 s elapsed
Epoch  8,   450/  454; acc:  71.16; ppl:   3.89; 3102 src tok/s; 3207 tgt tok/s;    123 s elapsed
Train perplexity: 3.65211
Train accuracy: 72.0319
Validation perplexity: 6.75227
Validation accuracy: 67.1279
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.57; ppl:   2.80; 3146 src tok/s; 3247 tgt tok/s;     14 s elapsed
Epoch  9,   100/  454; acc:  76.90; ppl:   2.72; 3022 src tok/s; 3151 tgt tok/s;     27 s elapsed
Epoch  9,   150/  454; acc:  77.21; ppl:   2.71; 3054 src tok/s; 3183 tgt tok/s;     41 s elapsed
Epoch  9,   200/  454; acc:  77.46; ppl:   2.69; 3084 src tok/s; 3177 tgt tok/s;     55 s elapsed
Epoch  9,   250/  454; acc:  77.45; ppl:   2.70; 3104 src tok/s; 3234 tgt tok/s;     68 s elapsed
Epoch  9,   300/  454; acc:  77.38; ppl:   2.68; 3061 src tok/s; 3178 tgt tok/s;     82 s elapsed
Epoch  9,   350/  454; acc:  75.96; ppl:   2.99; 3152 src tok/s; 3242 tgt tok/s;     96 s elapsed
Epoch  9,   400/  454; acc:  78.23; ppl:   2.55; 3014 src tok/s; 3165 tgt tok/s;    109 s elapsed
Epoch  9,   450/  454; acc:  76.84; ppl:   2.75; 3027 src tok/s; 3141 tgt tok/s;    123 s elapsed
Train perplexity: 2.73148
Train accuracy: 77.11
Validation perplexity: 6.18292
Validation accuracy: 68.9868
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.97; ppl:   2.25; 3065 src tok/s; 3175 tgt tok/s;     14 s elapsed
Epoch 10,   100/  454; acc:  81.16; ppl:   2.23; 3073 src tok/s; 3203 tgt tok/s;     27 s elapsed
Epoch 10,   150/  454; acc:  80.67; ppl:   2.26; 3094 src tok/s; 3203 tgt tok/s;     41 s elapsed
Epoch 10,   200/  454; acc:  81.05; ppl:   2.25; 3095 src tok/s; 3220 tgt tok/s;     55 s elapsed
Epoch 10,   250/  454; acc:  81.24; ppl:   2.22; 3064 src tok/s; 3196 tgt tok/s;     68 s elapsed
Epoch 10,   300/  454; acc:  80.23; ppl:   2.28; 3085 src tok/s; 3189 tgt tok/s;     82 s elapsed
Epoch 10,   350/  454; acc:  80.14; ppl:   2.34; 3098 src tok/s; 3196 tgt tok/s;     96 s elapsed
Epoch 10,   400/  454; acc:  81.74; ppl:   2.15; 3051 src tok/s; 3183 tgt tok/s;    109 s elapsed
Epoch 10,   450/  454; acc:  80.51; ppl:   2.28; 3067 src tok/s; 3175 tgt tok/s;    123 s elapsed
Train perplexity: 2.24762
Train accuracy: 80.8785
Validation perplexity: 6.26318
Validation accuracy: 69.299
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  84.38; ppl:   1.90; 2995 src tok/s; 3158 tgt tok/s;     13 s elapsed
Epoch 11,   100/  454; acc:  82.22; ppl:   2.12; 3146 src tok/s; 3238 tgt tok/s;     27 s elapsed
Epoch 11,   150/  454; acc:  83.71; ppl:   1.96; 3067 src tok/s; 3192 tgt tok/s;     40 s elapsed
Epoch 11,   200/  454; acc:  82.44; ppl:   2.08; 3095 src tok/s; 3188 tgt tok/s;     55 s elapsed
Epoch 11,   250/  454; acc:  82.52; ppl:   2.08; 3081 src tok/s; 3185 tgt tok/s;     69 s elapsed
Epoch 11,   300/  454; acc:  83.16; ppl:   2.01; 3077 src tok/s; 3210 tgt tok/s;     82 s elapsed
Epoch 11,   350/  454; acc:  82.95; ppl:   2.05; 3120 src tok/s; 3213 tgt tok/s;     95 s elapsed
Epoch 11,   400/  454; acc:  83.21; ppl:   2.00; 3032 src tok/s; 3171 tgt tok/s;    109 s elapsed
Epoch 11,   450/  454; acc:  82.80; ppl:   2.06; 3084 src tok/s; 3189 tgt tok/s;    123 s elapsed
Train perplexity: 2.02796
Train accuracy: 83.0372
Validation perplexity: 6.38526
Validation accuracy: 69.4622
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  83.23; ppl:   2.03; 3154 src tok/s; 3250 tgt tok/s;     14 s elapsed
Epoch 12,   100/  454; acc:  85.66; ppl:   1.78; 3079 src tok/s; 3206 tgt tok/s;     27 s elapsed
Epoch 12,   150/  454; acc:  84.10; ppl:   1.96; 3065 src tok/s; 3182 tgt tok/s;     41 s elapsed
Epoch 12,   200/  454; acc:  84.40; ppl:   1.92; 3079 src tok/s; 3193 tgt tok/s;     54 s elapsed
Epoch 12,   250/  454; acc:  85.08; ppl:   1.86; 3075 src tok/s; 3226 tgt tok/s;     67 s elapsed
Epoch 12,   300/  454; acc:  83.28; ppl:   2.02; 3067 src tok/s; 3168 tgt tok/s;     82 s elapsed
Epoch 12,   350/  454; acc:  83.65; ppl:   2.00; 3155 src tok/s; 3262 tgt tok/s;     95 s elapsed
Epoch 12,   400/  454; acc:  84.35; ppl:   1.89; 3047 src tok/s; 3183 tgt tok/s;    109 s elapsed
Epoch 12,   450/  454; acc:  84.22; ppl:   1.91; 3012 src tok/s; 3130 tgt tok/s;    122 s elapsed
Train perplexity: 1.9314
Train accuracy: 84.1687
Validation perplexity: 6.46229
Validation accuracy: 69.526
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  83.93; ppl:   1.96; 3093 src tok/s; 3184 tgt tok/s;     14 s elapsed
Epoch 13,   100/  454; acc:  85.50; ppl:   1.80; 3114 src tok/s; 3233 tgt tok/s;     27 s elapsed
Epoch 13,   150/  454; acc:  86.12; ppl:   1.76; 3057 src tok/s; 3195 tgt tok/s;     40 s elapsed
Epoch 13,   200/  454; acc:  83.96; ppl:   1.98; 3120 src tok/s; 3209 tgt tok/s;     54 s elapsed
Epoch 13,   250/  454; acc:  85.38; ppl:   1.81; 3089 src tok/s; 3217 tgt tok/s;     68 s elapsed
Epoch 13,   300/  454; acc:  84.22; ppl:   1.93; 3083 src tok/s; 3221 tgt tok/s;     81 s elapsed
Epoch 13,   350/  454; acc:  85.02; ppl:   1.83; 3108 src tok/s; 3232 tgt tok/s;     95 s elapsed
Epoch 13,   400/  454; acc:  84.05; ppl:   1.95; 3130 src tok/s; 3239 tgt tok/s;    108 s elapsed
Epoch 13,   450/  454; acc:  84.48; ppl:   1.88; 3022 src tok/s; 3141 tgt tok/s;    122 s elapsed
Train perplexity: 1.87941
Train accuracy: 84.7047
Validation perplexity: 6.51561
Validation accuracy: 69.4409
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.60; ppl:   1.83; 3056 src tok/s; 3188 tgt tok/s;     14 s elapsed
Epoch 14,   100/  454; acc:  84.75; ppl:   1.88; 3114 src tok/s; 3224 tgt tok/s;     27 s elapsed
Epoch 14,   150/  454; acc:  84.89; ppl:   1.89; 3081 src tok/s; 3190 tgt tok/s;     41 s elapsed
Epoch 14,   200/  454; acc:  85.21; ppl:   1.83; 3154 src tok/s; 3287 tgt tok/s;     54 s elapsed
Epoch 14,   250/  454; acc:  85.27; ppl:   1.84; 3110 src tok/s; 3227 tgt tok/s;     67 s elapsed
Epoch 14,   300/  454; acc:  84.78; ppl:   1.87; 3047 src tok/s; 3161 tgt tok/s;     81 s elapsed
Epoch 14,   350/  454; acc:  84.95; ppl:   1.88; 3106 src tok/s; 3197 tgt tok/s;     95 s elapsed
Epoch 14,   400/  454; acc:  85.08; ppl:   1.84; 3055 src tok/s; 3178 tgt tok/s;    109 s elapsed
Epoch 14,   450/  454; acc:  84.96; ppl:   1.84; 2983 src tok/s; 3109 tgt tok/s;    122 s elapsed
Train perplexity: 1.85635
Train accuracy: 85.0372
Validation perplexity: 6.55693
Validation accuracy: 69.4835
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  84.42; ppl:   1.91; 3064 src tok/s; 3193 tgt tok/s;     14 s elapsed
Epoch 15,   100/  454; acc:  86.16; ppl:   1.77; 3071 src tok/s; 3198 tgt tok/s;     27 s elapsed
Epoch 15,   150/  454; acc:  86.18; ppl:   1.75; 3088 src tok/s; 3226 tgt tok/s;     40 s elapsed
Epoch 15,   200/  454; acc:  84.29; ppl:   1.94; 3117 src tok/s; 3218 tgt tok/s;     54 s elapsed
Epoch 15,   250/  454; acc:  84.27; ppl:   1.92; 3094 src tok/s; 3209 tgt tok/s;     68 s elapsed
Epoch 15,   300/  454; acc:  85.49; ppl:   1.80; 3072 src tok/s; 3186 tgt tok/s;     82 s elapsed
Epoch 15,   350/  454; acc:  85.17; ppl:   1.84; 3101 src tok/s; 3221 tgt tok/s;     95 s elapsed
Epoch 15,   400/  454; acc:  85.21; ppl:   1.84; 3106 src tok/s; 3213 tgt tok/s;    109 s elapsed
Epoch 15,   450/  454; acc:  84.99; ppl:   1.84; 3048 src tok/s; 3151 tgt tok/s;    122 s elapsed
Train perplexity: 1.84694
Train accuracy: 85.098
Validation perplexity: 6.57212
Validation accuracy: 69.4693
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  84.70; ppl:   1.90; 3165 src tok/s; 3264 tgt tok/s;     14 s elapsed
Epoch 16,   100/  454; acc:  85.64; ppl:   1.79; 3149 src tok/s; 3261 tgt tok/s;     27 s elapsed
Epoch 16,   150/  454; acc:  84.92; ppl:   1.86; 3119 src tok/s; 3224 tgt tok/s;     41 s elapsed
Epoch 16,   200/  454; acc:  85.49; ppl:   1.82; 3080 src tok/s; 3199 tgt tok/s;     54 s elapsed
Epoch 16,   250/  454; acc:  85.77; ppl:   1.78; 3086 src tok/s; 3230 tgt tok/s;     67 s elapsed
Epoch 16,   300/  454; acc:  84.26; ppl:   1.91; 3070 src tok/s; 3182 tgt tok/s;     81 s elapsed
Epoch 16,   350/  454; acc:  85.90; ppl:   1.79; 3071 src tok/s; 3194 tgt tok/s;     94 s elapsed
Epoch 16,   400/  454; acc:  84.66; ppl:   1.90; 3098 src tok/s; 3225 tgt tok/s;    108 s elapsed
Epoch 16,   450/  454; acc:  85.49; ppl:   1.81; 3006 src tok/s; 3119 tgt tok/s;    122 s elapsed
Train perplexity: 1.83966
Train accuracy: 85.1862
Validation perplexity: 6.58455
Validation accuracy: 69.4338
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.61; ppl:   1.81; 3109 src tok/s; 3229 tgt tok/s;     13 s elapsed
Epoch 17,   100/  454; acc:  84.94; ppl:   1.84; 3045 src tok/s; 3163 tgt tok/s;     27 s elapsed
Epoch 17,   150/  454; acc:  85.32; ppl:   1.85; 3080 src tok/s; 3183 tgt tok/s;     41 s elapsed
Epoch 17,   200/  454; acc:  85.39; ppl:   1.83; 3113 src tok/s; 3242 tgt tok/s;     54 s elapsed
Epoch 17,   250/  454; acc:  84.57; ppl:   1.90; 3095 src tok/s; 3216 tgt tok/s;     68 s elapsed
Epoch 17,   300/  454; acc:  85.33; ppl:   1.81; 3162 src tok/s; 3278 tgt tok/s;     81 s elapsed
Epoch 17,   350/  454; acc:  85.40; ppl:   1.80; 3118 src tok/s; 3222 tgt tok/s;     95 s elapsed
Epoch 17,   400/  454; acc:  84.87; ppl:   1.85; 3039 src tok/s; 3162 tgt tok/s;    109 s elapsed
Epoch 17,   450/  454; acc:  85.39; ppl:   1.83; 3099 src tok/s; 3219 tgt tok/s;    122 s elapsed
Train perplexity: 1.83499
Train accuracy: 85.2035
Validation perplexity: 6.58932
Validation accuracy: 69.4267
Decaying learning rate to 0.000976562
