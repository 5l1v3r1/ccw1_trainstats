<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.25, kappa_enc=0.0, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0decoder0.25dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on decoder', 0.25)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   9.11; ppl: 17287.51; 2779 src tok/s; 2882 tgt tok/s;     15 s elapsed
Epoch  1,   100/  454; acc:  14.60; ppl: 1785.77; 3347 src tok/s; 3477 tgt tok/s;     27 s elapsed
Epoch  1,   150/  454; acc:  17.37; ppl: 705.27; 3359 src tok/s; 3466 tgt tok/s;     40 s elapsed
Epoch  1,   200/  454; acc:  21.56; ppl: 257.82; 3388 src tok/s; 3536 tgt tok/s;     52 s elapsed
Epoch  1,   250/  454; acc:  24.34; ppl: 182.09; 3379 src tok/s; 3516 tgt tok/s;     65 s elapsed
Epoch  1,   300/  454; acc:  27.65; ppl: 125.01; 3386 src tok/s; 3506 tgt tok/s;     77 s elapsed
Epoch  1,   350/  454; acc:  28.60; ppl: 103.77; 3383 src tok/s; 3496 tgt tok/s;     90 s elapsed
Epoch  1,   400/  454; acc:  32.50; ppl:  74.08; 3351 src tok/s; 3491 tgt tok/s;    102 s elapsed
Epoch  1,   450/  454; acc:  33.24; ppl:  68.07; 3312 src tok/s; 3439 tgt tok/s;    115 s elapsed
Train perplexity: 339.075
Train accuracy: 23.279
Validation perplexity: 55.5501
Validation accuracy: 36.9164

Epoch  2,    50/  454; acc:  35.54; ppl:  55.71; 3327 src tok/s; 3456 tgt tok/s;     12 s elapsed
Epoch  2,   100/  454; acc:  37.53; ppl:  47.61; 3315 src tok/s; 3431 tgt tok/s;     25 s elapsed
Epoch  2,   150/  454; acc:  39.55; ppl:  41.76; 3378 src tok/s; 3484 tgt tok/s;     38 s elapsed
Epoch  2,   200/  454; acc:  43.42; ppl:  33.07; 3316 src tok/s; 3462 tgt tok/s;     50 s elapsed
Epoch  2,   250/  454; acc:  45.01; ppl:  28.30; 3354 src tok/s; 3493 tgt tok/s;     63 s elapsed
Epoch  2,   300/  454; acc:  46.16; ppl:  26.29; 3286 src tok/s; 3421 tgt tok/s;     76 s elapsed
Epoch  2,   350/  454; acc:  47.46; ppl:  23.91; 3378 src tok/s; 3487 tgt tok/s;     89 s elapsed
Epoch  2,   400/  454; acc:  51.37; ppl:  18.45; 3271 src tok/s; 3417 tgt tok/s;    101 s elapsed
Epoch  2,   450/  454; acc:  51.44; ppl:  18.73; 3334 src tok/s; 3443 tgt tok/s;    113 s elapsed
Train perplexity: 30.3463
Train accuracy: 44.2135
Validation perplexity: 16.3905
Validation accuracy: 53.1361

Epoch  3,    50/  454; acc:  54.49; ppl:  14.50; 3239 src tok/s; 3371 tgt tok/s;     13 s elapsed
Epoch  3,   100/  454; acc:  54.36; ppl:  14.50; 3383 src tok/s; 3493 tgt tok/s;     25 s elapsed
Epoch  3,   150/  454; acc:  54.76; ppl:  14.33; 3325 src tok/s; 3449 tgt tok/s;     38 s elapsed
Epoch  3,   200/  454; acc:  56.47; ppl:  12.79; 3354 src tok/s; 3502 tgt tok/s;     50 s elapsed
Epoch  3,   250/  454; acc:  57.89; ppl:  11.73; 3249 src tok/s; 3400 tgt tok/s;     63 s elapsed
Epoch  3,   300/  454; acc:  55.86; ppl:  13.08; 3325 src tok/s; 3415 tgt tok/s;     76 s elapsed
Epoch  3,   350/  454; acc:  57.57; ppl:  11.78; 3332 src tok/s; 3447 tgt tok/s;     89 s elapsed
Epoch  3,   400/  454; acc:  59.02; ppl:  10.84; 3329 src tok/s; 3481 tgt tok/s;    101 s elapsed
Epoch  3,   450/  454; acc:  58.25; ppl:  11.19; 3374 src tok/s; 3482 tgt tok/s;    114 s elapsed
Train perplexity: 12.6548
Train accuracy: 56.5497
Validation perplexity: 10.1319
Validation accuracy: 60.6854

Epoch  4,    50/  454; acc:  62.50; ppl:   8.04; 3329 src tok/s; 3479 tgt tok/s;     12 s elapsed
Epoch  4,   100/  454; acc:  61.47; ppl:   8.54; 3324 src tok/s; 3448 tgt tok/s;     25 s elapsed
Epoch  4,   150/  454; acc:  60.56; ppl:   8.98; 3324 src tok/s; 3452 tgt tok/s;     38 s elapsed
Epoch  4,   200/  454; acc:  62.56; ppl:   8.08; 3289 src tok/s; 3402 tgt tok/s;     51 s elapsed
Epoch  4,   250/  454; acc:  62.33; ppl:   8.22; 3291 src tok/s; 3419 tgt tok/s;     63 s elapsed
Epoch  4,   300/  454; acc:  62.33; ppl:   8.06; 3291 src tok/s; 3415 tgt tok/s;     76 s elapsed
Epoch  4,   350/  454; acc:  61.81; ppl:   8.40; 3390 src tok/s; 3519 tgt tok/s;     88 s elapsed
Epoch  4,   400/  454; acc:  62.87; ppl:   7.76; 3328 src tok/s; 3452 tgt tok/s;    101 s elapsed
Epoch  4,   450/  454; acc:  62.39; ppl:   8.07; 3327 src tok/s; 3443 tgt tok/s;    114 s elapsed
Train perplexity: 8.22586
Train accuracy: 62.1003
Validation perplexity: 8.23606
Validation accuracy: 63.8782

Epoch  5,    50/  454; acc:  65.62; ppl:   6.18; 3258 src tok/s; 3381 tgt tok/s;     13 s elapsed
Epoch  5,   100/  454; acc:  66.21; ppl:   6.07; 3319 src tok/s; 3432 tgt tok/s;     25 s elapsed
Epoch  5,   150/  454; acc:  65.27; ppl:   6.33; 3315 src tok/s; 3446 tgt tok/s;     38 s elapsed
Epoch  5,   200/  454; acc:  65.56; ppl:   6.23; 3344 src tok/s; 3464 tgt tok/s;     51 s elapsed
Epoch  5,   250/  454; acc:  65.49; ppl:   6.13; 3324 src tok/s; 3460 tgt tok/s;     63 s elapsed
Epoch  5,   300/  454; acc:  65.16; ppl:   6.26; 3334 src tok/s; 3481 tgt tok/s;     76 s elapsed
Epoch  5,   350/  454; acc:  67.93; ppl:   5.49; 3250 src tok/s; 3415 tgt tok/s;     88 s elapsed
Epoch  5,   400/  454; acc:  63.71; ppl:   6.86; 3414 src tok/s; 3489 tgt tok/s;    101 s elapsed
Epoch  5,   450/  454; acc:  65.98; ppl:   6.15; 3264 src tok/s; 3393 tgt tok/s;    114 s elapsed
Train perplexity: 6.20226
Train accuracy: 65.6041
Validation perplexity: 7.37297
Validation accuracy: 64.382

Epoch  6,    50/  454; acc:  68.59; ppl:   5.00; 3264 src tok/s; 3379 tgt tok/s;     13 s elapsed
Epoch  6,   100/  454; acc:  68.79; ppl:   4.83; 3317 src tok/s; 3441 tgt tok/s;     26 s elapsed
Epoch  6,   150/  454; acc:  68.60; ppl:   4.90; 3341 src tok/s; 3467 tgt tok/s;     38 s elapsed
Epoch  6,   200/  454; acc:  68.03; ppl:   5.04; 3296 src tok/s; 3433 tgt tok/s;     51 s elapsed
Epoch  6,   250/  454; acc:  68.03; ppl:   5.10; 3334 src tok/s; 3449 tgt tok/s;     63 s elapsed
Epoch  6,   300/  454; acc:  68.11; ppl:   4.99; 3342 src tok/s; 3483 tgt tok/s;     76 s elapsed
Epoch  6,   350/  454; acc:  68.96; ppl:   4.83; 3255 src tok/s; 3397 tgt tok/s;     88 s elapsed
Epoch  6,   400/  454; acc:  67.46; ppl:   5.29; 3326 src tok/s; 3445 tgt tok/s;    101 s elapsed
Epoch  6,   450/  454; acc:  68.06; ppl:   5.04; 3321 src tok/s; 3435 tgt tok/s;    114 s elapsed
Train perplexity: 5.00084
Train accuracy: 68.2885
Validation perplexity: 6.87206
Validation accuracy: 66.4467

Epoch  7,    50/  454; acc:  70.90; ppl:   4.06; 3322 src tok/s; 3434 tgt tok/s;     13 s elapsed
Epoch  7,   100/  454; acc:  71.48; ppl:   3.81; 3310 src tok/s; 3449 tgt tok/s;     25 s elapsed
Epoch  7,   150/  454; acc:  71.29; ppl:   3.97; 3344 src tok/s; 3467 tgt tok/s;     38 s elapsed
Epoch  7,   200/  454; acc:  70.50; ppl:   4.18; 3230 src tok/s; 3366 tgt tok/s;     51 s elapsed
Epoch  7,   250/  454; acc:  70.37; ppl:   4.19; 3224 src tok/s; 3361 tgt tok/s;     64 s elapsed
Epoch  7,   300/  454; acc:  70.37; ppl:   4.20; 3352 src tok/s; 3464 tgt tok/s;     76 s elapsed
Epoch  7,   350/  454; acc:  69.43; ppl:   4.46; 3330 src tok/s; 3455 tgt tok/s;     89 s elapsed
Epoch  7,   400/  454; acc:  70.20; ppl:   4.28; 3361 src tok/s; 3490 tgt tok/s;    101 s elapsed
Epoch  7,   450/  454; acc:  69.50; ppl:   4.48; 3276 src tok/s; 3391 tgt tok/s;    114 s elapsed
Train perplexity: 4.17832
Train accuracy: 70.4444
Validation perplexity: 6.42551
Validation accuracy: 67.4471

Epoch  8,    50/  454; acc:  73.70; ppl:   3.34; 3381 src tok/s; 3500 tgt tok/s;     13 s elapsed
Epoch  8,   100/  454; acc:  72.65; ppl:   3.57; 3319 src tok/s; 3450 tgt tok/s;     25 s elapsed
Epoch  8,   150/  454; acc:  71.50; ppl:   3.77; 3324 src tok/s; 3438 tgt tok/s;     38 s elapsed
Epoch  8,   200/  454; acc:  73.00; ppl:   3.46; 3233 src tok/s; 3388 tgt tok/s;     51 s elapsed
Epoch  8,   250/  454; acc:  72.05; ppl:   3.58; 3398 src tok/s; 3515 tgt tok/s;     63 s elapsed
Epoch  8,   300/  454; acc:  71.42; ppl:   3.76; 3363 src tok/s; 3485 tgt tok/s;     75 s elapsed
Epoch  8,   350/  454; acc:  70.88; ppl:   3.90; 3313 src tok/s; 3429 tgt tok/s;     89 s elapsed
Epoch  8,   400/  454; acc:  72.95; ppl:   3.52; 3280 src tok/s; 3423 tgt tok/s;    101 s elapsed
Epoch  8,   450/  454; acc:  72.09; ppl:   3.73; 3295 src tok/s; 3407 tgt tok/s;    113 s elapsed
Train perplexity: 3.62268
Train accuracy: 72.2336
Validation perplexity: 6.48636
Validation accuracy: 67.6529
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.63; ppl:   2.83; 3292 src tok/s; 3422 tgt tok/s;     13 s elapsed
Epoch  9,   100/  454; acc:  76.99; ppl:   2.74; 3392 src tok/s; 3499 tgt tok/s;     25 s elapsed
Epoch  9,   150/  454; acc:  77.50; ppl:   2.69; 3240 src tok/s; 3382 tgt tok/s;     38 s elapsed
Epoch  9,   200/  454; acc:  77.58; ppl:   2.68; 3366 src tok/s; 3483 tgt tok/s;     51 s elapsed
Epoch  9,   250/  454; acc:  76.67; ppl:   2.79; 3380 src tok/s; 3480 tgt tok/s;     64 s elapsed
Epoch  9,   300/  454; acc:  78.14; ppl:   2.56; 3294 src tok/s; 3439 tgt tok/s;     76 s elapsed
Epoch  9,   350/  454; acc:  77.53; ppl:   2.64; 3303 src tok/s; 3461 tgt tok/s;     88 s elapsed
Epoch  9,   400/  454; acc:  76.66; ppl:   2.80; 3318 src tok/s; 3416 tgt tok/s;    101 s elapsed
Epoch  9,   450/  454; acc:  77.47; ppl:   2.66; 3276 src tok/s; 3412 tgt tok/s;    114 s elapsed
Train perplexity: 2.70972
Train accuracy: 77.231
Validation perplexity: 6.01444
Validation accuracy: 69.4764
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.69; ppl:   2.16; 3270 src tok/s; 3407 tgt tok/s;     13 s elapsed
Epoch 10,   100/  454; acc:  80.93; ppl:   2.24; 3348 src tok/s; 3474 tgt tok/s;     25 s elapsed
Epoch 10,   150/  454; acc:  80.65; ppl:   2.28; 3358 src tok/s; 3486 tgt tok/s;     38 s elapsed
Epoch 10,   200/  454; acc:  81.55; ppl:   2.18; 3355 src tok/s; 3482 tgt tok/s;     50 s elapsed
Epoch 10,   250/  454; acc:  80.82; ppl:   2.25; 3285 src tok/s; 3409 tgt tok/s;     63 s elapsed
Epoch 10,   300/  454; acc:  81.23; ppl:   2.19; 3378 src tok/s; 3491 tgt tok/s;     75 s elapsed
Epoch 10,   350/  454; acc:  80.66; ppl:   2.26; 3373 src tok/s; 3488 tgt tok/s;     88 s elapsed
Epoch 10,   400/  454; acc:  81.12; ppl:   2.22; 3243 src tok/s; 3383 tgt tok/s;    101 s elapsed
Epoch 10,   450/  454; acc:  81.10; ppl:   2.23; 3226 src tok/s; 3349 tgt tok/s;    114 s elapsed
Train perplexity: 2.22723
Train accuracy: 81.0511
Validation perplexity: 6.15955
Validation accuracy: 69.4835
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  84.22; ppl:   1.93; 3288 src tok/s; 3405 tgt tok/s;     13 s elapsed
Epoch 11,   100/  454; acc:  82.75; ppl:   2.06; 3289 src tok/s; 3412 tgt tok/s;     26 s elapsed
Epoch 11,   150/  454; acc:  83.13; ppl:   1.99; 3285 src tok/s; 3415 tgt tok/s;     38 s elapsed
Epoch 11,   200/  454; acc:  83.00; ppl:   2.05; 3338 src tok/s; 3464 tgt tok/s;     51 s elapsed
Epoch 11,   250/  454; acc:  83.25; ppl:   2.04; 3319 src tok/s; 3453 tgt tok/s;     63 s elapsed
Epoch 11,   300/  454; acc:  83.38; ppl:   1.99; 3317 src tok/s; 3447 tgt tok/s;     76 s elapsed
Epoch 11,   350/  454; acc:  82.33; ppl:   2.10; 3357 src tok/s; 3482 tgt tok/s;     89 s elapsed
Epoch 11,   400/  454; acc:  83.91; ppl:   1.96; 3361 src tok/s; 3505 tgt tok/s;    101 s elapsed
Epoch 11,   450/  454; acc:  83.04; ppl:   2.03; 3261 src tok/s; 3363 tgt tok/s;    114 s elapsed
Train perplexity: 2.01653
Train accuracy: 83.2072
Validation perplexity: 6.31075
Validation accuracy: 69.5757
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  83.87; ppl:   1.95; 3281 src tok/s; 3412 tgt tok/s;     13 s elapsed
Epoch 12,   100/  454; acc:  84.85; ppl:   1.87; 3303 src tok/s; 3441 tgt tok/s;     26 s elapsed
Epoch 12,   150/  454; acc:  84.08; ppl:   1.95; 3288 src tok/s; 3412 tgt tok/s;     38 s elapsed
Epoch 12,   200/  454; acc:  84.46; ppl:   1.89; 3314 src tok/s; 3430 tgt tok/s;     51 s elapsed
Epoch 12,   250/  454; acc:  84.83; ppl:   1.85; 3312 src tok/s; 3450 tgt tok/s;     63 s elapsed
Epoch 12,   300/  454; acc:  83.93; ppl:   1.95; 3331 src tok/s; 3443 tgt tok/s;     76 s elapsed
Epoch 12,   350/  454; acc:  84.73; ppl:   1.88; 3310 src tok/s; 3468 tgt tok/s;     88 s elapsed
Epoch 12,   400/  454; acc:  83.60; ppl:   1.97; 3345 src tok/s; 3447 tgt tok/s;    101 s elapsed
Epoch 12,   450/  454; acc:  83.89; ppl:   1.93; 3323 src tok/s; 3432 tgt tok/s;    114 s elapsed
Train perplexity: 1.91432
Train accuracy: 84.2539
Validation perplexity: 6.39905
Validation accuracy: 69.526
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.90; ppl:   1.88; 3302 src tok/s; 3398 tgt tok/s;     13 s elapsed
Epoch 13,   100/  454; acc:  85.34; ppl:   1.82; 3286 src tok/s; 3432 tgt tok/s;     25 s elapsed
Epoch 13,   150/  454; acc:  84.63; ppl:   1.89; 3307 src tok/s; 3410 tgt tok/s;     38 s elapsed
Epoch 13,   200/  454; acc:  85.01; ppl:   1.86; 3338 src tok/s; 3470 tgt tok/s;     51 s elapsed
Epoch 13,   250/  454; acc:  85.56; ppl:   1.78; 3307 src tok/s; 3447 tgt tok/s;     63 s elapsed
Epoch 13,   300/  454; acc:  84.39; ppl:   1.90; 3376 src tok/s; 3494 tgt tok/s;     76 s elapsed
Epoch 13,   350/  454; acc:  86.42; ppl:   1.72; 3198 src tok/s; 3373 tgt tok/s;     88 s elapsed
Epoch 13,   400/  454; acc:  83.04; ppl:   2.03; 3407 src tok/s; 3502 tgt tok/s;    101 s elapsed
Epoch 13,   450/  454; acc:  84.43; ppl:   1.90; 3322 src tok/s; 3445 tgt tok/s;    114 s elapsed
Train perplexity: 1.86572
Train accuracy: 84.8376
Validation perplexity: 6.45208
Validation accuracy: 69.5473
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  84.42; ppl:   1.91; 3298 src tok/s; 3425 tgt tok/s;     13 s elapsed
Epoch 14,   100/  454; acc:  85.84; ppl:   1.78; 3350 src tok/s; 3466 tgt tok/s;     25 s elapsed
Epoch 14,   150/  454; acc:  85.06; ppl:   1.88; 3354 src tok/s; 3480 tgt tok/s;     38 s elapsed
Epoch 14,   200/  454; acc:  85.29; ppl:   1.83; 3303 src tok/s; 3420 tgt tok/s;     51 s elapsed
Epoch 14,   250/  454; acc:  84.77; ppl:   1.90; 3342 src tok/s; 3450 tgt tok/s;     63 s elapsed
Epoch 14,   300/  454; acc:  85.82; ppl:   1.78; 3304 src tok/s; 3446 tgt tok/s;     76 s elapsed
Epoch 14,   350/  454; acc:  85.34; ppl:   1.83; 3315 src tok/s; 3429 tgt tok/s;     88 s elapsed
Epoch 14,   400/  454; acc:  85.09; ppl:   1.83; 3260 src tok/s; 3407 tgt tok/s;    101 s elapsed
Epoch 14,   450/  454; acc:  84.85; ppl:   1.85; 3291 src tok/s; 3412 tgt tok/s;    114 s elapsed
Train perplexity: 1.84183
Train accuracy: 85.173
Validation perplexity: 6.49468
Validation accuracy: 69.5544
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.42; ppl:   1.83; 3254 src tok/s; 3370 tgt tok/s;     13 s elapsed
Epoch 15,   100/  454; acc:  85.26; ppl:   1.81; 3293 src tok/s; 3428 tgt tok/s;     26 s elapsed
Epoch 15,   150/  454; acc:  85.12; ppl:   1.85; 3345 src tok/s; 3484 tgt tok/s;     38 s elapsed
Epoch 15,   200/  454; acc:  85.32; ppl:   1.84; 3238 src tok/s; 3372 tgt tok/s;     51 s elapsed
Epoch 15,   250/  454; acc:  85.56; ppl:   1.78; 3358 src tok/s; 3477 tgt tok/s;     63 s elapsed
Epoch 15,   300/  454; acc:  84.90; ppl:   1.86; 3375 src tok/s; 3499 tgt tok/s;     76 s elapsed
Epoch 15,   350/  454; acc:  84.92; ppl:   1.88; 3343 src tok/s; 3440 tgt tok/s;     89 s elapsed
Epoch 15,   400/  454; acc:  85.90; ppl:   1.78; 3332 src tok/s; 3484 tgt tok/s;    101 s elapsed
Epoch 15,   450/  454; acc:  84.96; ppl:   1.85; 3327 src tok/s; 3448 tgt tok/s;    114 s elapsed
Train perplexity: 1.83286
Train accuracy: 85.2572
Validation perplexity: 6.50655
Validation accuracy: 69.5615
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.03; ppl:   1.87; 3342 src tok/s; 3443 tgt tok/s;     13 s elapsed
Epoch 16,   100/  454; acc:  85.95; ppl:   1.77; 3352 src tok/s; 3503 tgt tok/s;     25 s elapsed
Epoch 16,   150/  454; acc:  84.60; ppl:   1.92; 3291 src tok/s; 3421 tgt tok/s;     38 s elapsed
Epoch 16,   200/  454; acc:  86.57; ppl:   1.73; 3335 src tok/s; 3479 tgt tok/s;     50 s elapsed
Epoch 16,   250/  454; acc:  85.46; ppl:   1.82; 3272 src tok/s; 3403 tgt tok/s;     63 s elapsed
Epoch 16,   300/  454; acc:  85.23; ppl:   1.83; 3428 src tok/s; 3538 tgt tok/s;     75 s elapsed
Epoch 16,   350/  454; acc:  85.20; ppl:   1.86; 3289 src tok/s; 3414 tgt tok/s;     88 s elapsed
Epoch 16,   400/  454; acc:  85.38; ppl:   1.79; 3307 src tok/s; 3425 tgt tok/s;    101 s elapsed
Epoch 16,   450/  454; acc:  85.21; ppl:   1.86; 3262 src tok/s; 3379 tgt tok/s;    114 s elapsed
Train perplexity: 1.82628
Train accuracy: 85.4186
Validation perplexity: 6.5131
Validation accuracy: 69.4977
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  84.29; ppl:   1.90; 3255 src tok/s; 3355 tgt tok/s;     13 s elapsed
Epoch 17,   100/  454; acc:  87.00; ppl:   1.70; 3313 src tok/s; 3466 tgt tok/s;     26 s elapsed
Epoch 17,   150/  454; acc:  85.41; ppl:   1.83; 3378 src tok/s; 3481 tgt tok/s;     38 s elapsed
Epoch 17,   200/  454; acc:  85.56; ppl:   1.82; 3268 src tok/s; 3414 tgt tok/s;     51 s elapsed
Epoch 17,   250/  454; acc:  84.80; ppl:   1.90; 3352 src tok/s; 3454 tgt tok/s;     64 s elapsed
Epoch 17,   300/  454; acc:  86.19; ppl:   1.74; 3243 src tok/s; 3390 tgt tok/s;     76 s elapsed
Epoch 17,   350/  454; acc:  85.91; ppl:   1.79; 3223 src tok/s; 3374 tgt tok/s;     89 s elapsed
Epoch 17,   400/  454; acc:  84.73; ppl:   1.88; 3436 src tok/s; 3534 tgt tok/s;    101 s elapsed
Epoch 17,   450/  454; acc:  85.12; ppl:   1.85; 3321 src tok/s; 3444 tgt tok/s;    114 s elapsed
Train perplexity: 1.82299
Train accuracy: 85.4299
Validation perplexity: 6.51706
Validation accuracy: 69.5118
Decaying learning rate to 0.000976562
