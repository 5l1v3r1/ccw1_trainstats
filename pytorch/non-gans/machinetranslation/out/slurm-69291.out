<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.3, kappa_enc=0.15, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.15decoder0.30dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.15)
('Using Kappa L2 loss on decoder', 0.3)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.68; ppl: 30044.37; 3777 src tok/s; 3931 tgt tok/s;     11 s elapsed
Epoch  1,   100/  454; acc:  15.02; ppl: 1627.37; 4676 src tok/s; 4836 tgt tok/s;     20 s elapsed
Epoch  1,   150/  454; acc:  18.07; ppl: 536.64; 4541 src tok/s; 4751 tgt tok/s;     29 s elapsed
Epoch  1,   200/  454; acc:  19.87; ppl: 301.21; 4657 src tok/s; 4805 tgt tok/s;     38 s elapsed
Epoch  1,   250/  454; acc:  23.63; ppl: 186.45; 4662 src tok/s; 4846 tgt tok/s;     47 s elapsed
Epoch  1,   300/  454; acc:  26.15; ppl: 137.54; 4654 src tok/s; 4834 tgt tok/s;     56 s elapsed
Epoch  1,   350/  454; acc:  30.01; ppl:  97.19; 4497 src tok/s; 4680 tgt tok/s;     65 s elapsed
Epoch  1,   400/  454; acc:  30.26; ppl:  85.73; 4703 src tok/s; 4844 tgt tok/s;     75 s elapsed
Epoch  1,   450/  454; acc:  32.03; ppl:  73.06; 4562 src tok/s; 4738 tgt tok/s;     84 s elapsed
Train perplexity: 360.332
Train accuracy: 22.7397
Validation perplexity: 68.2214
Validation accuracy: 35.9586

Epoch  2,    50/  454; acc:  34.01; ppl:  59.25; 4560 src tok/s; 4739 tgt tok/s;      9 s elapsed
Epoch  2,   100/  454; acc:  36.90; ppl:  48.76; 4657 src tok/s; 4855 tgt tok/s;     18 s elapsed
Epoch  2,   150/  454; acc:  38.63; ppl:  43.32; 4583 src tok/s; 4745 tgt tok/s;     28 s elapsed
Epoch  2,   200/  454; acc:  41.34; ppl:  36.00; 4588 src tok/s; 4785 tgt tok/s;     37 s elapsed
Epoch  2,   250/  454; acc:  43.58; ppl:  31.32; 4674 src tok/s; 4831 tgt tok/s;     46 s elapsed
Epoch  2,   300/  454; acc:  46.29; ppl:  26.68; 4580 src tok/s; 4760 tgt tok/s;     55 s elapsed
Epoch  2,   350/  454; acc:  47.14; ppl:  24.29; 4593 src tok/s; 4766 tgt tok/s;     64 s elapsed
Epoch  2,   400/  454; acc:  49.07; ppl:  21.71; 4598 src tok/s; 4767 tgt tok/s;     73 s elapsed
Epoch  2,   450/  454; acc:  51.23; ppl:  19.17; 4537 src tok/s; 4711 tgt tok/s;     82 s elapsed
Train perplexity: 32.265
Train accuracy: 43.1349
Validation perplexity: 17.3377
Validation accuracy: 52.7529

Epoch  3,    50/  454; acc:  52.69; ppl:  16.44; 4574 src tok/s; 4764 tgt tok/s;      9 s elapsed
Epoch  3,   100/  454; acc:  54.14; ppl:  15.09; 4653 src tok/s; 4828 tgt tok/s;     18 s elapsed
Epoch  3,   150/  454; acc:  54.70; ppl:  14.22; 4617 src tok/s; 4800 tgt tok/s;     27 s elapsed
Epoch  3,   200/  454; acc:  56.14; ppl:  12.88; 4685 src tok/s; 4872 tgt tok/s;     36 s elapsed
Epoch  3,   250/  454; acc:  57.68; ppl:  11.89; 4545 src tok/s; 4747 tgt tok/s;     45 s elapsed
Epoch  3,   300/  454; acc:  56.46; ppl:  12.91; 4636 src tok/s; 4780 tgt tok/s;     54 s elapsed
Epoch  3,   350/  454; acc:  57.12; ppl:  12.14; 4562 src tok/s; 4705 tgt tok/s;     64 s elapsed
Epoch  3,   400/  454; acc:  58.99; ppl:  10.82; 4648 src tok/s; 4838 tgt tok/s;     73 s elapsed
Epoch  3,   450/  454; acc:  59.09; ppl:  10.54; 4562 src tok/s; 4737 tgt tok/s;     82 s elapsed
Train perplexity: 12.9083
Train accuracy: 56.2835
Validation perplexity: 10.4402
Validation accuracy: 60.6074

Epoch  4,    50/  454; acc:  60.72; ppl:   9.01; 4622 src tok/s; 4764 tgt tok/s;      9 s elapsed
Epoch  4,   100/  454; acc:  62.04; ppl:   8.43; 4629 src tok/s; 4824 tgt tok/s;     18 s elapsed
Epoch  4,   150/  454; acc:  61.51; ppl:   8.47; 4595 src tok/s; 4756 tgt tok/s;     27 s elapsed
Epoch  4,   200/  454; acc:  60.98; ppl:   8.96; 4685 src tok/s; 4837 tgt tok/s;     36 s elapsed
Epoch  4,   250/  454; acc:  61.65; ppl:   8.51; 4671 src tok/s; 4882 tgt tok/s;     45 s elapsed
Epoch  4,   300/  454; acc:  62.63; ppl:   8.08; 4564 src tok/s; 4748 tgt tok/s;     54 s elapsed
Epoch  4,   350/  454; acc:  62.42; ppl:   7.97; 4583 src tok/s; 4792 tgt tok/s;     63 s elapsed
Epoch  4,   400/  454; acc:  62.53; ppl:   8.09; 4562 src tok/s; 4715 tgt tok/s;     73 s elapsed
Epoch  4,   450/  454; acc:  62.71; ppl:   8.01; 4597 src tok/s; 4770 tgt tok/s;     82 s elapsed
Train perplexity: 8.37917
Train accuracy: 61.9171
Validation perplexity: 8.26344
Validation accuracy: 63.4242

Epoch  5,    50/  454; acc:  66.41; ppl:   5.93; 4578 src tok/s; 4771 tgt tok/s;      9 s elapsed
Epoch  5,   100/  454; acc:  64.18; ppl:   6.63; 4693 src tok/s; 4844 tgt tok/s;     18 s elapsed
Epoch  5,   150/  454; acc:  65.37; ppl:   6.35; 4660 src tok/s; 4825 tgt tok/s;     27 s elapsed
Epoch  5,   200/  454; acc:  65.61; ppl:   6.33; 4662 src tok/s; 4818 tgt tok/s;     36 s elapsed
Epoch  5,   250/  454; acc:  65.73; ppl:   6.15; 4589 src tok/s; 4793 tgt tok/s;     45 s elapsed
Epoch  5,   300/  454; acc:  65.28; ppl:   6.28; 4604 src tok/s; 4790 tgt tok/s;     55 s elapsed
Epoch  5,   350/  454; acc:  65.25; ppl:   6.32; 4414 src tok/s; 4581 tgt tok/s;     64 s elapsed
Epoch  5,   400/  454; acc:  65.75; ppl:   6.20; 4664 src tok/s; 4839 tgt tok/s;     73 s elapsed
Epoch  5,   450/  454; acc:  66.22; ppl:   6.02; 4593 src tok/s; 4788 tgt tok/s;     82 s elapsed
Train perplexity: 6.27093
Train accuracy: 65.4496
Validation perplexity: 7.84265
Validation accuracy: 63.4951

Epoch  6,    50/  454; acc:  69.05; ppl:   4.78; 4629 src tok/s; 4792 tgt tok/s;      9 s elapsed
Epoch  6,   100/  454; acc:  68.32; ppl:   4.99; 4624 src tok/s; 4824 tgt tok/s;     18 s elapsed
Epoch  6,   150/  454; acc:  67.20; ppl:   5.23; 4533 src tok/s; 4701 tgt tok/s;     28 s elapsed
Epoch  6,   200/  454; acc:  69.48; ppl:   4.71; 4519 src tok/s; 4723 tgt tok/s;     37 s elapsed
Epoch  6,   250/  454; acc:  67.37; ppl:   5.26; 4580 src tok/s; 4732 tgt tok/s;     46 s elapsed
Epoch  6,   300/  454; acc:  67.87; ppl:   5.08; 4605 src tok/s; 4807 tgt tok/s;     55 s elapsed
Epoch  6,   350/  454; acc:  67.79; ppl:   5.23; 4664 src tok/s; 4818 tgt tok/s;     64 s elapsed
Epoch  6,   400/  454; acc:  67.98; ppl:   5.07; 4647 src tok/s; 4818 tgt tok/s;     73 s elapsed
Epoch  6,   450/  454; acc:  68.00; ppl:   5.04; 4675 src tok/s; 4820 tgt tok/s;     82 s elapsed
Train perplexity: 5.03601
Train accuracy: 68.1316
Validation perplexity: 6.82048
Validation accuracy: 66.248

Epoch  7,    50/  454; acc:  70.66; ppl:   4.16; 4586 src tok/s; 4760 tgt tok/s;      9 s elapsed
Epoch  7,   100/  454; acc:  71.67; ppl:   3.85; 4668 src tok/s; 4835 tgt tok/s;     18 s elapsed
Epoch  7,   150/  454; acc:  71.07; ppl:   3.93; 4544 src tok/s; 4763 tgt tok/s;     27 s elapsed
Epoch  7,   200/  454; acc:  69.09; ppl:   4.43; 4638 src tok/s; 4795 tgt tok/s;     36 s elapsed
Epoch  7,   250/  454; acc:  71.28; ppl:   4.02; 4520 src tok/s; 4718 tgt tok/s;     45 s elapsed
Epoch  7,   300/  454; acc:  68.87; ppl:   4.57; 4672 src tok/s; 4820 tgt tok/s;     54 s elapsed
Epoch  7,   350/  454; acc:  69.64; ppl:   4.44; 4578 src tok/s; 4743 tgt tok/s;     64 s elapsed
Epoch  7,   400/  454; acc:  70.01; ppl:   4.35; 4668 src tok/s; 4833 tgt tok/s;     73 s elapsed
Epoch  7,   450/  454; acc:  69.24; ppl:   4.52; 4560 src tok/s; 4734 tgt tok/s;     82 s elapsed
Train perplexity: 4.24782
Train accuracy: 70.1613
Validation perplexity: 6.58743
Validation accuracy: 66.5035

Epoch  8,    50/  454; acc:  74.21; ppl:   3.28; 4574 src tok/s; 4773 tgt tok/s;      9 s elapsed
Epoch  8,   100/  454; acc:  72.16; ppl:   3.65; 4595 src tok/s; 4758 tgt tok/s;     18 s elapsed
Epoch  8,   150/  454; acc:  73.91; ppl:   3.29; 4533 src tok/s; 4741 tgt tok/s;     27 s elapsed
Epoch  8,   200/  454; acc:  71.31; ppl:   3.81; 4741 src tok/s; 4864 tgt tok/s;     36 s elapsed
Epoch  8,   250/  454; acc:  72.34; ppl:   3.62; 4523 src tok/s; 4695 tgt tok/s;     46 s elapsed
Epoch  8,   300/  454; acc:  71.10; ppl:   3.91; 4530 src tok/s; 4697 tgt tok/s;     55 s elapsed
Epoch  8,   350/  454; acc:  72.18; ppl:   3.58; 4610 src tok/s; 4795 tgt tok/s;     64 s elapsed
Epoch  8,   400/  454; acc:  70.88; ppl:   3.95; 4649 src tok/s; 4824 tgt tok/s;     73 s elapsed
Epoch  8,   450/  454; acc:  71.68; ppl:   3.73; 4560 src tok/s; 4749 tgt tok/s;     82 s elapsed
Train perplexity: 3.6589
Train accuracy: 72.1074
Validation perplexity: 6.51119
Validation accuracy: 67.0782
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.02; ppl:   2.73; 4711 src tok/s; 4873 tgt tok/s;      9 s elapsed
Epoch  9,   100/  454; acc:  76.74; ppl:   2.79; 4660 src tok/s; 4815 tgt tok/s;     18 s elapsed
Epoch  9,   150/  454; acc:  77.61; ppl:   2.68; 4563 src tok/s; 4756 tgt tok/s;     27 s elapsed
Epoch  9,   200/  454; acc:  77.04; ppl:   2.78; 4559 src tok/s; 4749 tgt tok/s;     36 s elapsed
Epoch  9,   250/  454; acc:  77.79; ppl:   2.60; 4633 src tok/s; 4815 tgt tok/s;     45 s elapsed
Epoch  9,   300/  454; acc:  76.62; ppl:   2.83; 4570 src tok/s; 4735 tgt tok/s;     55 s elapsed
Epoch  9,   350/  454; acc:  76.60; ppl:   2.79; 4701 src tok/s; 4858 tgt tok/s;     64 s elapsed
Epoch  9,   400/  454; acc:  77.98; ppl:   2.61; 4565 src tok/s; 4776 tgt tok/s;     73 s elapsed
Epoch  9,   450/  454; acc:  77.42; ppl:   2.67; 4524 src tok/s; 4691 tgt tok/s;     82 s elapsed
Train perplexity: 2.7246
Train accuracy: 77.1562
Validation perplexity: 6.19863
Validation accuracy: 68.6959
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.00; ppl:   2.33; 4610 src tok/s; 4762 tgt tok/s;      9 s elapsed
Epoch 10,   100/  454; acc:  81.45; ppl:   2.18; 4724 src tok/s; 4912 tgt tok/s;     18 s elapsed
Epoch 10,   150/  454; acc:  80.98; ppl:   2.24; 4613 src tok/s; 4780 tgt tok/s;     27 s elapsed
Epoch 10,   200/  454; acc:  81.14; ppl:   2.22; 4571 src tok/s; 4750 tgt tok/s;     36 s elapsed
Epoch 10,   250/  454; acc:  81.06; ppl:   2.21; 4634 src tok/s; 4810 tgt tok/s;     45 s elapsed
Epoch 10,   300/  454; acc:  80.56; ppl:   2.28; 4544 src tok/s; 4730 tgt tok/s;     55 s elapsed
Epoch 10,   350/  454; acc:  79.32; ppl:   2.44; 4630 src tok/s; 4775 tgt tok/s;     64 s elapsed
Epoch 10,   400/  454; acc:  82.26; ppl:   2.07; 4676 src tok/s; 4888 tgt tok/s;     73 s elapsed
Epoch 10,   450/  454; acc:  80.97; ppl:   2.23; 4448 src tok/s; 4615 tgt tok/s;     82 s elapsed
Train perplexity: 2.24651
Train accuracy: 80.8347
Validation perplexity: 6.21764
Validation accuracy: 69.228
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.93; ppl:   1.95; 4510 src tok/s; 4722 tgt tok/s;      9 s elapsed
Epoch 11,   100/  454; acc:  82.41; ppl:   2.12; 4692 src tok/s; 4826 tgt tok/s;     18 s elapsed
Epoch 11,   150/  454; acc:  82.79; ppl:   2.06; 4563 src tok/s; 4752 tgt tok/s;     28 s elapsed
Epoch 11,   200/  454; acc:  83.22; ppl:   2.00; 4604 src tok/s; 4788 tgt tok/s;     37 s elapsed
Epoch 11,   250/  454; acc:  82.46; ppl:   2.12; 4609 src tok/s; 4772 tgt tok/s;     46 s elapsed
Epoch 11,   300/  454; acc:  83.62; ppl:   1.95; 4636 src tok/s; 4816 tgt tok/s;     55 s elapsed
Epoch 11,   350/  454; acc:  84.01; ppl:   1.95; 4483 src tok/s; 4703 tgt tok/s;     64 s elapsed
Epoch 11,   400/  454; acc:  82.27; ppl:   2.08; 4701 src tok/s; 4841 tgt tok/s;     73 s elapsed
Epoch 11,   450/  454; acc:  83.00; ppl:   2.01; 4582 src tok/s; 4743 tgt tok/s;     82 s elapsed
Train perplexity: 2.02857
Train accuracy: 83.0601
Validation perplexity: 6.36961
Validation accuracy: 69.4125
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  83.96; ppl:   1.94; 4559 src tok/s; 4711 tgt tok/s;      9 s elapsed
Epoch 12,   100/  454; acc:  84.61; ppl:   1.89; 4644 src tok/s; 4822 tgt tok/s;     18 s elapsed
Epoch 12,   150/  454; acc:  83.73; ppl:   1.97; 4655 src tok/s; 4837 tgt tok/s;     27 s elapsed
Epoch 12,   200/  454; acc:  84.99; ppl:   1.86; 4607 src tok/s; 4795 tgt tok/s;     36 s elapsed
Epoch 12,   250/  454; acc:  83.89; ppl:   1.95; 4565 src tok/s; 4750 tgt tok/s;     45 s elapsed
Epoch 12,   300/  454; acc:  83.92; ppl:   1.93; 4666 src tok/s; 4839 tgt tok/s;     54 s elapsed
Epoch 12,   350/  454; acc:  84.08; ppl:   1.91; 4669 src tok/s; 4830 tgt tok/s;     64 s elapsed
Epoch 12,   400/  454; acc:  83.82; ppl:   1.97; 4571 src tok/s; 4749 tgt tok/s;     73 s elapsed
Epoch 12,   450/  454; acc:  84.03; ppl:   1.94; 4556 src tok/s; 4729 tgt tok/s;     82 s elapsed
Train perplexity: 1.92665
Train accuracy: 84.1242
Validation perplexity: 6.45863
Validation accuracy: 69.2706
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.49; ppl:   1.91; 4541 src tok/s; 4717 tgt tok/s;      9 s elapsed
Epoch 13,   100/  454; acc:  85.04; ppl:   1.84; 4660 src tok/s; 4836 tgt tok/s;     18 s elapsed
Epoch 13,   150/  454; acc:  85.12; ppl:   1.83; 4638 src tok/s; 4803 tgt tok/s;     27 s elapsed
Epoch 13,   200/  454; acc:  84.38; ppl:   1.93; 4578 src tok/s; 4745 tgt tok/s;     37 s elapsed
Epoch 13,   250/  454; acc:  84.46; ppl:   1.91; 4473 src tok/s; 4644 tgt tok/s;     46 s elapsed
Epoch 13,   300/  454; acc:  84.86; ppl:   1.88; 4587 src tok/s; 4760 tgt tok/s;     55 s elapsed
Epoch 13,   350/  454; acc:  83.86; ppl:   1.93; 4606 src tok/s; 4767 tgt tok/s;     64 s elapsed
Epoch 13,   400/  454; acc:  85.28; ppl:   1.81; 4702 src tok/s; 4907 tgt tok/s;     73 s elapsed
Epoch 13,   450/  454; acc:  84.20; ppl:   1.91; 4531 src tok/s; 4695 tgt tok/s;     82 s elapsed
Train perplexity: 1.88061
Train accuracy: 84.6511
Validation perplexity: 6.51957
Validation accuracy: 69.3699
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  84.04; ppl:   1.94; 4602 src tok/s; 4747 tgt tok/s;     10 s elapsed
Epoch 14,   100/  454; acc:  86.19; ppl:   1.75; 4597 src tok/s; 4790 tgt tok/s;     18 s elapsed
Epoch 14,   150/  454; acc:  86.40; ppl:   1.73; 4645 src tok/s; 4834 tgt tok/s;     27 s elapsed
Epoch 14,   200/  454; acc:  83.89; ppl:   1.97; 4667 src tok/s; 4838 tgt tok/s;     36 s elapsed
Epoch 14,   250/  454; acc:  84.01; ppl:   1.96; 4572 src tok/s; 4703 tgt tok/s;     46 s elapsed
Epoch 14,   300/  454; acc:  85.77; ppl:   1.79; 4490 src tok/s; 4738 tgt tok/s;     55 s elapsed
Epoch 14,   350/  454; acc:  84.53; ppl:   1.89; 4633 src tok/s; 4777 tgt tok/s;     64 s elapsed
Epoch 14,   400/  454; acc:  85.71; ppl:   1.78; 4632 src tok/s; 4832 tgt tok/s;     73 s elapsed
Epoch 14,   450/  454; acc:  84.49; ppl:   1.91; 4530 src tok/s; 4684 tgt tok/s;     82 s elapsed
Train perplexity: 1.85788
Train accuracy: 84.988
Validation perplexity: 6.55169
Validation accuracy: 69.2635
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.78; ppl:   1.81; 4626 src tok/s; 4776 tgt tok/s;      9 s elapsed
Epoch 15,   100/  454; acc:  85.38; ppl:   1.84; 4554 src tok/s; 4736 tgt tok/s;     18 s elapsed
Epoch 15,   150/  454; acc:  85.02; ppl:   1.83; 4608 src tok/s; 4780 tgt tok/s;     27 s elapsed
Epoch 15,   200/  454; acc:  85.27; ppl:   1.85; 4629 src tok/s; 4830 tgt tok/s;     36 s elapsed
Epoch 15,   250/  454; acc:  84.79; ppl:   1.88; 4515 src tok/s; 4681 tgt tok/s;     46 s elapsed
Epoch 15,   300/  454; acc:  84.94; ppl:   1.86; 4606 src tok/s; 4789 tgt tok/s;     55 s elapsed
Epoch 15,   350/  454; acc:  84.41; ppl:   1.91; 4629 src tok/s; 4794 tgt tok/s;     64 s elapsed
Epoch 15,   400/  454; acc:  85.82; ppl:   1.78; 4635 src tok/s; 4834 tgt tok/s;     73 s elapsed
Epoch 15,   450/  454; acc:  85.15; ppl:   1.85; 4549 src tok/s; 4693 tgt tok/s;     82 s elapsed
Train perplexity: 1.84522
Train accuracy: 85.1626
Validation perplexity: 6.55771
Validation accuracy: 69.3132
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.00; ppl:   1.84; 4592 src tok/s; 4781 tgt tok/s;      9 s elapsed
Epoch 16,   100/  454; acc:  84.71; ppl:   1.87; 4643 src tok/s; 4787 tgt tok/s;     18 s elapsed
Epoch 16,   150/  454; acc:  85.03; ppl:   1.88; 4596 src tok/s; 4778 tgt tok/s;     27 s elapsed
Epoch 16,   200/  454; acc:  86.02; ppl:   1.77; 4553 src tok/s; 4740 tgt tok/s;     36 s elapsed
Epoch 16,   250/  454; acc:  85.86; ppl:   1.79; 4478 src tok/s; 4676 tgt tok/s;     46 s elapsed
Epoch 16,   300/  454; acc:  84.58; ppl:   1.88; 4676 src tok/s; 4823 tgt tok/s;     55 s elapsed
Epoch 16,   350/  454; acc:  85.81; ppl:   1.78; 4604 src tok/s; 4786 tgt tok/s;     64 s elapsed
Epoch 16,   400/  454; acc:  84.98; ppl:   1.87; 4531 src tok/s; 4703 tgt tok/s;     73 s elapsed
Epoch 16,   450/  454; acc:  85.18; ppl:   1.87; 4534 src tok/s; 4693 tgt tok/s;     82 s elapsed
Train perplexity: 1.83872
Train accuracy: 85.245
Validation perplexity: 6.56582
Validation accuracy: 69.3132
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  84.65; ppl:   1.88; 4620 src tok/s; 4760 tgt tok/s;     10 s elapsed
Epoch 17,   100/  454; acc:  86.32; ppl:   1.75; 4494 src tok/s; 4720 tgt tok/s;     18 s elapsed
Epoch 17,   150/  454; acc:  85.90; ppl:   1.80; 4630 src tok/s; 4804 tgt tok/s;     27 s elapsed
Epoch 17,   200/  454; acc:  84.63; ppl:   1.89; 4600 src tok/s; 4755 tgt tok/s;     37 s elapsed
Epoch 17,   250/  454; acc:  85.27; ppl:   1.83; 4598 src tok/s; 4774 tgt tok/s;     46 s elapsed
Epoch 17,   300/  454; acc:  84.66; ppl:   1.87; 4617 src tok/s; 4793 tgt tok/s;     55 s elapsed
Epoch 17,   350/  454; acc:  84.77; ppl:   1.87; 4641 src tok/s; 4797 tgt tok/s;     64 s elapsed
Epoch 17,   400/  454; acc:  85.83; ppl:   1.79; 4607 src tok/s; 4801 tgt tok/s;     73 s elapsed
Epoch 17,   450/  454; acc:  85.16; ppl:   1.84; 4546 src tok/s; 4717 tgt tok/s;     82 s elapsed
Train perplexity: 1.83438
Train accuracy: 85.2486
Validation perplexity: 6.56983
Validation accuracy: 69.3203
Decaying learning rate to 0.000976562
