<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.05, kappa_enc=0.25, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.25decoder0.05dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.25)
('Using Kappa L2 loss on decoder', 0.05)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.90; ppl: 24627.70; 5096 src tok/s; 5261 tgt tok/s;      8 s elapsed
Epoch  1,   100/  454; acc:  15.01; ppl: 1235.57; 7185 src tok/s; 7469 tgt tok/s;     14 s elapsed
Epoch  1,   150/  454; acc:  18.19; ppl: 462.16; 6958 src tok/s; 7218 tgt tok/s;     20 s elapsed
Epoch  1,   200/  454; acc:  21.24; ppl: 264.34; 7025 src tok/s; 7325 tgt tok/s;     26 s elapsed
Epoch  1,   250/  454; acc:  23.68; ppl: 187.62; 7207 src tok/s; 7407 tgt tok/s;     32 s elapsed
Epoch  1,   300/  454; acc:  28.43; ppl: 114.66; 6962 src tok/s; 7267 tgt tok/s;     38 s elapsed
Epoch  1,   350/  454; acc:  30.15; ppl:  92.99; 6824 src tok/s; 7132 tgt tok/s;     44 s elapsed
Epoch  1,   400/  454; acc:  30.18; ppl:  88.57; 7178 src tok/s; 7401 tgt tok/s;     50 s elapsed
Epoch  1,   450/  454; acc:  32.83; ppl:  68.81; 6954 src tok/s; 7236 tgt tok/s;     56 s elapsed
Train perplexity: 326.472
Train accuracy: 23.2501
Validation perplexity: 62.2627
Validation accuracy: 33.9293

Epoch  2,    50/  454; acc:  35.92; ppl:  54.89; 6814 src tok/s; 7073 tgt tok/s;      6 s elapsed
Epoch  2,   100/  454; acc:  37.63; ppl:  47.38; 7183 src tok/s; 7440 tgt tok/s;     12 s elapsed
Epoch  2,   150/  454; acc:  40.10; ppl:  40.04; 7204 src tok/s; 7461 tgt tok/s;     18 s elapsed
Epoch  2,   200/  454; acc:  43.38; ppl:  32.80; 7007 src tok/s; 7307 tgt tok/s;     24 s elapsed
Epoch  2,   250/  454; acc:  44.76; ppl:  29.28; 7015 src tok/s; 7245 tgt tok/s;     30 s elapsed
Epoch  2,   300/  454; acc:  47.67; ppl:  23.67; 6981 src tok/s; 7300 tgt tok/s;     36 s elapsed
Epoch  2,   350/  454; acc:  49.30; ppl:  21.94; 7169 src tok/s; 7454 tgt tok/s;     42 s elapsed
Epoch  2,   400/  454; acc:  50.49; ppl:  20.25; 7057 src tok/s; 7311 tgt tok/s;     48 s elapsed
Epoch  2,   450/  454; acc:  50.80; ppl:  19.80; 7033 src tok/s; 7274 tgt tok/s;     54 s elapsed
Train perplexity: 30.0511
Train accuracy: 44.5237
Validation perplexity: 15.7181
Validation accuracy: 53.9946

Epoch  3,    50/  454; acc:  54.63; ppl:  14.35; 7030 src tok/s; 7336 tgt tok/s;      6 s elapsed
Epoch  3,   100/  454; acc:  54.15; ppl:  14.95; 7011 src tok/s; 7225 tgt tok/s;     12 s elapsed
Epoch  3,   150/  454; acc:  55.96; ppl:  12.95; 7057 src tok/s; 7330 tgt tok/s;     18 s elapsed
Epoch  3,   200/  454; acc:  56.52; ppl:  12.81; 7003 src tok/s; 7272 tgt tok/s;     24 s elapsed
Epoch  3,   250/  454; acc:  57.00; ppl:  12.42; 7093 src tok/s; 7361 tgt tok/s;     30 s elapsed
Epoch  3,   300/  454; acc:  57.82; ppl:  11.85; 7031 src tok/s; 7300 tgt tok/s;     36 s elapsed
Epoch  3,   350/  454; acc:  58.70; ppl:  11.22; 7174 src tok/s; 7508 tgt tok/s;     41 s elapsed
Epoch  3,   400/  454; acc:  57.65; ppl:  11.79; 7081 src tok/s; 7308 tgt tok/s;     48 s elapsed
Epoch  3,   450/  454; acc:  58.70; ppl:  10.82; 7040 src tok/s; 7289 tgt tok/s;     53 s elapsed
Train perplexity: 12.4887
Train accuracy: 56.8144
Validation perplexity: 10.2828
Validation accuracy: 60.3874

Epoch  4,    50/  454; acc:  60.63; ppl:   9.07; 7171 src tok/s; 7406 tgt tok/s;      6 s elapsed
Epoch  4,   100/  454; acc:  62.50; ppl:   8.09; 6932 src tok/s; 7227 tgt tok/s;     12 s elapsed
Epoch  4,   150/  454; acc:  60.74; ppl:   9.14; 7083 src tok/s; 7303 tgt tok/s;     18 s elapsed
Epoch  4,   200/  454; acc:  63.08; ppl:   7.87; 6986 src tok/s; 7330 tgt tok/s;     24 s elapsed
Epoch  4,   250/  454; acc:  62.39; ppl:   8.10; 7081 src tok/s; 7361 tgt tok/s;     30 s elapsed
Epoch  4,   300/  454; acc:  62.56; ppl:   7.97; 7066 src tok/s; 7337 tgt tok/s;     36 s elapsed
Epoch  4,   350/  454; acc:  63.65; ppl:   7.50; 6983 src tok/s; 7289 tgt tok/s;     41 s elapsed
Epoch  4,   400/  454; acc:  62.30; ppl:   8.13; 7221 src tok/s; 7446 tgt tok/s;     47 s elapsed
Epoch  4,   450/  454; acc:  62.76; ppl:   8.09; 7032 src tok/s; 7269 tgt tok/s;     53 s elapsed
Train perplexity: 8.21489
Train accuracy: 62.2603
Validation perplexity: 8.57695
Validation accuracy: 63.0339

Epoch  5,    50/  454; acc:  65.20; ppl:   6.39; 6943 src tok/s; 7211 tgt tok/s;      6 s elapsed
Epoch  5,   100/  454; acc:  66.19; ppl:   5.94; 7057 src tok/s; 7362 tgt tok/s;     12 s elapsed
Epoch  5,   150/  454; acc:  65.28; ppl:   6.33; 6873 src tok/s; 7135 tgt tok/s;     18 s elapsed
Epoch  5,   200/  454; acc:  65.63; ppl:   6.26; 7152 src tok/s; 7397 tgt tok/s;     24 s elapsed
Epoch  5,   250/  454; acc:  66.56; ppl:   5.81; 7171 src tok/s; 7489 tgt tok/s;     30 s elapsed
Epoch  5,   300/  454; acc:  64.64; ppl:   6.65; 7145 src tok/s; 7381 tgt tok/s;     36 s elapsed
Epoch  5,   350/  454; acc:  66.22; ppl:   6.03; 6922 src tok/s; 7208 tgt tok/s;     42 s elapsed
Epoch  5,   400/  454; acc:  65.41; ppl:   6.22; 7321 src tok/s; 7546 tgt tok/s;     48 s elapsed
Epoch  5,   450/  454; acc:  65.88; ppl:   6.05; 6994 src tok/s; 7273 tgt tok/s;     53 s elapsed
Train perplexity: 6.19438
Train accuracy: 65.6358
Validation perplexity: 7.49204
Validation accuracy: 64.4813

Epoch  6,    50/  454; acc:  69.76; ppl:   4.59; 6862 src tok/s; 7156 tgt tok/s;      6 s elapsed
Epoch  6,   100/  454; acc:  67.43; ppl:   5.19; 7063 src tok/s; 7290 tgt tok/s;     12 s elapsed
Epoch  6,   150/  454; acc:  69.78; ppl:   4.55; 6859 src tok/s; 7156 tgt tok/s;     18 s elapsed
Epoch  6,   200/  454; acc:  67.40; ppl:   5.31; 7217 src tok/s; 7432 tgt tok/s;     24 s elapsed
Epoch  6,   250/  454; acc:  67.78; ppl:   5.16; 6955 src tok/s; 7256 tgt tok/s;     30 s elapsed
Epoch  6,   300/  454; acc:  68.27; ppl:   5.03; 7250 src tok/s; 7484 tgt tok/s;     36 s elapsed
Epoch  6,   350/  454; acc:  68.20; ppl:   5.01; 7112 src tok/s; 7402 tgt tok/s;     42 s elapsed
Epoch  6,   400/  454; acc:  67.82; ppl:   5.21; 7382 src tok/s; 7625 tgt tok/s;     47 s elapsed
Epoch  6,   450/  454; acc:  67.63; ppl:   5.13; 6985 src tok/s; 7285 tgt tok/s;     53 s elapsed
Train perplexity: 5.02082
Train accuracy: 68.1998
Validation perplexity: 7.22774
Validation accuracy: 66.1203

Epoch  7,    50/  454; acc:  71.50; ppl:   3.96; 6923 src tok/s; 7208 tgt tok/s;      6 s elapsed
Epoch  7,   100/  454; acc:  70.80; ppl:   4.14; 7210 src tok/s; 7428 tgt tok/s;     12 s elapsed
Epoch  7,   150/  454; acc:  72.08; ppl:   3.78; 7148 src tok/s; 7492 tgt tok/s;     17 s elapsed
Epoch  7,   200/  454; acc:  69.20; ppl:   4.47; 7269 src tok/s; 7474 tgt tok/s;     24 s elapsed
Epoch  7,   250/  454; acc:  71.10; ppl:   4.03; 7161 src tok/s; 7441 tgt tok/s;     29 s elapsed
Epoch  7,   300/  454; acc:  69.64; ppl:   4.33; 7128 src tok/s; 7404 tgt tok/s;     35 s elapsed
Epoch  7,   350/  454; acc:  70.11; ppl:   4.24; 6970 src tok/s; 7276 tgt tok/s;     41 s elapsed
Epoch  7,   400/  454; acc:  68.99; ppl:   4.59; 7324 src tok/s; 7568 tgt tok/s;     47 s elapsed
Epoch  7,   450/  454; acc:  69.77; ppl:   4.29; 7065 src tok/s; 7343 tgt tok/s;     53 s elapsed
Train perplexity: 4.20624
Train accuracy: 70.3162
Validation perplexity: 6.74789
Validation accuracy: 67.1137

Epoch  8,    50/  454; acc:  73.75; ppl:   3.37; 6914 src tok/s; 7198 tgt tok/s;      6 s elapsed
Epoch  8,   100/  454; acc:  72.48; ppl:   3.58; 7160 src tok/s; 7404 tgt tok/s;     12 s elapsed
Epoch  8,   150/  454; acc:  72.35; ppl:   3.56; 6995 src tok/s; 7251 tgt tok/s;     18 s elapsed
Epoch  8,   200/  454; acc:  72.51; ppl:   3.61; 7112 src tok/s; 7415 tgt tok/s;     24 s elapsed
Epoch  8,   250/  454; acc:  71.77; ppl:   3.73; 7006 src tok/s; 7273 tgt tok/s;     30 s elapsed
Epoch  8,   300/  454; acc:  72.53; ppl:   3.54; 7168 src tok/s; 7440 tgt tok/s;     36 s elapsed
Epoch  8,   350/  454; acc:  71.60; ppl:   3.74; 7201 src tok/s; 7449 tgt tok/s;     42 s elapsed
Epoch  8,   400/  454; acc:  71.42; ppl:   3.74; 7168 src tok/s; 7462 tgt tok/s;     47 s elapsed
Epoch  8,   450/  454; acc:  71.34; ppl:   3.82; 7038 src tok/s; 7275 tgt tok/s;     53 s elapsed
Train perplexity: 3.62952
Train accuracy: 72.1959
Validation perplexity: 6.89883
Validation accuracy: 66.9505
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.60; ppl:   2.84; 6946 src tok/s; 7175 tgt tok/s;      6 s elapsed
Epoch  9,   100/  454; acc:  77.62; ppl:   2.66; 6968 src tok/s; 7271 tgt tok/s;     12 s elapsed
Epoch  9,   150/  454; acc:  77.12; ppl:   2.71; 7094 src tok/s; 7375 tgt tok/s;     18 s elapsed
Epoch  9,   200/  454; acc:  77.84; ppl:   2.64; 6964 src tok/s; 7241 tgt tok/s;     24 s elapsed
Epoch  9,   250/  454; acc:  77.46; ppl:   2.68; 7049 src tok/s; 7362 tgt tok/s;     30 s elapsed
Epoch  9,   300/  454; acc:  76.65; ppl:   2.81; 7212 src tok/s; 7445 tgt tok/s;     36 s elapsed
Epoch  9,   350/  454; acc:  78.28; ppl:   2.52; 6862 src tok/s; 7189 tgt tok/s;     41 s elapsed
Epoch  9,   400/  454; acc:  75.61; ppl:   2.91; 7158 src tok/s; 7363 tgt tok/s;     48 s elapsed
Epoch  9,   450/  454; acc:  77.12; ppl:   2.72; 7074 src tok/s; 7322 tgt tok/s;     54 s elapsed
Train perplexity: 2.72071
Train accuracy: 77.1238
Validation perplexity: 6.20049
Validation accuracy: 69.0932
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.49; ppl:   2.17; 6932 src tok/s; 7226 tgt tok/s;      6 s elapsed
Epoch 10,   100/  454; acc:  80.32; ppl:   2.31; 6970 src tok/s; 7176 tgt tok/s;     12 s elapsed
Epoch 10,   150/  454; acc:  81.79; ppl:   2.16; 6931 src tok/s; 7216 tgt tok/s;     18 s elapsed
Epoch 10,   200/  454; acc:  80.54; ppl:   2.29; 7009 src tok/s; 7235 tgt tok/s;     24 s elapsed
Epoch 10,   250/  454; acc:  81.30; ppl:   2.19; 6961 src tok/s; 7217 tgt tok/s;     30 s elapsed
Epoch 10,   300/  454; acc:  80.86; ppl:   2.25; 7043 src tok/s; 7307 tgt tok/s;     36 s elapsed
Epoch 10,   350/  454; acc:  80.39; ppl:   2.28; 6917 src tok/s; 7219 tgt tok/s;     42 s elapsed
Epoch 10,   400/  454; acc:  80.98; ppl:   2.21; 7177 src tok/s; 7463 tgt tok/s;     48 s elapsed
Epoch 10,   450/  454; acc:  80.37; ppl:   2.28; 7115 src tok/s; 7388 tgt tok/s;     54 s elapsed
Train perplexity: 2.2372
Train accuracy: 80.8892
Validation perplexity: 6.21973
Validation accuracy: 69.2635
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  82.33; ppl:   2.09; 6844 src tok/s; 7103 tgt tok/s;      6 s elapsed
Epoch 11,   100/  454; acc:  84.15; ppl:   1.90; 7137 src tok/s; 7412 tgt tok/s;     12 s elapsed
Epoch 11,   150/  454; acc:  83.42; ppl:   1.99; 7106 src tok/s; 7393 tgt tok/s;     18 s elapsed
Epoch 11,   200/  454; acc:  82.34; ppl:   2.08; 7231 src tok/s; 7480 tgt tok/s;     24 s elapsed
Epoch 11,   250/  454; acc:  82.94; ppl:   2.01; 7041 src tok/s; 7363 tgt tok/s;     30 s elapsed
Epoch 11,   300/  454; acc:  83.14; ppl:   2.01; 7153 src tok/s; 7394 tgt tok/s;     36 s elapsed
Epoch 11,   350/  454; acc:  82.95; ppl:   2.00; 7072 src tok/s; 7355 tgt tok/s;     41 s elapsed
Epoch 11,   400/  454; acc:  82.86; ppl:   2.06; 7178 src tok/s; 7426 tgt tok/s;     47 s elapsed
Epoch 11,   450/  454; acc:  82.84; ppl:   2.02; 7130 src tok/s; 7385 tgt tok/s;     53 s elapsed
Train perplexity: 2.02187
Train accuracy: 82.9642
Validation perplexity: 6.42302
Validation accuracy: 69.4551
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  83.67; ppl:   1.97; 6865 src tok/s; 7091 tgt tok/s;      6 s elapsed
Epoch 12,   100/  454; acc:  84.93; ppl:   1.84; 6933 src tok/s; 7237 tgt tok/s;     12 s elapsed
Epoch 12,   150/  454; acc:  83.65; ppl:   1.97; 6928 src tok/s; 7207 tgt tok/s;     18 s elapsed
Epoch 12,   200/  454; acc:  84.02; ppl:   1.91; 7023 src tok/s; 7295 tgt tok/s;     24 s elapsed
Epoch 12,   250/  454; acc:  84.64; ppl:   1.90; 6894 src tok/s; 7177 tgt tok/s;     30 s elapsed
Epoch 12,   300/  454; acc:  83.89; ppl:   1.94; 7113 src tok/s; 7351 tgt tok/s;     36 s elapsed
Epoch 12,   350/  454; acc:  84.09; ppl:   1.95; 7212 src tok/s; 7424 tgt tok/s;     42 s elapsed
Epoch 12,   400/  454; acc:  84.46; ppl:   1.88; 7062 src tok/s; 7359 tgt tok/s;     48 s elapsed
Epoch 12,   450/  454; acc:  84.05; ppl:   1.93; 6966 src tok/s; 7240 tgt tok/s;     54 s elapsed
Train perplexity: 1.92238
Train accuracy: 84.1444
Validation perplexity: 6.53068
Validation accuracy: 69.3841
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.04; ppl:   1.95; 7021 src tok/s; 7262 tgt tok/s;      6 s elapsed
Epoch 13,   100/  454; acc:  85.58; ppl:   1.79; 6942 src tok/s; 7235 tgt tok/s;     12 s elapsed
Epoch 13,   150/  454; acc:  84.71; ppl:   1.88; 7317 src tok/s; 7546 tgt tok/s;     18 s elapsed
Epoch 13,   200/  454; acc:  84.98; ppl:   1.87; 6941 src tok/s; 7249 tgt tok/s;     24 s elapsed
Epoch 13,   250/  454; acc:  83.86; ppl:   1.93; 7141 src tok/s; 7381 tgt tok/s;     30 s elapsed
Epoch 13,   300/  454; acc:  84.97; ppl:   1.85; 7115 src tok/s; 7402 tgt tok/s;     36 s elapsed
Epoch 13,   350/  454; acc:  85.04; ppl:   1.84; 7031 src tok/s; 7301 tgt tok/s;     41 s elapsed
Epoch 13,   400/  454; acc:  84.48; ppl:   1.88; 7238 src tok/s; 7541 tgt tok/s;     47 s elapsed
Epoch 13,   450/  454; acc:  84.49; ppl:   1.88; 6968 src tok/s; 7215 tgt tok/s;     53 s elapsed
Train perplexity: 1.87335
Train accuracy: 84.6804
Validation perplexity: 6.60657
Validation accuracy: 69.3628
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.03; ppl:   1.83; 6893 src tok/s; 7171 tgt tok/s;      6 s elapsed
Epoch 14,   100/  454; acc:  85.17; ppl:   1.85; 7202 src tok/s; 7426 tgt tok/s;     12 s elapsed
Epoch 14,   150/  454; acc:  84.62; ppl:   1.90; 6947 src tok/s; 7209 tgt tok/s;     18 s elapsed
Epoch 14,   200/  454; acc:  85.56; ppl:   1.80; 7180 src tok/s; 7439 tgt tok/s;     24 s elapsed
Epoch 14,   250/  454; acc:  84.58; ppl:   1.89; 7153 src tok/s; 7387 tgt tok/s;     30 s elapsed
Epoch 14,   300/  454; acc:  85.66; ppl:   1.78; 7167 src tok/s; 7487 tgt tok/s;     36 s elapsed
Epoch 14,   350/  454; acc:  85.09; ppl:   1.86; 7162 src tok/s; 7414 tgt tok/s;     41 s elapsed
Epoch 14,   400/  454; acc:  84.82; ppl:   1.85; 7018 src tok/s; 7330 tgt tok/s;     47 s elapsed
Epoch 14,   450/  454; acc:  84.23; ppl:   1.92; 7027 src tok/s; 7278 tgt tok/s;     53 s elapsed
Train perplexity: 1.85078
Train accuracy: 84.9938
Validation perplexity: 6.62759
Validation accuracy: 69.3203
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  83.49; ppl:   1.99; 7092 src tok/s; 7283 tgt tok/s;      6 s elapsed
Epoch 15,   100/  454; acc:  86.73; ppl:   1.69; 6902 src tok/s; 7241 tgt tok/s;     12 s elapsed
Epoch 15,   150/  454; acc:  84.39; ppl:   1.92; 6939 src tok/s; 7179 tgt tok/s;     18 s elapsed
Epoch 15,   200/  454; acc:  86.11; ppl:   1.75; 7115 src tok/s; 7426 tgt tok/s;     24 s elapsed
Epoch 15,   250/  454; acc:  84.71; ppl:   1.88; 7374 src tok/s; 7627 tgt tok/s;     30 s elapsed
Epoch 15,   300/  454; acc:  85.59; ppl:   1.80; 7007 src tok/s; 7316 tgt tok/s;     36 s elapsed
Epoch 15,   350/  454; acc:  85.88; ppl:   1.79; 7227 src tok/s; 7472 tgt tok/s;     41 s elapsed
Epoch 15,   400/  454; acc:  84.69; ppl:   1.88; 7045 src tok/s; 7294 tgt tok/s;     47 s elapsed
Epoch 15,   450/  454; acc:  85.25; ppl:   1.83; 7010 src tok/s; 7281 tgt tok/s;     53 s elapsed
Train perplexity: 1.83765
Train accuracy: 85.1739
Validation perplexity: 6.64776
Validation accuracy: 69.2919
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  84.84; ppl:   1.88; 6891 src tok/s; 7162 tgt tok/s;      6 s elapsed
Epoch 16,   100/  454; acc:  86.11; ppl:   1.75; 6876 src tok/s; 7184 tgt tok/s;     12 s elapsed
Epoch 16,   150/  454; acc:  84.98; ppl:   1.86; 7032 src tok/s; 7332 tgt tok/s;     18 s elapsed
Epoch 16,   200/  454; acc:  85.19; ppl:   1.81; 7176 src tok/s; 7453 tgt tok/s;     24 s elapsed
Epoch 16,   250/  454; acc:  85.22; ppl:   1.83; 7272 src tok/s; 7514 tgt tok/s;     30 s elapsed
Epoch 16,   300/  454; acc:  85.32; ppl:   1.83; 7262 src tok/s; 7538 tgt tok/s;     36 s elapsed
Epoch 16,   350/  454; acc:  84.96; ppl:   1.85; 7041 src tok/s; 7314 tgt tok/s;     41 s elapsed
Epoch 16,   400/  454; acc:  85.37; ppl:   1.82; 7011 src tok/s; 7243 tgt tok/s;     47 s elapsed
Epoch 16,   450/  454; acc:  85.17; ppl:   1.85; 7054 src tok/s; 7277 tgt tok/s;     53 s elapsed
Train perplexity: 1.83158
Train accuracy: 85.2349
Validation perplexity: 6.65504
Validation accuracy: 69.3061
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.94; ppl:   1.77; 6962 src tok/s; 7213 tgt tok/s;      6 s elapsed
Epoch 17,   100/  454; acc:  84.86; ppl:   1.86; 7001 src tok/s; 7261 tgt tok/s;     12 s elapsed
Epoch 17,   150/  454; acc:  84.86; ppl:   1.85; 6919 src tok/s; 7172 tgt tok/s;     18 s elapsed
Epoch 17,   200/  454; acc:  85.61; ppl:   1.80; 7217 src tok/s; 7489 tgt tok/s;     24 s elapsed
Epoch 17,   250/  454; acc:  85.22; ppl:   1.83; 7163 src tok/s; 7449 tgt tok/s;     30 s elapsed
Epoch 17,   300/  454; acc:  84.71; ppl:   1.88; 7160 src tok/s; 7415 tgt tok/s;     36 s elapsed
Epoch 17,   350/  454; acc:  85.34; ppl:   1.81; 7067 src tok/s; 7336 tgt tok/s;     42 s elapsed
Epoch 17,   400/  454; acc:  85.13; ppl:   1.85; 6971 src tok/s; 7271 tgt tok/s;     48 s elapsed
Epoch 17,   450/  454; acc:  85.26; ppl:   1.83; 7243 src tok/s; 7497 tgt tok/s;     53 s elapsed
Train perplexity: 1.83118
Train accuracy: 85.2258
Validation perplexity: 6.66008
Validation accuracy: 69.3699
Decaying learning rate to 0.000976562
