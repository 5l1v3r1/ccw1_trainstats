<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.1, kappa_enc=0.15, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.15decoder0.1dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.15)
('Using Kappa L2 loss on decoder', 0.1)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.46; ppl: 20952.59; 4866 src tok/s; 5029 tgt tok/s;      9 s elapsed
Epoch  1,   100/  454; acc:  14.68; ppl: 1369.83; 6554 src tok/s; 6814 tgt tok/s;     15 s elapsed
Epoch  1,   150/  454; acc:  17.85; ppl: 541.80; 6644 src tok/s; 6840 tgt tok/s;     22 s elapsed
Epoch  1,   200/  454; acc:  21.45; ppl: 255.52; 6667 src tok/s; 6951 tgt tok/s;     28 s elapsed
Epoch  1,   250/  454; acc:  26.02; ppl: 154.61; 6576 src tok/s; 6849 tgt tok/s;     34 s elapsed
Epoch  1,   300/  454; acc:  27.16; ppl: 126.26; 6618 src tok/s; 6899 tgt tok/s;     40 s elapsed
Epoch  1,   350/  454; acc:  28.47; ppl: 102.18; 6731 src tok/s; 6910 tgt tok/s;     47 s elapsed
Epoch  1,   400/  454; acc:  33.22; ppl:  69.60; 6587 src tok/s; 6898 tgt tok/s;     53 s elapsed
Epoch  1,   450/  454; acc:  33.09; ppl:  67.32; 6410 src tok/s; 6667 tgt tok/s;     59 s elapsed
Train perplexity: 320.032
Train accuracy: 23.4179
Validation perplexity: 57.3325
Validation accuracy: 36.8668

Epoch  2,    50/  454; acc:  36.23; ppl:  51.99; 6345 src tok/s; 6594 tgt tok/s;      7 s elapsed
Epoch  2,   100/  454; acc:  38.60; ppl:  46.12; 6529 src tok/s; 6765 tgt tok/s;     13 s elapsed
Epoch  2,   150/  454; acc:  41.63; ppl:  36.58; 6515 src tok/s; 6814 tgt tok/s;     19 s elapsed
Epoch  2,   200/  454; acc:  42.31; ppl:  33.27; 6595 src tok/s; 6803 tgt tok/s;     26 s elapsed
Epoch  2,   250/  454; acc:  46.13; ppl:  26.81; 6512 src tok/s; 6734 tgt tok/s;     32 s elapsed
Epoch  2,   300/  454; acc:  47.22; ppl:  24.46; 6656 src tok/s; 6908 tgt tok/s;     39 s elapsed
Epoch  2,   350/  454; acc:  48.95; ppl:  21.92; 6541 src tok/s; 6820 tgt tok/s;     45 s elapsed
Epoch  2,   400/  454; acc:  49.83; ppl:  20.97; 6501 src tok/s; 6748 tgt tok/s;     51 s elapsed
Epoch  2,   450/  454; acc:  51.49; ppl:  18.80; 6596 src tok/s; 6826 tgt tok/s;     58 s elapsed
Train perplexity: 29.2496
Train accuracy: 44.7991
Validation perplexity: 15.2679
Validation accuracy: 54.8744

Epoch  3,    50/  454; acc:  53.66; ppl:  15.24; 6595 src tok/s; 6804 tgt tok/s;      6 s elapsed
Epoch  3,   100/  454; acc:  55.63; ppl:  13.50; 6414 src tok/s; 6666 tgt tok/s;     13 s elapsed
Epoch  3,   150/  454; acc:  55.98; ppl:  13.28; 6562 src tok/s; 6816 tgt tok/s;     19 s elapsed
Epoch  3,   200/  454; acc:  55.58; ppl:  13.31; 6467 src tok/s; 6748 tgt tok/s;     26 s elapsed
Epoch  3,   250/  454; acc:  57.49; ppl:  12.03; 6465 src tok/s; 6758 tgt tok/s;     32 s elapsed
Epoch  3,   300/  454; acc:  56.88; ppl:  12.40; 6567 src tok/s; 6777 tgt tok/s;     39 s elapsed
Epoch  3,   350/  454; acc:  59.00; ppl:  10.75; 6093 src tok/s; 6370 tgt tok/s;     45 s elapsed
Epoch  3,   400/  454; acc:  58.53; ppl:  11.14; 6726 src tok/s; 6915 tgt tok/s;     52 s elapsed
Epoch  3,   450/  454; acc:  58.57; ppl:  10.94; 6367 src tok/s; 6599 tgt tok/s;     58 s elapsed
Train perplexity: 12.4023
Train accuracy: 56.8583
Validation perplexity: 10.229
Validation accuracy: 60.1887

Epoch  4,    50/  454; acc:  61.13; ppl:   8.99; 6581 src tok/s; 6789 tgt tok/s;      7 s elapsed
Epoch  4,   100/  454; acc:  62.73; ppl:   7.88; 6327 src tok/s; 6612 tgt tok/s;     13 s elapsed
Epoch  4,   150/  454; acc:  62.23; ppl:   8.17; 6439 src tok/s; 6696 tgt tok/s;     20 s elapsed
Epoch  4,   200/  454; acc:  61.54; ppl:   8.64; 6569 src tok/s; 6818 tgt tok/s;     26 s elapsed
Epoch  4,   250/  454; acc:  61.52; ppl:   8.67; 6485 src tok/s; 6683 tgt tok/s;     33 s elapsed
Epoch  4,   300/  454; acc:  62.87; ppl:   7.88; 6607 src tok/s; 6890 tgt tok/s;     39 s elapsed
Epoch  4,   350/  454; acc:  62.91; ppl:   7.68; 6594 src tok/s; 6866 tgt tok/s;     45 s elapsed
Epoch  4,   400/  454; acc:  62.60; ppl:   7.89; 6532 src tok/s; 6751 tgt tok/s;     52 s elapsed
Epoch  4,   450/  454; acc:  62.77; ppl:   7.70; 6374 src tok/s; 6632 tgt tok/s;     58 s elapsed
Train perplexity: 8.15153
Train accuracy: 62.2663
Validation perplexity: 8.36525
Validation accuracy: 63.0623

Epoch  5,    50/  454; acc:  65.40; ppl:   6.35; 6559 src tok/s; 6712 tgt tok/s;      7 s elapsed
Epoch  5,   100/  454; acc:  66.16; ppl:   6.05; 6649 src tok/s; 6949 tgt tok/s;     13 s elapsed
Epoch  5,   150/  454; acc:  65.20; ppl:   6.28; 6800 src tok/s; 7040 tgt tok/s;     19 s elapsed
Epoch  5,   200/  454; acc:  66.20; ppl:   6.01; 6579 src tok/s; 6867 tgt tok/s;     25 s elapsed
Epoch  5,   250/  454; acc:  66.30; ppl:   5.99; 6804 src tok/s; 7081 tgt tok/s;     31 s elapsed
Epoch  5,   300/  454; acc:  64.75; ppl:   6.46; 6445 src tok/s; 6676 tgt tok/s;     38 s elapsed
Epoch  5,   350/  454; acc:  65.83; ppl:   6.05; 6665 src tok/s; 6944 tgt tok/s;     44 s elapsed
Epoch  5,   400/  454; acc:  66.06; ppl:   6.00; 6537 src tok/s; 6793 tgt tok/s;     51 s elapsed
Epoch  5,   450/  454; acc:  66.14; ppl:   6.00; 6600 src tok/s; 6848 tgt tok/s;     57 s elapsed
Train perplexity: 6.14343
Train accuracy: 65.7597
Validation perplexity: 7.21676
Validation accuracy: 65.5882

Epoch  6,    50/  454; acc:  69.36; ppl:   4.71; 6416 src tok/s; 6624 tgt tok/s;      7 s elapsed
Epoch  6,   100/  454; acc:  68.30; ppl:   4.85; 6522 src tok/s; 6774 tgt tok/s;     13 s elapsed
Epoch  6,   150/  454; acc:  68.23; ppl:   4.89; 6650 src tok/s; 6894 tgt tok/s;     19 s elapsed
Epoch  6,   200/  454; acc:  68.51; ppl:   4.99; 6639 src tok/s; 6881 tgt tok/s;     26 s elapsed
Epoch  6,   250/  454; acc:  68.92; ppl:   4.89; 6675 src tok/s; 6969 tgt tok/s;     32 s elapsed
Epoch  6,   300/  454; acc:  67.59; ppl:   5.22; 6641 src tok/s; 6923 tgt tok/s;     38 s elapsed
Epoch  6,   350/  454; acc:  67.73; ppl:   5.24; 6781 src tok/s; 7035 tgt tok/s;     44 s elapsed
Epoch  6,   400/  454; acc:  68.20; ppl:   4.90; 6755 src tok/s; 6986 tgt tok/s;     51 s elapsed
Epoch  6,   450/  454; acc:  68.37; ppl:   4.94; 6622 src tok/s; 6873 tgt tok/s;     57 s elapsed
Train perplexity: 4.9618
Train accuracy: 68.3496
Validation perplexity: 7.03274
Validation accuracy: 66.468

Epoch  7,    50/  454; acc:  72.75; ppl:   3.63; 6506 src tok/s; 6799 tgt tok/s;      6 s elapsed
Epoch  7,   100/  454; acc:  70.00; ppl:   4.32; 6657 src tok/s; 6875 tgt tok/s;     13 s elapsed
Epoch  7,   150/  454; acc:  70.38; ppl:   4.19; 6515 src tok/s; 6787 tgt tok/s;     19 s elapsed
Epoch  7,   200/  454; acc:  71.10; ppl:   4.05; 6599 src tok/s; 6865 tgt tok/s;     26 s elapsed
Epoch  7,   250/  454; acc:  71.35; ppl:   3.91; 6656 src tok/s; 6938 tgt tok/s;     32 s elapsed
Epoch  7,   300/  454; acc:  69.27; ppl:   4.51; 6738 src tok/s; 6955 tgt tok/s;     38 s elapsed
Epoch  7,   350/  454; acc:  70.04; ppl:   4.28; 6778 src tok/s; 6960 tgt tok/s;     44 s elapsed
Epoch  7,   400/  454; acc:  70.33; ppl:   4.16; 6476 src tok/s; 6765 tgt tok/s;     51 s elapsed
Epoch  7,   450/  454; acc:  69.82; ppl:   4.37; 6600 src tok/s; 6844 tgt tok/s;     57 s elapsed
Train perplexity: 4.15879
Train accuracy: 70.5184
Validation perplexity: 6.93392
Validation accuracy: 65.4108

Epoch  8,    50/  454; acc:  72.65; ppl:   3.57; 6485 src tok/s; 6707 tgt tok/s;      7 s elapsed
Epoch  8,   100/  454; acc:  73.24; ppl:   3.38; 6513 src tok/s; 6785 tgt tok/s;     13 s elapsed
Epoch  8,   150/  454; acc:  72.25; ppl:   3.55; 6592 src tok/s; 6873 tgt tok/s;     19 s elapsed
Epoch  8,   200/  454; acc:  72.21; ppl:   3.60; 6629 src tok/s; 6867 tgt tok/s;     26 s elapsed
Epoch  8,   250/  454; acc:  72.68; ppl:   3.52; 6581 src tok/s; 6840 tgt tok/s;     32 s elapsed
Epoch  8,   300/  454; acc:  72.10; ppl:   3.67; 6773 src tok/s; 7030 tgt tok/s;     38 s elapsed
Epoch  8,   350/  454; acc:  72.50; ppl:   3.55; 6749 src tok/s; 6998 tgt tok/s;     44 s elapsed
Epoch  8,   400/  454; acc:  71.65; ppl:   3.75; 6745 src tok/s; 6999 tgt tok/s;     51 s elapsed
Epoch  8,   450/  454; acc:  71.20; ppl:   3.87; 6573 src tok/s; 6788 tgt tok/s;     57 s elapsed
Train perplexity: 3.60618
Train accuracy: 72.2643
Validation perplexity: 6.58662
Validation accuracy: 66.6312
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.35; ppl:   2.84; 6673 src tok/s; 6921 tgt tok/s;      6 s elapsed
Epoch  9,   100/  454; acc:  77.98; ppl:   2.60; 6596 src tok/s; 6878 tgt tok/s;     13 s elapsed
Epoch  9,   150/  454; acc:  78.29; ppl:   2.54; 6616 src tok/s; 6911 tgt tok/s;     19 s elapsed
Epoch  9,   200/  454; acc:  76.84; ppl:   2.76; 6750 src tok/s; 6970 tgt tok/s;     25 s elapsed
Epoch  9,   250/  454; acc:  77.94; ppl:   2.63; 6698 src tok/s; 6939 tgt tok/s;     31 s elapsed
Epoch  9,   300/  454; acc:  76.93; ppl:   2.75; 6432 src tok/s; 6676 tgt tok/s;     38 s elapsed
Epoch  9,   350/  454; acc:  77.16; ppl:   2.72; 6599 src tok/s; 6844 tgt tok/s;     44 s elapsed
Epoch  9,   400/  454; acc:  76.99; ppl:   2.76; 6656 src tok/s; 6901 tgt tok/s;     51 s elapsed
Epoch  9,   450/  454; acc:  77.48; ppl:   2.62; 6510 src tok/s; 6745 tgt tok/s;     57 s elapsed
Train perplexity: 2.69388
Train accuracy: 77.2936
Validation perplexity: 6.11979
Validation accuracy: 69.1145
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  82.18; ppl:   2.10; 6380 src tok/s; 6688 tgt tok/s;      6 s elapsed
Epoch 10,   100/  454; acc:  80.52; ppl:   2.30; 6642 src tok/s; 6855 tgt tok/s;     13 s elapsed
Epoch 10,   150/  454; acc:  80.37; ppl:   2.34; 6588 src tok/s; 6829 tgt tok/s;     19 s elapsed
Epoch 10,   200/  454; acc:  81.76; ppl:   2.13; 6686 src tok/s; 6940 tgt tok/s;     26 s elapsed
Epoch 10,   250/  454; acc:  81.22; ppl:   2.18; 6723 src tok/s; 7010 tgt tok/s;     32 s elapsed
Epoch 10,   300/  454; acc:  81.74; ppl:   2.16; 6630 src tok/s; 6828 tgt tok/s;     38 s elapsed
Epoch 10,   350/  454; acc:  80.87; ppl:   2.25; 6516 src tok/s; 6749 tgt tok/s;     45 s elapsed
Epoch 10,   400/  454; acc:  81.25; ppl:   2.17; 6531 src tok/s; 6794 tgt tok/s;     51 s elapsed
Epoch 10,   450/  454; acc:  80.33; ppl:   2.29; 6494 src tok/s; 6714 tgt tok/s;     57 s elapsed
Train perplexity: 2.21248
Train accuracy: 81.1505
Validation perplexity: 6.32769
Validation accuracy: 69.0294
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.48; ppl:   1.99; 6405 src tok/s; 6680 tgt tok/s;      6 s elapsed
Epoch 11,   100/  454; acc:  83.11; ppl:   1.99; 6333 src tok/s; 6565 tgt tok/s;     13 s elapsed
Epoch 11,   150/  454; acc:  83.11; ppl:   2.03; 6437 src tok/s; 6668 tgt tok/s;     20 s elapsed
Epoch 11,   200/  454; acc:  83.82; ppl:   1.95; 6557 src tok/s; 6807 tgt tok/s;     26 s elapsed
Epoch 11,   250/  454; acc:  83.08; ppl:   2.02; 6482 src tok/s; 6726 tgt tok/s;     33 s elapsed
Epoch 11,   300/  454; acc:  83.37; ppl:   2.00; 6464 src tok/s; 6730 tgt tok/s;     39 s elapsed
Epoch 11,   350/  454; acc:  82.66; ppl:   2.06; 6537 src tok/s; 6781 tgt tok/s;     45 s elapsed
Epoch 11,   400/  454; acc:  83.48; ppl:   1.97; 6445 src tok/s; 6685 tgt tok/s;     52 s elapsed
Epoch 11,   450/  454; acc:  82.98; ppl:   2.01; 6462 src tok/s; 6683 tgt tok/s;     58 s elapsed
Train perplexity: 2.00161
Train accuracy: 83.2342
Validation perplexity: 6.42218
Validation accuracy: 69.2422
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  83.60; ppl:   1.98; 6628 src tok/s; 6850 tgt tok/s;      7 s elapsed
Epoch 12,   100/  454; acc:  85.70; ppl:   1.78; 6442 src tok/s; 6687 tgt tok/s;     13 s elapsed
Epoch 12,   150/  454; acc:  84.76; ppl:   1.88; 6451 src tok/s; 6711 tgt tok/s;     19 s elapsed
Epoch 12,   200/  454; acc:  83.83; ppl:   1.94; 6615 src tok/s; 6866 tgt tok/s;     26 s elapsed
Epoch 12,   250/  454; acc:  83.32; ppl:   2.02; 6579 src tok/s; 6771 tgt tok/s;     32 s elapsed
Epoch 12,   300/  454; acc:  85.38; ppl:   1.79; 6498 src tok/s; 6792 tgt tok/s;     39 s elapsed
Epoch 12,   350/  454; acc:  84.41; ppl:   1.90; 6470 src tok/s; 6737 tgt tok/s;     45 s elapsed
Epoch 12,   400/  454; acc:  84.17; ppl:   1.92; 6684 src tok/s; 6942 tgt tok/s;     51 s elapsed
Epoch 12,   450/  454; acc:  84.48; ppl:   1.89; 6418 src tok/s; 6668 tgt tok/s;     58 s elapsed
Train perplexity: 1.90158
Train accuracy: 84.3864
Validation perplexity: 6.56486
Validation accuracy: 69.5048
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.39; ppl:   1.90; 6271 src tok/s; 6557 tgt tok/s;      7 s elapsed
Epoch 13,   100/  454; acc:  85.52; ppl:   1.82; 6363 src tok/s; 6629 tgt tok/s;     13 s elapsed
Epoch 13,   150/  454; acc:  85.30; ppl:   1.84; 6505 src tok/s; 6765 tgt tok/s;     20 s elapsed
Epoch 13,   200/  454; acc:  85.08; ppl:   1.85; 6592 src tok/s; 6787 tgt tok/s;     26 s elapsed
Epoch 13,   250/  454; acc:  85.60; ppl:   1.80; 6445 src tok/s; 6696 tgt tok/s;     32 s elapsed
Epoch 13,   300/  454; acc:  85.02; ppl:   1.86; 6505 src tok/s; 6715 tgt tok/s;     39 s elapsed
Epoch 13,   350/  454; acc:  84.41; ppl:   1.90; 6498 src tok/s; 6731 tgt tok/s;     46 s elapsed
Epoch 13,   400/  454; acc:  85.16; ppl:   1.83; 6347 src tok/s; 6595 tgt tok/s;     52 s elapsed
Epoch 13,   450/  454; acc:  84.58; ppl:   1.89; 6605 src tok/s; 6853 tgt tok/s;     58 s elapsed
Train perplexity: 1.85618
Train accuracy: 85.0032
Validation perplexity: 6.60903
Validation accuracy: 69.5331
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.10; ppl:   1.83; 6641 src tok/s; 6899 tgt tok/s;      6 s elapsed
Epoch 14,   100/  454; acc:  85.27; ppl:   1.84; 6776 src tok/s; 7028 tgt tok/s;     13 s elapsed
Epoch 14,   150/  454; acc:  84.51; ppl:   1.92; 6798 src tok/s; 6988 tgt tok/s;     19 s elapsed
Epoch 14,   200/  454; acc:  86.30; ppl:   1.75; 6503 src tok/s; 6834 tgt tok/s;     25 s elapsed
Epoch 14,   250/  454; acc:  84.70; ppl:   1.88; 6698 src tok/s; 6909 tgt tok/s;     32 s elapsed
Epoch 14,   300/  454; acc:  85.75; ppl:   1.77; 6624 src tok/s; 6879 tgt tok/s;     38 s elapsed
Epoch 14,   350/  454; acc:  85.28; ppl:   1.83; 6692 src tok/s; 6928 tgt tok/s;     44 s elapsed
Epoch 14,   400/  454; acc:  85.18; ppl:   1.86; 6689 src tok/s; 6953 tgt tok/s;     50 s elapsed
Epoch 14,   450/  454; acc:  85.56; ppl:   1.82; 6469 src tok/s; 6742 tgt tok/s;     57 s elapsed
Train perplexity: 1.83287
Train accuracy: 85.2856
Validation perplexity: 6.65632
Validation accuracy: 69.4764
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.70; ppl:   1.79; 6460 src tok/s; 6722 tgt tok/s;      6 s elapsed
Epoch 15,   100/  454; acc:  85.13; ppl:   1.84; 6691 src tok/s; 6904 tgt tok/s;     13 s elapsed
Epoch 15,   150/  454; acc:  85.51; ppl:   1.81; 6431 src tok/s; 6691 tgt tok/s;     19 s elapsed
Epoch 15,   200/  454; acc:  85.58; ppl:   1.82; 6806 src tok/s; 7056 tgt tok/s;     25 s elapsed
Epoch 15,   250/  454; acc:  84.45; ppl:   1.90; 6601 src tok/s; 6834 tgt tok/s;     32 s elapsed
Epoch 15,   300/  454; acc:  86.28; ppl:   1.74; 6590 src tok/s; 6899 tgt tok/s;     38 s elapsed
Epoch 15,   350/  454; acc:  84.50; ppl:   1.91; 6736 src tok/s; 6960 tgt tok/s;     45 s elapsed
Epoch 15,   400/  454; acc:  86.71; ppl:   1.73; 6747 src tok/s; 7031 tgt tok/s;     51 s elapsed
Epoch 15,   450/  454; acc:  84.94; ppl:   1.86; 6594 src tok/s; 6809 tgt tok/s;     57 s elapsed
Train perplexity: 1.82106
Train accuracy: 85.4357
Validation perplexity: 6.67179
Validation accuracy: 69.5189
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.27; ppl:   1.83; 6572 src tok/s; 6765 tgt tok/s;      7 s elapsed
Epoch 16,   100/  454; acc:  85.84; ppl:   1.79; 6619 src tok/s; 6895 tgt tok/s;     13 s elapsed
Epoch 16,   150/  454; acc:  84.67; ppl:   1.89; 6677 src tok/s; 6904 tgt tok/s;     19 s elapsed
Epoch 16,   200/  454; acc:  86.59; ppl:   1.73; 6505 src tok/s; 6844 tgt tok/s;     25 s elapsed
Epoch 16,   250/  454; acc:  86.64; ppl:   1.72; 6597 src tok/s; 6913 tgt tok/s;     32 s elapsed
Epoch 16,   300/  454; acc:  84.47; ppl:   1.90; 6640 src tok/s; 6821 tgt tok/s;     38 s elapsed
Epoch 16,   350/  454; acc:  85.17; ppl:   1.84; 6824 src tok/s; 7064 tgt tok/s;     44 s elapsed
Epoch 16,   400/  454; acc:  85.63; ppl:   1.80; 6739 src tok/s; 6993 tgt tok/s;     51 s elapsed
Epoch 16,   450/  454; acc:  85.29; ppl:   1.82; 6562 src tok/s; 6806 tgt tok/s;     57 s elapsed
Train perplexity: 1.81474
Train accuracy: 85.4957
Validation perplexity: 6.67674
Validation accuracy: 69.526
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  84.67; ppl:   1.88; 6551 src tok/s; 6747 tgt tok/s;      7 s elapsed
Epoch 17,   100/  454; acc:  86.54; ppl:   1.72; 6664 src tok/s; 7001 tgt tok/s;     13 s elapsed
Epoch 17,   150/  454; acc:  85.56; ppl:   1.80; 6687 src tok/s; 6900 tgt tok/s;     19 s elapsed
Epoch 17,   200/  454; acc:  85.13; ppl:   1.85; 6692 src tok/s; 6956 tgt tok/s;     25 s elapsed
Epoch 17,   250/  454; acc:  84.80; ppl:   1.90; 6792 src tok/s; 7018 tgt tok/s;     32 s elapsed
Epoch 17,   300/  454; acc:  86.59; ppl:   1.72; 6640 src tok/s; 6912 tgt tok/s;     38 s elapsed
Epoch 17,   350/  454; acc:  85.06; ppl:   1.85; 6744 src tok/s; 6954 tgt tok/s;     44 s elapsed
Epoch 17,   400/  454; acc:  85.94; ppl:   1.77; 6579 src tok/s; 6886 tgt tok/s;     50 s elapsed
Epoch 17,   450/  454; acc:  85.22; ppl:   1.83; 6518 src tok/s; 6777 tgt tok/s;     57 s elapsed
Train perplexity: 1.81265
Train accuracy: 85.485
Validation perplexity: 6.68236
Validation accuracy: 69.4906
Decaying learning rate to 0.000976562
