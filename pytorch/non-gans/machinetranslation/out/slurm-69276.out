<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.25, kappa_enc=0.05, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.05decoder0.25dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.05)
('Using Kappa L2 loss on decoder', 0.25)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:  10.03; ppl: 17368.46; 4939 src tok/s; 5164 tgt tok/s;      8 s elapsed
Epoch  1,   100/  454; acc:  15.04; ppl: 1378.47; 5484 src tok/s; 5680 tgt tok/s;     16 s elapsed
Epoch  1,   150/  454; acc:  18.49; ppl: 513.07; 5489 src tok/s; 5702 tgt tok/s;     24 s elapsed
Epoch  1,   200/  454; acc:  20.60; ppl: 277.43; 5588 src tok/s; 5767 tgt tok/s;     31 s elapsed
Epoch  1,   250/  454; acc:  24.01; ppl: 169.87; 5446 src tok/s; 5654 tgt tok/s;     39 s elapsed
Epoch  1,   300/  454; acc:  27.16; ppl: 126.45; 5466 src tok/s; 5688 tgt tok/s;     47 s elapsed
Epoch  1,   350/  454; acc:  29.35; ppl:  97.64; 5585 src tok/s; 5786 tgt tok/s;     54 s elapsed
Epoch  1,   400/  454; acc:  31.07; ppl:  81.31; 5458 src tok/s; 5664 tgt tok/s;     62 s elapsed
Epoch  1,   450/  454; acc:  32.51; ppl:  69.92; 5390 src tok/s; 5590 tgt tok/s;     69 s elapsed
Train perplexity: 317.866
Train accuracy: 23.2377
Validation perplexity: 60.1772
Validation accuracy: 35.5045

Epoch  2,    50/  454; acc:  34.02; ppl:  59.77; 5602 src tok/s; 5768 tgt tok/s;      8 s elapsed
Epoch  2,   100/  454; acc:  37.92; ppl:  46.21; 5401 src tok/s; 5644 tgt tok/s;     15 s elapsed
Epoch  2,   150/  454; acc:  38.82; ppl:  43.08; 5644 src tok/s; 5848 tgt tok/s;     23 s elapsed
Epoch  2,   200/  454; acc:  42.81; ppl:  32.98; 5503 src tok/s; 5699 tgt tok/s;     30 s elapsed
Epoch  2,   250/  454; acc:  43.81; ppl:  30.81; 5433 src tok/s; 5654 tgt tok/s;     38 s elapsed
Epoch  2,   300/  454; acc:  47.44; ppl:  24.54; 5538 src tok/s; 5753 tgt tok/s;     46 s elapsed
Epoch  2,   350/  454; acc:  49.45; ppl:  22.01; 5431 src tok/s; 5676 tgt tok/s;     53 s elapsed
Epoch  2,   400/  454; acc:  49.62; ppl:  21.33; 5604 src tok/s; 5785 tgt tok/s;     61 s elapsed
Epoch  2,   450/  454; acc:  51.77; ppl:  18.61; 5443 src tok/s; 5654 tgt tok/s;     68 s elapsed
Train perplexity: 30.9269
Train accuracy: 43.9558
Validation perplexity: 17.5312
Validation accuracy: 53.2283

Epoch  3,    50/  454; acc:  54.71; ppl:  14.55; 5417 src tok/s; 5620 tgt tok/s;      8 s elapsed
Epoch  3,   100/  454; acc:  54.59; ppl:  14.71; 5628 src tok/s; 5840 tgt tok/s;     15 s elapsed
Epoch  3,   150/  454; acc:  56.57; ppl:  13.07; 5522 src tok/s; 5709 tgt tok/s;     23 s elapsed
Epoch  3,   200/  454; acc:  56.00; ppl:  13.09; 5585 src tok/s; 5782 tgt tok/s;     30 s elapsed
Epoch  3,   250/  454; acc:  56.74; ppl:  12.51; 5459 src tok/s; 5677 tgt tok/s;     38 s elapsed
Epoch  3,   300/  454; acc:  57.66; ppl:  11.98; 5464 src tok/s; 5675 tgt tok/s;     46 s elapsed
Epoch  3,   350/  454; acc:  58.42; ppl:  11.26; 5429 src tok/s; 5709 tgt tok/s;     53 s elapsed
Epoch  3,   400/  454; acc:  57.91; ppl:  11.46; 5535 src tok/s; 5694 tgt tok/s;     61 s elapsed
Epoch  3,   450/  454; acc:  58.35; ppl:  11.35; 5315 src tok/s; 5529 tgt tok/s;     69 s elapsed
Train perplexity: 12.6147
Train accuracy: 56.7526
Validation perplexity: 10.3838
Validation accuracy: 59.7275

Epoch  4,    50/  454; acc:  60.90; ppl:   8.85; 5478 src tok/s; 5688 tgt tok/s;      8 s elapsed
Epoch  4,   100/  454; acc:  62.51; ppl:   8.29; 5453 src tok/s; 5705 tgt tok/s;     15 s elapsed
Epoch  4,   150/  454; acc:  62.34; ppl:   8.19; 5468 src tok/s; 5692 tgt tok/s;     23 s elapsed
Epoch  4,   200/  454; acc:  61.29; ppl:   8.65; 5502 src tok/s; 5663 tgt tok/s;     31 s elapsed
Epoch  4,   250/  454; acc:  62.81; ppl:   7.75; 5408 src tok/s; 5637 tgt tok/s;     38 s elapsed
Epoch  4,   300/  454; acc:  61.27; ppl:   8.66; 5498 src tok/s; 5701 tgt tok/s;     46 s elapsed
Epoch  4,   350/  454; acc:  63.23; ppl:   7.79; 5399 src tok/s; 5600 tgt tok/s;     54 s elapsed
Epoch  4,   400/  454; acc:  62.43; ppl:   8.16; 5599 src tok/s; 5790 tgt tok/s;     61 s elapsed
Epoch  4,   450/  454; acc:  62.82; ppl:   7.83; 5427 src tok/s; 5608 tgt tok/s;     69 s elapsed
Train perplexity: 8.22239
Train accuracy: 62.2016
Validation perplexity: 7.97381
Validation accuracy: 64.1691

Epoch  5,    50/  454; acc:  64.84; ppl:   6.39; 5498 src tok/s; 5660 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  66.15; ppl:   5.94; 5557 src tok/s; 5789 tgt tok/s;     15 s elapsed
Epoch  5,   150/  454; acc:  64.65; ppl:   6.60; 5591 src tok/s; 5797 tgt tok/s;     23 s elapsed
Epoch  5,   200/  454; acc:  65.99; ppl:   6.10; 5460 src tok/s; 5671 tgt tok/s;     30 s elapsed
Epoch  5,   250/  454; acc:  65.70; ppl:   6.10; 5464 src tok/s; 5705 tgt tok/s;     38 s elapsed
Epoch  5,   300/  454; acc:  65.81; ppl:   6.20; 5587 src tok/s; 5792 tgt tok/s;     46 s elapsed
Epoch  5,   350/  454; acc:  65.57; ppl:   6.24; 5442 src tok/s; 5636 tgt tok/s;     53 s elapsed
Epoch  5,   400/  454; acc:  65.88; ppl:   6.17; 5412 src tok/s; 5636 tgt tok/s;     61 s elapsed
Epoch  5,   450/  454; acc:  65.70; ppl:   6.08; 5449 src tok/s; 5651 tgt tok/s;     69 s elapsed
Train perplexity: 6.19704
Train accuracy: 65.5937
Validation perplexity: 7.4422
Validation accuracy: 64.8929

Epoch  6,    50/  454; acc:  68.84; ppl:   4.84; 5407 src tok/s; 5624 tgt tok/s;      8 s elapsed
Epoch  6,   100/  454; acc:  68.44; ppl:   4.95; 5004 src tok/s; 5216 tgt tok/s;     16 s elapsed
Epoch  6,   150/  454; acc:  68.57; ppl:   4.88; 5535 src tok/s; 5770 tgt tok/s;     24 s elapsed
Epoch  6,   200/  454; acc:  67.79; ppl:   5.07; 5577 src tok/s; 5757 tgt tok/s;     31 s elapsed
Epoch  6,   250/  454; acc:  67.93; ppl:   5.10; 5582 src tok/s; 5788 tgt tok/s;     39 s elapsed
Epoch  6,   300/  454; acc:  68.57; ppl:   4.84; 5664 src tok/s; 5859 tgt tok/s;     46 s elapsed
Epoch  6,   350/  454; acc:  68.27; ppl:   4.98; 5154 src tok/s; 5353 tgt tok/s;     54 s elapsed
Epoch  6,   400/  454; acc:  67.38; ppl:   5.24; 5494 src tok/s; 5689 tgt tok/s;     62 s elapsed
Epoch  6,   450/  454; acc:  68.01; ppl:   5.10; 5488 src tok/s; 5687 tgt tok/s;     69 s elapsed
Train perplexity: 4.99217
Train accuracy: 68.2143
Validation perplexity: 6.83872
Validation accuracy: 66.1416

Epoch  7,    50/  454; acc:  70.69; ppl:   4.06; 5452 src tok/s; 5640 tgt tok/s;      8 s elapsed
Epoch  7,   100/  454; acc:  71.16; ppl:   3.98; 5536 src tok/s; 5750 tgt tok/s;     15 s elapsed
Epoch  7,   150/  454; acc:  70.32; ppl:   4.21; 5551 src tok/s; 5745 tgt tok/s;     23 s elapsed
Epoch  7,   200/  454; acc:  70.71; ppl:   4.08; 5333 src tok/s; 5571 tgt tok/s;     31 s elapsed
Epoch  7,   250/  454; acc:  69.67; ppl:   4.31; 5566 src tok/s; 5767 tgt tok/s;     38 s elapsed
Epoch  7,   300/  454; acc:  70.71; ppl:   4.08; 5547 src tok/s; 5782 tgt tok/s;     46 s elapsed
Epoch  7,   350/  454; acc:  70.41; ppl:   4.18; 5511 src tok/s; 5716 tgt tok/s;     53 s elapsed
Epoch  7,   400/  454; acc:  69.32; ppl:   4.43; 5526 src tok/s; 5705 tgt tok/s;     61 s elapsed
Epoch  7,   450/  454; acc:  69.41; ppl:   4.42; 5430 src tok/s; 5645 tgt tok/s;     69 s elapsed
Train perplexity: 4.18893
Train accuracy: 70.2802
Validation perplexity: 6.69923
Validation accuracy: 66.5177

Epoch  8,    50/  454; acc:  73.74; ppl:   3.30; 5419 src tok/s; 5645 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  72.58; ppl:   3.55; 5538 src tok/s; 5739 tgt tok/s;     15 s elapsed
Epoch  8,   150/  454; acc:  71.86; ppl:   3.70; 5486 src tok/s; 5700 tgt tok/s;     23 s elapsed
Epoch  8,   200/  454; acc:  72.93; ppl:   3.47; 5536 src tok/s; 5737 tgt tok/s;     31 s elapsed
Epoch  8,   250/  454; acc:  72.80; ppl:   3.49; 5523 src tok/s; 5738 tgt tok/s;     38 s elapsed
Epoch  8,   300/  454; acc:  71.66; ppl:   3.75; 5436 src tok/s; 5621 tgt tok/s;     46 s elapsed
Epoch  8,   350/  454; acc:  71.07; ppl:   3.87; 5583 src tok/s; 5750 tgt tok/s;     54 s elapsed
Epoch  8,   400/  454; acc:  72.48; ppl:   3.60; 5410 src tok/s; 5635 tgt tok/s;     61 s elapsed
Epoch  8,   450/  454; acc:  70.50; ppl:   3.95; 5420 src tok/s; 5647 tgt tok/s;     69 s elapsed
Train perplexity: 3.62803
Train accuracy: 72.1778
Validation perplexity: 6.70195
Validation accuracy: 66.8724
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.18; ppl:   2.72; 5447 src tok/s; 5652 tgt tok/s;      8 s elapsed
Epoch  9,   100/  454; acc:  76.61; ppl:   2.83; 5525 src tok/s; 5718 tgt tok/s;     15 s elapsed
Epoch  9,   150/  454; acc:  77.55; ppl:   2.65; 5526 src tok/s; 5761 tgt tok/s;     23 s elapsed
Epoch  9,   200/  454; acc:  76.46; ppl:   2.84; 5084 src tok/s; 5264 tgt tok/s;     31 s elapsed
Epoch  9,   250/  454; acc:  77.46; ppl:   2.67; 5531 src tok/s; 5728 tgt tok/s;     39 s elapsed
Epoch  9,   300/  454; acc:  77.21; ppl:   2.68; 5569 src tok/s; 5767 tgt tok/s;     46 s elapsed
Epoch  9,   350/  454; acc:  77.63; ppl:   2.67; 5564 src tok/s; 5803 tgt tok/s;     54 s elapsed
Epoch  9,   400/  454; acc:  77.57; ppl:   2.65; 5262 src tok/s; 5467 tgt tok/s;     62 s elapsed
Epoch  9,   450/  454; acc:  76.63; ppl:   2.78; 5449 src tok/s; 5642 tgt tok/s;     69 s elapsed
Train perplexity: 2.71648
Train accuracy: 77.1709
Validation perplexity: 6.11672
Validation accuracy: 68.8307
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.59; ppl:   2.28; 5455 src tok/s; 5628 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  81.79; ppl:   2.15; 5412 src tok/s; 5644 tgt tok/s;     15 s elapsed
Epoch 10,   150/  454; acc:  80.01; ppl:   2.34; 5524 src tok/s; 5734 tgt tok/s;     23 s elapsed
Epoch 10,   200/  454; acc:  81.47; ppl:   2.17; 5558 src tok/s; 5761 tgt tok/s;     31 s elapsed
Epoch 10,   250/  454; acc:  81.43; ppl:   2.18; 5393 src tok/s; 5604 tgt tok/s;     38 s elapsed
Epoch 10,   300/  454; acc:  80.30; ppl:   2.29; 5487 src tok/s; 5672 tgt tok/s;     46 s elapsed
Epoch 10,   350/  454; acc:  80.71; ppl:   2.24; 5510 src tok/s; 5750 tgt tok/s;     54 s elapsed
Epoch 10,   400/  454; acc:  80.72; ppl:   2.24; 5496 src tok/s; 5723 tgt tok/s;     61 s elapsed
Epoch 10,   450/  454; acc:  80.64; ppl:   2.24; 5326 src tok/s; 5510 tgt tok/s;     69 s elapsed
Train perplexity: 2.23566
Train accuracy: 80.8552
Validation perplexity: 6.17258
Validation accuracy: 69.3274
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.46; ppl:   1.98; 5275 src tok/s; 5520 tgt tok/s;      8 s elapsed
Epoch 11,   100/  454; acc:  82.55; ppl:   2.08; 5593 src tok/s; 5773 tgt tok/s;     16 s elapsed
Epoch 11,   150/  454; acc:  83.11; ppl:   2.01; 5521 src tok/s; 5711 tgt tok/s;     23 s elapsed
Epoch 11,   200/  454; acc:  83.08; ppl:   2.01; 5506 src tok/s; 5695 tgt tok/s;     31 s elapsed
Epoch 11,   250/  454; acc:  83.23; ppl:   1.99; 5585 src tok/s; 5770 tgt tok/s;     38 s elapsed
Epoch 11,   300/  454; acc:  83.26; ppl:   1.99; 5530 src tok/s; 5760 tgt tok/s;     46 s elapsed
Epoch 11,   350/  454; acc:  82.62; ppl:   2.08; 5581 src tok/s; 5791 tgt tok/s;     54 s elapsed
Epoch 11,   400/  454; acc:  83.23; ppl:   1.99; 5326 src tok/s; 5578 tgt tok/s;     61 s elapsed
Epoch 11,   450/  454; acc:  82.74; ppl:   2.05; 5345 src tok/s; 5547 tgt tok/s;     69 s elapsed
Train perplexity: 2.01963
Train accuracy: 83.0263
Validation perplexity: 6.36626
Validation accuracy: 69.1358
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.83; ppl:   1.85; 5383 src tok/s; 5628 tgt tok/s;      8 s elapsed
Epoch 12,   100/  454; acc:  83.60; ppl:   1.99; 5604 src tok/s; 5798 tgt tok/s;     15 s elapsed
Epoch 12,   150/  454; acc:  84.45; ppl:   1.88; 5523 src tok/s; 5727 tgt tok/s;     23 s elapsed
Epoch 12,   200/  454; acc:  84.45; ppl:   1.90; 5535 src tok/s; 5712 tgt tok/s;     30 s elapsed
Epoch 12,   250/  454; acc:  84.03; ppl:   1.95; 5366 src tok/s; 5579 tgt tok/s;     38 s elapsed
Epoch 12,   300/  454; acc:  84.15; ppl:   1.94; 5658 src tok/s; 5838 tgt tok/s;     46 s elapsed
Epoch 12,   350/  454; acc:  84.04; ppl:   1.94; 5351 src tok/s; 5577 tgt tok/s;     53 s elapsed
Epoch 12,   400/  454; acc:  84.26; ppl:   1.92; 5448 src tok/s; 5676 tgt tok/s;     61 s elapsed
Epoch 12,   450/  454; acc:  84.24; ppl:   1.91; 5465 src tok/s; 5663 tgt tok/s;     69 s elapsed
Train perplexity: 1.91855
Train accuracy: 84.2354
Validation perplexity: 6.39235
Validation accuracy: 69.4551
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  83.69; ppl:   1.97; 5517 src tok/s; 5687 tgt tok/s;      8 s elapsed
Epoch 13,   100/  454; acc:  86.45; ppl:   1.73; 5527 src tok/s; 5747 tgt tok/s;     15 s elapsed
Epoch 13,   150/  454; acc:  84.74; ppl:   1.87; 5428 src tok/s; 5641 tgt tok/s;     23 s elapsed
Epoch 13,   200/  454; acc:  84.71; ppl:   1.86; 5523 src tok/s; 5733 tgt tok/s;     31 s elapsed
Epoch 13,   250/  454; acc:  85.18; ppl:   1.83; 5491 src tok/s; 5700 tgt tok/s;     38 s elapsed
Epoch 13,   300/  454; acc:  84.23; ppl:   1.94; 5494 src tok/s; 5690 tgt tok/s;     46 s elapsed
Epoch 13,   350/  454; acc:  84.51; ppl:   1.90; 5463 src tok/s; 5675 tgt tok/s;     54 s elapsed
Epoch 13,   400/  454; acc:  84.74; ppl:   1.85; 5556 src tok/s; 5782 tgt tok/s;     61 s elapsed
Epoch 13,   450/  454; acc:  85.07; ppl:   1.84; 5357 src tok/s; 5576 tgt tok/s;     69 s elapsed
Train perplexity: 1.87093
Train accuracy: 84.7408
Validation perplexity: 6.48262
Validation accuracy: 69.3132
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.43; ppl:   1.83; 5376 src tok/s; 5575 tgt tok/s;      8 s elapsed
Epoch 14,   100/  454; acc:  84.82; ppl:   1.87; 5360 src tok/s; 5605 tgt tok/s;     16 s elapsed
Epoch 14,   150/  454; acc:  84.83; ppl:   1.88; 5573 src tok/s; 5764 tgt tok/s;     23 s elapsed
Epoch 14,   200/  454; acc:  85.31; ppl:   1.82; 5418 src tok/s; 5636 tgt tok/s;     31 s elapsed
Epoch 14,   250/  454; acc:  84.32; ppl:   1.91; 5514 src tok/s; 5694 tgt tok/s;     39 s elapsed
Epoch 14,   300/  454; acc:  86.32; ppl:   1.76; 5402 src tok/s; 5638 tgt tok/s;     46 s elapsed
Epoch 14,   350/  454; acc:  85.33; ppl:   1.81; 5561 src tok/s; 5786 tgt tok/s;     54 s elapsed
Epoch 14,   400/  454; acc:  84.47; ppl:   1.89; 5476 src tok/s; 5666 tgt tok/s;     61 s elapsed
Epoch 14,   450/  454; acc:  84.98; ppl:   1.84; 5519 src tok/s; 5708 tgt tok/s;     69 s elapsed
Train perplexity: 1.84739
Train accuracy: 85.0501
Validation perplexity: 6.50771
Validation accuracy: 69.2706
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  84.86; ppl:   1.87; 5516 src tok/s; 5732 tgt tok/s;      8 s elapsed
Epoch 15,   100/  454; acc:  85.12; ppl:   1.80; 5502 src tok/s; 5686 tgt tok/s;     15 s elapsed
Epoch 15,   150/  454; acc:  85.30; ppl:   1.85; 5486 src tok/s; 5680 tgt tok/s;     23 s elapsed
Epoch 15,   200/  454; acc:  85.08; ppl:   1.84; 5496 src tok/s; 5716 tgt tok/s;     31 s elapsed
Epoch 15,   250/  454; acc:  86.36; ppl:   1.74; 5282 src tok/s; 5559 tgt tok/s;     38 s elapsed
Epoch 15,   300/  454; acc:  84.33; ppl:   1.93; 5670 src tok/s; 5830 tgt tok/s;     46 s elapsed
Epoch 15,   350/  454; acc:  84.78; ppl:   1.87; 5451 src tok/s; 5642 tgt tok/s;     54 s elapsed
Epoch 15,   400/  454; acc:  85.62; ppl:   1.79; 5504 src tok/s; 5721 tgt tok/s;     61 s elapsed
Epoch 15,   450/  454; acc:  84.85; ppl:   1.85; 5407 src tok/s; 5616 tgt tok/s;     69 s elapsed
Train perplexity: 1.83522
Train accuracy: 85.1564
Validation perplexity: 6.5192
Validation accuracy: 69.2777
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.41; ppl:   1.81; 5546 src tok/s; 5749 tgt tok/s;      7 s elapsed
Epoch 16,   100/  454; acc:  85.29; ppl:   1.83; 5436 src tok/s; 5626 tgt tok/s;     15 s elapsed
Epoch 16,   150/  454; acc:  84.87; ppl:   1.85; 5464 src tok/s; 5676 tgt tok/s;     23 s elapsed
Epoch 16,   200/  454; acc:  85.19; ppl:   1.82; 5456 src tok/s; 5637 tgt tok/s;     31 s elapsed
Epoch 16,   250/  454; acc:  85.09; ppl:   1.86; 5395 src tok/s; 5648 tgt tok/s;     38 s elapsed
Epoch 16,   300/  454; acc:  85.33; ppl:   1.83; 5584 src tok/s; 5767 tgt tok/s;     46 s elapsed
Epoch 16,   350/  454; acc:  85.00; ppl:   1.84; 5447 src tok/s; 5630 tgt tok/s;     54 s elapsed
Epoch 16,   400/  454; acc:  85.37; ppl:   1.82; 5591 src tok/s; 5827 tgt tok/s;     61 s elapsed
Epoch 16,   450/  454; acc:  84.98; ppl:   1.84; 5410 src tok/s; 5642 tgt tok/s;     69 s elapsed
Train perplexity: 1.83033
Train accuracy: 85.2024
Validation perplexity: 6.52917
Validation accuracy: 69.2706
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.33; ppl:   1.81; 5367 src tok/s; 5553 tgt tok/s;      8 s elapsed
Epoch 17,   100/  454; acc:  84.96; ppl:   1.84; 5522 src tok/s; 5761 tgt tok/s;     15 s elapsed
Epoch 17,   150/  454; acc:  85.11; ppl:   1.85; 5429 src tok/s; 5608 tgt tok/s;     23 s elapsed
Epoch 17,   200/  454; acc:  85.73; ppl:   1.79; 5577 src tok/s; 5816 tgt tok/s;     31 s elapsed
Epoch 17,   250/  454; acc:  85.25; ppl:   1.84; 5487 src tok/s; 5672 tgt tok/s;     38 s elapsed
Epoch 17,   300/  454; acc:  85.28; ppl:   1.81; 5575 src tok/s; 5778 tgt tok/s;     46 s elapsed
Epoch 17,   350/  454; acc:  85.51; ppl:   1.81; 5513 src tok/s; 5695 tgt tok/s;     54 s elapsed
Epoch 17,   400/  454; acc:  85.27; ppl:   1.82; 5398 src tok/s; 5630 tgt tok/s;     61 s elapsed
Epoch 17,   450/  454; acc:  85.80; ppl:   1.77; 5380 src tok/s; 5624 tgt tok/s;     69 s elapsed
Train perplexity: 1.82424
Train accuracy: 85.261
Validation perplexity: 6.53213
Validation accuracy: 69.2635
Decaying learning rate to 0.000976562
