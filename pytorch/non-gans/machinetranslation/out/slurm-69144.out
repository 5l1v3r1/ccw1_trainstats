<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.0, kappa_enc=0.0, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0decoder0dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.86; ppl: 14293.74; 3774 src tok/s; 3910 tgt tok/s;     11 s elapsed
Epoch  1,   100/  454; acc:  14.96; ppl: 1506.57; 5773 src tok/s; 6018 tgt tok/s;     18 s elapsed
Epoch  1,   150/  454; acc:  18.49; ppl: 461.47; 5967 src tok/s; 6171 tgt tok/s;     26 s elapsed
Epoch  1,   200/  454; acc:  21.41; ppl: 251.11; 5687 src tok/s; 5890 tgt tok/s;     33 s elapsed
Epoch  1,   250/  454; acc:  24.59; ppl: 175.09; 5924 src tok/s; 6098 tgt tok/s;     40 s elapsed
Epoch  1,   300/  454; acc:  28.46; ppl: 118.89; 5820 src tok/s; 6048 tgt tok/s;     47 s elapsed
Epoch  1,   350/  454; acc:  29.96; ppl:  94.62; 5697 src tok/s; 5991 tgt tok/s;     54 s elapsed
Epoch  1,   400/  454; acc:  30.82; ppl:  83.92; 5775 src tok/s; 5962 tgt tok/s;     62 s elapsed
Epoch  1,   450/  454; acc:  33.87; ppl:  64.49; 5724 src tok/s; 5960 tgt tok/s;     69 s elapsed
Train perplexity: 308.948
Train accuracy: 23.5295
Validation perplexity: 57.6193
Validation accuracy: 35.8167

Epoch  2,    50/  454; acc:  36.57; ppl:  50.99; 5747 src tok/s; 5925 tgt tok/s;      7 s elapsed
Epoch  2,   100/  454; acc:  38.25; ppl:  46.89; 5493 src tok/s; 5718 tgt tok/s;     15 s elapsed
Epoch  2,   150/  454; acc:  40.79; ppl:  38.17; 5427 src tok/s; 5612 tgt tok/s;     23 s elapsed
Epoch  2,   200/  454; acc:  43.07; ppl:  31.45; 5499 src tok/s; 5734 tgt tok/s;     30 s elapsed
Epoch  2,   250/  454; acc:  45.17; ppl:  28.16; 5568 src tok/s; 5778 tgt tok/s;     38 s elapsed
Epoch  2,   300/  454; acc:  46.96; ppl:  24.82; 5569 src tok/s; 5798 tgt tok/s;     45 s elapsed
Epoch  2,   350/  454; acc:  49.50; ppl:  21.32; 5681 src tok/s; 5872 tgt tok/s;     53 s elapsed
Epoch  2,   400/  454; acc:  50.19; ppl:  20.60; 5474 src tok/s; 5697 tgt tok/s;     60 s elapsed
Epoch  2,   450/  454; acc:  52.25; ppl:  17.82; 5461 src tok/s; 5672 tgt tok/s;     68 s elapsed
Train perplexity: 29.1615
Train accuracy: 44.7916
Validation perplexity: 16.0957
Validation accuracy: 53.5973

Epoch  3,    50/  454; acc:  53.57; ppl:  15.44; 5543 src tok/s; 5732 tgt tok/s;      8 s elapsed
Epoch  3,   100/  454; acc:  56.16; ppl:  13.26; 5573 src tok/s; 5798 tgt tok/s;     15 s elapsed
Epoch  3,   150/  454; acc:  56.81; ppl:  12.29; 5372 src tok/s; 5603 tgt tok/s;     23 s elapsed
Epoch  3,   200/  454; acc:  55.45; ppl:  13.26; 5567 src tok/s; 5747 tgt tok/s;     30 s elapsed
Epoch  3,   250/  454; acc:  58.18; ppl:  11.63; 5432 src tok/s; 5661 tgt tok/s;     38 s elapsed
Epoch  3,   300/  454; acc:  56.40; ppl:  12.67; 5628 src tok/s; 5814 tgt tok/s;     45 s elapsed
Epoch  3,   350/  454; acc:  59.72; ppl:  10.53; 5447 src tok/s; 5700 tgt tok/s;     53 s elapsed
Epoch  3,   400/  454; acc:  56.89; ppl:  12.23; 5427 src tok/s; 5596 tgt tok/s;     61 s elapsed
Epoch  3,   450/  454; acc:  58.72; ppl:  10.65; 5454 src tok/s; 5692 tgt tok/s;     68 s elapsed
Train perplexity: 12.4059
Train accuracy: 56.8248
Validation perplexity: 10.3752
Validation accuracy: 60.806

Epoch  4,    50/  454; acc:  61.45; ppl:   8.58; 5549 src tok/s; 5750 tgt tok/s;      8 s elapsed
Epoch  4,   100/  454; acc:  62.66; ppl:   8.12; 5629 src tok/s; 5849 tgt tok/s;     15 s elapsed
Epoch  4,   150/  454; acc:  61.49; ppl:   8.58; 5624 src tok/s; 5841 tgt tok/s;     22 s elapsed
Epoch  4,   200/  454; acc:  62.27; ppl:   8.25; 5473 src tok/s; 5691 tgt tok/s;     30 s elapsed
Epoch  4,   250/  454; acc:  62.00; ppl:   8.48; 5428 src tok/s; 5617 tgt tok/s;     38 s elapsed
Epoch  4,   300/  454; acc:  61.95; ppl:   8.21; 5650 src tok/s; 5860 tgt tok/s;     45 s elapsed
Epoch  4,   350/  454; acc:  62.40; ppl:   8.11; 5467 src tok/s; 5651 tgt tok/s;     53 s elapsed
Epoch  4,   400/  454; acc:  63.58; ppl:   7.46; 5480 src tok/s; 5704 tgt tok/s;     61 s elapsed
Epoch  4,   450/  454; acc:  62.93; ppl:   7.75; 5460 src tok/s; 5693 tgt tok/s;     68 s elapsed
Train perplexity: 8.16965
Train accuracy: 62.2761
Validation perplexity: 8.56456
Validation accuracy: 61.8845

Epoch  5,    50/  454; acc:  65.44; ppl:   6.35; 5592 src tok/s; 5809 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  66.59; ppl:   5.87; 5493 src tok/s; 5712 tgt tok/s;     15 s elapsed
Epoch  5,   150/  454; acc:  66.24; ppl:   6.02; 5512 src tok/s; 5719 tgt tok/s;     23 s elapsed
Epoch  5,   200/  454; acc:  65.16; ppl:   6.40; 5484 src tok/s; 5680 tgt tok/s;     30 s elapsed
Epoch  5,   250/  454; acc:  64.44; ppl:   6.68; 5414 src tok/s; 5622 tgt tok/s;     38 s elapsed
Epoch  5,   300/  454; acc:  66.28; ppl:   5.90; 4841 src tok/s; 5022 tgt tok/s;     47 s elapsed
Epoch  5,   350/  454; acc:  64.85; ppl:   6.48; 5345 src tok/s; 5525 tgt tok/s;     55 s elapsed
Epoch  5,   400/  454; acc:  66.26; ppl:   5.91; 5376 src tok/s; 5605 tgt tok/s;     62 s elapsed
Epoch  5,   450/  454; acc:  65.31; ppl:   6.24; 5358 src tok/s; 5540 tgt tok/s;     70 s elapsed
Train perplexity: 6.19644
Train accuracy: 65.6225
Validation perplexity: 7.33203
Validation accuracy: 65.3257

Epoch  6,    50/  454; acc:  69.45; ppl:   4.63; 5371 src tok/s; 5606 tgt tok/s;      8 s elapsed
Epoch  6,   100/  454; acc:  68.07; ppl:   4.99; 5311 src tok/s; 5491 tgt tok/s;     16 s elapsed
Epoch  6,   150/  454; acc:  68.33; ppl:   4.97; 5489 src tok/s; 5689 tgt tok/s;     23 s elapsed
Epoch  6,   200/  454; acc:  68.07; ppl:   5.02; 5515 src tok/s; 5714 tgt tok/s;     31 s elapsed
Epoch  6,   250/  454; acc:  67.60; ppl:   5.23; 5614 src tok/s; 5820 tgt tok/s;     39 s elapsed
Epoch  6,   300/  454; acc:  68.50; ppl:   4.94; 5474 src tok/s; 5694 tgt tok/s;     46 s elapsed
Epoch  6,   350/  454; acc:  68.26; ppl:   4.95; 5443 src tok/s; 5686 tgt tok/s;     54 s elapsed
Epoch  6,   400/  454; acc:  67.20; ppl:   5.28; 5527 src tok/s; 5738 tgt tok/s;     61 s elapsed
Epoch  6,   450/  454; acc:  67.87; ppl:   5.08; 5488 src tok/s; 5651 tgt tok/s;     69 s elapsed
Train perplexity: 5.00282
Train accuracy: 68.1544
Validation perplexity: 7.0135
Validation accuracy: 64.7722

Epoch  7,    50/  454; acc:  71.05; ppl:   3.97; 5452 src tok/s; 5651 tgt tok/s;      8 s elapsed
Epoch  7,   100/  454; acc:  70.84; ppl:   4.16; 5456 src tok/s; 5663 tgt tok/s;     15 s elapsed
Epoch  7,   150/  454; acc:  69.67; ppl:   4.30; 5479 src tok/s; 5652 tgt tok/s;     23 s elapsed
Epoch  7,   200/  454; acc:  71.32; ppl:   3.97; 5440 src tok/s; 5658 tgt tok/s;     31 s elapsed
Epoch  7,   250/  454; acc:  70.47; ppl:   4.14; 5654 src tok/s; 5888 tgt tok/s;     38 s elapsed
Epoch  7,   300/  454; acc:  70.23; ppl:   4.21; 5437 src tok/s; 5648 tgt tok/s;     46 s elapsed
Epoch  7,   350/  454; acc:  69.14; ppl:   4.55; 5675 src tok/s; 5875 tgt tok/s;     54 s elapsed
Epoch  7,   400/  454; acc:  70.78; ppl:   4.12; 5448 src tok/s; 5652 tgt tok/s;     61 s elapsed
Epoch  7,   450/  454; acc:  69.78; ppl:   4.38; 5344 src tok/s; 5567 tgt tok/s;     69 s elapsed
Train perplexity: 4.20138
Train accuracy: 70.3357
Validation perplexity: 6.59925
Validation accuracy: 66.7802

Epoch  8,    50/  454; acc:  73.60; ppl:   3.37; 5451 src tok/s; 5652 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  73.44; ppl:   3.41; 5537 src tok/s; 5698 tgt tok/s;     15 s elapsed
Epoch  8,   150/  454; acc:  73.44; ppl:   3.36; 5470 src tok/s; 5689 tgt tok/s;     23 s elapsed
Epoch  8,   200/  454; acc:  71.62; ppl:   3.81; 5263 src tok/s; 5458 tgt tok/s;     31 s elapsed
Epoch  8,   250/  454; acc:  72.02; ppl:   3.70; 5423 src tok/s; 5641 tgt tok/s;     39 s elapsed
Epoch  8,   300/  454; acc:  71.73; ppl:   3.72; 5499 src tok/s; 5706 tgt tok/s;     46 s elapsed
Epoch  8,   350/  454; acc:  71.32; ppl:   3.73; 5591 src tok/s; 5790 tgt tok/s;     54 s elapsed
Epoch  8,   400/  454; acc:  71.97; ppl:   3.69; 5510 src tok/s; 5746 tgt tok/s;     61 s elapsed
Epoch  8,   450/  454; acc:  71.15; ppl:   3.84; 5502 src tok/s; 5736 tgt tok/s;     69 s elapsed
Train perplexity: 3.62402
Train accuracy: 72.2344
Validation perplexity: 6.95753
Validation accuracy: 66.0139
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.48; ppl:   2.69; 5443 src tok/s; 5676 tgt tok/s;      7 s elapsed
Epoch  9,   100/  454; acc:  77.03; ppl:   2.78; 5631 src tok/s; 5806 tgt tok/s;     15 s elapsed
Epoch  9,   150/  454; acc:  77.90; ppl:   2.63; 5537 src tok/s; 5747 tgt tok/s;     22 s elapsed
Epoch  9,   200/  454; acc:  76.74; ppl:   2.77; 5488 src tok/s; 5674 tgt tok/s;     30 s elapsed
Epoch  9,   250/  454; acc:  77.33; ppl:   2.67; 5500 src tok/s; 5725 tgt tok/s;     38 s elapsed
Epoch  9,   300/  454; acc:  76.80; ppl:   2.76; 5434 src tok/s; 5622 tgt tok/s;     46 s elapsed
Epoch  9,   350/  454; acc:  75.85; ppl:   2.87; 5548 src tok/s; 5718 tgt tok/s;     54 s elapsed
Epoch  9,   400/  454; acc:  78.44; ppl:   2.51; 5486 src tok/s; 5775 tgt tok/s;     61 s elapsed
Epoch  9,   450/  454; acc:  77.18; ppl:   2.69; 5374 src tok/s; 5597 tgt tok/s;     68 s elapsed
Train perplexity: 2.71725
Train accuracy: 77.1148
Validation perplexity: 6.14215
Validation accuracy: 68.9442
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.81; ppl:   2.27; 5622 src tok/s; 5824 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  80.89; ppl:   2.22; 5585 src tok/s; 5808 tgt tok/s;     15 s elapsed
Epoch 10,   150/  454; acc:  81.03; ppl:   2.23; 5496 src tok/s; 5713 tgt tok/s;     23 s elapsed
Epoch 10,   200/  454; acc:  81.25; ppl:   2.20; 5477 src tok/s; 5681 tgt tok/s;     30 s elapsed
Epoch 10,   250/  454; acc:  80.30; ppl:   2.33; 5383 src tok/s; 5576 tgt tok/s;     38 s elapsed
Epoch 10,   300/  454; acc:  81.70; ppl:   2.15; 5591 src tok/s; 5815 tgt tok/s;     46 s elapsed
Epoch 10,   350/  454; acc:  80.67; ppl:   2.28; 5570 src tok/s; 5766 tgt tok/s;     53 s elapsed
Epoch 10,   400/  454; acc:  81.05; ppl:   2.20; 5565 src tok/s; 5770 tgt tok/s;     61 s elapsed
Epoch 10,   450/  454; acc:  81.72; ppl:   2.14; 5511 src tok/s; 5744 tgt tok/s;     68 s elapsed
Train perplexity: 2.2343
Train accuracy: 80.9494
Validation perplexity: 6.24665
Validation accuracy: 69.2919
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.92; ppl:   1.93; 5421 src tok/s; 5622 tgt tok/s;      8 s elapsed
Epoch 11,   100/  454; acc:  82.75; ppl:   2.07; 5707 src tok/s; 5895 tgt tok/s;     15 s elapsed
Epoch 11,   150/  454; acc:  83.09; ppl:   2.07; 5412 src tok/s; 5600 tgt tok/s;     23 s elapsed
Epoch 11,   200/  454; acc:  83.43; ppl:   1.99; 5609 src tok/s; 5817 tgt tok/s;     30 s elapsed
Epoch 11,   250/  454; acc:  84.43; ppl:   1.89; 5325 src tok/s; 5597 tgt tok/s;     38 s elapsed
Epoch 11,   300/  454; acc:  82.06; ppl:   2.12; 5604 src tok/s; 5761 tgt tok/s;     46 s elapsed
Epoch 11,   350/  454; acc:  82.58; ppl:   2.07; 5405 src tok/s; 5634 tgt tok/s;     53 s elapsed
Epoch 11,   400/  454; acc:  83.04; ppl:   1.99; 5612 src tok/s; 5825 tgt tok/s;     61 s elapsed
Epoch 11,   450/  454; acc:  82.63; ppl:   2.05; 5444 src tok/s; 5665 tgt tok/s;     68 s elapsed
Train perplexity: 2.01908
Train accuracy: 83.097
Validation perplexity: 6.41916
Validation accuracy: 69.299
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  83.82; ppl:   1.96; 5591 src tok/s; 5774 tgt tok/s;      8 s elapsed
Epoch 12,   100/  454; acc:  85.01; ppl:   1.85; 5544 src tok/s; 5788 tgt tok/s;     15 s elapsed
Epoch 12,   150/  454; acc:  83.43; ppl:   1.98; 5550 src tok/s; 5709 tgt tok/s;     23 s elapsed
Epoch 12,   200/  454; acc:  84.87; ppl:   1.86; 5517 src tok/s; 5760 tgt tok/s;     30 s elapsed
Epoch 12,   250/  454; acc:  84.17; ppl:   1.90; 5533 src tok/s; 5765 tgt tok/s;     38 s elapsed
Epoch 12,   300/  454; acc:  84.13; ppl:   1.94; 5432 src tok/s; 5640 tgt tok/s;     46 s elapsed
Epoch 12,   350/  454; acc:  83.72; ppl:   1.97; 5589 src tok/s; 5806 tgt tok/s;     53 s elapsed
Epoch 12,   400/  454; acc:  84.30; ppl:   1.89; 5549 src tok/s; 5751 tgt tok/s;     61 s elapsed
Epoch 12,   450/  454; acc:  84.72; ppl:   1.89; 5414 src tok/s; 5614 tgt tok/s;     68 s elapsed
Train perplexity: 1.91808
Train accuracy: 84.221
Validation perplexity: 6.50695
Validation accuracy: 69.2422
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  85.17; ppl:   1.84; 5669 src tok/s; 5897 tgt tok/s;      7 s elapsed
Epoch 13,   100/  454; acc:  84.71; ppl:   1.88; 5549 src tok/s; 5749 tgt tok/s;     15 s elapsed
Epoch 13,   150/  454; acc:  84.86; ppl:   1.86; 5436 src tok/s; 5618 tgt tok/s;     23 s elapsed
Epoch 13,   200/  454; acc:  85.24; ppl:   1.83; 5566 src tok/s; 5774 tgt tok/s;     30 s elapsed
Epoch 13,   250/  454; acc:  84.59; ppl:   1.85; 5477 src tok/s; 5699 tgt tok/s;     38 s elapsed
Epoch 13,   300/  454; acc:  84.71; ppl:   1.88; 5512 src tok/s; 5726 tgt tok/s;     45 s elapsed
Epoch 13,   350/  454; acc:  85.09; ppl:   1.83; 5548 src tok/s; 5793 tgt tok/s;     53 s elapsed
Epoch 13,   400/  454; acc:  84.27; ppl:   1.92; 5442 src tok/s; 5630 tgt tok/s;     61 s elapsed
Epoch 13,   450/  454; acc:  84.74; ppl:   1.88; 5385 src tok/s; 5590 tgt tok/s;     68 s elapsed
Train perplexity: 1.86824
Train accuracy: 84.7805
Validation perplexity: 6.60075
Validation accuracy: 69.1003
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.97; ppl:   1.77; 5616 src tok/s; 5843 tgt tok/s;      7 s elapsed
Epoch 14,   100/  454; acc:  84.26; ppl:   1.91; 5584 src tok/s; 5770 tgt tok/s;     15 s elapsed
Epoch 14,   150/  454; acc:  84.70; ppl:   1.87; 5484 src tok/s; 5674 tgt tok/s;     23 s elapsed
Epoch 14,   200/  454; acc:  85.44; ppl:   1.81; 5358 src tok/s; 5589 tgt tok/s;     30 s elapsed
Epoch 14,   250/  454; acc:  84.78; ppl:   1.87; 5484 src tok/s; 5699 tgt tok/s;     38 s elapsed
Epoch 14,   300/  454; acc:  85.15; ppl:   1.85; 5549 src tok/s; 5779 tgt tok/s;     46 s elapsed
Epoch 14,   350/  454; acc:  84.77; ppl:   1.87; 5516 src tok/s; 5707 tgt tok/s;     53 s elapsed
Epoch 14,   400/  454; acc:  85.14; ppl:   1.83; 5577 src tok/s; 5787 tgt tok/s;     61 s elapsed
Epoch 14,   450/  454; acc:  85.10; ppl:   1.86; 5429 src tok/s; 5629 tgt tok/s;     68 s elapsed
Train perplexity: 1.84734
Train accuracy: 85.0357
Validation perplexity: 6.62111
Validation accuracy: 69.1145
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.08; ppl:   1.85; 5387 src tok/s; 5584 tgt tok/s;      8 s elapsed
Epoch 15,   100/  454; acc:  85.79; ppl:   1.77; 5528 src tok/s; 5751 tgt tok/s;     15 s elapsed
Epoch 15,   150/  454; acc:  85.89; ppl:   1.78; 5455 src tok/s; 5687 tgt tok/s;     23 s elapsed
Epoch 15,   200/  454; acc:  84.50; ppl:   1.91; 5461 src tok/s; 5646 tgt tok/s;     31 s elapsed
Epoch 15,   250/  454; acc:  84.96; ppl:   1.86; 5601 src tok/s; 5802 tgt tok/s;     38 s elapsed
Epoch 15,   300/  454; acc:  85.05; ppl:   1.83; 5618 src tok/s; 5836 tgt tok/s;     46 s elapsed
Epoch 15,   350/  454; acc:  85.78; ppl:   1.77; 5714 src tok/s; 5914 tgt tok/s;     53 s elapsed
Epoch 15,   400/  454; acc:  84.99; ppl:   1.88; 5525 src tok/s; 5746 tgt tok/s;     61 s elapsed
Epoch 15,   450/  454; acc:  85.05; ppl:   1.84; 5561 src tok/s; 5780 tgt tok/s;     68 s elapsed
Train perplexity: 1.83371
Train accuracy: 85.2264
Validation perplexity: 6.62674
Validation accuracy: 69.0932
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.70; ppl:   1.80; 5576 src tok/s; 5813 tgt tok/s;      7 s elapsed
Epoch 16,   100/  454; acc:  84.98; ppl:   1.84; 5490 src tok/s; 5671 tgt tok/s;     15 s elapsed
Epoch 16,   150/  454; acc:  85.38; ppl:   1.82; 5532 src tok/s; 5759 tgt tok/s;     23 s elapsed
Epoch 16,   200/  454; acc:  85.05; ppl:   1.86; 5552 src tok/s; 5756 tgt tok/s;     30 s elapsed
Epoch 16,   250/  454; acc:  85.16; ppl:   1.84; 5531 src tok/s; 5727 tgt tok/s;     38 s elapsed
Epoch 16,   300/  454; acc:  85.60; ppl:   1.78; 5650 src tok/s; 5860 tgt tok/s;     45 s elapsed
Epoch 16,   350/  454; acc:  85.49; ppl:   1.82; 5544 src tok/s; 5728 tgt tok/s;     53 s elapsed
Epoch 16,   400/  454; acc:  84.62; ppl:   1.87; 5392 src tok/s; 5621 tgt tok/s;     61 s elapsed
Epoch 16,   450/  454; acc:  85.57; ppl:   1.81; 5570 src tok/s; 5793 tgt tok/s;     68 s elapsed
Train perplexity: 1.82873
Train accuracy: 85.2767
Validation perplexity: 6.63571
Validation accuracy: 69.0649
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.78; ppl:   1.79; 5564 src tok/s; 5798 tgt tok/s;      7 s elapsed
Epoch 17,   100/  454; acc:  84.80; ppl:   1.86; 5524 src tok/s; 5718 tgt tok/s;     15 s elapsed
Epoch 17,   150/  454; acc:  85.04; ppl:   1.87; 5560 src tok/s; 5725 tgt tok/s;     23 s elapsed
Epoch 17,   200/  454; acc:  85.80; ppl:   1.80; 5395 src tok/s; 5623 tgt tok/s;     30 s elapsed
Epoch 17,   250/  454; acc:  85.22; ppl:   1.85; 5554 src tok/s; 5748 tgt tok/s;     38 s elapsed
Epoch 17,   300/  454; acc:  85.86; ppl:   1.76; 5488 src tok/s; 5712 tgt tok/s;     46 s elapsed
Epoch 17,   350/  454; acc:  85.89; ppl:   1.79; 5519 src tok/s; 5711 tgt tok/s;     53 s elapsed
Epoch 17,   400/  454; acc:  84.95; ppl:   1.87; 5451 src tok/s; 5690 tgt tok/s;     61 s elapsed
Epoch 17,   450/  454; acc:  85.19; ppl:   1.86; 5397 src tok/s; 5594 tgt tok/s;     69 s elapsed
Train perplexity: 1.82635
Train accuracy: 85.3973
Validation perplexity: 6.63878
Validation accuracy: 69.0507
Decaying learning rate to 0.000976562
