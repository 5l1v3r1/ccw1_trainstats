<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.4, kappa_enc=0.3, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/seeds/encoder0.3decoder0.4dropout0.3wdropTrueseed2', seed=2, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.3)
('Using Kappa L2 loss on decoder', 0.4)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.65; ppl: 13897.08; 2831 src tok/s; 2919 tgt tok/s;     15 s elapsed
Epoch  1,   100/  454; acc:  15.89; ppl: 996.03; 3252 src tok/s; 3404 tgt tok/s;     28 s elapsed
Epoch  1,   150/  454; acc:  19.02; ppl: 446.26; 3306 src tok/s; 3447 tgt tok/s;     40 s elapsed
Epoch  1,   200/  454; acc:  22.62; ppl: 240.39; 3272 src tok/s; 3407 tgt tok/s;     53 s elapsed
Epoch  1,   250/  454; acc:  25.65; ppl: 164.39; 3344 src tok/s; 3452 tgt tok/s;     66 s elapsed
Epoch  1,   300/  454; acc:  27.65; ppl: 119.53; 3233 src tok/s; 3359 tgt tok/s;     79 s elapsed
Epoch  1,   350/  454; acc:  29.81; ppl:  93.52; 3236 src tok/s; 3361 tgt tok/s;     91 s elapsed
Epoch  1,   400/  454; acc:  31.47; ppl:  78.21; 3284 src tok/s; 3391 tgt tok/s;    105 s elapsed
Epoch  1,   450/  454; acc:  32.92; ppl:  67.66; 3287 src tok/s; 3406 tgt tok/s;    117 s elapsed
Train perplexity: 287.636
Train accuracy: 23.8043
Validation perplexity: 107.578
Validation accuracy: 30.2043

Epoch  2,    50/  454; acc:  33.69; ppl:  59.17; 3240 src tok/s; 3363 tgt tok/s;     13 s elapsed
Epoch  2,   100/  454; acc:  37.55; ppl:  45.42; 3242 src tok/s; 3391 tgt tok/s;     26 s elapsed
Epoch  2,   150/  454; acc:  39.28; ppl:  40.72; 3366 src tok/s; 3461 tgt tok/s;     39 s elapsed
Epoch  2,   200/  454; acc:  43.53; ppl:  32.30; 3246 src tok/s; 3388 tgt tok/s;     51 s elapsed
Epoch  2,   250/  454; acc:  44.94; ppl:  29.42; 3276 src tok/s; 3382 tgt tok/s;     64 s elapsed
Epoch  2,   300/  454; acc:  46.30; ppl:  25.74; 3300 src tok/s; 3418 tgt tok/s;     77 s elapsed
Epoch  2,   350/  454; acc:  48.11; ppl:  23.47; 3260 src tok/s; 3384 tgt tok/s;     90 s elapsed
Epoch  2,   400/  454; acc:  50.23; ppl:  20.10; 3219 src tok/s; 3363 tgt tok/s;    103 s elapsed
Epoch  2,   450/  454; acc:  51.14; ppl:  19.14; 3229 src tok/s; 3336 tgt tok/s;    116 s elapsed
Train perplexity: 30.5748
Train accuracy: 43.9221
Validation perplexity: 16.7007
Validation accuracy: 53.1858

Epoch  3,    50/  454; acc:  53.64; ppl:  15.36; 3254 src tok/s; 3395 tgt tok/s;     13 s elapsed
Epoch  3,   100/  454; acc:  53.87; ppl:  15.27; 3324 src tok/s; 3434 tgt tok/s;     26 s elapsed
Epoch  3,   150/  454; acc:  55.00; ppl:  13.61; 3246 src tok/s; 3365 tgt tok/s;     39 s elapsed
Epoch  3,   200/  454; acc:  56.47; ppl:  12.74; 3252 src tok/s; 3384 tgt tok/s;     51 s elapsed
Epoch  3,   250/  454; acc:  55.61; ppl:  13.63; 3222 src tok/s; 3343 tgt tok/s;     65 s elapsed
Epoch  3,   300/  454; acc:  58.03; ppl:  11.83; 3303 src tok/s; 3438 tgt tok/s;     77 s elapsed
Epoch  3,   350/  454; acc:  58.26; ppl:  11.12; 3267 src tok/s; 3377 tgt tok/s;     90 s elapsed
Epoch  3,   400/  454; acc:  58.36; ppl:  11.22; 3233 src tok/s; 3359 tgt tok/s;    103 s elapsed
Epoch  3,   450/  454; acc:  59.64; ppl:  10.41; 3207 src tok/s; 3336 tgt tok/s;    115 s elapsed
Train perplexity: 12.6994
Train accuracy: 56.5148
Validation perplexity: 11.2409
Validation accuracy: 59.5005

Epoch  4,    50/  454; acc:  61.18; ppl:   8.77; 3291 src tok/s; 3392 tgt tok/s;     13 s elapsed
Epoch  4,   100/  454; acc:  62.27; ppl:   8.32; 3273 src tok/s; 3409 tgt tok/s;     26 s elapsed
Epoch  4,   150/  454; acc:  62.87; ppl:   8.08; 3197 src tok/s; 3324 tgt tok/s;     38 s elapsed
Epoch  4,   200/  454; acc:  60.56; ppl:   9.12; 3318 src tok/s; 3421 tgt tok/s;     51 s elapsed
Epoch  4,   250/  454; acc:  62.11; ppl:   8.33; 3267 src tok/s; 3414 tgt tok/s;     64 s elapsed
Epoch  4,   300/  454; acc:  61.89; ppl:   8.28; 3296 src tok/s; 3409 tgt tok/s;     77 s elapsed
Epoch  4,   350/  454; acc:  61.34; ppl:   8.54; 3277 src tok/s; 3381 tgt tok/s;     90 s elapsed
Epoch  4,   400/  454; acc:  64.07; ppl:   7.38; 3186 src tok/s; 3348 tgt tok/s;    103 s elapsed
Epoch  4,   450/  454; acc:  62.84; ppl:   7.85; 3253 src tok/s; 3368 tgt tok/s;    116 s elapsed
Train perplexity: 8.27337
Train accuracy: 62.1343
Validation perplexity: 8.52017
Validation accuracy: 62.7714

Epoch  5,    50/  454; acc:  65.22; ppl:   6.40; 3248 src tok/s; 3357 tgt tok/s;     13 s elapsed
Epoch  5,   100/  454; acc:  65.91; ppl:   6.06; 3297 src tok/s; 3430 tgt tok/s;     26 s elapsed
Epoch  5,   150/  454; acc:  64.79; ppl:   6.49; 3243 src tok/s; 3368 tgt tok/s;     39 s elapsed
Epoch  5,   200/  454; acc:  66.45; ppl:   5.87; 3230 src tok/s; 3374 tgt tok/s;     52 s elapsed
Epoch  5,   250/  454; acc:  65.18; ppl:   6.36; 3283 src tok/s; 3394 tgt tok/s;     64 s elapsed
Epoch  5,   300/  454; acc:  66.10; ppl:   6.07; 3254 src tok/s; 3372 tgt tok/s;     77 s elapsed
Epoch  5,   350/  454; acc:  65.18; ppl:   6.40; 3356 src tok/s; 3464 tgt tok/s;     90 s elapsed
Epoch  5,   400/  454; acc:  65.97; ppl:   6.12; 3161 src tok/s; 3295 tgt tok/s;    103 s elapsed
Epoch  5,   450/  454; acc:  65.33; ppl:   6.29; 3192 src tok/s; 3319 tgt tok/s;    116 s elapsed
Train perplexity: 6.2397
Train accuracy: 65.5272
Validation perplexity: 7.43763
Validation accuracy: 65.127

Epoch  6,    50/  454; acc:  69.40; ppl:   4.70; 3282 src tok/s; 3411 tgt tok/s;     13 s elapsed
Epoch  6,   100/  454; acc:  68.24; ppl:   5.09; 3286 src tok/s; 3398 tgt tok/s;     25 s elapsed
Epoch  6,   150/  454; acc:  69.10; ppl:   4.71; 3239 src tok/s; 3384 tgt tok/s;     38 s elapsed
Epoch  6,   200/  454; acc:  67.23; ppl:   5.31; 3289 src tok/s; 3395 tgt tok/s;     51 s elapsed
Epoch  6,   250/  454; acc:  67.97; ppl:   5.07; 3332 src tok/s; 3453 tgt tok/s;     64 s elapsed
Epoch  6,   300/  454; acc:  67.47; ppl:   5.23; 3189 src tok/s; 3328 tgt tok/s;     77 s elapsed
Epoch  6,   350/  454; acc:  68.70; ppl:   4.84; 3320 src tok/s; 3447 tgt tok/s;     90 s elapsed
Epoch  6,   400/  454; acc:  67.76; ppl:   5.17; 3236 src tok/s; 3353 tgt tok/s;    103 s elapsed
Epoch  6,   450/  454; acc:  68.48; ppl:   4.90; 3214 src tok/s; 3341 tgt tok/s;    115 s elapsed
Train perplexity: 5.02295
Train accuracy: 68.1767
Validation perplexity: 6.65266
Validation accuracy: 66.4964

Epoch  7,    50/  454; acc:  71.56; ppl:   3.94; 3273 src tok/s; 3394 tgt tok/s;     13 s elapsed
Epoch  7,   100/  454; acc:  70.84; ppl:   4.03; 3225 src tok/s; 3353 tgt tok/s;     26 s elapsed
Epoch  7,   150/  454; acc:  71.14; ppl:   3.98; 3272 src tok/s; 3403 tgt tok/s;     38 s elapsed
Epoch  7,   200/  454; acc:  69.69; ppl:   4.39; 3315 src tok/s; 3424 tgt tok/s;     51 s elapsed
Epoch  7,   250/  454; acc:  70.91; ppl:   4.10; 3319 src tok/s; 3462 tgt tok/s;     63 s elapsed
Epoch  7,   300/  454; acc:  69.70; ppl:   4.36; 3316 src tok/s; 3418 tgt tok/s;     76 s elapsed
Epoch  7,   350/  454; acc:  69.32; ppl:   4.44; 3239 src tok/s; 3360 tgt tok/s;     90 s elapsed
Epoch  7,   400/  454; acc:  70.09; ppl:   4.24; 3227 src tok/s; 3362 tgt tok/s;    102 s elapsed
Epoch  7,   450/  454; acc:  69.68; ppl:   4.33; 3236 src tok/s; 3359 tgt tok/s;    115 s elapsed
Train perplexity: 4.19797
Train accuracy: 70.3227
Validation perplexity: 6.81699
Validation accuracy: 65.9359
Decaying learning rate to 0.5

Epoch  8,    50/  454; acc:  73.90; ppl:   3.33; 3279 src tok/s; 3389 tgt tok/s;     14 s elapsed
Epoch  8,   100/  454; acc:  77.31; ppl:   2.79; 3219 src tok/s; 3356 tgt tok/s;     26 s elapsed
Epoch  8,   150/  454; acc:  74.57; ppl:   3.25; 3330 src tok/s; 3445 tgt tok/s;     39 s elapsed
Epoch  8,   200/  454; acc:  76.42; ppl:   2.88; 3230 src tok/s; 3380 tgt tok/s;     51 s elapsed
Epoch  8,   250/  454; acc:  75.44; ppl:   3.09; 3306 src tok/s; 3428 tgt tok/s;     64 s elapsed
Epoch  8,   300/  454; acc:  75.34; ppl:   3.10; 3236 src tok/s; 3359 tgt tok/s;     77 s elapsed
Epoch  8,   350/  454; acc:  74.98; ppl:   3.13; 3307 src tok/s; 3423 tgt tok/s;     90 s elapsed
Epoch  8,   400/  454; acc:  75.69; ppl:   2.99; 3294 src tok/s; 3434 tgt tok/s;    102 s elapsed
Epoch  8,   450/  454; acc:  74.82; ppl:   3.15; 3258 src tok/s; 3353 tgt tok/s;    115 s elapsed
Train perplexity: 3.07506
Train accuracy: 75.386
Validation perplexity: 6.03062
Validation accuracy: 68.8236
Decaying learning rate to 0.25

Epoch  9,    50/  454; acc:  79.91; ppl:   2.43; 3230 src tok/s; 3374 tgt tok/s;     12 s elapsed
Epoch  9,   100/  454; acc:  78.96; ppl:   2.53; 3302 src tok/s; 3413 tgt tok/s;     26 s elapsed
Epoch  9,   150/  454; acc:  79.27; ppl:   2.49; 3242 src tok/s; 3380 tgt tok/s;     38 s elapsed
Epoch  9,   200/  454; acc:  78.67; ppl:   2.53; 3303 src tok/s; 3412 tgt tok/s;     51 s elapsed
Epoch  9,   250/  454; acc:  79.45; ppl:   2.46; 3287 src tok/s; 3412 tgt tok/s;     64 s elapsed
Epoch  9,   300/  454; acc:  78.78; ppl:   2.51; 3215 src tok/s; 3348 tgt tok/s;     77 s elapsed
Epoch  9,   350/  454; acc:  77.60; ppl:   2.69; 3252 src tok/s; 3364 tgt tok/s;     91 s elapsed
Epoch  9,   400/  454; acc:  80.10; ppl:   2.37; 3306 src tok/s; 3436 tgt tok/s;    103 s elapsed
Epoch  9,   450/  454; acc:  78.63; ppl:   2.55; 3228 src tok/s; 3340 tgt tok/s;    116 s elapsed
Train perplexity: 2.50598
Train accuracy: 79.0366
Validation perplexity: 6.08035
Validation accuracy: 69.1358
Decaying learning rate to 0.125

Epoch 10,    50/  454; acc:  81.21; ppl:   2.25; 3304 src tok/s; 3418 tgt tok/s;     13 s elapsed
Epoch 10,   100/  454; acc:  81.44; ppl:   2.22; 3249 src tok/s; 3381 tgt tok/s;     26 s elapsed
Epoch 10,   150/  454; acc:  81.10; ppl:   2.26; 3307 src tok/s; 3407 tgt tok/s;     39 s elapsed
Epoch 10,   200/  454; acc:  81.98; ppl:   2.18; 3313 src tok/s; 3433 tgt tok/s;     51 s elapsed
Epoch 10,   250/  454; acc:  80.92; ppl:   2.26; 3255 src tok/s; 3363 tgt tok/s;     64 s elapsed
Epoch 10,   300/  454; acc:  80.70; ppl:   2.27; 3267 src tok/s; 3406 tgt tok/s;     77 s elapsed
Epoch 10,   350/  454; acc:  82.11; ppl:   2.15; 3200 src tok/s; 3358 tgt tok/s;     89 s elapsed
Epoch 10,   400/  454; acc:  80.51; ppl:   2.34; 3242 src tok/s; 3354 tgt tok/s;    103 s elapsed
Epoch 10,   450/  454; acc:  81.05; ppl:   2.26; 3214 src tok/s; 3353 tgt tok/s;    115 s elapsed
Train perplexity: 2.24719
Train accuracy: 81.1903
Validation perplexity: 6.19292
Validation accuracy: 69.3345
Decaying learning rate to 0.0625

Epoch 11,    50/  454; acc:  82.78; ppl:   2.09; 3261 src tok/s; 3394 tgt tok/s;     13 s elapsed
Epoch 11,   100/  454; acc:  82.39; ppl:   2.14; 3314 src tok/s; 3428 tgt tok/s;     25 s elapsed
Epoch 11,   150/  454; acc:  82.48; ppl:   2.13; 3249 src tok/s; 3372 tgt tok/s;     38 s elapsed
Epoch 11,   200/  454; acc:  82.61; ppl:   2.11; 3268 src tok/s; 3395 tgt tok/s;     51 s elapsed
Epoch 11,   250/  454; acc:  82.09; ppl:   2.13; 3234 src tok/s; 3359 tgt tok/s;     64 s elapsed
Epoch 11,   300/  454; acc:  82.33; ppl:   2.11; 3239 src tok/s; 3377 tgt tok/s;     77 s elapsed
Epoch 11,   350/  454; acc:  83.26; ppl:   2.03; 3300 src tok/s; 3424 tgt tok/s;     90 s elapsed
Epoch 11,   400/  454; acc:  81.38; ppl:   2.25; 3230 src tok/s; 3340 tgt tok/s;    103 s elapsed
Epoch 11,   450/  454; acc:  82.06; ppl:   2.16; 3277 src tok/s; 3395 tgt tok/s;    116 s elapsed
Train perplexity: 2.12599
Train accuracy: 82.3795
Validation perplexity: 6.28406
Validation accuracy: 69.3628
Decaying learning rate to 0.03125

Epoch 12,    50/  454; acc:  83.57; ppl:   2.00; 3270 src tok/s; 3399 tgt tok/s;     12 s elapsed
Epoch 12,   100/  454; acc:  82.41; ppl:   2.11; 3324 src tok/s; 3417 tgt tok/s;     25 s elapsed
Epoch 12,   150/  454; acc:  83.38; ppl:   2.03; 3277 src tok/s; 3421 tgt tok/s;     38 s elapsed
Epoch 12,   200/  454; acc:  82.94; ppl:   2.06; 3346 src tok/s; 3463 tgt tok/s;     51 s elapsed
Epoch 12,   250/  454; acc:  82.39; ppl:   2.14; 3247 src tok/s; 3373 tgt tok/s;     64 s elapsed
Epoch 12,   300/  454; acc:  83.47; ppl:   2.00; 3270 src tok/s; 3396 tgt tok/s;     77 s elapsed
Epoch 12,   350/  454; acc:  82.59; ppl:   2.13; 3219 src tok/s; 3330 tgt tok/s;     90 s elapsed
Epoch 12,   400/  454; acc:  83.20; ppl:   2.03; 3231 src tok/s; 3366 tgt tok/s;    103 s elapsed
Epoch 12,   450/  454; acc:  83.61; ppl:   2.01; 3229 src tok/s; 3372 tgt tok/s;    115 s elapsed
Train perplexity: 2.0649
Train accuracy: 82.9924
Validation perplexity: 6.31807
Validation accuracy: 69.4125
Decaying learning rate to 0.015625

Epoch 13,    50/  454; acc:  84.15; ppl:   1.94; 3242 src tok/s; 3388 tgt tok/s;     12 s elapsed
Epoch 13,   100/  454; acc:  82.22; ppl:   2.16; 3342 src tok/s; 3455 tgt tok/s;     26 s elapsed
Epoch 13,   150/  454; acc:  84.25; ppl:   1.96; 3199 src tok/s; 3353 tgt tok/s;     38 s elapsed
Epoch 13,   200/  454; acc:  82.17; ppl:   2.16; 3275 src tok/s; 3380 tgt tok/s;     52 s elapsed
Epoch 13,   250/  454; acc:  83.73; ppl:   1.99; 3306 src tok/s; 3434 tgt tok/s;     64 s elapsed
Epoch 13,   300/  454; acc:  82.96; ppl:   2.07; 3290 src tok/s; 3390 tgt tok/s;     77 s elapsed
Epoch 13,   350/  454; acc:  82.79; ppl:   2.05; 3203 src tok/s; 3317 tgt tok/s;     90 s elapsed
Epoch 13,   400/  454; acc:  84.16; ppl:   1.94; 3240 src tok/s; 3374 tgt tok/s;    103 s elapsed
Epoch 13,   450/  454; acc:  83.82; ppl:   1.99; 3276 src tok/s; 3406 tgt tok/s;    115 s elapsed
Train perplexity: 2.03691
Train accuracy: 83.2744
Validation perplexity: 6.35826
Validation accuracy: 69.3061
Decaying learning rate to 0.0078125

Epoch 14,    50/  454; acc:  83.23; ppl:   2.05; 3291 src tok/s; 3403 tgt tok/s;     13 s elapsed
Epoch 14,   100/  454; acc:  83.90; ppl:   1.98; 3288 src tok/s; 3431 tgt tok/s;     26 s elapsed
Epoch 14,   150/  454; acc:  83.39; ppl:   2.04; 3205 src tok/s; 3330 tgt tok/s;     39 s elapsed
Epoch 14,   200/  454; acc:  82.97; ppl:   2.05; 3224 src tok/s; 3347 tgt tok/s;     52 s elapsed
Epoch 14,   250/  454; acc:  84.49; ppl:   1.93; 3234 src tok/s; 3374 tgt tok/s;     64 s elapsed
Epoch 14,   300/  454; acc:  83.16; ppl:   2.04; 3244 src tok/s; 3362 tgt tok/s;     78 s elapsed
Epoch 14,   350/  454; acc:  83.95; ppl:   1.95; 3260 src tok/s; 3406 tgt tok/s;     90 s elapsed
Epoch 14,   400/  454; acc:  82.38; ppl:   2.13; 3335 src tok/s; 3426 tgt tok/s;    103 s elapsed
Epoch 14,   450/  454; acc:  83.97; ppl:   1.96; 3272 src tok/s; 3394 tgt tok/s;    115 s elapsed
Train perplexity: 2.02024
Train accuracy: 83.4178
Validation perplexity: 6.37517
Validation accuracy: 69.2848
Decaying learning rate to 0.00390625

Epoch 15,    50/  454; acc:  83.53; ppl:   2.02; 3362 src tok/s; 3484 tgt tok/s;     13 s elapsed
Epoch 15,   100/  454; acc:  83.43; ppl:   2.03; 3230 src tok/s; 3365 tgt tok/s;     25 s elapsed
Epoch 15,   150/  454; acc:  84.34; ppl:   1.91; 3306 src tok/s; 3432 tgt tok/s;     38 s elapsed
Epoch 15,   200/  454; acc:  82.53; ppl:   2.11; 3237 src tok/s; 3356 tgt tok/s;     51 s elapsed
Epoch 15,   250/  454; acc:  85.12; ppl:   1.86; 3131 src tok/s; 3263 tgt tok/s;     64 s elapsed
Epoch 15,   300/  454; acc:  82.37; ppl:   2.13; 3285 src tok/s; 3386 tgt tok/s;     77 s elapsed
Epoch 15,   350/  454; acc:  83.19; ppl:   2.03; 3260 src tok/s; 3395 tgt tok/s;     90 s elapsed
Epoch 15,   400/  454; acc:  83.68; ppl:   2.00; 3253 src tok/s; 3381 tgt tok/s;    103 s elapsed
Epoch 15,   450/  454; acc:  83.58; ppl:   2.00; 3185 src tok/s; 3303 tgt tok/s;    116 s elapsed
Train perplexity: 2.01268
Train accuracy: 83.4921
Validation perplexity: 6.38764
Validation accuracy: 69.3699
Decaying learning rate to 0.00195312

Epoch 16,    50/  454; acc:  82.72; ppl:   2.08; 3252 src tok/s; 3348 tgt tok/s;     14 s elapsed
Epoch 16,   100/  454; acc:  84.23; ppl:   1.96; 3176 src tok/s; 3311 tgt tok/s;     26 s elapsed
Epoch 16,   150/  454; acc:  84.18; ppl:   1.94; 3232 src tok/s; 3374 tgt tok/s;     39 s elapsed
Epoch 16,   200/  454; acc:  82.73; ppl:   2.08; 3321 src tok/s; 3453 tgt tok/s;     52 s elapsed
Epoch 16,   250/  454; acc:  83.68; ppl:   1.99; 3287 src tok/s; 3410 tgt tok/s;     64 s elapsed
Epoch 16,   300/  454; acc:  83.79; ppl:   1.99; 3263 src tok/s; 3387 tgt tok/s;     77 s elapsed
Epoch 16,   350/  454; acc:  82.35; ppl:   2.13; 3313 src tok/s; 3424 tgt tok/s;     91 s elapsed
Epoch 16,   400/  454; acc:  84.53; ppl:   1.93; 3233 src tok/s; 3366 tgt tok/s;    103 s elapsed
Epoch 16,   450/  454; acc:  83.52; ppl:   2.02; 3229 src tok/s; 3346 tgt tok/s;    116 s elapsed
Train perplexity: 2.01161
Train accuracy: 83.5141
Validation perplexity: 6.39194
Validation accuracy: 69.3983
Decaying learning rate to 0.000976562

Epoch 17,    50/  454; acc:  83.69; ppl:   1.97; 3294 src tok/s; 3433 tgt tok/s;     13 s elapsed
Epoch 17,   100/  454; acc:  83.23; ppl:   2.04; 3252 src tok/s; 3382 tgt tok/s;     26 s elapsed
Epoch 17,   150/  454; acc:  84.31; ppl:   1.94; 3174 src tok/s; 3306 tgt tok/s;     38 s elapsed
Epoch 17,   200/  454; acc:  82.81; ppl:   2.08; 3369 src tok/s; 3478 tgt tok/s;     51 s elapsed
Epoch 17,   250/  454; acc:  83.74; ppl:   2.00; 3219 src tok/s; 3350 tgt tok/s;     64 s elapsed
Epoch 17,   300/  454; acc:  83.14; ppl:   2.04; 3284 src tok/s; 3386 tgt tok/s;     77 s elapsed
Epoch 17,   350/  454; acc:  83.63; ppl:   2.01; 3227 src tok/s; 3346 tgt tok/s;     90 s elapsed
Epoch 17,   400/  454; acc:  83.88; ppl:   1.99; 3256 src tok/s; 3382 tgt tok/s;    103 s elapsed
Epoch 17,   450/  454; acc:  83.21; ppl:   2.03; 3201 src tok/s; 3315 tgt tok/s;    116 s elapsed
Train perplexity: 2.00886
Train accuracy: 83.5345
Validation perplexity: 6.3938
Validation accuracy: 69.377
Decaying learning rate to 0.000488281
