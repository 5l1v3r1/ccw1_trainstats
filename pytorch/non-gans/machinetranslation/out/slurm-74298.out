<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.4, kappa_enc=0.3, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/seeds/encoder0.3decoder0.4dropout0.3wdropTrueseed3', seed=3, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.3)
('Using Kappa L2 loss on decoder', 0.4)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.02; ppl: 20439.57; 2635 src tok/s; 2732 tgt tok/s;     16 s elapsed
Epoch  1,   100/  454; acc:  13.14; ppl: 1800.04; 3094 src tok/s; 3214 tgt tok/s;     29 s elapsed
Epoch  1,   150/  454; acc:  17.45; ppl: 571.97; 3180 src tok/s; 3306 tgt tok/s;     42 s elapsed
Epoch  1,   200/  454; acc:  20.74; ppl: 298.56; 3114 src tok/s; 3226 tgt tok/s;     56 s elapsed
Epoch  1,   250/  454; acc:  24.24; ppl: 182.06; 3045 src tok/s; 3191 tgt tok/s;     69 s elapsed
Epoch  1,   300/  454; acc:  26.54; ppl: 140.22; 3107 src tok/s; 3206 tgt tok/s;     83 s elapsed
Epoch  1,   350/  454; acc:  30.22; ppl:  92.24; 3126 src tok/s; 3279 tgt tok/s;     96 s elapsed
Epoch  1,   400/  454; acc:  30.30; ppl:  90.29; 3149 src tok/s; 3240 tgt tok/s;    110 s elapsed
Epoch  1,   450/  454; acc:  34.51; ppl:  64.24; 3126 src tok/s; 3245 tgt tok/s;    123 s elapsed
Train perplexity: 347.28
Train accuracy: 22.8416
Validation perplexity: 65.4276
Validation accuracy: 32.8438

Epoch  2,    50/  454; acc:  35.82; ppl:  53.82; 3087 src tok/s; 3226 tgt tok/s;     13 s elapsed
Epoch  2,   100/  454; acc:  37.49; ppl:  48.33; 3162 src tok/s; 3267 tgt tok/s;     27 s elapsed
Epoch  2,   150/  454; acc:  41.64; ppl:  36.13; 3138 src tok/s; 3276 tgt tok/s;     40 s elapsed
Epoch  2,   200/  454; acc:  41.61; ppl:  36.74; 3152 src tok/s; 3239 tgt tok/s;     54 s elapsed
Epoch  2,   250/  454; acc:  45.07; ppl:  27.92; 3124 src tok/s; 3261 tgt tok/s;     67 s elapsed
Epoch  2,   300/  454; acc:  46.10; ppl:  26.64; 3156 src tok/s; 3269 tgt tok/s;     80 s elapsed
Epoch  2,   350/  454; acc:  48.89; ppl:  22.35; 3101 src tok/s; 3225 tgt tok/s;     94 s elapsed
Epoch  2,   400/  454; acc:  50.38; ppl:  20.58; 3133 src tok/s; 3241 tgt tok/s;    107 s elapsed
Epoch  2,   450/  454; acc:  51.81; ppl:  18.27; 3063 src tok/s; 3181 tgt tok/s;    121 s elapsed
Train perplexity: 30.2846
Train accuracy: 44.326
Validation perplexity: 17.0307
Validation accuracy: 52.2208

Epoch  3,    50/  454; acc:  52.65; ppl:  16.33; 3146 src tok/s; 3253 tgt tok/s;     14 s elapsed
Epoch  3,   100/  454; acc:  55.23; ppl:  14.11; 3159 src tok/s; 3277 tgt tok/s;     27 s elapsed
Epoch  3,   150/  454; acc:  55.18; ppl:  13.78; 3146 src tok/s; 3262 tgt tok/s;     40 s elapsed
Epoch  3,   200/  454; acc:  56.28; ppl:  12.87; 3084 src tok/s; 3214 tgt tok/s;     54 s elapsed
Epoch  3,   250/  454; acc:  56.68; ppl:  12.55; 3033 src tok/s; 3158 tgt tok/s;     68 s elapsed
Epoch  3,   300/  454; acc:  57.50; ppl:  11.79; 3134 src tok/s; 3257 tgt tok/s;     81 s elapsed
Epoch  3,   350/  454; acc:  56.89; ppl:  12.45; 3147 src tok/s; 3250 tgt tok/s;     95 s elapsed
Epoch  3,   400/  454; acc:  59.12; ppl:  10.74; 3128 src tok/s; 3251 tgt tok/s;    107 s elapsed
Epoch  3,   450/  454; acc:  58.73; ppl:  10.94; 3140 src tok/s; 3256 tgt tok/s;    121 s elapsed
Train perplexity: 12.721
Train accuracy: 56.4951
Validation perplexity: 10.6642
Validation accuracy: 60.5293

Epoch  4,    50/  454; acc:  61.15; ppl:   8.62; 3169 src tok/s; 3277 tgt tok/s;     14 s elapsed
Epoch  4,   100/  454; acc:  62.30; ppl:   8.28; 3039 src tok/s; 3179 tgt tok/s;     27 s elapsed
Epoch  4,   150/  454; acc:  61.31; ppl:   8.69; 3150 src tok/s; 3262 tgt tok/s;     40 s elapsed
Epoch  4,   200/  454; acc:  62.55; ppl:   8.02; 3107 src tok/s; 3229 tgt tok/s;     54 s elapsed
Epoch  4,   250/  454; acc:  62.68; ppl:   8.00; 3096 src tok/s; 3222 tgt tok/s;     67 s elapsed
Epoch  4,   300/  454; acc:  61.90; ppl:   8.35; 3125 src tok/s; 3252 tgt tok/s;     81 s elapsed
Epoch  4,   350/  454; acc:  63.21; ppl:   7.85; 3159 src tok/s; 3277 tgt tok/s;     94 s elapsed
Epoch  4,   400/  454; acc:  61.88; ppl:   8.41; 3153 src tok/s; 3258 tgt tok/s;    107 s elapsed
Epoch  4,   450/  454; acc:  63.13; ppl:   7.74; 3080 src tok/s; 3190 tgt tok/s;    121 s elapsed
Train perplexity: 8.21543
Train accuracy: 62.2219
Validation perplexity: 8.3662
Validation accuracy: 63.2468

Epoch  5,    50/  454; acc:  67.44; ppl:   5.48; 3027 src tok/s; 3185 tgt tok/s;     13 s elapsed
Epoch  5,   100/  454; acc:  64.44; ppl:   6.60; 3109 src tok/s; 3203 tgt tok/s;     27 s elapsed
Epoch  5,   150/  454; acc:  64.88; ppl:   6.55; 3183 src tok/s; 3286 tgt tok/s;     41 s elapsed
Epoch  5,   200/  454; acc:  66.68; ppl:   5.80; 3128 src tok/s; 3272 tgt tok/s;     54 s elapsed
Epoch  5,   250/  454; acc:  64.25; ppl:   6.64; 3191 src tok/s; 3293 tgt tok/s;     68 s elapsed
Epoch  5,   300/  454; acc:  66.53; ppl:   5.94; 3127 src tok/s; 3253 tgt tok/s;     80 s elapsed
Epoch  5,   350/  454; acc:  65.63; ppl:   6.19; 3142 src tok/s; 3251 tgt tok/s;     94 s elapsed
Epoch  5,   400/  454; acc:  65.64; ppl:   6.26; 3110 src tok/s; 3232 tgt tok/s;    107 s elapsed
Epoch  5,   450/  454; acc:  65.65; ppl:   6.25; 3058 src tok/s; 3170 tgt tok/s;    121 s elapsed
Train perplexity: 6.1981
Train accuracy: 65.6254
Validation perplexity: 7.25464
Validation accuracy: 65.1554

Epoch  6,    50/  454; acc:  69.10; ppl:   4.72; 3117 src tok/s; 3236 tgt tok/s;     13 s elapsed
Epoch  6,   100/  454; acc:  68.03; ppl:   5.07; 3090 src tok/s; 3203 tgt tok/s;     27 s elapsed
Epoch  6,   150/  454; acc:  67.72; ppl:   5.20; 3184 src tok/s; 3289 tgt tok/s;     40 s elapsed
Epoch  6,   200/  454; acc:  69.57; ppl:   4.65; 3078 src tok/s; 3201 tgt tok/s;     54 s elapsed
Epoch  6,   250/  454; acc:  68.77; ppl:   4.89; 3101 src tok/s; 3229 tgt tok/s;     67 s elapsed
Epoch  6,   300/  454; acc:  67.51; ppl:   5.25; 3168 src tok/s; 3269 tgt tok/s;     81 s elapsed
Epoch  6,   350/  454; acc:  67.53; ppl:   5.21; 3150 src tok/s; 3272 tgt tok/s;     94 s elapsed
Epoch  6,   400/  454; acc:  68.91; ppl:   4.78; 3149 src tok/s; 3296 tgt tok/s;    107 s elapsed
Epoch  6,   450/  454; acc:  67.36; ppl:   5.22; 3112 src tok/s; 3212 tgt tok/s;    121 s elapsed
Train perplexity: 4.98874
Train accuracy: 68.2989
Validation perplexity: 6.99157
Validation accuracy: 65.8578

Epoch  7,    50/  454; acc:  71.78; ppl:   3.90; 3123 src tok/s; 3254 tgt tok/s;     13 s elapsed
Epoch  7,   100/  454; acc:  71.33; ppl:   4.02; 3162 src tok/s; 3270 tgt tok/s;     27 s elapsed
Epoch  7,   150/  454; acc:  70.96; ppl:   4.06; 3055 src tok/s; 3183 tgt tok/s;     40 s elapsed
Epoch  7,   200/  454; acc:  69.70; ppl:   4.30; 3201 src tok/s; 3297 tgt tok/s;     54 s elapsed
Epoch  7,   250/  454; acc:  69.61; ppl:   4.39; 3153 src tok/s; 3248 tgt tok/s;     67 s elapsed
Epoch  7,   300/  454; acc:  71.16; ppl:   3.95; 3102 src tok/s; 3240 tgt tok/s;     80 s elapsed
Epoch  7,   350/  454; acc:  70.49; ppl:   4.11; 3068 src tok/s; 3206 tgt tok/s;     94 s elapsed
Epoch  7,   400/  454; acc:  69.31; ppl:   4.42; 3113 src tok/s; 3226 tgt tok/s;    107 s elapsed
Epoch  7,   450/  454; acc:  69.69; ppl:   4.47; 3098 src tok/s; 3211 tgt tok/s;    121 s elapsed
Train perplexity: 4.1763
Train accuracy: 70.4518
Validation perplexity: 6.78773
Validation accuracy: 66.3474

Epoch  8,    50/  454; acc:  73.20; ppl:   3.40; 3082 src tok/s; 3200 tgt tok/s;     14 s elapsed
Epoch  8,   100/  454; acc:  73.57; ppl:   3.35; 3175 src tok/s; 3292 tgt tok/s;     27 s elapsed
Epoch  8,   150/  454; acc:  72.72; ppl:   3.53; 3112 src tok/s; 3223 tgt tok/s;     41 s elapsed
Epoch  8,   200/  454; acc:  72.58; ppl:   3.54; 3146 src tok/s; 3265 tgt tok/s;     54 s elapsed
Epoch  8,   250/  454; acc:  71.43; ppl:   3.84; 3140 src tok/s; 3220 tgt tok/s;     68 s elapsed
Epoch  8,   300/  454; acc:  72.21; ppl:   3.53; 3135 src tok/s; 3288 tgt tok/s;     81 s elapsed
Epoch  8,   350/  454; acc:  71.87; ppl:   3.70; 3087 src tok/s; 3209 tgt tok/s;     94 s elapsed
Epoch  8,   400/  454; acc:  72.06; ppl:   3.60; 3148 src tok/s; 3258 tgt tok/s;    107 s elapsed
Epoch  8,   450/  454; acc:  71.16; ppl:   3.86; 3061 src tok/s; 3198 tgt tok/s;    121 s elapsed
Train perplexity: 3.59424
Train accuracy: 72.3002
Validation perplexity: 6.7219
Validation accuracy: 67.1066
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.49; ppl:   2.70; 3124 src tok/s; 3252 tgt tok/s;     13 s elapsed
Epoch  9,   100/  454; acc:  77.17; ppl:   2.78; 3140 src tok/s; 3245 tgt tok/s;     27 s elapsed
Epoch  9,   150/  454; acc:  77.54; ppl:   2.69; 3093 src tok/s; 3205 tgt tok/s;     41 s elapsed
Epoch  9,   200/  454; acc:  77.50; ppl:   2.70; 3052 src tok/s; 3164 tgt tok/s;     54 s elapsed
Epoch  9,   250/  454; acc:  78.91; ppl:   2.46; 3076 src tok/s; 3234 tgt tok/s;     67 s elapsed
Epoch  9,   300/  454; acc:  76.10; ppl:   2.89; 3201 src tok/s; 3286 tgt tok/s;     81 s elapsed
Epoch  9,   350/  454; acc:  77.49; ppl:   2.65; 3128 src tok/s; 3259 tgt tok/s;     94 s elapsed
Epoch  9,   400/  454; acc:  76.92; ppl:   2.76; 3119 src tok/s; 3239 tgt tok/s;    108 s elapsed
Epoch  9,   450/  454; acc:  77.35; ppl:   2.70; 3112 src tok/s; 3218 tgt tok/s;    121 s elapsed
Train perplexity: 2.69719
Train accuracy: 77.3908
Validation perplexity: 6.22357
Validation accuracy: 68.8733
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.08; ppl:   2.27; 3015 src tok/s; 3115 tgt tok/s;     14 s elapsed
Epoch 10,   100/  454; acc:  81.57; ppl:   2.16; 3199 src tok/s; 3319 tgt tok/s;     27 s elapsed
Epoch 10,   150/  454; acc:  81.55; ppl:   2.18; 3158 src tok/s; 3296 tgt tok/s;     40 s elapsed
Epoch 10,   200/  454; acc:  81.31; ppl:   2.20; 3164 src tok/s; 3275 tgt tok/s;     54 s elapsed
Epoch 10,   250/  454; acc:  82.12; ppl:   2.13; 3100 src tok/s; 3238 tgt tok/s;     67 s elapsed
Epoch 10,   300/  454; acc:  80.16; ppl:   2.31; 3113 src tok/s; 3217 tgt tok/s;     81 s elapsed
Epoch 10,   350/  454; acc:  81.35; ppl:   2.19; 3137 src tok/s; 3256 tgt tok/s;     94 s elapsed
Epoch 10,   400/  454; acc:  80.39; ppl:   2.29; 3110 src tok/s; 3233 tgt tok/s;    107 s elapsed
Epoch 10,   450/  454; acc:  80.57; ppl:   2.24; 3068 src tok/s; 3179 tgt tok/s;    121 s elapsed
Train perplexity: 2.21921
Train accuracy: 81.1228
Validation perplexity: 6.29684
Validation accuracy: 68.9655
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.15; ppl:   2.02; 3138 src tok/s; 3235 tgt tok/s;     14 s elapsed
Epoch 11,   100/  454; acc:  83.70; ppl:   1.94; 3071 src tok/s; 3213 tgt tok/s;     27 s elapsed
Epoch 11,   150/  454; acc:  83.78; ppl:   1.98; 3113 src tok/s; 3243 tgt tok/s;     40 s elapsed
Epoch 11,   200/  454; acc:  82.81; ppl:   2.05; 3115 src tok/s; 3223 tgt tok/s;     54 s elapsed
Epoch 11,   250/  454; acc:  82.56; ppl:   2.08; 3192 src tok/s; 3281 tgt tok/s;     68 s elapsed
Epoch 11,   300/  454; acc:  84.21; ppl:   1.93; 3058 src tok/s; 3194 tgt tok/s;     81 s elapsed
Epoch 11,   350/  454; acc:  83.45; ppl:   1.99; 3125 src tok/s; 3249 tgt tok/s;     94 s elapsed
Epoch 11,   400/  454; acc:  82.75; ppl:   2.05; 3122 src tok/s; 3240 tgt tok/s;    108 s elapsed
Epoch 11,   450/  454; acc:  82.89; ppl:   2.06; 3108 src tok/s; 3218 tgt tok/s;    121 s elapsed
Train perplexity: 2.00785
Train accuracy: 83.2625
Validation perplexity: 6.50178
Validation accuracy: 68.9371
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  85.61; ppl:   1.81; 3074 src tok/s; 3200 tgt tok/s;     13 s elapsed
Epoch 12,   100/  454; acc:  83.37; ppl:   1.99; 3133 src tok/s; 3228 tgt tok/s;     27 s elapsed
Epoch 12,   150/  454; acc:  84.92; ppl:   1.86; 3138 src tok/s; 3267 tgt tok/s;     40 s elapsed
Epoch 12,   200/  454; acc:  84.25; ppl:   1.91; 3148 src tok/s; 3259 tgt tok/s;     54 s elapsed
Epoch 12,   250/  454; acc:  84.34; ppl:   1.92; 3103 src tok/s; 3229 tgt tok/s;     67 s elapsed
Epoch 12,   300/  454; acc:  83.95; ppl:   1.96; 3154 src tok/s; 3250 tgt tok/s;     81 s elapsed
Epoch 12,   350/  454; acc:  84.14; ppl:   1.91; 3090 src tok/s; 3219 tgt tok/s;     94 s elapsed
Epoch 12,   400/  454; acc:  84.21; ppl:   1.91; 3153 src tok/s; 3278 tgt tok/s;    108 s elapsed
Epoch 12,   450/  454; acc:  84.51; ppl:   1.91; 3067 src tok/s; 3195 tgt tok/s;    121 s elapsed
Train perplexity: 1.90839
Train accuracy: 84.359
Validation perplexity: 6.58583
Validation accuracy: 68.8023
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.90; ppl:   1.87; 3156 src tok/s; 3273 tgt tok/s;     13 s elapsed
Epoch 13,   100/  454; acc:  85.18; ppl:   1.84; 3094 src tok/s; 3222 tgt tok/s;     27 s elapsed
Epoch 13,   150/  454; acc:  85.61; ppl:   1.79; 3146 src tok/s; 3284 tgt tok/s;     40 s elapsed
Epoch 13,   200/  454; acc:  84.27; ppl:   1.90; 3134 src tok/s; 3246 tgt tok/s;     54 s elapsed
Epoch 13,   250/  454; acc:  84.44; ppl:   1.89; 3152 src tok/s; 3239 tgt tok/s;     67 s elapsed
Epoch 13,   300/  454; acc:  84.83; ppl:   1.86; 3034 src tok/s; 3172 tgt tok/s;     81 s elapsed
Epoch 13,   350/  454; acc:  83.32; ppl:   2.01; 3195 src tok/s; 3288 tgt tok/s;     95 s elapsed
Epoch 13,   400/  454; acc:  86.63; ppl:   1.71; 3065 src tok/s; 3203 tgt tok/s;    108 s elapsed
Epoch 13,   450/  454; acc:  85.00; ppl:   1.85; 3107 src tok/s; 3221 tgt tok/s;    121 s elapsed
Train perplexity: 1.85911
Train accuracy: 84.8765
Validation perplexity: 6.64265
Validation accuracy: 68.9939
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  86.62; ppl:   1.72; 3003 src tok/s; 3170 tgt tok/s;     13 s elapsed
Epoch 14,   100/  454; acc:  84.13; ppl:   1.94; 3203 src tok/s; 3290 tgt tok/s;     27 s elapsed
Epoch 14,   150/  454; acc:  85.68; ppl:   1.80; 3137 src tok/s; 3268 tgt tok/s;     40 s elapsed
Epoch 14,   200/  454; acc:  84.66; ppl:   1.88; 3089 src tok/s; 3198 tgt tok/s;     54 s elapsed
Epoch 14,   250/  454; acc:  85.70; ppl:   1.81; 3110 src tok/s; 3228 tgt tok/s;     67 s elapsed
Epoch 14,   300/  454; acc:  85.08; ppl:   1.86; 3095 src tok/s; 3216 tgt tok/s;     81 s elapsed
Epoch 14,   350/  454; acc:  84.95; ppl:   1.87; 3124 src tok/s; 3250 tgt tok/s;     94 s elapsed
Epoch 14,   400/  454; acc:  85.34; ppl:   1.82; 3152 src tok/s; 3258 tgt tok/s;    108 s elapsed
Epoch 14,   450/  454; acc:  85.71; ppl:   1.79; 3155 src tok/s; 3267 tgt tok/s;    121 s elapsed
Train perplexity: 1.83863
Train accuracy: 85.2296
Validation perplexity: 6.67462
Validation accuracy: 69.0294
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.33; ppl:   1.84; 3148 src tok/s; 3249 tgt tok/s;     14 s elapsed
Epoch 15,   100/  454; acc:  85.29; ppl:   1.83; 3149 src tok/s; 3265 tgt tok/s;     27 s elapsed
Epoch 15,   150/  454; acc:  85.81; ppl:   1.78; 3152 src tok/s; 3268 tgt tok/s;     40 s elapsed
Epoch 15,   200/  454; acc:  84.62; ppl:   1.90; 3075 src tok/s; 3207 tgt tok/s;     54 s elapsed
Epoch 15,   250/  454; acc:  86.39; ppl:   1.73; 3139 src tok/s; 3275 tgt tok/s;     66 s elapsed
Epoch 15,   300/  454; acc:  84.34; ppl:   1.92; 3092 src tok/s; 3202 tgt tok/s;     81 s elapsed
Epoch 15,   350/  454; acc:  84.51; ppl:   1.91; 3126 src tok/s; 3240 tgt tok/s;     94 s elapsed
Epoch 15,   400/  454; acc:  86.45; ppl:   1.74; 3089 src tok/s; 3207 tgt tok/s;    108 s elapsed
Epoch 15,   450/  454; acc:  85.79; ppl:   1.77; 3119 src tok/s; 3238 tgt tok/s;    121 s elapsed
Train perplexity: 1.82462
Train accuracy: 85.37
Validation perplexity: 6.69521
Validation accuracy: 68.8733
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  84.81; ppl:   1.85; 3137 src tok/s; 3261 tgt tok/s;     14 s elapsed
Epoch 16,   100/  454; acc:  85.85; ppl:   1.78; 3083 src tok/s; 3214 tgt tok/s;     27 s elapsed
Epoch 16,   150/  454; acc:  85.48; ppl:   1.83; 3138 src tok/s; 3244 tgt tok/s;     41 s elapsed
Epoch 16,   200/  454; acc:  85.90; ppl:   1.77; 3071 src tok/s; 3190 tgt tok/s;     54 s elapsed
Epoch 16,   250/  454; acc:  85.69; ppl:   1.79; 3146 src tok/s; 3265 tgt tok/s;     67 s elapsed
Epoch 16,   300/  454; acc:  85.00; ppl:   1.84; 3128 src tok/s; 3242 tgt tok/s;     81 s elapsed
Epoch 16,   350/  454; acc:  84.83; ppl:   1.88; 3106 src tok/s; 3225 tgt tok/s;     94 s elapsed
Epoch 16,   400/  454; acc:  85.54; ppl:   1.79; 3122 src tok/s; 3237 tgt tok/s;    108 s elapsed
Epoch 16,   450/  454; acc:  85.30; ppl:   1.83; 3114 src tok/s; 3227 tgt tok/s;    121 s elapsed
Train perplexity: 1.81899
Train accuracy: 85.3872
Validation perplexity: 6.70876
Validation accuracy: 68.8733
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  86.40; ppl:   1.74; 3067 src tok/s; 3212 tgt tok/s;     13 s elapsed
Epoch 17,   100/  454; acc:  85.02; ppl:   1.88; 3153 src tok/s; 3243 tgt tok/s;     27 s elapsed
Epoch 17,   150/  454; acc:  85.13; ppl:   1.84; 3135 src tok/s; 3233 tgt tok/s;     41 s elapsed
Epoch 17,   200/  454; acc:  85.69; ppl:   1.80; 3128 src tok/s; 3251 tgt tok/s;     54 s elapsed
Epoch 17,   250/  454; acc:  85.20; ppl:   1.85; 3072 src tok/s; 3184 tgt tok/s;     68 s elapsed
Epoch 17,   300/  454; acc:  85.59; ppl:   1.81; 3084 src tok/s; 3207 tgt tok/s;     81 s elapsed
Epoch 17,   350/  454; acc:  84.40; ppl:   1.92; 3173 src tok/s; 3286 tgt tok/s;     95 s elapsed
Epoch 17,   400/  454; acc:  86.40; ppl:   1.72; 3105 src tok/s; 3232 tgt tok/s;    108 s elapsed
Epoch 17,   450/  454; acc:  85.49; ppl:   1.81; 3101 src tok/s; 3233 tgt tok/s;    121 s elapsed
Train perplexity: 1.81838
Train accuracy: 85.4711
Validation perplexity: 6.71226
Validation accuracy: 68.8591
Decaying learning rate to 0.000976562
