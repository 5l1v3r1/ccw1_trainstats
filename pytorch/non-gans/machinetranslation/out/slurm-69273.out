<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.1, kappa_enc=0.05, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.05decoder0.1dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.05)
('Using Kappa L2 loss on decoder', 0.1)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.76; ppl: 15309.35; 4119 src tok/s; 4262 tgt tok/s;     10 s elapsed
Epoch  1,   100/  454; acc:  15.38; ppl: 1497.15; 5566 src tok/s; 5782 tgt tok/s;     18 s elapsed
Epoch  1,   150/  454; acc:  17.69; ppl: 471.22; 5459 src tok/s; 5625 tgt tok/s;     26 s elapsed
Epoch  1,   200/  454; acc:  21.16; ppl: 253.83; 5458 src tok/s; 5728 tgt tok/s;     33 s elapsed
Epoch  1,   250/  454; acc:  24.01; ppl: 176.56; 5431 src tok/s; 5637 tgt tok/s;     41 s elapsed
Epoch  1,   300/  454; acc:  27.53; ppl: 121.97; 5270 src tok/s; 5457 tgt tok/s;     49 s elapsed
Epoch  1,   350/  454; acc:  29.18; ppl:  98.08; 5151 src tok/s; 5337 tgt tok/s;     57 s elapsed
Epoch  1,   400/  454; acc:  32.39; ppl:  72.33; 5126 src tok/s; 5358 tgt tok/s;     65 s elapsed
Epoch  1,   450/  454; acc:  33.52; ppl:  67.27; 5240 src tok/s; 5414 tgt tok/s;     73 s elapsed
Train perplexity: 310.27
Train accuracy: 23.3608
Validation perplexity: 52.8347
Validation accuracy: 37.4628

Epoch  2,    50/  454; acc:  35.93; ppl:  53.71; 5323 src tok/s; 5522 tgt tok/s;      8 s elapsed
Epoch  2,   100/  454; acc:  37.80; ppl:  47.63; 5229 src tok/s; 5409 tgt tok/s;     16 s elapsed
Epoch  2,   150/  454; acc:  41.22; ppl:  38.26; 5205 src tok/s; 5431 tgt tok/s;     24 s elapsed
Epoch  2,   200/  454; acc:  42.69; ppl:  33.47; 5223 src tok/s; 5413 tgt tok/s;     32 s elapsed
Epoch  2,   250/  454; acc:  45.95; ppl:  27.69; 5109 src tok/s; 5305 tgt tok/s;     40 s elapsed
Epoch  2,   300/  454; acc:  47.13; ppl:  25.17; 5113 src tok/s; 5297 tgt tok/s;     48 s elapsed
Epoch  2,   350/  454; acc:  48.38; ppl:  22.73; 5227 src tok/s; 5405 tgt tok/s;     57 s elapsed
Epoch  2,   400/  454; acc:  51.35; ppl:  19.08; 5171 src tok/s; 5394 tgt tok/s;     65 s elapsed
Epoch  2,   450/  454; acc:  52.52; ppl:  17.20; 5141 src tok/s; 5343 tgt tok/s;     73 s elapsed
Train perplexity: 29.407
Train accuracy: 44.8362
Validation perplexity: 16.9467
Validation accuracy: 52.0576

Epoch  3,    50/  454; acc:  52.66; ppl:  16.34; 5384 src tok/s; 5543 tgt tok/s;      8 s elapsed
Epoch  3,   100/  454; acc:  56.28; ppl:  13.12; 5163 src tok/s; 5385 tgt tok/s;     16 s elapsed
Epoch  3,   150/  454; acc:  54.74; ppl:  14.35; 5341 src tok/s; 5486 tgt tok/s;     24 s elapsed
Epoch  3,   200/  454; acc:  58.47; ppl:  11.34; 5237 src tok/s; 5475 tgt tok/s;     32 s elapsed
Epoch  3,   250/  454; acc:  56.89; ppl:  12.68; 5232 src tok/s; 5413 tgt tok/s;     40 s elapsed
Epoch  3,   300/  454; acc:  58.08; ppl:  11.40; 5221 src tok/s; 5432 tgt tok/s;     48 s elapsed
Epoch  3,   350/  454; acc:  57.55; ppl:  11.81; 5188 src tok/s; 5383 tgt tok/s;     56 s elapsed
Epoch  3,   400/  454; acc:  59.31; ppl:  10.49; 5209 src tok/s; 5429 tgt tok/s;     64 s elapsed
Epoch  3,   450/  454; acc:  58.75; ppl:  11.04; 5047 src tok/s; 5261 tgt tok/s;     72 s elapsed
Train perplexity: 12.4096
Train accuracy: 56.9424
Validation perplexity: 10.4418
Validation accuracy: 59.685

Epoch  4,    50/  454; acc:  62.03; ppl:   8.33; 5271 src tok/s; 5530 tgt tok/s;      8 s elapsed
Epoch  4,   100/  454; acc:  61.05; ppl:   8.72; 5280 src tok/s; 5446 tgt tok/s;     16 s elapsed
Epoch  4,   150/  454; acc:  62.28; ppl:   8.34; 5321 src tok/s; 5501 tgt tok/s;     24 s elapsed
Epoch  4,   200/  454; acc:  61.94; ppl:   8.20; 5266 src tok/s; 5466 tgt tok/s;     32 s elapsed
Epoch  4,   250/  454; acc:  61.30; ppl:   8.76; 5228 src tok/s; 5407 tgt tok/s;     40 s elapsed
Epoch  4,   300/  454; acc:  63.07; ppl:   7.77; 5223 src tok/s; 5435 tgt tok/s;     48 s elapsed
Epoch  4,   350/  454; acc:  63.39; ppl:   7.63; 5214 src tok/s; 5454 tgt tok/s;     55 s elapsed
Epoch  4,   400/  454; acc:  62.57; ppl:   7.92; 5304 src tok/s; 5465 tgt tok/s;     64 s elapsed
Epoch  4,   450/  454; acc:  63.31; ppl:   7.56; 5212 src tok/s; 5417 tgt tok/s;     72 s elapsed
Train perplexity: 8.13995
Train accuracy: 62.3045
Validation perplexity: 8.07212
Validation accuracy: 63.8712

Epoch  5,    50/  454; acc:  66.03; ppl:   6.00; 5325 src tok/s; 5536 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  65.22; ppl:   6.34; 5220 src tok/s; 5418 tgt tok/s;     16 s elapsed
Epoch  5,   150/  454; acc:  64.90; ppl:   6.43; 5368 src tok/s; 5548 tgt tok/s;     24 s elapsed
Epoch  5,   200/  454; acc:  65.99; ppl:   6.09; 5272 src tok/s; 5473 tgt tok/s;     32 s elapsed
Epoch  5,   250/  454; acc:  64.87; ppl:   6.39; 5242 src tok/s; 5425 tgt tok/s;     40 s elapsed
Epoch  5,   300/  454; acc:  66.79; ppl:   5.71; 5314 src tok/s; 5546 tgt tok/s;     47 s elapsed
Epoch  5,   350/  454; acc:  66.41; ppl:   5.85; 5261 src tok/s; 5492 tgt tok/s;     55 s elapsed
Epoch  5,   400/  454; acc:  65.10; ppl:   6.35; 5384 src tok/s; 5564 tgt tok/s;     63 s elapsed
Epoch  5,   450/  454; acc:  66.10; ppl:   6.03; 5303 src tok/s; 5505 tgt tok/s;     71 s elapsed
Train perplexity: 6.1411
Train accuracy: 65.6777
Validation perplexity: 7.42382
Validation accuracy: 64.0769

Epoch  6,    50/  454; acc:  68.43; ppl:   4.96; 5270 src tok/s; 5460 tgt tok/s;      8 s elapsed
Epoch  6,   100/  454; acc:  69.25; ppl:   4.68; 5328 src tok/s; 5555 tgt tok/s;     16 s elapsed
Epoch  6,   150/  454; acc:  68.49; ppl:   4.83; 5292 src tok/s; 5512 tgt tok/s;     24 s elapsed
Epoch  6,   200/  454; acc:  68.06; ppl:   5.02; 5343 src tok/s; 5501 tgt tok/s;     32 s elapsed
Epoch  6,   250/  454; acc:  67.31; ppl:   5.17; 5395 src tok/s; 5592 tgt tok/s;     40 s elapsed
Epoch  6,   300/  454; acc:  68.95; ppl:   4.81; 5348 src tok/s; 5560 tgt tok/s;     47 s elapsed
Epoch  6,   350/  454; acc:  67.64; ppl:   5.18; 5334 src tok/s; 5529 tgt tok/s;     55 s elapsed
Epoch  6,   400/  454; acc:  67.65; ppl:   5.09; 5423 src tok/s; 5632 tgt tok/s;     63 s elapsed
Epoch  6,   450/  454; acc:  68.25; ppl:   5.06; 5178 src tok/s; 5391 tgt tok/s;     71 s elapsed
Train perplexity: 4.97653
Train accuracy: 68.2079
Validation perplexity: 7.05832
Validation accuracy: 64.8858

Epoch  7,    50/  454; acc:  70.88; ppl:   4.02; 5364 src tok/s; 5522 tgt tok/s;      8 s elapsed
Epoch  7,   100/  454; acc:  71.53; ppl:   3.88; 5265 src tok/s; 5463 tgt tok/s;     16 s elapsed
Epoch  7,   150/  454; acc:  70.75; ppl:   4.10; 5258 src tok/s; 5477 tgt tok/s;     24 s elapsed
Epoch  7,   200/  454; acc:  70.65; ppl:   4.12; 5353 src tok/s; 5554 tgt tok/s;     32 s elapsed
Epoch  7,   250/  454; acc:  71.34; ppl:   3.94; 5345 src tok/s; 5590 tgt tok/s;     39 s elapsed
Epoch  7,   300/  454; acc:  68.97; ppl:   4.60; 5303 src tok/s; 5493 tgt tok/s;     47 s elapsed
Epoch  7,   350/  454; acc:  70.77; ppl:   4.12; 5245 src tok/s; 5482 tgt tok/s;     55 s elapsed
Epoch  7,   400/  454; acc:  69.21; ppl:   4.45; 5301 src tok/s; 5487 tgt tok/s;     63 s elapsed
Epoch  7,   450/  454; acc:  69.66; ppl:   4.38; 5297 src tok/s; 5466 tgt tok/s;     71 s elapsed
Train perplexity: 4.17229
Train accuracy: 70.4168
Validation perplexity: 7.10278
Validation accuracy: 64.6091
Decaying learning rate to 0.5

Epoch  8,    50/  454; acc:  73.77; ppl:   3.36; 5361 src tok/s; 5520 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  76.36; ppl:   2.90; 5417 src tok/s; 5639 tgt tok/s;     16 s elapsed
Epoch  8,   150/  454; acc:  75.50; ppl:   3.11; 5332 src tok/s; 5535 tgt tok/s;     23 s elapsed
Epoch  8,   200/  454; acc:  75.81; ppl:   2.96; 5330 src tok/s; 5504 tgt tok/s;     31 s elapsed
Epoch  8,   250/  454; acc:  74.92; ppl:   3.12; 5256 src tok/s; 5446 tgt tok/s;     40 s elapsed
Epoch  8,   300/  454; acc:  76.00; ppl:   2.94; 5340 src tok/s; 5587 tgt tok/s;     47 s elapsed
Epoch  8,   350/  454; acc:  75.50; ppl:   3.00; 5365 src tok/s; 5576 tgt tok/s;     55 s elapsed
Epoch  8,   400/  454; acc:  74.90; ppl:   3.17; 5277 src tok/s; 5500 tgt tok/s;     63 s elapsed
Epoch  8,   450/  454; acc:  75.34; ppl:   3.08; 5247 src tok/s; 5434 tgt tok/s;     71 s elapsed
Train perplexity: 3.06563
Train accuracy: 75.3507
Validation perplexity: 6.13727
Validation accuracy: 69.2351
Decaying learning rate to 0.25

Epoch  9,    50/  454; acc:  79.62; ppl:   2.43; 5394 src tok/s; 5609 tgt tok/s;      8 s elapsed
Epoch  9,   100/  454; acc:  79.34; ppl:   2.46; 5428 src tok/s; 5634 tgt tok/s;     16 s elapsed
Epoch  9,   150/  454; acc:  79.94; ppl:   2.40; 5318 src tok/s; 5510 tgt tok/s;     23 s elapsed
Epoch  9,   200/  454; acc:  78.75; ppl:   2.58; 5268 src tok/s; 5447 tgt tok/s;     31 s elapsed
Epoch  9,   250/  454; acc:  79.66; ppl:   2.43; 5337 src tok/s; 5555 tgt tok/s;     39 s elapsed
Epoch  9,   300/  454; acc:  78.32; ppl:   2.64; 5287 src tok/s; 5498 tgt tok/s;     47 s elapsed
Epoch  9,   350/  454; acc:  78.73; ppl:   2.56; 5288 src tok/s; 5479 tgt tok/s;     55 s elapsed
Epoch  9,   400/  454; acc:  79.10; ppl:   2.49; 5239 src tok/s; 5450 tgt tok/s;     63 s elapsed
Epoch  9,   450/  454; acc:  78.97; ppl:   2.50; 5205 src tok/s; 5396 tgt tok/s;     71 s elapsed
Train perplexity: 2.49833
Train accuracy: 79.1486
Validation perplexity: 6.22011
Validation accuracy: 68.9655
Decaying learning rate to 0.125

Epoch 10,    50/  454; acc:  81.11; ppl:   2.29; 5367 src tok/s; 5554 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  81.86; ppl:   2.14; 5501 src tok/s; 5702 tgt tok/s;     15 s elapsed
Epoch 10,   150/  454; acc:  82.83; ppl:   2.07; 5288 src tok/s; 5537 tgt tok/s;     23 s elapsed
Epoch 10,   200/  454; acc:  80.10; ppl:   2.42; 5235 src tok/s; 5378 tgt tok/s;     32 s elapsed
Epoch 10,   250/  454; acc:  82.05; ppl:   2.13; 5248 src tok/s; 5482 tgt tok/s;     39 s elapsed
Epoch 10,   300/  454; acc:  80.31; ppl:   2.34; 5386 src tok/s; 5546 tgt tok/s;     47 s elapsed
Epoch 10,   350/  454; acc:  80.45; ppl:   2.33; 5246 src tok/s; 5465 tgt tok/s;     55 s elapsed
Epoch 10,   400/  454; acc:  82.07; ppl:   2.15; 5307 src tok/s; 5510 tgt tok/s;     63 s elapsed
Epoch 10,   450/  454; acc:  81.30; ppl:   2.24; 5174 src tok/s; 5394 tgt tok/s;     71 s elapsed
Train perplexity: 2.23629
Train accuracy: 81.306
Validation perplexity: 6.27128
Validation accuracy: 69.1216
Decaying learning rate to 0.0625

Epoch 11,    50/  454; acc:  82.30; ppl:   2.13; 5514 src tok/s; 5681 tgt tok/s;      8 s elapsed
Epoch 11,   100/  454; acc:  82.47; ppl:   2.10; 5217 src tok/s; 5453 tgt tok/s;     16 s elapsed
Epoch 11,   150/  454; acc:  83.41; ppl:   2.01; 5325 src tok/s; 5562 tgt tok/s;     23 s elapsed
Epoch 11,   200/  454; acc:  81.37; ppl:   2.25; 5320 src tok/s; 5518 tgt tok/s;     31 s elapsed
Epoch 11,   250/  454; acc:  82.38; ppl:   2.14; 5149 src tok/s; 5369 tgt tok/s;     40 s elapsed
Epoch 11,   300/  454; acc:  82.42; ppl:   2.11; 5432 src tok/s; 5597 tgt tok/s;     47 s elapsed
Epoch 11,   350/  454; acc:  82.74; ppl:   2.10; 5308 src tok/s; 5509 tgt tok/s;     55 s elapsed
Epoch 11,   400/  454; acc:  82.51; ppl:   2.11; 5323 src tok/s; 5517 tgt tok/s;     63 s elapsed
Epoch 11,   450/  454; acc:  82.13; ppl:   2.13; 5195 src tok/s; 5391 tgt tok/s;     71 s elapsed
Train perplexity: 2.11768
Train accuracy: 82.418
Validation perplexity: 6.37263
Validation accuracy: 69.2068
Decaying learning rate to 0.03125

Epoch 12,    50/  454; acc:  82.70; ppl:   2.10; 5367 src tok/s; 5540 tgt tok/s;      8 s elapsed
Epoch 12,   100/  454; acc:  83.59; ppl:   1.98; 5306 src tok/s; 5538 tgt tok/s;     16 s elapsed
Epoch 12,   150/  454; acc:  83.29; ppl:   2.01; 5418 src tok/s; 5637 tgt tok/s;     23 s elapsed
Epoch 12,   200/  454; acc:  83.04; ppl:   2.06; 5271 src tok/s; 5487 tgt tok/s;     31 s elapsed
Epoch 12,   250/  454; acc:  82.50; ppl:   2.12; 5354 src tok/s; 5520 tgt tok/s;     40 s elapsed
Epoch 12,   300/  454; acc:  83.28; ppl:   2.02; 5274 src tok/s; 5477 tgt tok/s;     47 s elapsed
Epoch 12,   350/  454; acc:  82.49; ppl:   2.13; 5226 src tok/s; 5420 tgt tok/s;     55 s elapsed
Epoch 12,   400/  454; acc:  82.89; ppl:   2.05; 5368 src tok/s; 5590 tgt tok/s;     63 s elapsed
Epoch 12,   450/  454; acc:  82.90; ppl:   2.05; 5344 src tok/s; 5536 tgt tok/s;     71 s elapsed
Train perplexity: 2.05887
Train accuracy: 82.952
Validation perplexity: 6.40383
Validation accuracy: 69.1713
Decaying learning rate to 0.015625

Epoch 13,    50/  454; acc:  82.86; ppl:   2.08; 5417 src tok/s; 5589 tgt tok/s;      8 s elapsed
Epoch 13,   100/  454; acc:  84.15; ppl:   1.94; 5361 src tok/s; 5561 tgt tok/s;     16 s elapsed
Epoch 13,   150/  454; acc:  82.45; ppl:   2.14; 5371 src tok/s; 5550 tgt tok/s;     24 s elapsed
Epoch 13,   200/  454; acc:  84.04; ppl:   1.95; 5177 src tok/s; 5413 tgt tok/s;     32 s elapsed
Epoch 13,   250/  454; acc:  83.56; ppl:   1.99; 5249 src tok/s; 5453 tgt tok/s;     40 s elapsed
Epoch 13,   300/  454; acc:  82.92; ppl:   2.07; 5328 src tok/s; 5533 tgt tok/s;     47 s elapsed
Epoch 13,   350/  454; acc:  83.02; ppl:   2.05; 5406 src tok/s; 5596 tgt tok/s;     55 s elapsed
Epoch 13,   400/  454; acc:  83.21; ppl:   2.03; 5307 src tok/s; 5529 tgt tok/s;     63 s elapsed
Epoch 13,   450/  454; acc:  83.32; ppl:   2.03; 5229 src tok/s; 5424 tgt tok/s;     71 s elapsed
Train perplexity: 2.03071
Train accuracy: 83.2812
Validation perplexity: 6.45506
Validation accuracy: 69.1358
Decaying learning rate to 0.0078125

Epoch 14,    50/  454; acc:  83.47; ppl:   2.01; 5262 src tok/s; 5468 tgt tok/s;      8 s elapsed
Epoch 14,   100/  454; acc:  83.29; ppl:   2.03; 5298 src tok/s; 5519 tgt tok/s;     16 s elapsed
Epoch 14,   150/  454; acc:  83.02; ppl:   2.05; 5359 src tok/s; 5576 tgt tok/s;     24 s elapsed
Epoch 14,   200/  454; acc:  83.64; ppl:   2.01; 5391 src tok/s; 5577 tgt tok/s;     31 s elapsed
Epoch 14,   250/  454; acc:  83.89; ppl:   1.98; 5329 src tok/s; 5516 tgt tok/s;     39 s elapsed
Epoch 14,   300/  454; acc:  82.99; ppl:   2.03; 5299 src tok/s; 5484 tgt tok/s;     47 s elapsed
Epoch 14,   350/  454; acc:  83.68; ppl:   1.98; 5380 src tok/s; 5576 tgt tok/s;     55 s elapsed
Epoch 14,   400/  454; acc:  83.55; ppl:   2.02; 5196 src tok/s; 5427 tgt tok/s;     63 s elapsed
Epoch 14,   450/  454; acc:  82.96; ppl:   2.05; 5246 src tok/s; 5425 tgt tok/s;     71 s elapsed
Train perplexity: 2.01771
Train accuracy: 83.3989
Validation perplexity: 6.46827
Validation accuracy: 69.0861
Decaying learning rate to 0.00390625

Epoch 15,    50/  454; acc:  83.23; ppl:   2.05; 5342 src tok/s; 5535 tgt tok/s;      8 s elapsed
Epoch 15,   100/  454; acc:  84.01; ppl:   1.97; 5403 src tok/s; 5626 tgt tok/s;     16 s elapsed
Epoch 15,   150/  454; acc:  83.79; ppl:   2.00; 5246 src tok/s; 5445 tgt tok/s;     24 s elapsed
Epoch 15,   200/  454; acc:  83.69; ppl:   1.99; 5400 src tok/s; 5591 tgt tok/s;     31 s elapsed
Epoch 15,   250/  454; acc:  82.85; ppl:   2.08; 5202 src tok/s; 5384 tgt tok/s;     40 s elapsed
Epoch 15,   300/  454; acc:  84.32; ppl:   1.91; 5293 src tok/s; 5526 tgt tok/s;     47 s elapsed
Epoch 15,   350/  454; acc:  84.61; ppl:   1.89; 5342 src tok/s; 5582 tgt tok/s;     55 s elapsed
Epoch 15,   400/  454; acc:  82.31; ppl:   2.13; 5343 src tok/s; 5504 tgt tok/s;     63 s elapsed
Epoch 15,   450/  454; acc:  82.70; ppl:   2.09; 5321 src tok/s; 5495 tgt tok/s;     71 s elapsed
Train perplexity: 2.01058
Train accuracy: 83.5135
Validation perplexity: 6.47481
Validation accuracy: 69.0507
Decaying learning rate to 0.00195312

Epoch 16,    50/  454; acc:  82.93; ppl:   2.08; 5430 src tok/s; 5627 tgt tok/s;      8 s elapsed
Epoch 16,   100/  454; acc:  84.08; ppl:   1.93; 5339 src tok/s; 5569 tgt tok/s;     16 s elapsed
Epoch 16,   150/  454; acc:  83.85; ppl:   2.00; 5306 src tok/s; 5515 tgt tok/s;     24 s elapsed
Epoch 16,   200/  454; acc:  83.53; ppl:   2.00; 5288 src tok/s; 5497 tgt tok/s;     31 s elapsed
Epoch 16,   250/  454; acc:  83.62; ppl:   1.99; 5254 src tok/s; 5442 tgt tok/s;     39 s elapsed
Epoch 16,   300/  454; acc:  83.35; ppl:   2.02; 5247 src tok/s; 5470 tgt tok/s;     47 s elapsed
Epoch 16,   350/  454; acc:  83.61; ppl:   2.00; 5378 src tok/s; 5556 tgt tok/s;     55 s elapsed
Epoch 16,   400/  454; acc:  83.41; ppl:   2.02; 5309 src tok/s; 5525 tgt tok/s;     63 s elapsed
Epoch 16,   450/  454; acc:  83.41; ppl:   2.02; 5230 src tok/s; 5383 tgt tok/s;     71 s elapsed
Train perplexity: 2.00613
Train accuracy: 83.5491
Validation perplexity: 6.48054
Validation accuracy: 69.0719
Decaying learning rate to 0.000976562

Epoch 17,    50/  454; acc:  83.74; ppl:   1.99; 5345 src tok/s; 5539 tgt tok/s;      8 s elapsed
Epoch 17,   100/  454; acc:  83.47; ppl:   2.01; 5335 src tok/s; 5539 tgt tok/s;     16 s elapsed
Epoch 17,   150/  454; acc:  82.93; ppl:   2.09; 5349 src tok/s; 5520 tgt tok/s;     24 s elapsed
Epoch 17,   200/  454; acc:  84.52; ppl:   1.91; 5282 src tok/s; 5524 tgt tok/s;     32 s elapsed
Epoch 17,   250/  454; acc:  82.46; ppl:   2.12; 5323 src tok/s; 5516 tgt tok/s;     40 s elapsed
Epoch 17,   300/  454; acc:  84.27; ppl:   1.91; 5304 src tok/s; 5522 tgt tok/s;     47 s elapsed
Epoch 17,   350/  454; acc:  83.23; ppl:   2.06; 5310 src tok/s; 5498 tgt tok/s;     55 s elapsed
Epoch 17,   400/  454; acc:  84.16; ppl:   1.95; 5209 src tok/s; 5429 tgt tok/s;     63 s elapsed
Epoch 17,   450/  454; acc:  83.31; ppl:   2.03; 5340 src tok/s; 5510 tgt tok/s;     71 s elapsed
Train perplexity: 2.00462
Train accuracy: 83.5782
Validation perplexity: 6.48191
Validation accuracy: 69.0719
Decaying learning rate to 0.000488281
