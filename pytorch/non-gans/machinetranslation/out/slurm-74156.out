<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.1, kappa_enc=0.25, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.25decoder0.10dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.25)
('Using Kappa L2 loss on decoder', 0.1)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   7.45; ppl: 62628.50; 4289 src tok/s; 4455 tgt tok/s;     10 s elapsed
Epoch  1,   100/  454; acc:  12.64; ppl: 2359.91; 5564 src tok/s; 5761 tgt tok/s;     17 s elapsed
Epoch  1,   150/  454; acc:  16.76; ppl: 720.50; 5487 src tok/s; 5676 tgt tok/s;     25 s elapsed
Epoch  1,   200/  454; acc:  20.94; ppl: 305.08; 5550 src tok/s; 5765 tgt tok/s;     33 s elapsed
Epoch  1,   250/  454; acc:  25.40; ppl: 171.20; 5461 src tok/s; 5684 tgt tok/s;     40 s elapsed
Epoch  1,   300/  454; acc:  26.29; ppl: 135.13; 5608 src tok/s; 5806 tgt tok/s;     48 s elapsed
Epoch  1,   350/  454; acc:  29.75; ppl:  95.75; 5590 src tok/s; 5800 tgt tok/s;     55 s elapsed
Epoch  1,   400/  454; acc:  32.26; ppl:  77.28; 5343 src tok/s; 5549 tgt tok/s;     63 s elapsed
Epoch  1,   450/  454; acc:  32.81; ppl:  72.24; 5331 src tok/s; 5549 tgt tok/s;     71 s elapsed
Train perplexity: 411.189
Train accuracy: 22.8068
Validation perplexity: 62.7728
Validation accuracy: 34.5608

Epoch  2,    50/  454; acc:  36.81; ppl:  51.96; 5376 src tok/s; 5614 tgt tok/s;      8 s elapsed
Epoch  2,   100/  454; acc:  37.42; ppl:  47.51; 5561 src tok/s; 5750 tgt tok/s;     15 s elapsed
Epoch  2,   150/  454; acc:  40.41; ppl:  39.06; 5530 src tok/s; 5756 tgt tok/s;     23 s elapsed
Epoch  2,   200/  454; acc:  42.55; ppl:  33.17; 5546 src tok/s; 5728 tgt tok/s;     31 s elapsed
Epoch  2,   250/  454; acc:  44.89; ppl:  29.06; 5563 src tok/s; 5768 tgt tok/s;     38 s elapsed
Epoch  2,   300/  454; acc:  46.67; ppl:  25.79; 5515 src tok/s; 5711 tgt tok/s;     46 s elapsed
Epoch  2,   350/  454; acc:  48.64; ppl:  22.64; 5532 src tok/s; 5766 tgt tok/s;     53 s elapsed
Epoch  2,   400/  454; acc:  50.91; ppl:  19.00; 5467 src tok/s; 5680 tgt tok/s;     61 s elapsed
Epoch  2,   450/  454; acc:  51.90; ppl:  18.30; 5410 src tok/s; 5620 tgt tok/s;     68 s elapsed
Train perplexity: 29.8866
Train accuracy: 44.4505
Validation perplexity: 16.4663
Validation accuracy: 53.4625

Epoch  3,    50/  454; acc:  53.22; ppl:  15.87; 5397 src tok/s; 5587 tgt tok/s;      8 s elapsed
Epoch  3,   100/  454; acc:  54.51; ppl:  14.50; 5549 src tok/s; 5758 tgt tok/s;     15 s elapsed
Epoch  3,   150/  454; acc:  55.98; ppl:  13.00; 5507 src tok/s; 5728 tgt tok/s;     23 s elapsed
Epoch  3,   200/  454; acc:  55.81; ppl:  13.16; 5503 src tok/s; 5704 tgt tok/s;     31 s elapsed
Epoch  3,   250/  454; acc:  56.95; ppl:  12.70; 5493 src tok/s; 5729 tgt tok/s;     38 s elapsed
Epoch  3,   300/  454; acc:  57.39; ppl:  11.99; 5488 src tok/s; 5692 tgt tok/s;     46 s elapsed
Epoch  3,   350/  454; acc:  57.58; ppl:  11.96; 5520 src tok/s; 5718 tgt tok/s;     54 s elapsed
Epoch  3,   400/  454; acc:  58.51; ppl:  10.92; 5550 src tok/s; 5765 tgt tok/s;     61 s elapsed
Epoch  3,   450/  454; acc:  58.93; ppl:  10.69; 5584 src tok/s; 5780 tgt tok/s;     68 s elapsed
Train perplexity: 12.6433
Train accuracy: 56.5713
Validation perplexity: 10.4448
Validation accuracy: 59.5573

Epoch  4,    50/  454; acc:  61.68; ppl:   8.72; 5474 src tok/s; 5701 tgt tok/s;      8 s elapsed
Epoch  4,   100/  454; acc:  62.13; ppl:   8.29; 5533 src tok/s; 5742 tgt tok/s;     15 s elapsed
Epoch  4,   150/  454; acc:  61.34; ppl:   8.79; 5455 src tok/s; 5649 tgt tok/s;     23 s elapsed
Epoch  4,   200/  454; acc:  62.43; ppl:   8.20; 5536 src tok/s; 5752 tgt tok/s;     31 s elapsed
Epoch  4,   250/  454; acc:  61.15; ppl:   8.70; 5538 src tok/s; 5741 tgt tok/s;     38 s elapsed
Epoch  4,   300/  454; acc:  62.79; ppl:   7.84; 5487 src tok/s; 5713 tgt tok/s;     46 s elapsed
Epoch  4,   350/  454; acc:  63.14; ppl:   7.71; 5450 src tok/s; 5681 tgt tok/s;     53 s elapsed
Epoch  4,   400/  454; acc:  62.44; ppl:   8.19; 5515 src tok/s; 5702 tgt tok/s;     61 s elapsed
Epoch  4,   450/  454; acc:  62.33; ppl:   8.09; 5290 src tok/s; 5467 tgt tok/s;     69 s elapsed
Train perplexity: 8.27133
Train accuracy: 62.1591
Validation perplexity: 8.32351
Validation accuracy: 63.0197

Epoch  5,    50/  454; acc:  66.06; ppl:   5.99; 5458 src tok/s; 5722 tgt tok/s;      7 s elapsed
Epoch  5,   100/  454; acc:  65.26; ppl:   6.29; 5584 src tok/s; 5764 tgt tok/s;     15 s elapsed
Epoch  5,   150/  454; acc:  65.42; ppl:   6.42; 5503 src tok/s; 5696 tgt tok/s;     23 s elapsed
Epoch  5,   200/  454; acc:  65.27; ppl:   6.27; 5410 src tok/s; 5627 tgt tok/s;     30 s elapsed
Epoch  5,   250/  454; acc:  64.81; ppl:   6.56; 5439 src tok/s; 5646 tgt tok/s;     38 s elapsed
Epoch  5,   300/  454; acc:  66.00; ppl:   6.03; 5545 src tok/s; 5725 tgt tok/s;     46 s elapsed
Epoch  5,   350/  454; acc:  65.80; ppl:   6.15; 5560 src tok/s; 5753 tgt tok/s;     54 s elapsed
Epoch  5,   400/  454; acc:  66.34; ppl:   6.00; 5407 src tok/s; 5642 tgt tok/s;     61 s elapsed
Epoch  5,   450/  454; acc:  65.58; ppl:   6.33; 5405 src tok/s; 5605 tgt tok/s;     69 s elapsed
Train perplexity: 6.22171
Train accuracy: 65.6159
Validation perplexity: 7.43025
Validation accuracy: 64.8006

Epoch  6,    50/  454; acc:  68.44; ppl:   4.88; 5406 src tok/s; 5590 tgt tok/s;      8 s elapsed
Epoch  6,   100/  454; acc:  69.28; ppl:   4.65; 5425 src tok/s; 5664 tgt tok/s;     16 s elapsed
Epoch  6,   150/  454; acc:  67.93; ppl:   5.05; 5379 src tok/s; 5571 tgt tok/s;     23 s elapsed
Epoch  6,   200/  454; acc:  68.70; ppl:   4.86; 5340 src tok/s; 5553 tgt tok/s;     31 s elapsed
Epoch  6,   250/  454; acc:  67.25; ppl:   5.29; 5473 src tok/s; 5668 tgt tok/s;     39 s elapsed
Epoch  6,   300/  454; acc:  68.60; ppl:   4.96; 5412 src tok/s; 5612 tgt tok/s;     47 s elapsed
Epoch  6,   350/  454; acc:  67.33; ppl:   5.36; 5414 src tok/s; 5618 tgt tok/s;     54 s elapsed
Epoch  6,   400/  454; acc:  68.47; ppl:   4.90; 5425 src tok/s; 5639 tgt tok/s;     62 s elapsed
Epoch  6,   450/  454; acc:  67.91; ppl:   5.05; 5509 src tok/s; 5702 tgt tok/s;     70 s elapsed
Train perplexity: 4.99238
Train accuracy: 68.2276
Validation perplexity: 6.73334
Validation accuracy: 66.7092

Epoch  7,    50/  454; acc:  70.97; ppl:   4.05; 5530 src tok/s; 5726 tgt tok/s;      8 s elapsed
Epoch  7,   100/  454; acc:  71.78; ppl:   3.89; 5607 src tok/s; 5848 tgt tok/s;     15 s elapsed
Epoch  7,   150/  454; acc:  70.79; ppl:   4.06; 5380 src tok/s; 5606 tgt tok/s;     23 s elapsed
Epoch  7,   200/  454; acc:  69.88; ppl:   4.31; 5554 src tok/s; 5768 tgt tok/s;     30 s elapsed
Epoch  7,   250/  454; acc:  70.61; ppl:   4.16; 5654 src tok/s; 5862 tgt tok/s;     38 s elapsed
Epoch  7,   300/  454; acc:  69.65; ppl:   4.38; 5545 src tok/s; 5754 tgt tok/s;     45 s elapsed
Epoch  7,   350/  454; acc:  69.13; ppl:   4.57; 5500 src tok/s; 5690 tgt tok/s;     53 s elapsed
Epoch  7,   400/  454; acc:  70.69; ppl:   4.06; 5482 src tok/s; 5693 tgt tok/s;     61 s elapsed
Epoch  7,   450/  454; acc:  69.95; ppl:   4.38; 5517 src tok/s; 5707 tgt tok/s;     68 s elapsed
Train perplexity: 4.19938
Train accuracy: 70.3942
Validation perplexity: 6.6499
Validation accuracy: 66.2339

Epoch  8,    50/  454; acc:  74.05; ppl:   3.24; 5538 src tok/s; 5755 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  72.14; ppl:   3.65; 5481 src tok/s; 5674 tgt tok/s;     15 s elapsed
Epoch  8,   150/  454; acc:  71.65; ppl:   3.79; 5541 src tok/s; 5742 tgt tok/s;     23 s elapsed
Epoch  8,   200/  454; acc:  73.16; ppl:   3.40; 5550 src tok/s; 5792 tgt tok/s;     30 s elapsed
Epoch  8,   250/  454; acc:  72.67; ppl:   3.51; 5560 src tok/s; 5801 tgt tok/s;     38 s elapsed
Epoch  8,   300/  454; acc:  71.82; ppl:   3.74; 5471 src tok/s; 5635 tgt tok/s;     45 s elapsed
Epoch  8,   350/  454; acc:  72.28; ppl:   3.65; 5316 src tok/s; 5529 tgt tok/s;     53 s elapsed
Epoch  8,   400/  454; acc:  71.13; ppl:   3.85; 5442 src tok/s; 5625 tgt tok/s;     61 s elapsed
Epoch  8,   450/  454; acc:  71.80; ppl:   3.74; 5393 src tok/s; 5604 tgt tok/s;     69 s elapsed
Train perplexity: 3.61158
Train accuracy: 72.2992
Validation perplexity: 6.52056
Validation accuracy: 67.5536
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.64; ppl:   2.68; 5399 src tok/s; 5615 tgt tok/s;      8 s elapsed
Epoch  9,   100/  454; acc:  76.82; ppl:   2.77; 5553 src tok/s; 5733 tgt tok/s;     15 s elapsed
Epoch  9,   150/  454; acc:  78.75; ppl:   2.48; 5337 src tok/s; 5592 tgt tok/s;     23 s elapsed
Epoch  9,   200/  454; acc:  76.02; ppl:   2.94; 5536 src tok/s; 5715 tgt tok/s;     31 s elapsed
Epoch  9,   250/  454; acc:  76.99; ppl:   2.69; 5355 src tok/s; 5557 tgt tok/s;     39 s elapsed
Epoch  9,   300/  454; acc:  76.84; ppl:   2.77; 5567 src tok/s; 5785 tgt tok/s;     46 s elapsed
Epoch  9,   350/  454; acc:  77.49; ppl:   2.65; 5506 src tok/s; 5726 tgt tok/s;     54 s elapsed
Epoch  9,   400/  454; acc:  76.93; ppl:   2.77; 5472 src tok/s; 5663 tgt tok/s;     61 s elapsed
Epoch  9,   450/  454; acc:  77.12; ppl:   2.70; 5413 src tok/s; 5621 tgt tok/s;     69 s elapsed
Train perplexity: 2.71737
Train accuracy: 77.1623
Validation perplexity: 6.13629
Validation accuracy: 68.5611
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.75; ppl:   2.17; 5371 src tok/s; 5602 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  80.51; ppl:   2.27; 5484 src tok/s; 5699 tgt tok/s;     16 s elapsed
Epoch 10,   150/  454; acc:  81.66; ppl:   2.15; 5453 src tok/s; 5699 tgt tok/s;     23 s elapsed
Epoch 10,   200/  454; acc:  80.60; ppl:   2.30; 5449 src tok/s; 5614 tgt tok/s;     31 s elapsed
Epoch 10,   250/  454; acc:  80.72; ppl:   2.27; 5512 src tok/s; 5702 tgt tok/s;     39 s elapsed
Epoch 10,   300/  454; acc:  80.90; ppl:   2.22; 5525 src tok/s; 5725 tgt tok/s;     46 s elapsed
Epoch 10,   350/  454; acc:  80.87; ppl:   2.25; 5575 src tok/s; 5765 tgt tok/s;     54 s elapsed
Epoch 10,   400/  454; acc:  80.74; ppl:   2.22; 5511 src tok/s; 5722 tgt tok/s;     61 s elapsed
Epoch 10,   450/  454; acc:  81.18; ppl:   2.21; 5461 src tok/s; 5695 tgt tok/s;     69 s elapsed
Train perplexity: 2.23364
Train accuracy: 80.9501
Validation perplexity: 6.26951
Validation accuracy: 69.1713
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.63; ppl:   1.96; 5545 src tok/s; 5764 tgt tok/s;      8 s elapsed
Epoch 11,   100/  454; acc:  82.86; ppl:   2.04; 5448 src tok/s; 5672 tgt tok/s;     15 s elapsed
Epoch 11,   150/  454; acc:  84.81; ppl:   1.89; 5444 src tok/s; 5734 tgt tok/s;     22 s elapsed
Epoch 11,   200/  454; acc:  81.74; ppl:   2.15; 5582 src tok/s; 5748 tgt tok/s;     30 s elapsed
Epoch 11,   250/  454; acc:  83.63; ppl:   1.96; 5593 src tok/s; 5788 tgt tok/s;     38 s elapsed
Epoch 11,   300/  454; acc:  82.79; ppl:   2.06; 5429 src tok/s; 5639 tgt tok/s;     46 s elapsed
Epoch 11,   350/  454; acc:  83.44; ppl:   1.98; 5495 src tok/s; 5720 tgt tok/s;     53 s elapsed
Epoch 11,   400/  454; acc:  82.02; ppl:   2.14; 5806 src tok/s; 5981 tgt tok/s;     61 s elapsed
Epoch 11,   450/  454; acc:  82.97; ppl:   2.02; 5471 src tok/s; 5660 tgt tok/s;     68 s elapsed
Train perplexity: 2.02167
Train accuracy: 83.0714
Validation perplexity: 6.36787
Validation accuracy: 69.5402
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  83.86; ppl:   1.94; 5438 src tok/s; 5631 tgt tok/s;      8 s elapsed
Epoch 12,   100/  454; acc:  85.25; ppl:   1.84; 5479 src tok/s; 5706 tgt tok/s;     15 s elapsed
Epoch 12,   150/  454; acc:  84.64; ppl:   1.90; 5433 src tok/s; 5642 tgt tok/s;     23 s elapsed
Epoch 12,   200/  454; acc:  83.68; ppl:   1.97; 5622 src tok/s; 5842 tgt tok/s;     31 s elapsed
Epoch 12,   250/  454; acc:  83.61; ppl:   1.96; 5678 src tok/s; 5866 tgt tok/s;     38 s elapsed
Epoch 12,   300/  454; acc:  84.65; ppl:   1.88; 5488 src tok/s; 5710 tgt tok/s;     46 s elapsed
Epoch 12,   350/  454; acc:  83.93; ppl:   1.96; 5451 src tok/s; 5661 tgt tok/s;     53 s elapsed
Epoch 12,   400/  454; acc:  84.04; ppl:   1.93; 5370 src tok/s; 5580 tgt tok/s;     61 s elapsed
Epoch 12,   450/  454; acc:  84.12; ppl:   1.94; 5504 src tok/s; 5700 tgt tok/s;     69 s elapsed
Train perplexity: 1.9233
Train accuracy: 84.2099
Validation perplexity: 6.49547
Validation accuracy: 69.4054
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  86.09; ppl:   1.77; 5443 src tok/s; 5692 tgt tok/s;      7 s elapsed
Epoch 13,   100/  454; acc:  84.21; ppl:   1.94; 5463 src tok/s; 5635 tgt tok/s;     15 s elapsed
Epoch 13,   150/  454; acc:  85.09; ppl:   1.84; 5406 src tok/s; 5604 tgt tok/s;     23 s elapsed
Epoch 13,   200/  454; acc:  84.19; ppl:   1.94; 5333 src tok/s; 5551 tgt tok/s;     31 s elapsed
Epoch 13,   250/  454; acc:  85.78; ppl:   1.79; 5466 src tok/s; 5686 tgt tok/s;     39 s elapsed
Epoch 13,   300/  454; acc:  83.68; ppl:   1.97; 5527 src tok/s; 5700 tgt tok/s;     46 s elapsed
Epoch 13,   350/  454; acc:  84.34; ppl:   1.93; 5504 src tok/s; 5669 tgt tok/s;     54 s elapsed
Epoch 13,   400/  454; acc:  85.52; ppl:   1.79; 5427 src tok/s; 5692 tgt tok/s;     62 s elapsed
Epoch 13,   450/  454; acc:  84.79; ppl:   1.87; 5365 src tok/s; 5572 tgt tok/s;     69 s elapsed
Train perplexity: 1.87313
Train accuracy: 84.8119
Validation perplexity: 6.55562
Validation accuracy: 69.2635
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.50; ppl:   1.81; 5367 src tok/s; 5541 tgt tok/s;      8 s elapsed
Epoch 14,   100/  454; acc:  84.83; ppl:   1.88; 5452 src tok/s; 5665 tgt tok/s;     16 s elapsed
Epoch 14,   150/  454; acc:  84.82; ppl:   1.88; 5445 src tok/s; 5676 tgt tok/s;     23 s elapsed
Epoch 14,   200/  454; acc:  85.61; ppl:   1.79; 5522 src tok/s; 5722 tgt tok/s;     31 s elapsed
Epoch 14,   250/  454; acc:  84.11; ppl:   1.94; 5470 src tok/s; 5625 tgt tok/s;     39 s elapsed
Epoch 14,   300/  454; acc:  85.87; ppl:   1.78; 5374 src tok/s; 5652 tgt tok/s;     46 s elapsed
Epoch 14,   350/  454; acc:  83.81; ppl:   1.94; 5487 src tok/s; 5663 tgt tok/s;     54 s elapsed
Epoch 14,   400/  454; acc:  85.81; ppl:   1.77; 5566 src tok/s; 5792 tgt tok/s;     61 s elapsed
Epoch 14,   450/  454; acc:  84.83; ppl:   1.86; 5343 src tok/s; 5556 tgt tok/s;     69 s elapsed
Train perplexity: 1.8499
Train accuracy: 85.006
Validation perplexity: 6.5893
Validation accuracy: 69.2919
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  84.66; ppl:   1.88; 5550 src tok/s; 5723 tgt tok/s;      8 s elapsed
Epoch 15,   100/  454; acc:  85.97; ppl:   1.76; 5536 src tok/s; 5767 tgt tok/s;     15 s elapsed
Epoch 15,   150/  454; acc:  85.73; ppl:   1.79; 5536 src tok/s; 5757 tgt tok/s;     23 s elapsed
Epoch 15,   200/  454; acc:  84.93; ppl:   1.86; 5475 src tok/s; 5680 tgt tok/s;     30 s elapsed
Epoch 15,   250/  454; acc:  85.67; ppl:   1.80; 5535 src tok/s; 5741 tgt tok/s;     38 s elapsed
Epoch 15,   300/  454; acc:  84.55; ppl:   1.90; 5478 src tok/s; 5691 tgt tok/s;     46 s elapsed
Epoch 15,   350/  454; acc:  84.83; ppl:   1.86; 5552 src tok/s; 5744 tgt tok/s;     53 s elapsed
Epoch 15,   400/  454; acc:  85.52; ppl:   1.82; 5483 src tok/s; 5712 tgt tok/s;     61 s elapsed
Epoch 15,   450/  454; acc:  85.19; ppl:   1.85; 5353 src tok/s; 5562 tgt tok/s;     69 s elapsed
Train perplexity: 1.83689
Train accuracy: 85.2146
Validation perplexity: 6.607
Validation accuracy: 69.3558
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  86.37; ppl:   1.73; 5435 src tok/s; 5672 tgt tok/s;      7 s elapsed
Epoch 16,   100/  454; acc:  84.33; ppl:   1.93; 5552 src tok/s; 5730 tgt tok/s;     15 s elapsed
Epoch 16,   150/  454; acc:  85.68; ppl:   1.78; 5434 src tok/s; 5687 tgt tok/s;     23 s elapsed
Epoch 16,   200/  454; acc:  84.95; ppl:   1.85; 5547 src tok/s; 5723 tgt tok/s;     30 s elapsed
Epoch 16,   250/  454; acc:  85.29; ppl:   1.84; 5475 src tok/s; 5661 tgt tok/s;     38 s elapsed
Epoch 16,   300/  454; acc:  85.57; ppl:   1.80; 5576 src tok/s; 5795 tgt tok/s;     46 s elapsed
Epoch 16,   350/  454; acc:  85.94; ppl:   1.78; 5300 src tok/s; 5519 tgt tok/s;     53 s elapsed
Epoch 16,   400/  454; acc:  84.36; ppl:   1.91; 5362 src tok/s; 5549 tgt tok/s;     61 s elapsed
Epoch 16,   450/  454; acc:  84.72; ppl:   1.88; 5360 src tok/s; 5562 tgt tok/s;     69 s elapsed
Train perplexity: 1.83318
Train accuracy: 85.2459
Validation perplexity: 6.614
Validation accuracy: 69.3061
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.82; ppl:   1.79; 5367 src tok/s; 5566 tgt tok/s;      8 s elapsed
Epoch 17,   100/  454; acc:  84.89; ppl:   1.86; 5476 src tok/s; 5694 tgt tok/s;     16 s elapsed
Epoch 17,   150/  454; acc:  85.42; ppl:   1.83; 5566 src tok/s; 5774 tgt tok/s;     23 s elapsed
Epoch 17,   200/  454; acc:  85.44; ppl:   1.83; 5468 src tok/s; 5663 tgt tok/s;     31 s elapsed
Epoch 17,   250/  454; acc:  85.27; ppl:   1.85; 5535 src tok/s; 5727 tgt tok/s;     38 s elapsed
Epoch 17,   300/  454; acc:  85.52; ppl:   1.82; 5533 src tok/s; 5759 tgt tok/s;     46 s elapsed
Epoch 17,   350/  454; acc:  85.73; ppl:   1.81; 5020 src tok/s; 5246 tgt tok/s;     54 s elapsed
Epoch 17,   400/  454; acc:  85.01; ppl:   1.87; 5718 src tok/s; 5907 tgt tok/s;     62 s elapsed
Epoch 17,   450/  454; acc:  85.48; ppl:   1.82; 5590 src tok/s; 5796 tgt tok/s;     69 s elapsed
Train perplexity: 1.83039
Train accuracy: 85.4178
Validation perplexity: 6.61741
Validation accuracy: 69.2706
Decaying learning rate to 0.000976562
