<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.0, kappa_enc=0.2, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.20decoder0dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.2)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   9.83; ppl: 13865.71; 4206 src tok/s; 4367 tgt tok/s;     10 s elapsed
Epoch  1,   100/  454; acc:  14.57; ppl: 1881.19; 5839 src tok/s; 6070 tgt tok/s;     17 s elapsed
Epoch  1,   150/  454; acc:  18.05; ppl: 566.62; 5564 src tok/s; 5767 tgt tok/s;     25 s elapsed
Epoch  1,   200/  454; acc:  21.47; ppl: 254.25; 5696 src tok/s; 5890 tgt tok/s;     32 s elapsed
Epoch  1,   250/  454; acc:  24.20; ppl: 167.75; 5703 src tok/s; 5931 tgt tok/s;     40 s elapsed
Epoch  1,   300/  454; acc:  27.01; ppl: 121.36; 5401 src tok/s; 5608 tgt tok/s;     47 s elapsed
Epoch  1,   350/  454; acc:  29.73; ppl:  97.58; 5271 src tok/s; 5490 tgt tok/s;     55 s elapsed
Epoch  1,   400/  454; acc:  32.10; ppl:  76.04; 5431 src tok/s; 5623 tgt tok/s;     63 s elapsed
Epoch  1,   450/  454; acc:  32.84; ppl:  69.71; 5303 src tok/s; 5490 tgt tok/s;     71 s elapsed
Train perplexity: 322.126
Train accuracy: 23.3679
Validation perplexity: 58.5047
Validation accuracy: 35.767

Epoch  2,    50/  454; acc:  33.79; ppl:  61.67; 5301 src tok/s; 5456 tgt tok/s;      8 s elapsed
Epoch  2,   100/  454; acc:  37.84; ppl:  46.17; 5337 src tok/s; 5585 tgt tok/s;     16 s elapsed
Epoch  2,   150/  454; acc:  40.04; ppl:  40.20; 5326 src tok/s; 5559 tgt tok/s;     23 s elapsed
Epoch  2,   200/  454; acc:  41.39; ppl:  36.38; 5380 src tok/s; 5546 tgt tok/s;     31 s elapsed
Epoch  2,   250/  454; acc:  45.37; ppl:  28.20; 5358 src tok/s; 5574 tgt tok/s;     39 s elapsed
Epoch  2,   300/  454; acc:  45.93; ppl:  27.26; 5447 src tok/s; 5637 tgt tok/s;     47 s elapsed
Epoch  2,   350/  454; acc:  48.65; ppl:  22.42; 5528 src tok/s; 5751 tgt tok/s;     54 s elapsed
Epoch  2,   400/  454; acc:  49.65; ppl:  21.33; 5384 src tok/s; 5586 tgt tok/s;     62 s elapsed
Epoch  2,   450/  454; acc:  51.97; ppl:  18.45; 5221 src tok/s; 5438 tgt tok/s;     70 s elapsed
Train perplexity: 31.1618
Train accuracy: 43.878
Validation perplexity: 16.4315
Validation accuracy: 53.9237

Epoch  3,    50/  454; acc:  53.73; ppl:  15.56; 5383 src tok/s; 5599 tgt tok/s;      8 s elapsed
Epoch  3,   100/  454; acc:  54.42; ppl:  14.83; 5346 src tok/s; 5552 tgt tok/s;     16 s elapsed
Epoch  3,   150/  454; acc:  54.30; ppl:  14.58; 5432 src tok/s; 5598 tgt tok/s;     24 s elapsed
Epoch  3,   200/  454; acc:  57.13; ppl:  12.33; 5373 src tok/s; 5633 tgt tok/s;     31 s elapsed
Epoch  3,   250/  454; acc:  57.63; ppl:  11.85; 5429 src tok/s; 5638 tgt tok/s;     39 s elapsed
Epoch  3,   300/  454; acc:  56.98; ppl:  12.42; 5434 src tok/s; 5620 tgt tok/s;     47 s elapsed
Epoch  3,   350/  454; acc:  58.62; ppl:  11.28; 5498 src tok/s; 5722 tgt tok/s;     54 s elapsed
Epoch  3,   400/  454; acc:  58.48; ppl:  11.15; 5384 src tok/s; 5568 tgt tok/s;     62 s elapsed
Epoch  3,   450/  454; acc:  58.93; ppl:  10.86; 5287 src tok/s; 5474 tgt tok/s;     70 s elapsed
Train perplexity: 12.6321
Train accuracy: 56.7226
Validation perplexity: 9.85117
Validation accuracy: 61.3098

Epoch  4,    50/  454; acc:  60.31; ppl:   9.29; 5436 src tok/s; 5600 tgt tok/s;      8 s elapsed
Epoch  4,   100/  454; acc:  62.39; ppl:   8.15; 5351 src tok/s; 5613 tgt tok/s;     16 s elapsed
Epoch  4,   150/  454; acc:  62.06; ppl:   8.49; 5356 src tok/s; 5591 tgt tok/s;     23 s elapsed
Epoch  4,   200/  454; acc:  61.36; ppl:   8.72; 5446 src tok/s; 5653 tgt tok/s;     31 s elapsed
Epoch  4,   250/  454; acc:  62.05; ppl:   8.34; 5428 src tok/s; 5606 tgt tok/s;     39 s elapsed
Epoch  4,   300/  454; acc:  62.49; ppl:   7.93; 5377 src tok/s; 5589 tgt tok/s;     47 s elapsed
Epoch  4,   350/  454; acc:  62.93; ppl:   7.77; 5438 src tok/s; 5638 tgt tok/s;     54 s elapsed
Epoch  4,   400/  454; acc:  62.93; ppl:   7.80; 5473 src tok/s; 5663 tgt tok/s;     62 s elapsed
Epoch  4,   450/  454; acc:  63.41; ppl:   7.63; 5506 src tok/s; 5706 tgt tok/s;     69 s elapsed
Train perplexity: 8.23755
Train accuracy: 62.1751
Validation perplexity: 8.19227
Validation accuracy: 63.7505

Epoch  5,    50/  454; acc:  65.21; ppl:   6.31; 5456 src tok/s; 5671 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  65.94; ppl:   6.07; 5371 src tok/s; 5593 tgt tok/s;     15 s elapsed
Epoch  5,   150/  454; acc:  65.59; ppl:   6.20; 5551 src tok/s; 5733 tgt tok/s;     23 s elapsed
Epoch  5,   200/  454; acc:  65.59; ppl:   6.24; 5379 src tok/s; 5600 tgt tok/s;     31 s elapsed
Epoch  5,   250/  454; acc:  65.73; ppl:   6.16; 5596 src tok/s; 5798 tgt tok/s;     38 s elapsed
Epoch  5,   300/  454; acc:  65.14; ppl:   6.33; 5435 src tok/s; 5635 tgt tok/s;     46 s elapsed
Epoch  5,   350/  454; acc:  67.33; ppl:   5.61; 5497 src tok/s; 5741 tgt tok/s;     53 s elapsed
Epoch  5,   400/  454; acc:  64.55; ppl:   6.55; 5415 src tok/s; 5582 tgt tok/s;     61 s elapsed
Epoch  5,   450/  454; acc:  65.47; ppl:   6.28; 5364 src tok/s; 5568 tgt tok/s;     69 s elapsed
Train perplexity: 6.18922
Train accuracy: 65.6255
Validation perplexity: 7.41151
Validation accuracy: 64.8219

Epoch  6,    50/  454; acc:  69.41; ppl:   4.61; 5447 src tok/s; 5668 tgt tok/s;      8 s elapsed
Epoch  6,   100/  454; acc:  68.24; ppl:   5.00; 5397 src tok/s; 5605 tgt tok/s;     15 s elapsed
Epoch  6,   150/  454; acc:  67.54; ppl:   5.28; 5401 src tok/s; 5573 tgt tok/s;     24 s elapsed
Epoch  6,   200/  454; acc:  69.26; ppl:   4.78; 5449 src tok/s; 5694 tgt tok/s;     31 s elapsed
Epoch  6,   250/  454; acc:  69.22; ppl:   4.71; 5411 src tok/s; 5643 tgt tok/s;     38 s elapsed
Epoch  6,   300/  454; acc:  67.46; ppl:   5.21; 5490 src tok/s; 5655 tgt tok/s;     46 s elapsed
Epoch  6,   350/  454; acc:  67.75; ppl:   5.08; 5478 src tok/s; 5680 tgt tok/s;     54 s elapsed
Epoch  6,   400/  454; acc:  67.76; ppl:   5.02; 5338 src tok/s; 5544 tgt tok/s;     62 s elapsed
Epoch  6,   450/  454; acc:  67.86; ppl:   5.14; 5400 src tok/s; 5610 tgt tok/s;     69 s elapsed
Train perplexity: 4.99249
Train accuracy: 68.2315
Validation perplexity: 6.96639
Validation accuracy: 66.695

Epoch  7,    50/  454; acc:  72.51; ppl:   3.70; 5537 src tok/s; 5778 tgt tok/s;      7 s elapsed
Epoch  7,   100/  454; acc:  69.80; ppl:   4.25; 5462 src tok/s; 5631 tgt tok/s;     15 s elapsed
Epoch  7,   150/  454; acc:  69.69; ppl:   4.29; 5405 src tok/s; 5605 tgt tok/s;     23 s elapsed
Epoch  7,   200/  454; acc:  70.75; ppl:   4.13; 5337 src tok/s; 5546 tgt tok/s;     31 s elapsed
Epoch  7,   250/  454; acc:  69.68; ppl:   4.41; 5585 src tok/s; 5782 tgt tok/s;     39 s elapsed
Epoch  7,   300/  454; acc:  71.06; ppl:   3.99; 5514 src tok/s; 5762 tgt tok/s;     46 s elapsed
Epoch  7,   350/  454; acc:  69.48; ppl:   4.54; 5530 src tok/s; 5686 tgt tok/s;     54 s elapsed
Epoch  7,   400/  454; acc:  70.82; ppl:   4.06; 5325 src tok/s; 5543 tgt tok/s;     62 s elapsed
Epoch  7,   450/  454; acc:  69.79; ppl:   4.31; 5367 src tok/s; 5604 tgt tok/s;     69 s elapsed
Train perplexity: 4.19062
Train accuracy: 70.358
Validation perplexity: 6.86379
Validation accuracy: 66.6312

Epoch  8,    50/  454; acc:  73.74; ppl:   3.35; 5450 src tok/s; 5660 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  72.20; ppl:   3.62; 5376 src tok/s; 5568 tgt tok/s;     16 s elapsed
Epoch  8,   150/  454; acc:  72.18; ppl:   3.60; 5471 src tok/s; 5645 tgt tok/s;     23 s elapsed
Epoch  8,   200/  454; acc:  72.75; ppl:   3.51; 5538 src tok/s; 5740 tgt tok/s;     31 s elapsed
Epoch  8,   250/  454; acc:  72.65; ppl:   3.51; 5290 src tok/s; 5578 tgt tok/s;     38 s elapsed
Epoch  8,   300/  454; acc:  71.32; ppl:   3.78; 5473 src tok/s; 5653 tgt tok/s;     46 s elapsed
Epoch  8,   350/  454; acc:  71.75; ppl:   3.70; 5437 src tok/s; 5608 tgt tok/s;     54 s elapsed
Epoch  8,   400/  454; acc:  72.55; ppl:   3.50; 5399 src tok/s; 5648 tgt tok/s;     62 s elapsed
Epoch  8,   450/  454; acc:  70.62; ppl:   3.91; 5382 src tok/s; 5558 tgt tok/s;     70 s elapsed
Train perplexity: 3.60173
Train accuracy: 72.2131
Validation perplexity: 6.73625
Validation accuracy: 66.9363
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.34; ppl:   2.69; 5532 src tok/s; 5784 tgt tok/s;      7 s elapsed
Epoch  9,   100/  454; acc:  76.89; ppl:   2.74; 5545 src tok/s; 5709 tgt tok/s;     15 s elapsed
Epoch  9,   150/  454; acc:  76.41; ppl:   2.81; 5439 src tok/s; 5615 tgt tok/s;     23 s elapsed
Epoch  9,   200/  454; acc:  77.90; ppl:   2.57; 5490 src tok/s; 5713 tgt tok/s;     31 s elapsed
Epoch  9,   250/  454; acc:  77.16; ppl:   2.73; 5400 src tok/s; 5612 tgt tok/s;     39 s elapsed
Epoch  9,   300/  454; acc:  77.72; ppl:   2.63; 5416 src tok/s; 5653 tgt tok/s;     46 s elapsed
Epoch  9,   350/  454; acc:  76.84; ppl:   2.71; 5429 src tok/s; 5632 tgt tok/s;     54 s elapsed
Epoch  9,   400/  454; acc:  76.96; ppl:   2.71; 5504 src tok/s; 5724 tgt tok/s;     61 s elapsed
Epoch  9,   450/  454; acc:  77.29; ppl:   2.71; 5348 src tok/s; 5523 tgt tok/s;     69 s elapsed
Train perplexity: 2.70247
Train accuracy: 77.147
Validation perplexity: 6.23731
Validation accuracy: 68.93
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.43; ppl:   2.17; 5360 src tok/s; 5561 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  81.26; ppl:   2.20; 5318 src tok/s; 5521 tgt tok/s;     16 s elapsed
Epoch 10,   150/  454; acc:  81.17; ppl:   2.22; 5534 src tok/s; 5731 tgt tok/s;     23 s elapsed
Epoch 10,   200/  454; acc:  81.20; ppl:   2.20; 5505 src tok/s; 5726 tgt tok/s;     31 s elapsed
Epoch 10,   250/  454; acc:  81.41; ppl:   2.16; 5481 src tok/s; 5701 tgt tok/s;     38 s elapsed
Epoch 10,   300/  454; acc:  80.29; ppl:   2.29; 5434 src tok/s; 5646 tgt tok/s;     46 s elapsed
Epoch 10,   350/  454; acc:  81.20; ppl:   2.17; 5345 src tok/s; 5561 tgt tok/s;     54 s elapsed
Epoch 10,   400/  454; acc:  79.62; ppl:   2.37; 5500 src tok/s; 5671 tgt tok/s;     62 s elapsed
Epoch 10,   450/  454; acc:  80.83; ppl:   2.22; 5536 src tok/s; 5741 tgt tok/s;     69 s elapsed
Train perplexity: 2.22273
Train accuracy: 80.9148
Validation perplexity: 6.25852
Validation accuracy: 68.8733
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  84.14; ppl:   1.92; 5551 src tok/s; 5809 tgt tok/s;      7 s elapsed
Epoch 11,   100/  454; acc:  83.17; ppl:   2.01; 5410 src tok/s; 5613 tgt tok/s;     15 s elapsed
Epoch 11,   150/  454; acc:  83.22; ppl:   1.99; 5495 src tok/s; 5703 tgt tok/s;     23 s elapsed
Epoch 11,   200/  454; acc:  82.53; ppl:   2.04; 5522 src tok/s; 5703 tgt tok/s;     31 s elapsed
Epoch 11,   250/  454; acc:  82.78; ppl:   2.09; 5403 src tok/s; 5628 tgt tok/s;     38 s elapsed
Epoch 11,   300/  454; acc:  83.44; ppl:   1.95; 5541 src tok/s; 5778 tgt tok/s;     46 s elapsed
Epoch 11,   350/  454; acc:  83.18; ppl:   2.01; 5429 src tok/s; 5617 tgt tok/s;     53 s elapsed
Epoch 11,   400/  454; acc:  82.82; ppl:   2.03; 5401 src tok/s; 5551 tgt tok/s;     61 s elapsed
Epoch 11,   450/  454; acc:  82.81; ppl:   2.02; 5222 src tok/s; 5440 tgt tok/s;     69 s elapsed
Train perplexity: 2.00779
Train accuracy: 83.0962
Validation perplexity: 6.43256
Validation accuracy: 69.1287
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  85.29; ppl:   1.83; 5409 src tok/s; 5627 tgt tok/s;      7 s elapsed
Epoch 12,   100/  454; acc:  83.47; ppl:   1.98; 5487 src tok/s; 5652 tgt tok/s;     15 s elapsed
Epoch 12,   150/  454; acc:  85.17; ppl:   1.83; 5371 src tok/s; 5640 tgt tok/s;     23 s elapsed
Epoch 12,   200/  454; acc:  83.48; ppl:   1.98; 5475 src tok/s; 5648 tgt tok/s;     31 s elapsed
Epoch 12,   250/  454; acc:  84.83; ppl:   1.86; 5478 src tok/s; 5722 tgt tok/s;     38 s elapsed
Epoch 12,   300/  454; acc:  84.16; ppl:   1.92; 5572 src tok/s; 5769 tgt tok/s;     46 s elapsed
Epoch 12,   350/  454; acc:  83.89; ppl:   1.96; 5543 src tok/s; 5727 tgt tok/s;     54 s elapsed
Epoch 12,   400/  454; acc:  84.87; ppl:   1.86; 5398 src tok/s; 5620 tgt tok/s;     61 s elapsed
Epoch 12,   450/  454; acc:  84.01; ppl:   1.92; 5495 src tok/s; 5701 tgt tok/s;     69 s elapsed
Train perplexity: 1.90741
Train accuracy: 84.3101
Validation perplexity: 6.56599
Validation accuracy: 69.3132
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.20; ppl:   1.93; 5491 src tok/s; 5678 tgt tok/s;      8 s elapsed
Epoch 13,   100/  454; acc:  85.82; ppl:   1.77; 5549 src tok/s; 5778 tgt tok/s;     15 s elapsed
Epoch 13,   150/  454; acc:  84.59; ppl:   1.86; 5337 src tok/s; 5549 tgt tok/s;     23 s elapsed
Epoch 13,   200/  454; acc:  84.30; ppl:   1.93; 5394 src tok/s; 5586 tgt tok/s;     31 s elapsed
Epoch 13,   250/  454; acc:  86.28; ppl:   1.73; 5354 src tok/s; 5593 tgt tok/s;     38 s elapsed
Epoch 13,   300/  454; acc:  83.53; ppl:   1.96; 5550 src tok/s; 5722 tgt tok/s;     46 s elapsed
Epoch 13,   350/  454; acc:  85.36; ppl:   1.79; 5515 src tok/s; 5748 tgt tok/s;     54 s elapsed
Epoch 13,   400/  454; acc:  84.15; ppl:   1.92; 5465 src tok/s; 5657 tgt tok/s;     62 s elapsed
Epoch 13,   450/  454; acc:  84.94; ppl:   1.84; 5407 src tok/s; 5621 tgt tok/s;     69 s elapsed
Train perplexity: 1.85965
Train accuracy: 84.78
Validation perplexity: 6.59003
Validation accuracy: 69.3274
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.16; ppl:   1.83; 5488 src tok/s; 5736 tgt tok/s;      8 s elapsed
Epoch 14,   100/  454; acc:  85.04; ppl:   1.86; 5457 src tok/s; 5665 tgt tok/s;     15 s elapsed
Epoch 14,   150/  454; acc:  84.39; ppl:   1.91; 5404 src tok/s; 5583 tgt tok/s;     23 s elapsed
Epoch 14,   200/  454; acc:  86.09; ppl:   1.75; 5600 src tok/s; 5832 tgt tok/s;     31 s elapsed
Epoch 14,   250/  454; acc:  85.11; ppl:   1.84; 5561 src tok/s; 5764 tgt tok/s;     38 s elapsed
Epoch 14,   300/  454; acc:  85.59; ppl:   1.81; 5409 src tok/s; 5622 tgt tok/s;     46 s elapsed
Epoch 14,   350/  454; acc:  85.35; ppl:   1.81; 5459 src tok/s; 5661 tgt tok/s;     53 s elapsed
Epoch 14,   400/  454; acc:  84.88; ppl:   1.88; 5391 src tok/s; 5573 tgt tok/s;     61 s elapsed
Epoch 14,   450/  454; acc:  85.42; ppl:   1.79; 5562 src tok/s; 5777 tgt tok/s;     69 s elapsed
Train perplexity: 1.83756
Train accuracy: 85.1655
Validation perplexity: 6.62963
Validation accuracy: 69.4267
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  86.17; ppl:   1.76; 5478 src tok/s; 5700 tgt tok/s;      7 s elapsed
Epoch 15,   100/  454; acc:  85.09; ppl:   1.84; 5456 src tok/s; 5657 tgt tok/s;     15 s elapsed
Epoch 15,   150/  454; acc:  84.14; ppl:   1.94; 5383 src tok/s; 5576 tgt tok/s;     23 s elapsed
Epoch 15,   200/  454; acc:  86.29; ppl:   1.74; 5410 src tok/s; 5644 tgt tok/s;     31 s elapsed
Epoch 15,   250/  454; acc:  85.10; ppl:   1.84; 5505 src tok/s; 5693 tgt tok/s;     39 s elapsed
Epoch 15,   300/  454; acc:  85.06; ppl:   1.83; 5480 src tok/s; 5711 tgt tok/s;     46 s elapsed
Epoch 15,   350/  454; acc:  84.53; ppl:   1.90; 5562 src tok/s; 5717 tgt tok/s;     54 s elapsed
Epoch 15,   400/  454; acc:  86.12; ppl:   1.73; 5451 src tok/s; 5691 tgt tok/s;     61 s elapsed
Epoch 15,   450/  454; acc:  85.21; ppl:   1.84; 5368 src tok/s; 5556 tgt tok/s;     69 s elapsed
Train perplexity: 1.82475
Train accuracy: 85.2975
Validation perplexity: 6.64716
Validation accuracy: 69.2848
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.69; ppl:   1.78; 5497 src tok/s; 5736 tgt tok/s;      7 s elapsed
Epoch 16,   100/  454; acc:  85.37; ppl:   1.82; 5450 src tok/s; 5630 tgt tok/s;     15 s elapsed
Epoch 16,   150/  454; acc:  85.85; ppl:   1.77; 5413 src tok/s; 5661 tgt tok/s;     23 s elapsed
Epoch 16,   200/  454; acc:  84.98; ppl:   1.88; 5545 src tok/s; 5704 tgt tok/s;     31 s elapsed
Epoch 16,   250/  454; acc:  85.54; ppl:   1.80; 5405 src tok/s; 5619 tgt tok/s;     38 s elapsed
Epoch 16,   300/  454; acc:  85.07; ppl:   1.85; 5397 src tok/s; 5600 tgt tok/s;     46 s elapsed
Epoch 16,   350/  454; acc:  86.56; ppl:   1.73; 5443 src tok/s; 5703 tgt tok/s;     53 s elapsed
Epoch 16,   400/  454; acc:  84.35; ppl:   1.91; 5454 src tok/s; 5619 tgt tok/s;     62 s elapsed
Epoch 16,   450/  454; acc:  85.12; ppl:   1.83; 5246 src tok/s; 5441 tgt tok/s;     69 s elapsed
Train perplexity: 1.81915
Train accuracy: 85.3755
Validation perplexity: 6.65772
Validation accuracy: 69.2351
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  84.16; ppl:   1.91; 5590 src tok/s; 5744 tgt tok/s;      8 s elapsed
Epoch 17,   100/  454; acc:  86.57; ppl:   1.73; 5417 src tok/s; 5676 tgt tok/s;     15 s elapsed
Epoch 17,   150/  454; acc:  86.05; ppl:   1.75; 5501 src tok/s; 5742 tgt tok/s;     23 s elapsed
Epoch 17,   200/  454; acc:  84.11; ppl:   1.92; 5454 src tok/s; 5648 tgt tok/s;     31 s elapsed
Epoch 17,   250/  454; acc:  86.65; ppl:   1.72; 5407 src tok/s; 5644 tgt tok/s;     38 s elapsed
Epoch 17,   300/  454; acc:  84.71; ppl:   1.89; 5479 src tok/s; 5653 tgt tok/s;     46 s elapsed
Epoch 17,   350/  454; acc:  83.94; ppl:   1.92; 5399 src tok/s; 5557 tgt tok/s;     54 s elapsed
Epoch 17,   400/  454; acc:  87.08; ppl:   1.69; 5465 src tok/s; 5740 tgt tok/s;     61 s elapsed
Epoch 17,   450/  454; acc:  85.76; ppl:   1.77; 5497 src tok/s; 5700 tgt tok/s;     69 s elapsed
Train perplexity: 1.81745
Train accuracy: 85.3431
Validation perplexity: 6.66017
Validation accuracy: 69.2777
Decaying learning rate to 0.000976562
