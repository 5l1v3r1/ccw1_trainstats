<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.3, kappa_enc=0.05, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.05decoder0.3dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.05)
('Using Kappa L2 loss on decoder', 0.3)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.80; ppl: 26920.14; 4183 src tok/s; 4305 tgt tok/s;     10 s elapsed
Epoch  1,   100/  454; acc:  15.10; ppl: 1507.71; 5782 src tok/s; 6045 tgt tok/s;     17 s elapsed
Epoch  1,   150/  454; acc:  17.84; ppl: 481.53; 5733 src tok/s; 5950 tgt tok/s;     25 s elapsed
Epoch  1,   200/  454; acc:  21.21; ppl: 282.19; 5461 src tok/s; 5697 tgt tok/s;     32 s elapsed
Epoch  1,   250/  454; acc:  24.08; ppl: 170.33; 5496 src tok/s; 5651 tgt tok/s;     40 s elapsed
Epoch  1,   300/  454; acc:  28.07; ppl: 120.98; 5252 src tok/s; 5488 tgt tok/s;     48 s elapsed
Epoch  1,   350/  454; acc:  29.38; ppl:  99.16; 5320 src tok/s; 5527 tgt tok/s;     56 s elapsed
Epoch  1,   400/  454; acc:  31.95; ppl:  76.51; 5427 src tok/s; 5634 tgt tok/s;     64 s elapsed
Epoch  1,   450/  454; acc:  32.99; ppl:  68.26; 5372 src tok/s; 5560 tgt tok/s;     71 s elapsed
Train perplexity: 338.459
Train accuracy: 23.299
Validation perplexity: 63.1498
Validation accuracy: 30.8642

Epoch  2,    50/  454; acc:  35.54; ppl:  55.44; 5358 src tok/s; 5570 tgt tok/s;      8 s elapsed
Epoch  2,   100/  454; acc:  37.67; ppl:  46.57; 5335 src tok/s; 5537 tgt tok/s;     16 s elapsed
Epoch  2,   150/  454; acc:  39.24; ppl:  42.35; 5482 src tok/s; 5644 tgt tok/s;     24 s elapsed
Epoch  2,   200/  454; acc:  44.86; ppl:  29.97; 5295 src tok/s; 5556 tgt tok/s;     31 s elapsed
Epoch  2,   250/  454; acc:  45.47; ppl:  27.62; 5256 src tok/s; 5459 tgt tok/s;     39 s elapsed
Epoch  2,   300/  454; acc:  47.23; ppl:  25.20; 5504 src tok/s; 5707 tgt tok/s;     47 s elapsed
Epoch  2,   350/  454; acc:  49.32; ppl:  22.02; 5458 src tok/s; 5628 tgt tok/s;     55 s elapsed
Epoch  2,   400/  454; acc:  50.89; ppl:  20.06; 5454 src tok/s; 5687 tgt tok/s;     62 s elapsed
Epoch  2,   450/  454; acc:  51.55; ppl:  18.59; 5339 src tok/s; 5522 tgt tok/s;     70 s elapsed
Train perplexity: 29.787
Train accuracy: 44.6613
Validation perplexity: 15.6798
Validation accuracy: 53.8811

Epoch  3,    50/  454; acc:  54.52; ppl:  14.70; 5463 src tok/s; 5667 tgt tok/s;      7 s elapsed
Epoch  3,   100/  454; acc:  54.08; ppl:  14.81; 5473 src tok/s; 5661 tgt tok/s;     15 s elapsed
Epoch  3,   150/  454; acc:  54.74; ppl:  14.22; 5546 src tok/s; 5722 tgt tok/s;     23 s elapsed
Epoch  3,   200/  454; acc:  56.91; ppl:  12.38; 5362 src tok/s; 5602 tgt tok/s;     31 s elapsed
Epoch  3,   250/  454; acc:  56.72; ppl:  12.69; 5405 src tok/s; 5614 tgt tok/s;     39 s elapsed
Epoch  3,   300/  454; acc:  58.86; ppl:  10.90; 5400 src tok/s; 5597 tgt tok/s;     46 s elapsed
Epoch  3,   350/  454; acc:  59.76; ppl:  10.53; 5272 src tok/s; 5552 tgt tok/s;     54 s elapsed
Epoch  3,   400/  454; acc:  57.38; ppl:  11.90; 5412 src tok/s; 5562 tgt tok/s;     62 s elapsed
Epoch  3,   450/  454; acc:  58.60; ppl:  11.10; 5432 src tok/s; 5645 tgt tok/s;     70 s elapsed
Train perplexity: 12.4787
Train accuracy: 56.8458
Validation perplexity: 11.3426
Validation accuracy: 57.2229

Epoch  4,    50/  454; acc:  60.70; ppl:   9.16; 5411 src tok/s; 5596 tgt tok/s;      8 s elapsed
Epoch  4,   100/  454; acc:  62.07; ppl:   8.36; 5322 src tok/s; 5540 tgt tok/s;     16 s elapsed
Epoch  4,   150/  454; acc:  62.56; ppl:   8.02; 5394 src tok/s; 5592 tgt tok/s;     23 s elapsed
Epoch  4,   200/  454; acc:  61.46; ppl:   8.58; 5447 src tok/s; 5625 tgt tok/s;     31 s elapsed
Epoch  4,   250/  454; acc:  62.03; ppl:   8.19; 5431 src tok/s; 5659 tgt tok/s;     39 s elapsed
Epoch  4,   300/  454; acc:  62.51; ppl:   8.03; 5519 src tok/s; 5718 tgt tok/s;     46 s elapsed
Epoch  4,   350/  454; acc:  62.52; ppl:   8.06; 5349 src tok/s; 5545 tgt tok/s;     54 s elapsed
Epoch  4,   400/  454; acc:  63.13; ppl:   7.67; 5475 src tok/s; 5672 tgt tok/s;     62 s elapsed
Epoch  4,   450/  454; acc:  62.72; ppl:   7.91; 5316 src tok/s; 5560 tgt tok/s;     70 s elapsed
Train perplexity: 8.21234
Train accuracy: 62.1809
Validation perplexity: 8.27123
Validation accuracy: 63.1758

Epoch  5,    50/  454; acc:  65.45; ppl:   6.25; 5320 src tok/s; 5540 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  65.78; ppl:   6.12; 5447 src tok/s; 5628 tgt tok/s;     16 s elapsed
Epoch  5,   150/  454; acc:  66.96; ppl:   5.83; 5472 src tok/s; 5697 tgt tok/s;     23 s elapsed
Epoch  5,   200/  454; acc:  64.68; ppl:   6.48; 5483 src tok/s; 5650 tgt tok/s;     31 s elapsed
Epoch  5,   250/  454; acc:  65.59; ppl:   6.24; 5462 src tok/s; 5688 tgt tok/s;     39 s elapsed
Epoch  5,   300/  454; acc:  65.93; ppl:   6.10; 5446 src tok/s; 5675 tgt tok/s;     46 s elapsed
Epoch  5,   350/  454; acc:  65.37; ppl:   6.19; 5260 src tok/s; 5434 tgt tok/s;     54 s elapsed
Epoch  5,   400/  454; acc:  65.47; ppl:   6.22; 5414 src tok/s; 5641 tgt tok/s;     62 s elapsed
Epoch  5,   450/  454; acc:  65.68; ppl:   6.16; 5350 src tok/s; 5544 tgt tok/s;     70 s elapsed
Train perplexity: 6.17378
Train accuracy: 65.6497
Validation perplexity: 7.67308
Validation accuracy: 64.1621

Epoch  6,    50/  454; acc:  68.27; ppl:   5.11; 5515 src tok/s; 5673 tgt tok/s;      8 s elapsed
Epoch  6,   100/  454; acc:  70.03; ppl:   4.50; 5350 src tok/s; 5573 tgt tok/s;     15 s elapsed
Epoch  6,   150/  454; acc:  68.54; ppl:   4.76; 5423 src tok/s; 5657 tgt tok/s;     23 s elapsed
Epoch  6,   200/  454; acc:  67.36; ppl:   5.23; 5533 src tok/s; 5727 tgt tok/s;     31 s elapsed
Epoch  6,   250/  454; acc:  67.63; ppl:   5.07; 5457 src tok/s; 5606 tgt tok/s;     39 s elapsed
Epoch  6,   300/  454; acc:  68.54; ppl:   4.90; 5407 src tok/s; 5638 tgt tok/s;     46 s elapsed
Epoch  6,   350/  454; acc:  66.84; ppl:   5.32; 5509 src tok/s; 5713 tgt tok/s;     54 s elapsed
Epoch  6,   400/  454; acc:  68.59; ppl:   4.86; 5378 src tok/s; 5614 tgt tok/s;     62 s elapsed
Epoch  6,   450/  454; acc:  68.28; ppl:   4.95; 5195 src tok/s; 5433 tgt tok/s;     69 s elapsed
Train perplexity: 4.98302
Train accuracy: 68.155
Validation perplexity: 7.01009
Validation accuracy: 65.4463

Epoch  7,    50/  454; acc:  72.10; ppl:   3.83; 5405 src tok/s; 5642 tgt tok/s;      7 s elapsed
Epoch  7,   100/  454; acc:  70.56; ppl:   4.08; 5583 src tok/s; 5763 tgt tok/s;     15 s elapsed
Epoch  7,   150/  454; acc:  70.00; ppl:   4.29; 5445 src tok/s; 5639 tgt tok/s;     23 s elapsed
Epoch  7,   200/  454; acc:  70.30; ppl:   4.11; 5423 src tok/s; 5661 tgt tok/s;     31 s elapsed
Epoch  7,   250/  454; acc:  70.22; ppl:   4.24; 5510 src tok/s; 5675 tgt tok/s;     39 s elapsed
Epoch  7,   300/  454; acc:  69.72; ppl:   4.38; 5501 src tok/s; 5727 tgt tok/s;     46 s elapsed
Epoch  7,   350/  454; acc:  70.48; ppl:   4.23; 5509 src tok/s; 5718 tgt tok/s;     53 s elapsed
Epoch  7,   400/  454; acc:  69.70; ppl:   4.37; 5419 src tok/s; 5626 tgt tok/s;     61 s elapsed
Epoch  7,   450/  454; acc:  70.17; ppl:   4.28; 5350 src tok/s; 5548 tgt tok/s;     69 s elapsed
Train perplexity: 4.19409
Train accuracy: 70.3648
Validation perplexity: 6.78948
Validation accuracy: 65.9075

Epoch  8,    50/  454; acc:  72.92; ppl:   3.47; 5343 src tok/s; 5572 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  73.05; ppl:   3.43; 5399 src tok/s; 5575 tgt tok/s;     16 s elapsed
Epoch  8,   150/  454; acc:  72.55; ppl:   3.51; 5497 src tok/s; 5717 tgt tok/s;     23 s elapsed
Epoch  8,   200/  454; acc:  72.40; ppl:   3.58; 5365 src tok/s; 5567 tgt tok/s;     31 s elapsed
Epoch  8,   250/  454; acc:  71.55; ppl:   3.80; 5410 src tok/s; 5609 tgt tok/s;     39 s elapsed
Epoch  8,   300/  454; acc:  72.39; ppl:   3.58; 5437 src tok/s; 5643 tgt tok/s;     47 s elapsed
Epoch  8,   350/  454; acc:  72.05; ppl:   3.60; 5374 src tok/s; 5600 tgt tok/s;     54 s elapsed
Epoch  8,   400/  454; acc:  71.13; ppl:   3.83; 5453 src tok/s; 5641 tgt tok/s;     62 s elapsed
Epoch  8,   450/  454; acc:  71.50; ppl:   3.75; 5342 src tok/s; 5535 tgt tok/s;     70 s elapsed
Train perplexity: 3.61408
Train accuracy: 72.171
Validation perplexity: 6.72024
Validation accuracy: 65.943
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.31; ppl:   2.65; 5543 src tok/s; 5786 tgt tok/s;      7 s elapsed
Epoch  9,   100/  454; acc:  76.61; ppl:   2.82; 5476 src tok/s; 5667 tgt tok/s;     15 s elapsed
Epoch  9,   150/  454; acc:  77.19; ppl:   2.72; 5439 src tok/s; 5673 tgt tok/s;     23 s elapsed
Epoch  9,   200/  454; acc:  77.08; ppl:   2.73; 5553 src tok/s; 5727 tgt tok/s;     30 s elapsed
Epoch  9,   250/  454; acc:  77.33; ppl:   2.69; 5607 src tok/s; 5779 tgt tok/s;     38 s elapsed
Epoch  9,   300/  454; acc:  77.54; ppl:   2.65; 5386 src tok/s; 5619 tgt tok/s;     46 s elapsed
Epoch  9,   350/  454; acc:  78.23; ppl:   2.55; 5497 src tok/s; 5739 tgt tok/s;     53 s elapsed
Epoch  9,   400/  454; acc:  76.59; ppl:   2.83; 5354 src tok/s; 5518 tgt tok/s;     61 s elapsed
Epoch  9,   450/  454; acc:  76.63; ppl:   2.77; 5356 src tok/s; 5565 tgt tok/s;     69 s elapsed
Train perplexity: 2.70988
Train accuracy: 77.1744
Validation perplexity: 6.18943
Validation accuracy: 68.4618
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.14; ppl:   2.36; 5586 src tok/s; 5731 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  82.35; ppl:   2.08; 5503 src tok/s; 5738 tgt tok/s;     15 s elapsed
Epoch 10,   150/  454; acc:  81.59; ppl:   2.14; 5508 src tok/s; 5716 tgt tok/s;     23 s elapsed
Epoch 10,   200/  454; acc:  80.40; ppl:   2.30; 5407 src tok/s; 5593 tgt tok/s;     31 s elapsed
Epoch 10,   250/  454; acc:  81.43; ppl:   2.17; 5427 src tok/s; 5654 tgt tok/s;     38 s elapsed
Epoch 10,   300/  454; acc:  80.54; ppl:   2.29; 5454 src tok/s; 5658 tgt tok/s;     46 s elapsed
Epoch 10,   350/  454; acc:  81.12; ppl:   2.19; 5527 src tok/s; 5745 tgt tok/s;     53 s elapsed
Epoch 10,   400/  454; acc:  80.67; ppl:   2.29; 5470 src tok/s; 5678 tgt tok/s;     61 s elapsed
Epoch 10,   450/  454; acc:  80.29; ppl:   2.27; 5434 src tok/s; 5652 tgt tok/s;     69 s elapsed
Train perplexity: 2.23061
Train accuracy: 80.9593
Validation perplexity: 6.3362
Validation accuracy: 69.079
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  81.97; ppl:   2.15; 5550 src tok/s; 5744 tgt tok/s;      8 s elapsed
Epoch 11,   100/  454; acc:  84.84; ppl:   1.85; 5284 src tok/s; 5537 tgt tok/s;     15 s elapsed
Epoch 11,   150/  454; acc:  82.14; ppl:   2.13; 5518 src tok/s; 5645 tgt tok/s;     24 s elapsed
Epoch 11,   200/  454; acc:  84.78; ppl:   1.85; 5447 src tok/s; 5721 tgt tok/s;     31 s elapsed
Epoch 11,   250/  454; acc:  82.96; ppl:   2.04; 5292 src tok/s; 5486 tgt tok/s;     39 s elapsed
Epoch 11,   300/  454; acc:  82.90; ppl:   2.04; 5473 src tok/s; 5674 tgt tok/s;     46 s elapsed
Epoch 11,   350/  454; acc:  83.41; ppl:   1.99; 5487 src tok/s; 5708 tgt tok/s;     54 s elapsed
Epoch 11,   400/  454; acc:  82.92; ppl:   2.04; 5452 src tok/s; 5644 tgt tok/s;     62 s elapsed
Epoch 11,   450/  454; acc:  83.17; ppl:   2.00; 5355 src tok/s; 5576 tgt tok/s;     69 s elapsed
Train perplexity: 2.01345
Train accuracy: 83.1551
Validation perplexity: 6.38022
Validation accuracy: 69.0719
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  85.67; ppl:   1.78; 5577 src tok/s; 5826 tgt tok/s;      7 s elapsed
Epoch 12,   100/  454; acc:  83.34; ppl:   2.00; 5430 src tok/s; 5606 tgt tok/s;     15 s elapsed
Epoch 12,   150/  454; acc:  84.26; ppl:   1.92; 5353 src tok/s; 5580 tgt tok/s;     23 s elapsed
Epoch 12,   200/  454; acc:  84.28; ppl:   1.90; 5531 src tok/s; 5712 tgt tok/s;     31 s elapsed
Epoch 12,   250/  454; acc:  84.31; ppl:   1.91; 5536 src tok/s; 5744 tgt tok/s;     38 s elapsed
Epoch 12,   300/  454; acc:  84.29; ppl:   1.94; 5471 src tok/s; 5674 tgt tok/s;     46 s elapsed
Epoch 12,   350/  454; acc:  83.31; ppl:   2.00; 5509 src tok/s; 5701 tgt tok/s;     54 s elapsed
Epoch 12,   400/  454; acc:  84.61; ppl:   1.86; 5598 src tok/s; 5814 tgt tok/s;     61 s elapsed
Epoch 12,   450/  454; acc:  84.18; ppl:   1.91; 5350 src tok/s; 5566 tgt tok/s;     69 s elapsed
Train perplexity: 1.91546
Train accuracy: 84.2298
Validation perplexity: 6.49958
Validation accuracy: 69.2848
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  85.11; ppl:   1.84; 5629 src tok/s; 5826 tgt tok/s;      7 s elapsed
Epoch 13,   100/  454; acc:  85.28; ppl:   1.84; 5464 src tok/s; 5660 tgt tok/s;     15 s elapsed
Epoch 13,   150/  454; acc:  84.91; ppl:   1.86; 5433 src tok/s; 5629 tgt tok/s;     23 s elapsed
Epoch 13,   200/  454; acc:  84.32; ppl:   1.93; 5497 src tok/s; 5727 tgt tok/s;     31 s elapsed
Epoch 13,   250/  454; acc:  84.60; ppl:   1.89; 5322 src tok/s; 5545 tgt tok/s;     38 s elapsed
Epoch 13,   300/  454; acc:  85.16; ppl:   1.84; 5509 src tok/s; 5738 tgt tok/s;     46 s elapsed
Epoch 13,   350/  454; acc:  84.26; ppl:   1.92; 5483 src tok/s; 5677 tgt tok/s;     54 s elapsed
Epoch 13,   400/  454; acc:  85.02; ppl:   1.83; 5564 src tok/s; 5770 tgt tok/s;     61 s elapsed
Epoch 13,   450/  454; acc:  85.02; ppl:   1.83; 5499 src tok/s; 5714 tgt tok/s;     69 s elapsed
Train perplexity: 1.86677
Train accuracy: 84.8139
Validation perplexity: 6.5829
Validation accuracy: 69.2777
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  86.16; ppl:   1.75; 5555 src tok/s; 5773 tgt tok/s;      7 s elapsed
Epoch 14,   100/  454; acc:  84.47; ppl:   1.93; 5413 src tok/s; 5615 tgt tok/s;     15 s elapsed
Epoch 14,   150/  454; acc:  84.89; ppl:   1.86; 5451 src tok/s; 5640 tgt tok/s;     23 s elapsed
Epoch 14,   200/  454; acc:  85.31; ppl:   1.82; 5607 src tok/s; 5810 tgt tok/s;     30 s elapsed
Epoch 14,   250/  454; acc:  84.62; ppl:   1.89; 5411 src tok/s; 5619 tgt tok/s;     38 s elapsed
Epoch 14,   300/  454; acc:  85.48; ppl:   1.81; 5565 src tok/s; 5793 tgt tok/s;     46 s elapsed
Epoch 14,   350/  454; acc:  84.00; ppl:   1.94; 5617 src tok/s; 5781 tgt tok/s;     54 s elapsed
Epoch 14,   400/  454; acc:  86.11; ppl:   1.74; 5438 src tok/s; 5707 tgt tok/s;     61 s elapsed
Epoch 14,   450/  454; acc:  85.23; ppl:   1.85; 5342 src tok/s; 5542 tgt tok/s;     69 s elapsed
Train perplexity: 1.84454
Train accuracy: 85.1165
Validation perplexity: 6.60583
Validation accuracy: 69.2564
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  84.74; ppl:   1.87; 5690 src tok/s; 5835 tgt tok/s;      8 s elapsed
Epoch 15,   100/  454; acc:  85.71; ppl:   1.78; 5379 src tok/s; 5588 tgt tok/s;     15 s elapsed
Epoch 15,   150/  454; acc:  85.40; ppl:   1.80; 5407 src tok/s; 5651 tgt tok/s;     23 s elapsed
Epoch 15,   200/  454; acc:  84.57; ppl:   1.89; 5497 src tok/s; 5690 tgt tok/s;     31 s elapsed
Epoch 15,   250/  454; acc:  85.55; ppl:   1.81; 5477 src tok/s; 5711 tgt tok/s;     38 s elapsed
Epoch 15,   300/  454; acc:  85.28; ppl:   1.86; 5626 src tok/s; 5815 tgt tok/s;     46 s elapsed
Epoch 15,   350/  454; acc:  85.50; ppl:   1.82; 5475 src tok/s; 5709 tgt tok/s;     53 s elapsed
Epoch 15,   400/  454; acc:  85.16; ppl:   1.82; 5633 src tok/s; 5825 tgt tok/s;     61 s elapsed
Epoch 15,   450/  454; acc:  84.96; ppl:   1.83; 5427 src tok/s; 5651 tgt tok/s;     69 s elapsed
Train perplexity: 1.82925
Train accuracy: 85.2184
Validation perplexity: 6.62345
Validation accuracy: 69.2209
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  84.94; ppl:   1.87; 5536 src tok/s; 5730 tgt tok/s;      8 s elapsed
Epoch 16,   100/  454; acc:  85.62; ppl:   1.79; 5499 src tok/s; 5726 tgt tok/s;     15 s elapsed
Epoch 16,   150/  454; acc:  84.82; ppl:   1.88; 5435 src tok/s; 5655 tgt tok/s;     23 s elapsed
Epoch 16,   200/  454; acc:  85.59; ppl:   1.79; 5490 src tok/s; 5717 tgt tok/s;     31 s elapsed
Epoch 16,   250/  454; acc:  86.56; ppl:   1.70; 5461 src tok/s; 5687 tgt tok/s;     38 s elapsed
Epoch 16,   300/  454; acc:  84.08; ppl:   1.94; 5518 src tok/s; 5693 tgt tok/s;     46 s elapsed
Epoch 16,   350/  454; acc:  85.18; ppl:   1.84; 5449 src tok/s; 5641 tgt tok/s;     53 s elapsed
Epoch 16,   400/  454; acc:  85.58; ppl:   1.82; 5532 src tok/s; 5738 tgt tok/s;     61 s elapsed
Epoch 16,   450/  454; acc:  85.41; ppl:   1.82; 5481 src tok/s; 5684 tgt tok/s;     69 s elapsed
Train perplexity: 1.8261
Train accuracy: 85.3094
Validation perplexity: 6.63176
Validation accuracy: 69.2138
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.93; ppl:   1.76; 5517 src tok/s; 5782 tgt tok/s;      7 s elapsed
Epoch 17,   100/  454; acc:  84.42; ppl:   1.92; 5454 src tok/s; 5611 tgt tok/s;     15 s elapsed
Epoch 17,   150/  454; acc:  85.01; ppl:   1.84; 5519 src tok/s; 5726 tgt tok/s;     23 s elapsed
Epoch 17,   200/  454; acc:  85.50; ppl:   1.79; 5444 src tok/s; 5654 tgt tok/s;     31 s elapsed
Epoch 17,   250/  454; acc:  85.16; ppl:   1.84; 5650 src tok/s; 5847 tgt tok/s;     38 s elapsed
Epoch 17,   300/  454; acc:  85.52; ppl:   1.82; 5519 src tok/s; 5726 tgt tok/s;     46 s elapsed
Epoch 17,   350/  454; acc:  85.18; ppl:   1.82; 5495 src tok/s; 5709 tgt tok/s;     53 s elapsed
Epoch 17,   400/  454; acc:  85.76; ppl:   1.79; 5347 src tok/s; 5568 tgt tok/s;     61 s elapsed
Epoch 17,   450/  454; acc:  85.52; ppl:   1.82; 5381 src tok/s; 5581 tgt tok/s;     69 s elapsed
Train perplexity: 1.82478
Train accuracy: 85.301
Validation perplexity: 6.63588
Validation accuracy: 69.2138
Decaying learning rate to 0.000976562
