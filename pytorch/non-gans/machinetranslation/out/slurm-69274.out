<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.15, kappa_enc=0.05, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.05decoder0.15dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.05)
('Using Kappa L2 loss on decoder', 0.15)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   7.89; ppl: 54171.74; 4857 src tok/s; 5063 tgt tok/s;      8 s elapsed
Epoch  1,   100/  454; acc:  13.39; ppl: 2100.52; 6589 src tok/s; 6830 tgt tok/s;     15 s elapsed
Epoch  1,   150/  454; acc:  17.66; ppl: 583.54; 6371 src tok/s; 6608 tgt tok/s;     21 s elapsed
Epoch  1,   200/  454; acc:  20.17; ppl: 325.32; 6385 src tok/s; 6598 tgt tok/s;     28 s elapsed
Epoch  1,   250/  454; acc:  23.15; ppl: 196.36; 6559 src tok/s; 6788 tgt tok/s;     34 s elapsed
Epoch  1,   300/  454; acc:  26.07; ppl: 141.87; 6543 src tok/s; 6788 tgt tok/s;     41 s elapsed
Epoch  1,   350/  454; acc:  28.07; ppl: 110.45; 6495 src tok/s; 6719 tgt tok/s;     48 s elapsed
Epoch  1,   400/  454; acc:  30.83; ppl:  82.46; 6612 src tok/s; 6915 tgt tok/s;     54 s elapsed
Epoch  1,   450/  454; acc:  32.95; ppl:  68.27; 6530 src tok/s; 6782 tgt tok/s;     60 s elapsed
Train perplexity: 409.249
Train accuracy: 22.3076
Validation perplexity: 72.9869
Validation accuracy: 28.3667

Epoch  2,    50/  454; acc:  34.55; ppl:  57.92; 6432 src tok/s; 6669 tgt tok/s;      6 s elapsed
Epoch  2,   100/  454; acc:  36.29; ppl:  51.34; 6396 src tok/s; 6661 tgt tok/s;     13 s elapsed
Epoch  2,   150/  454; acc:  38.40; ppl:  44.00; 6378 src tok/s; 6651 tgt tok/s;     19 s elapsed
Epoch  2,   200/  454; acc:  39.10; ppl:  41.74; 6598 src tok/s; 6844 tgt tok/s;     26 s elapsed
Epoch  2,   250/  454; acc:  42.00; ppl:  35.06; 6640 src tok/s; 6841 tgt tok/s;     33 s elapsed
Epoch  2,   300/  454; acc:  45.58; ppl:  27.83; 6598 src tok/s; 6840 tgt tok/s;     39 s elapsed
Epoch  2,   350/  454; acc:  46.66; ppl:  25.52; 6490 src tok/s; 6709 tgt tok/s;     45 s elapsed
Epoch  2,   400/  454; acc:  48.74; ppl:  22.54; 6484 src tok/s; 6750 tgt tok/s;     52 s elapsed
Epoch  2,   450/  454; acc:  50.16; ppl:  20.48; 6431 src tok/s; 6691 tgt tok/s;     58 s elapsed
Train perplexity: 33.9678
Train accuracy: 42.4489
Validation perplexity: 17.8327
Validation accuracy: 51.5184

Epoch  3,    50/  454; acc:  52.96; ppl:  16.26; 6549 src tok/s; 6828 tgt tok/s;      6 s elapsed
Epoch  3,   100/  454; acc:  52.84; ppl:  16.14; 6608 src tok/s; 6848 tgt tok/s;     13 s elapsed
Epoch  3,   150/  454; acc:  55.28; ppl:  13.84; 6399 src tok/s; 6646 tgt tok/s;     19 s elapsed
Epoch  3,   200/  454; acc:  55.39; ppl:  13.64; 6426 src tok/s; 6689 tgt tok/s;     26 s elapsed
Epoch  3,   250/  454; acc:  55.53; ppl:  13.65; 6522 src tok/s; 6761 tgt tok/s;     32 s elapsed
Epoch  3,   300/  454; acc:  57.04; ppl:  12.28; 6537 src tok/s; 6826 tgt tok/s;     39 s elapsed
Epoch  3,   350/  454; acc:  57.51; ppl:  11.96; 6523 src tok/s; 6743 tgt tok/s;     45 s elapsed
Epoch  3,   400/  454; acc:  57.88; ppl:  11.46; 6481 src tok/s; 6675 tgt tok/s;     52 s elapsed
Epoch  3,   450/  454; acc:  58.37; ppl:  11.01; 6337 src tok/s; 6587 tgt tok/s;     58 s elapsed
Train perplexity: 13.2708
Train accuracy: 55.8325
Validation perplexity: 10.8887
Validation accuracy: 59.2734

Epoch  4,    50/  454; acc:  60.99; ppl:   8.98; 6480 src tok/s; 6705 tgt tok/s;      7 s elapsed
Epoch  4,   100/  454; acc:  61.55; ppl:   8.55; 6582 src tok/s; 6831 tgt tok/s;     13 s elapsed
Epoch  4,   150/  454; acc:  61.39; ppl:   8.76; 6478 src tok/s; 6763 tgt tok/s;     19 s elapsed
Epoch  4,   200/  454; acc:  61.33; ppl:   8.78; 6535 src tok/s; 6754 tgt tok/s;     26 s elapsed
Epoch  4,   250/  454; acc:  62.60; ppl:   8.15; 6484 src tok/s; 6778 tgt tok/s;     32 s elapsed
Epoch  4,   300/  454; acc:  60.94; ppl:   8.79; 6536 src tok/s; 6749 tgt tok/s;     39 s elapsed
Epoch  4,   350/  454; acc:  62.22; ppl:   8.32; 6478 src tok/s; 6712 tgt tok/s;     45 s elapsed
Epoch  4,   400/  454; acc:  62.56; ppl:   7.99; 6452 src tok/s; 6688 tgt tok/s;     52 s elapsed
Epoch  4,   450/  454; acc:  62.65; ppl:   7.95; 6343 src tok/s; 6591 tgt tok/s;     58 s elapsed
Train perplexity: 8.46799
Train accuracy: 61.8051
Validation perplexity: 8.57175
Validation accuracy: 62.963

Epoch  5,    50/  454; acc:  65.01; ppl:   6.41; 6540 src tok/s; 6785 tgt tok/s;      6 s elapsed
Epoch  5,   100/  454; acc:  65.35; ppl:   6.29; 6542 src tok/s; 6813 tgt tok/s;     13 s elapsed
Epoch  5,   150/  454; acc:  65.25; ppl:   6.32; 6544 src tok/s; 6765 tgt tok/s;     19 s elapsed
Epoch  5,   200/  454; acc:  65.12; ppl:   6.35; 6306 src tok/s; 6574 tgt tok/s;     26 s elapsed
Epoch  5,   250/  454; acc:  65.47; ppl:   6.34; 6365 src tok/s; 6605 tgt tok/s;     32 s elapsed
Epoch  5,   300/  454; acc:  65.14; ppl:   6.31; 6545 src tok/s; 6777 tgt tok/s;     39 s elapsed
Epoch  5,   350/  454; acc:  64.84; ppl:   6.49; 6397 src tok/s; 6679 tgt tok/s;     45 s elapsed
Epoch  5,   400/  454; acc:  65.71; ppl:   6.25; 6589 src tok/s; 6795 tgt tok/s;     52 s elapsed
Epoch  5,   450/  454; acc:  65.73; ppl:   6.13; 6387 src tok/s; 6617 tgt tok/s;     58 s elapsed
Train perplexity: 6.32521
Train accuracy: 65.2769
Validation perplexity: 7.30388
Validation accuracy: 65.198

Epoch  6,    50/  454; acc:  66.99; ppl:   5.37; 6415 src tok/s; 6662 tgt tok/s;      7 s elapsed
Epoch  6,   100/  454; acc:  69.63; ppl:   4.54; 6394 src tok/s; 6697 tgt tok/s;     13 s elapsed
Epoch  6,   150/  454; acc:  68.11; ppl:   5.14; 6499 src tok/s; 6719 tgt tok/s;     20 s elapsed
Epoch  6,   200/  454; acc:  68.60; ppl:   4.95; 6605 src tok/s; 6823 tgt tok/s;     26 s elapsed
Epoch  6,   250/  454; acc:  66.94; ppl:   5.39; 6500 src tok/s; 6714 tgt tok/s;     33 s elapsed
Epoch  6,   300/  454; acc:  68.67; ppl:   4.83; 6497 src tok/s; 6766 tgt tok/s;     39 s elapsed
Epoch  6,   350/  454; acc:  68.16; ppl:   4.95; 6440 src tok/s; 6693 tgt tok/s;     45 s elapsed
Epoch  6,   400/  454; acc:  67.27; ppl:   5.28; 6506 src tok/s; 6761 tgt tok/s;     52 s elapsed
Epoch  6,   450/  454; acc:  67.47; ppl:   5.26; 6488 src tok/s; 6715 tgt tok/s;     58 s elapsed
Train perplexity: 5.07898
Train accuracy: 67.9509
Validation perplexity: 6.98389
Validation accuracy: 65.7656

Epoch  7,    50/  454; acc:  71.49; ppl:   3.95; 6476 src tok/s; 6731 tgt tok/s;      6 s elapsed
Epoch  7,   100/  454; acc:  70.15; ppl:   4.24; 6555 src tok/s; 6786 tgt tok/s;     13 s elapsed
Epoch  7,   150/  454; acc:  70.58; ppl:   4.13; 6495 src tok/s; 6681 tgt tok/s;     19 s elapsed
Epoch  7,   200/  454; acc:  70.32; ppl:   4.16; 6447 src tok/s; 6718 tgt tok/s;     26 s elapsed
Epoch  7,   250/  454; acc:  70.66; ppl:   4.09; 6494 src tok/s; 6798 tgt tok/s;     32 s elapsed
Epoch  7,   300/  454; acc:  69.56; ppl:   4.42; 6517 src tok/s; 6724 tgt tok/s;     39 s elapsed
Epoch  7,   350/  454; acc:  69.69; ppl:   4.39; 6373 src tok/s; 6611 tgt tok/s;     45 s elapsed
Epoch  7,   400/  454; acc:  69.80; ppl:   4.32; 6492 src tok/s; 6755 tgt tok/s;     52 s elapsed
Epoch  7,   450/  454; acc:  69.40; ppl:   4.45; 6354 src tok/s; 6607 tgt tok/s;     58 s elapsed
Train perplexity: 4.23485
Train accuracy: 70.1885
Validation perplexity: 6.53014
Validation accuracy: 67.1208

Epoch  8,    50/  454; acc:  73.65; ppl:   3.36; 6455 src tok/s; 6696 tgt tok/s;      6 s elapsed
Epoch  8,   100/  454; acc:  72.70; ppl:   3.45; 6599 src tok/s; 6850 tgt tok/s;     13 s elapsed
Epoch  8,   150/  454; acc:  71.57; ppl:   3.74; 6569 src tok/s; 6787 tgt tok/s;     19 s elapsed
Epoch  8,   200/  454; acc:  71.97; ppl:   3.66; 6429 src tok/s; 6692 tgt tok/s;     26 s elapsed
Epoch  8,   250/  454; acc:  72.25; ppl:   3.61; 6477 src tok/s; 6726 tgt tok/s;     32 s elapsed
Epoch  8,   300/  454; acc:  71.34; ppl:   3.79; 6492 src tok/s; 6712 tgt tok/s;     39 s elapsed
Epoch  8,   350/  454; acc:  70.85; ppl:   3.97; 6435 src tok/s; 6634 tgt tok/s;     45 s elapsed
Epoch  8,   400/  454; acc:  72.55; ppl:   3.57; 6538 src tok/s; 6836 tgt tok/s;     52 s elapsed
Epoch  8,   450/  454; acc:  71.49; ppl:   3.78; 6419 src tok/s; 6682 tgt tok/s;     58 s elapsed
Train perplexity: 3.65896
Train accuracy: 72.0248
Validation perplexity: 6.74054
Validation accuracy: 66.397
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.40; ppl:   2.83; 6308 src tok/s; 6609 tgt tok/s;      6 s elapsed
Epoch  9,   100/  454; acc:  77.04; ppl:   2.72; 6600 src tok/s; 6816 tgt tok/s;     13 s elapsed
Epoch  9,   150/  454; acc:  77.88; ppl:   2.62; 6468 src tok/s; 6741 tgt tok/s;     19 s elapsed
Epoch  9,   200/  454; acc:  76.69; ppl:   2.82; 6612 src tok/s; 6814 tgt tok/s;     26 s elapsed
Epoch  9,   250/  454; acc:  78.04; ppl:   2.61; 6478 src tok/s; 6736 tgt tok/s;     32 s elapsed
Epoch  9,   300/  454; acc:  76.53; ppl:   2.81; 6486 src tok/s; 6718 tgt tok/s;     39 s elapsed
Epoch  9,   350/  454; acc:  77.67; ppl:   2.65; 6473 src tok/s; 6714 tgt tok/s;     45 s elapsed
Epoch  9,   400/  454; acc:  76.87; ppl:   2.76; 6413 src tok/s; 6648 tgt tok/s;     52 s elapsed
Epoch  9,   450/  454; acc:  76.87; ppl:   2.74; 6413 src tok/s; 6655 tgt tok/s;     58 s elapsed
Train perplexity: 2.72951
Train accuracy: 77.1053
Validation perplexity: 6.24918
Validation accuracy: 68.2986
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.06; ppl:   2.27; 6527 src tok/s; 6767 tgt tok/s;      6 s elapsed
Epoch 10,   100/  454; acc:  81.23; ppl:   2.20; 6570 src tok/s; 6824 tgt tok/s;     13 s elapsed
Epoch 10,   150/  454; acc:  80.12; ppl:   2.34; 6459 src tok/s; 6659 tgt tok/s;     20 s elapsed
Epoch 10,   200/  454; acc:  81.44; ppl:   2.17; 6534 src tok/s; 6816 tgt tok/s;     26 s elapsed
Epoch 10,   250/  454; acc:  80.57; ppl:   2.29; 6428 src tok/s; 6685 tgt tok/s;     32 s elapsed
Epoch 10,   300/  454; acc:  80.75; ppl:   2.26; 6579 src tok/s; 6825 tgt tok/s;     39 s elapsed
Epoch 10,   350/  454; acc:  81.28; ppl:   2.17; 6433 src tok/s; 6698 tgt tok/s;     45 s elapsed
Epoch 10,   400/  454; acc:  80.23; ppl:   2.29; 6522 src tok/s; 6763 tgt tok/s;     52 s elapsed
Epoch 10,   450/  454; acc:  80.73; ppl:   2.26; 6347 src tok/s; 6575 tgt tok/s;     58 s elapsed
Train perplexity: 2.24763
Train accuracy: 80.8291
Validation perplexity: 6.30889
Validation accuracy: 68.8165
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  82.96; ppl:   2.07; 6683 src tok/s; 6886 tgt tok/s;      6 s elapsed
Epoch 11,   100/  454; acc:  83.33; ppl:   1.97; 6465 src tok/s; 6765 tgt tok/s;     13 s elapsed
Epoch 11,   150/  454; acc:  83.39; ppl:   1.99; 6479 src tok/s; 6722 tgt tok/s;     19 s elapsed
Epoch 11,   200/  454; acc:  82.94; ppl:   2.03; 6493 src tok/s; 6748 tgt tok/s;     26 s elapsed
Epoch 11,   250/  454; acc:  82.81; ppl:   2.02; 6470 src tok/s; 6703 tgt tok/s;     32 s elapsed
Epoch 11,   300/  454; acc:  82.76; ppl:   2.08; 6428 src tok/s; 6677 tgt tok/s;     39 s elapsed
Epoch 11,   350/  454; acc:  82.59; ppl:   2.09; 6476 src tok/s; 6694 tgt tok/s;     45 s elapsed
Epoch 11,   400/  454; acc:  83.24; ppl:   2.00; 6450 src tok/s; 6715 tgt tok/s;     52 s elapsed
Epoch 11,   450/  454; acc:  82.89; ppl:   2.02; 6309 src tok/s; 6551 tgt tok/s;     58 s elapsed
Train perplexity: 2.0294
Train accuracy: 82.986
Validation perplexity: 6.41347
Validation accuracy: 69.2848
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.61; ppl:   1.90; 6360 src tok/s; 6624 tgt tok/s;      7 s elapsed
Epoch 12,   100/  454; acc:  84.18; ppl:   1.92; 6560 src tok/s; 6829 tgt tok/s;     13 s elapsed
Epoch 12,   150/  454; acc:  84.31; ppl:   1.92; 6566 src tok/s; 6780 tgt tok/s;     20 s elapsed
Epoch 12,   200/  454; acc:  84.32; ppl:   1.91; 6516 src tok/s; 6770 tgt tok/s;     26 s elapsed
Epoch 12,   250/  454; acc:  83.78; ppl:   1.96; 6384 src tok/s; 6640 tgt tok/s;     32 s elapsed
Epoch 12,   300/  454; acc:  84.02; ppl:   1.92; 6457 src tok/s; 6667 tgt tok/s;     39 s elapsed
Epoch 12,   350/  454; acc:  83.78; ppl:   1.94; 6566 src tok/s; 6788 tgt tok/s;     45 s elapsed
Epoch 12,   400/  454; acc:  84.21; ppl:   1.92; 6347 src tok/s; 6625 tgt tok/s;     52 s elapsed
Epoch 12,   450/  454; acc:  84.15; ppl:   1.93; 6363 src tok/s; 6595 tgt tok/s;     58 s elapsed
Train perplexity: 1.92755
Train accuracy: 84.1216
Validation perplexity: 6.48586
Validation accuracy: 69.3487
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.95; ppl:   1.87; 6451 src tok/s; 6736 tgt tok/s;      6 s elapsed
Epoch 13,   100/  454; acc:  84.67; ppl:   1.86; 6562 src tok/s; 6799 tgt tok/s;     13 s elapsed
Epoch 13,   150/  454; acc:  84.19; ppl:   1.93; 6469 src tok/s; 6705 tgt tok/s;     19 s elapsed
Epoch 13,   200/  454; acc:  85.06; ppl:   1.85; 6530 src tok/s; 6738 tgt tok/s;     26 s elapsed
Epoch 13,   250/  454; acc:  84.69; ppl:   1.85; 6567 src tok/s; 6810 tgt tok/s;     32 s elapsed
Epoch 13,   300/  454; acc:  84.81; ppl:   1.87; 6416 src tok/s; 6697 tgt tok/s;     39 s elapsed
Epoch 13,   350/  454; acc:  83.73; ppl:   1.98; 6438 src tok/s; 6647 tgt tok/s;     46 s elapsed
Epoch 13,   400/  454; acc:  85.30; ppl:   1.81; 6431 src tok/s; 6696 tgt tok/s;     52 s elapsed
Epoch 13,   450/  454; acc:  84.51; ppl:   1.88; 6344 src tok/s; 6579 tgt tok/s;     58 s elapsed
Train perplexity: 1.87842
Train accuracy: 84.651
Validation perplexity: 6.58571
Validation accuracy: 69.1358
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.57; ppl:   1.78; 6304 src tok/s; 6614 tgt tok/s;      6 s elapsed
Epoch 14,   100/  454; acc:  83.99; ppl:   1.95; 6488 src tok/s; 6700 tgt tok/s;     13 s elapsed
Epoch 14,   150/  454; acc:  84.23; ppl:   1.94; 6505 src tok/s; 6749 tgt tok/s;     20 s elapsed
Epoch 14,   200/  454; acc:  85.82; ppl:   1.78; 6527 src tok/s; 6761 tgt tok/s;     26 s elapsed
Epoch 14,   250/  454; acc:  84.02; ppl:   1.93; 6589 src tok/s; 6783 tgt tok/s;     33 s elapsed
Epoch 14,   300/  454; acc:  86.42; ppl:   1.72; 6427 src tok/s; 6708 tgt tok/s;     39 s elapsed
Epoch 14,   350/  454; acc:  84.60; ppl:   1.89; 6432 src tok/s; 6664 tgt tok/s;     46 s elapsed
Epoch 14,   400/  454; acc:  85.42; ppl:   1.80; 6490 src tok/s; 6766 tgt tok/s;     52 s elapsed
Epoch 14,   450/  454; acc:  84.34; ppl:   1.92; 6536 src tok/s; 6759 tgt tok/s;     58 s elapsed
Train perplexity: 1.85583
Train accuracy: 84.93
Validation perplexity: 6.57881
Validation accuracy: 69.1003
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.10; ppl:   1.85; 6472 src tok/s; 6687 tgt tok/s;      7 s elapsed
Epoch 15,   100/  454; acc:  85.08; ppl:   1.85; 6436 src tok/s; 6701 tgt tok/s;     13 s elapsed
Epoch 15,   150/  454; acc:  85.46; ppl:   1.79; 6512 src tok/s; 6756 tgt tok/s;     19 s elapsed
Epoch 15,   200/  454; acc:  84.70; ppl:   1.88; 6473 src tok/s; 6726 tgt tok/s;     26 s elapsed
Epoch 15,   250/  454; acc:  84.96; ppl:   1.86; 6607 src tok/s; 6833 tgt tok/s;     32 s elapsed
Epoch 15,   300/  454; acc:  84.98; ppl:   1.85; 6383 src tok/s; 6628 tgt tok/s;     39 s elapsed
Epoch 15,   350/  454; acc:  85.18; ppl:   1.84; 6595 src tok/s; 6835 tgt tok/s;     45 s elapsed
Epoch 15,   400/  454; acc:  85.27; ppl:   1.84; 6330 src tok/s; 6596 tgt tok/s;     52 s elapsed
Epoch 15,   450/  454; acc:  85.42; ppl:   1.82; 6437 src tok/s; 6700 tgt tok/s;     58 s elapsed
Train perplexity: 1.84265
Train accuracy: 85.0979
Validation perplexity: 6.60286
Validation accuracy: 69.1003
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.11; ppl:   1.83; 6494 src tok/s; 6730 tgt tok/s;      6 s elapsed
Epoch 16,   100/  454; acc:  85.22; ppl:   1.82; 6670 src tok/s; 6911 tgt tok/s;     13 s elapsed
Epoch 16,   150/  454; acc:  85.41; ppl:   1.85; 6504 src tok/s; 6741 tgt tok/s;     19 s elapsed
Epoch 16,   200/  454; acc:  85.04; ppl:   1.85; 6503 src tok/s; 6771 tgt tok/s;     26 s elapsed
Epoch 16,   250/  454; acc:  84.39; ppl:   1.93; 6498 src tok/s; 6749 tgt tok/s;     32 s elapsed
Epoch 16,   300/  454; acc:  85.62; ppl:   1.78; 6515 src tok/s; 6746 tgt tok/s;     39 s elapsed
Epoch 16,   350/  454; acc:  85.43; ppl:   1.82; 6411 src tok/s; 6662 tgt tok/s;     45 s elapsed
Epoch 16,   400/  454; acc:  85.15; ppl:   1.85; 6404 src tok/s; 6655 tgt tok/s;     52 s elapsed
Epoch 16,   450/  454; acc:  85.30; ppl:   1.82; 6303 src tok/s; 6547 tgt tok/s;     58 s elapsed
Train perplexity: 1.83809
Train accuracy: 85.1848
Validation perplexity: 6.60989
Validation accuracy: 69.1216
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.01; ppl:   1.85; 6642 src tok/s; 6857 tgt tok/s;      6 s elapsed
Epoch 17,   100/  454; acc:  85.56; ppl:   1.82; 6329 src tok/s; 6599 tgt tok/s;     13 s elapsed
Epoch 17,   150/  454; acc:  84.57; ppl:   1.88; 6453 src tok/s; 6671 tgt tok/s;     20 s elapsed
Epoch 17,   200/  454; acc:  85.60; ppl:   1.79; 6441 src tok/s; 6682 tgt tok/s;     26 s elapsed
Epoch 17,   250/  454; acc:  85.38; ppl:   1.81; 6531 src tok/s; 6786 tgt tok/s;     32 s elapsed
Epoch 17,   300/  454; acc:  84.91; ppl:   1.87; 6477 src tok/s; 6737 tgt tok/s;     39 s elapsed
Epoch 17,   350/  454; acc:  85.13; ppl:   1.86; 6429 src tok/s; 6657 tgt tok/s;     45 s elapsed
Epoch 17,   400/  454; acc:  85.69; ppl:   1.82; 6624 src tok/s; 6881 tgt tok/s;     52 s elapsed
Epoch 17,   450/  454; acc:  85.01; ppl:   1.84; 6421 src tok/s; 6673 tgt tok/s;     58 s elapsed
Train perplexity: 1.83494
Train accuracy: 85.2204
Validation perplexity: 6.61176
Validation accuracy: 69.0932
Decaying learning rate to 0.000976562
