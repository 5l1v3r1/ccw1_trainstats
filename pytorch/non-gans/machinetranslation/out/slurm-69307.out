<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.05, kappa_enc=0.3, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.30decoder0.05dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.3)
('Using Kappa L2 loss on decoder', 0.05)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   7.89; ppl: 27726.90; 4112 src tok/s; 4249 tgt tok/s;     11 s elapsed
Epoch  1,   100/  454; acc:  15.80; ppl: 1213.87; 5623 src tok/s; 5848 tgt tok/s;     18 s elapsed
Epoch  1,   150/  454; acc:  17.41; ppl: 478.88; 5685 src tok/s; 5838 tgt tok/s;     26 s elapsed
Epoch  1,   200/  454; acc:  22.08; ppl: 250.99; 5300 src tok/s; 5557 tgt tok/s;     33 s elapsed
Epoch  1,   250/  454; acc:  24.64; ppl: 163.11; 5260 src tok/s; 5439 tgt tok/s;     41 s elapsed
Epoch  1,   300/  454; acc:  27.63; ppl: 123.43; 5101 src tok/s; 5336 tgt tok/s;     49 s elapsed
Epoch  1,   350/  454; acc:  29.81; ppl:  94.00; 5242 src tok/s; 5407 tgt tok/s;     57 s elapsed
Epoch  1,   400/  454; acc:  31.71; ppl:  75.19; 5127 src tok/s; 5357 tgt tok/s;     65 s elapsed
Epoch  1,   450/  454; acc:  33.02; ppl:  66.76; 5147 src tok/s; 5346 tgt tok/s;     73 s elapsed
Train perplexity: 324.075
Train accuracy: 23.3423
Validation perplexity: 62.2333
Validation accuracy: 32.4606

Epoch  2,    50/  454; acc:  34.84; ppl:  56.63; 5360 src tok/s; 5532 tgt tok/s;      8 s elapsed
Epoch  2,   100/  454; acc:  38.66; ppl:  44.79; 5290 src tok/s; 5522 tgt tok/s;     16 s elapsed
Epoch  2,   150/  454; acc:  41.40; ppl:  36.34; 5134 src tok/s; 5370 tgt tok/s;     24 s elapsed
Epoch  2,   200/  454; acc:  42.21; ppl:  34.73; 5256 src tok/s; 5415 tgt tok/s;     32 s elapsed
Epoch  2,   250/  454; acc:  45.36; ppl:  28.74; 5115 src tok/s; 5332 tgt tok/s;     40 s elapsed
Epoch  2,   300/  454; acc:  47.17; ppl:  24.48; 5269 src tok/s; 5456 tgt tok/s;     48 s elapsed
Epoch  2,   350/  454; acc:  47.79; ppl:  23.92; 5189 src tok/s; 5368 tgt tok/s;     56 s elapsed
Epoch  2,   400/  454; acc:  51.89; ppl:  18.44; 5264 src tok/s; 5452 tgt tok/s;     64 s elapsed
Epoch  2,   450/  454; acc:  52.09; ppl:  18.03; 5086 src tok/s; 5299 tgt tok/s;     72 s elapsed
Train perplexity: 29.6624
Train accuracy: 44.6208
Validation perplexity: 15.9711
Validation accuracy: 54.25

Epoch  3,    50/  454; acc:  54.50; ppl:  14.62; 5253 src tok/s; 5440 tgt tok/s;      8 s elapsed
Epoch  3,   100/  454; acc:  55.65; ppl:  13.53; 5287 src tok/s; 5510 tgt tok/s;     16 s elapsed
Epoch  3,   150/  454; acc:  55.33; ppl:  13.96; 5284 src tok/s; 5465 tgt tok/s;     24 s elapsed
Epoch  3,   200/  454; acc:  56.74; ppl:  12.77; 5200 src tok/s; 5413 tgt tok/s;     32 s elapsed
Epoch  3,   250/  454; acc:  57.04; ppl:  12.31; 5288 src tok/s; 5471 tgt tok/s;     40 s elapsed
Epoch  3,   300/  454; acc:  58.04; ppl:  11.50; 5298 src tok/s; 5486 tgt tok/s;     48 s elapsed
Epoch  3,   350/  454; acc:  56.92; ppl:  12.28; 5143 src tok/s; 5318 tgt tok/s;     56 s elapsed
Epoch  3,   400/  454; acc:  59.75; ppl:  10.37; 5222 src tok/s; 5445 tgt tok/s;     64 s elapsed
Epoch  3,   450/  454; acc:  58.46; ppl:  11.07; 5241 src tok/s; 5442 tgt tok/s;     72 s elapsed
Train perplexity: 12.4065
Train accuracy: 56.9599
Validation perplexity: 10.3492
Validation accuracy: 59.6566

Epoch  4,    50/  454; acc:  62.21; ppl:   8.29; 5320 src tok/s; 5549 tgt tok/s;      8 s elapsed
Epoch  4,   100/  454; acc:  61.03; ppl:   8.90; 5166 src tok/s; 5351 tgt tok/s;     16 s elapsed
Epoch  4,   150/  454; acc:  61.59; ppl:   8.39; 5204 src tok/s; 5409 tgt tok/s;     24 s elapsed
Epoch  4,   200/  454; acc:  62.16; ppl:   8.38; 5320 src tok/s; 5528 tgt tok/s;     32 s elapsed
Epoch  4,   250/  454; acc:  62.16; ppl:   8.42; 5220 src tok/s; 5388 tgt tok/s;     40 s elapsed
Epoch  4,   300/  454; acc:  62.57; ppl:   7.98; 5158 src tok/s; 5329 tgt tok/s;     48 s elapsed
Epoch  4,   350/  454; acc:  63.24; ppl:   7.51; 5207 src tok/s; 5450 tgt tok/s;     56 s elapsed
Epoch  4,   400/  454; acc:  63.19; ppl:   7.74; 5288 src tok/s; 5468 tgt tok/s;     64 s elapsed
Epoch  4,   450/  454; acc:  63.26; ppl:   7.80; 5221 src tok/s; 5406 tgt tok/s;     72 s elapsed
Train perplexity: 8.1293
Train accuracy: 62.4052
Validation perplexity: 8.13448
Validation accuracy: 63.9776

Epoch  5,    50/  454; acc:  66.86; ppl:   5.83; 5434 src tok/s; 5631 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  65.58; ppl:   6.23; 5342 src tok/s; 5528 tgt tok/s;     16 s elapsed
Epoch  5,   150/  454; acc:  65.26; ppl:   6.33; 5235 src tok/s; 5436 tgt tok/s;     24 s elapsed
Epoch  5,   200/  454; acc:  65.29; ppl:   6.22; 5292 src tok/s; 5507 tgt tok/s;     32 s elapsed
Epoch  5,   250/  454; acc:  66.19; ppl:   6.00; 5309 src tok/s; 5474 tgt tok/s;     40 s elapsed
Epoch  5,   300/  454; acc:  65.80; ppl:   6.16; 5233 src tok/s; 5452 tgt tok/s;     47 s elapsed
Epoch  5,   350/  454; acc:  65.78; ppl:   6.21; 5321 src tok/s; 5531 tgt tok/s;     55 s elapsed
Epoch  5,   400/  454; acc:  65.86; ppl:   6.10; 5251 src tok/s; 5462 tgt tok/s;     63 s elapsed
Epoch  5,   450/  454; acc:  65.30; ppl:   6.26; 5290 src tok/s; 5481 tgt tok/s;     71 s elapsed
Train perplexity: 6.13243
Train accuracy: 65.8034
Validation perplexity: 7.3206
Validation accuracy: 64.8574

Epoch  6,    50/  454; acc:  69.25; ppl:   4.72; 5462 src tok/s; 5688 tgt tok/s;      8 s elapsed
Epoch  6,   100/  454; acc:  67.85; ppl:   5.10; 5344 src tok/s; 5538 tgt tok/s;     16 s elapsed
Epoch  6,   150/  454; acc:  69.59; ppl:   4.57; 5274 src tok/s; 5525 tgt tok/s;     23 s elapsed
Epoch  6,   200/  454; acc:  67.70; ppl:   5.08; 5380 src tok/s; 5557 tgt tok/s;     31 s elapsed
Epoch  6,   250/  454; acc:  69.04; ppl:   4.82; 5295 src tok/s; 5490 tgt tok/s;     39 s elapsed
Epoch  6,   300/  454; acc:  67.74; ppl:   5.13; 5301 src tok/s; 5497 tgt tok/s;     47 s elapsed
Epoch  6,   350/  454; acc:  69.07; ppl:   4.68; 5241 src tok/s; 5444 tgt tok/s;     55 s elapsed
Epoch  6,   400/  454; acc:  67.83; ppl:   5.23; 5390 src tok/s; 5577 tgt tok/s;     63 s elapsed
Epoch  6,   450/  454; acc:  68.27; ppl:   5.07; 5140 src tok/s; 5340 tgt tok/s;     71 s elapsed
Train perplexity: 4.94228
Train accuracy: 68.4464
Validation perplexity: 6.76781
Validation accuracy: 66.8653

Epoch  7,    50/  454; acc:  70.80; ppl:   4.13; 5479 src tok/s; 5637 tgt tok/s;      8 s elapsed
Epoch  7,   100/  454; acc:  71.76; ppl:   3.90; 5368 src tok/s; 5622 tgt tok/s;     16 s elapsed
Epoch  7,   150/  454; acc:  72.38; ppl:   3.70; 5307 src tok/s; 5532 tgt tok/s;     23 s elapsed
Epoch  7,   200/  454; acc:  69.24; ppl:   4.51; 5338 src tok/s; 5514 tgt tok/s;     31 s elapsed
Epoch  7,   250/  454; acc:  69.26; ppl:   4.46; 5211 src tok/s; 5407 tgt tok/s;     39 s elapsed
Epoch  7,   300/  454; acc:  71.10; ppl:   4.01; 5326 src tok/s; 5547 tgt tok/s;     47 s elapsed
Epoch  7,   350/  454; acc:  69.90; ppl:   4.25; 5289 src tok/s; 5504 tgt tok/s;     55 s elapsed
Epoch  7,   400/  454; acc:  70.24; ppl:   4.26; 5244 src tok/s; 5425 tgt tok/s;     63 s elapsed
Epoch  7,   450/  454; acc:  70.99; ppl:   4.09; 5327 src tok/s; 5542 tgt tok/s;     71 s elapsed
Train perplexity: 4.15494
Train accuracy: 70.5671
Validation perplexity: 6.66255
Validation accuracy: 66.7305

Epoch  8,    50/  454; acc:  73.22; ppl:   3.45; 5399 src tok/s; 5596 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  73.91; ppl:   3.32; 5359 src tok/s; 5553 tgt tok/s;     16 s elapsed
Epoch  8,   150/  454; acc:  73.23; ppl:   3.39; 5203 src tok/s; 5434 tgt tok/s;     23 s elapsed
Epoch  8,   200/  454; acc:  71.15; ppl:   3.82; 5264 src tok/s; 5432 tgt tok/s;     32 s elapsed
Epoch  8,   250/  454; acc:  71.66; ppl:   3.72; 5331 src tok/s; 5514 tgt tok/s;     40 s elapsed
Epoch  8,   300/  454; acc:  72.48; ppl:   3.53; 5259 src tok/s; 5498 tgt tok/s;     47 s elapsed
Epoch  8,   350/  454; acc:  72.04; ppl:   3.62; 5276 src tok/s; 5490 tgt tok/s;     55 s elapsed
Epoch  8,   400/  454; acc:  71.76; ppl:   3.72; 5269 src tok/s; 5444 tgt tok/s;     63 s elapsed
Epoch  8,   450/  454; acc:  71.45; ppl:   3.80; 5160 src tok/s; 5357 tgt tok/s;     71 s elapsed
Train perplexity: 3.59336
Train accuracy: 72.3089
Validation perplexity: 6.61701
Validation accuracy: 67.5323
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.15; ppl:   2.93; 5373 src tok/s; 5528 tgt tok/s;      8 s elapsed
Epoch  9,   100/  454; acc:  78.52; ppl:   2.55; 5294 src tok/s; 5543 tgt tok/s;     16 s elapsed
Epoch  9,   150/  454; acc:  78.06; ppl:   2.62; 5300 src tok/s; 5497 tgt tok/s;     24 s elapsed
Epoch  9,   200/  454; acc:  77.15; ppl:   2.71; 5300 src tok/s; 5507 tgt tok/s;     32 s elapsed
Epoch  9,   250/  454; acc:  76.09; ppl:   2.85; 5232 src tok/s; 5374 tgt tok/s;     40 s elapsed
Epoch  9,   300/  454; acc:  79.24; ppl:   2.42; 5331 src tok/s; 5597 tgt tok/s;     47 s elapsed
Epoch  9,   350/  454; acc:  77.15; ppl:   2.68; 5320 src tok/s; 5503 tgt tok/s;     55 s elapsed
Epoch  9,   400/  454; acc:  77.01; ppl:   2.71; 5164 src tok/s; 5376 tgt tok/s;     64 s elapsed
Epoch  9,   450/  454; acc:  76.96; ppl:   2.72; 5163 src tok/s; 5362 tgt tok/s;     72 s elapsed
Train perplexity: 2.68859
Train accuracy: 77.3444
Validation perplexity: 6.31854
Validation accuracy: 68.7527
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.69; ppl:   2.25; 5357 src tok/s; 5546 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  81.06; ppl:   2.24; 5120 src tok/s; 5327 tgt tok/s;     16 s elapsed
Epoch 10,   150/  454; acc:  80.90; ppl:   2.27; 5198 src tok/s; 5333 tgt tok/s;     25 s elapsed
Epoch 10,   200/  454; acc:  81.85; ppl:   2.16; 5273 src tok/s; 5480 tgt tok/s;     32 s elapsed
Epoch 10,   250/  454; acc:  82.52; ppl:   2.05; 5267 src tok/s; 5514 tgt tok/s;     40 s elapsed
Epoch 10,   300/  454; acc:  80.04; ppl:   2.33; 5287 src tok/s; 5462 tgt tok/s;     48 s elapsed
Epoch 10,   350/  454; acc:  81.53; ppl:   2.19; 5519 src tok/s; 5745 tgt tok/s;     56 s elapsed
Epoch 10,   400/  454; acc:  81.24; ppl:   2.23; 5294 src tok/s; 5499 tgt tok/s;     63 s elapsed
Epoch 10,   450/  454; acc:  81.56; ppl:   2.15; 5182 src tok/s; 5408 tgt tok/s;     71 s elapsed
Train perplexity: 2.21579
Train accuracy: 81.1846
Validation perplexity: 6.20874
Validation accuracy: 69.228
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.62; ppl:   1.99; 5326 src tok/s; 5529 tgt tok/s;      8 s elapsed
Epoch 11,   100/  454; acc:  83.88; ppl:   1.94; 5334 src tok/s; 5513 tgt tok/s;     16 s elapsed
Epoch 11,   150/  454; acc:  83.68; ppl:   1.95; 5320 src tok/s; 5533 tgt tok/s;     23 s elapsed
Epoch 11,   200/  454; acc:  83.18; ppl:   2.01; 5277 src tok/s; 5468 tgt tok/s;     31 s elapsed
Epoch 11,   250/  454; acc:  83.84; ppl:   1.97; 5222 src tok/s; 5439 tgt tok/s;     39 s elapsed
Epoch 11,   300/  454; acc:  82.57; ppl:   2.09; 5269 src tok/s; 5448 tgt tok/s;     47 s elapsed
Epoch 11,   350/  454; acc:  84.17; ppl:   1.93; 5276 src tok/s; 5524 tgt tok/s;     55 s elapsed
Epoch 11,   400/  454; acc:  82.05; ppl:   2.11; 5321 src tok/s; 5514 tgt tok/s;     63 s elapsed
Epoch 11,   450/  454; acc:  83.27; ppl:   2.03; 5351 src tok/s; 5535 tgt tok/s;     71 s elapsed
Train perplexity: 2.00173
Train accuracy: 83.3651
Validation perplexity: 6.38663
Validation accuracy: 69.5048
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  83.75; ppl:   1.96; 5289 src tok/s; 5478 tgt tok/s;      8 s elapsed
Epoch 12,   100/  454; acc:  85.29; ppl:   1.83; 5292 src tok/s; 5514 tgt tok/s;     16 s elapsed
Epoch 12,   150/  454; acc:  83.25; ppl:   2.05; 5311 src tok/s; 5477 tgt tok/s;     24 s elapsed
Epoch 12,   200/  454; acc:  85.85; ppl:   1.76; 5309 src tok/s; 5524 tgt tok/s;     32 s elapsed
Epoch 12,   250/  454; acc:  83.94; ppl:   1.95; 5250 src tok/s; 5449 tgt tok/s;     40 s elapsed
Epoch 12,   300/  454; acc:  84.84; ppl:   1.86; 5407 src tok/s; 5625 tgt tok/s;     47 s elapsed
Epoch 12,   350/  454; acc:  85.02; ppl:   1.85; 5347 src tok/s; 5574 tgt tok/s;     55 s elapsed
Epoch 12,   400/  454; acc:  83.81; ppl:   1.94; 5316 src tok/s; 5513 tgt tok/s;     63 s elapsed
Epoch 12,   450/  454; acc:  84.16; ppl:   1.94; 5272 src tok/s; 5435 tgt tok/s;     71 s elapsed
Train perplexity: 1.90347
Train accuracy: 84.4286
Validation perplexity: 6.50167
Validation accuracy: 69.5331
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  85.41; ppl:   1.80; 5417 src tok/s; 5616 tgt tok/s;      8 s elapsed
Epoch 13,   100/  454; acc:  84.70; ppl:   1.90; 5291 src tok/s; 5475 tgt tok/s;     16 s elapsed
Epoch 13,   150/  454; acc:  85.35; ppl:   1.83; 5294 src tok/s; 5515 tgt tok/s;     23 s elapsed
Epoch 13,   200/  454; acc:  84.88; ppl:   1.85; 5333 src tok/s; 5516 tgt tok/s;     31 s elapsed
Epoch 13,   250/  454; acc:  84.54; ppl:   1.91; 5241 src tok/s; 5454 tgt tok/s;     39 s elapsed
Epoch 13,   300/  454; acc:  85.17; ppl:   1.82; 5328 src tok/s; 5530 tgt tok/s;     47 s elapsed
Epoch 13,   350/  454; acc:  85.17; ppl:   1.84; 5248 src tok/s; 5476 tgt tok/s;     55 s elapsed
Epoch 13,   400/  454; acc:  84.55; ppl:   1.89; 5334 src tok/s; 5524 tgt tok/s;     63 s elapsed
Epoch 13,   450/  454; acc:  84.87; ppl:   1.86; 5416 src tok/s; 5593 tgt tok/s;     71 s elapsed
Train perplexity: 1.85422
Train accuracy: 84.9741
Validation perplexity: 6.56783
Validation accuracy: 69.6467
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.95; ppl:   1.78; 5292 src tok/s; 5514 tgt tok/s;      8 s elapsed
Epoch 14,   100/  454; acc:  84.78; ppl:   1.88; 5182 src tok/s; 5372 tgt tok/s;     16 s elapsed
Epoch 14,   150/  454; acc:  84.52; ppl:   1.93; 5128 src tok/s; 5323 tgt tok/s;     24 s elapsed
Epoch 14,   200/  454; acc:  85.94; ppl:   1.78; 5396 src tok/s; 5606 tgt tok/s;     32 s elapsed
Epoch 14,   250/  454; acc:  86.12; ppl:   1.75; 5116 src tok/s; 5317 tgt tok/s;     40 s elapsed
Epoch 14,   300/  454; acc:  84.23; ppl:   1.92; 5274 src tok/s; 5431 tgt tok/s;     48 s elapsed
Epoch 14,   350/  454; acc:  84.95; ppl:   1.85; 5123 src tok/s; 5326 tgt tok/s;     56 s elapsed
Epoch 14,   400/  454; acc:  85.49; ppl:   1.81; 5473 src tok/s; 5670 tgt tok/s;     64 s elapsed
Epoch 14,   450/  454; acc:  85.35; ppl:   1.81; 5301 src tok/s; 5507 tgt tok/s;     72 s elapsed
Train perplexity: 1.83407
Train accuracy: 85.2522
Validation perplexity: 6.58806
Validation accuracy: 69.5118
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  84.68; ppl:   1.88; 5240 src tok/s; 5408 tgt tok/s;      8 s elapsed
Epoch 15,   100/  454; acc:  86.03; ppl:   1.78; 5403 src tok/s; 5630 tgt tok/s;     16 s elapsed
Epoch 15,   150/  454; acc:  84.33; ppl:   1.91; 5377 src tok/s; 5538 tgt tok/s;     24 s elapsed
Epoch 15,   200/  454; acc:  86.77; ppl:   1.70; 5352 src tok/s; 5606 tgt tok/s;     31 s elapsed
Epoch 15,   250/  454; acc:  85.67; ppl:   1.81; 5042 src tok/s; 5268 tgt tok/s;     39 s elapsed
Epoch 15,   300/  454; acc:  84.98; ppl:   1.86; 5345 src tok/s; 5512 tgt tok/s;     48 s elapsed
Epoch 15,   350/  454; acc:  85.30; ppl:   1.83; 5186 src tok/s; 5414 tgt tok/s;     56 s elapsed
Epoch 15,   400/  454; acc:  85.63; ppl:   1.79; 5393 src tok/s; 5581 tgt tok/s;     63 s elapsed
Epoch 15,   450/  454; acc:  85.83; ppl:   1.78; 5324 src tok/s; 5529 tgt tok/s;     71 s elapsed
Train perplexity: 1.82025
Train accuracy: 85.3966
Validation perplexity: 6.60841
Validation accuracy: 69.4693
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.77; ppl:   1.79; 5330 src tok/s; 5568 tgt tok/s;      8 s elapsed
Epoch 16,   100/  454; acc:  85.10; ppl:   1.84; 5428 src tok/s; 5603 tgt tok/s;     16 s elapsed
Epoch 16,   150/  454; acc:  84.88; ppl:   1.88; 5203 src tok/s; 5374 tgt tok/s;     24 s elapsed
Epoch 16,   200/  454; acc:  86.13; ppl:   1.76; 5150 src tok/s; 5382 tgt tok/s;     32 s elapsed
Epoch 16,   250/  454; acc:  85.84; ppl:   1.79; 5098 src tok/s; 5325 tgt tok/s;     40 s elapsed
Epoch 16,   300/  454; acc:  85.28; ppl:   1.82; 5380 src tok/s; 5562 tgt tok/s;     48 s elapsed
Epoch 16,   350/  454; acc:  85.92; ppl:   1.77; 5373 src tok/s; 5578 tgt tok/s;     55 s elapsed
Epoch 16,   400/  454; acc:  84.86; ppl:   1.85; 5329 src tok/s; 5531 tgt tok/s;     64 s elapsed
Epoch 16,   450/  454; acc:  86.14; ppl:   1.75; 5252 src tok/s; 5439 tgt tok/s;     71 s elapsed
Train perplexity: 1.81316
Train accuracy: 85.4683
Validation perplexity: 6.61806
Validation accuracy: 69.4906
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  86.21; ppl:   1.75; 5457 src tok/s; 5670 tgt tok/s;      7 s elapsed
Epoch 17,   100/  454; acc:  84.93; ppl:   1.88; 5197 src tok/s; 5361 tgt tok/s;     16 s elapsed
Epoch 17,   150/  454; acc:  85.35; ppl:   1.84; 5217 src tok/s; 5421 tgt tok/s;     24 s elapsed
Epoch 17,   200/  454; acc:  85.54; ppl:   1.80; 5316 src tok/s; 5531 tgt tok/s;     32 s elapsed
Epoch 17,   250/  454; acc:  85.77; ppl:   1.77; 5446 src tok/s; 5673 tgt tok/s;     39 s elapsed
Epoch 17,   300/  454; acc:  85.28; ppl:   1.83; 5300 src tok/s; 5477 tgt tok/s;     47 s elapsed
Epoch 17,   350/  454; acc:  85.22; ppl:   1.84; 5314 src tok/s; 5500 tgt tok/s;     55 s elapsed
Epoch 17,   400/  454; acc:  85.76; ppl:   1.79; 5327 src tok/s; 5524 tgt tok/s;     63 s elapsed
Epoch 17,   450/  454; acc:  86.10; ppl:   1.78; 5196 src tok/s; 5409 tgt tok/s;     71 s elapsed
Train perplexity: 1.81192
Train accuracy: 85.5529
Validation perplexity: 6.62378
Validation accuracy: 69.5048
Decaying learning rate to 0.000976562
