<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.0, kappa_enc=0.05, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.05decoder0dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.05)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.45; ppl: 16562.90; 2843 src tok/s; 2954 tgt tok/s;     15 s elapsed
Epoch  1,   100/  454; acc:  15.53; ppl: 1313.82; 2959 src tok/s; 3073 tgt tok/s;     29 s elapsed
Epoch  1,   150/  454; acc:  18.51; ppl: 517.72; 2998 src tok/s; 3089 tgt tok/s;     43 s elapsed
Epoch  1,   200/  454; acc:  21.64; ppl: 263.02; 2990 src tok/s; 3122 tgt tok/s;     57 s elapsed
Epoch  1,   250/  454; acc:  25.00; ppl: 167.09; 2982 src tok/s; 3103 tgt tok/s;     71 s elapsed
Epoch  1,   300/  454; acc:  27.34; ppl: 125.31; 3005 src tok/s; 3120 tgt tok/s;     85 s elapsed
Epoch  1,   350/  454; acc:  29.33; ppl:  95.97; 3006 src tok/s; 3114 tgt tok/s;     99 s elapsed
Epoch  1,   400/  454; acc:  31.03; ppl:  79.46; 2995 src tok/s; 3109 tgt tok/s;    113 s elapsed
Epoch  1,   450/  454; acc:  32.54; ppl:  69.66; 2996 src tok/s; 3095 tgt tok/s;    127 s elapsed
Train perplexity: 311.798
Train accuracy: 23.3961
Validation perplexity: 54.8344
Validation accuracy: 35.8592

Epoch  2,    50/  454; acc:  35.42; ppl:  53.58; 2965 src tok/s; 3078 tgt tok/s;     14 s elapsed
Epoch  2,   100/  454; acc:  36.79; ppl:  50.10; 2963 src tok/s; 3077 tgt tok/s;     28 s elapsed
Epoch  2,   150/  454; acc:  38.40; ppl:  44.94; 3023 src tok/s; 3123 tgt tok/s;     43 s elapsed
Epoch  2,   200/  454; acc:  42.87; ppl:  33.95; 2968 src tok/s; 3096 tgt tok/s;     56 s elapsed
Epoch  2,   250/  454; acc:  43.00; ppl:  31.45; 3004 src tok/s; 3124 tgt tok/s;     70 s elapsed
Epoch  2,   300/  454; acc:  46.46; ppl:  25.84; 3088 src tok/s; 3206 tgt tok/s;     84 s elapsed
Epoch  2,   350/  454; acc:  49.22; ppl:  22.54; 2967 src tok/s; 3090 tgt tok/s;     97 s elapsed
Epoch  2,   400/  454; acc:  48.37; ppl:  22.16; 3022 src tok/s; 3117 tgt tok/s;    112 s elapsed
Epoch  2,   450/  454; acc:  51.30; ppl:  18.62; 3016 src tok/s; 3142 tgt tok/s;    125 s elapsed
Train perplexity: 31.5508
Train accuracy: 43.513
Validation perplexity: 17.4371
Validation accuracy: 51.4971

Epoch  3,    50/  454; acc:  52.15; ppl:  16.75; 2980 src tok/s; 3069 tgt tok/s;     15 s elapsed
Epoch  3,   100/  454; acc:  55.08; ppl:  13.86; 2981 src tok/s; 3115 tgt tok/s;     28 s elapsed
Epoch  3,   150/  454; acc:  52.51; ppl:  15.97; 3006 src tok/s; 3090 tgt tok/s;     43 s elapsed
Epoch  3,   200/  454; acc:  57.49; ppl:  12.12; 2978 src tok/s; 3128 tgt tok/s;     56 s elapsed
Epoch  3,   250/  454; acc:  55.60; ppl:  13.36; 3083 src tok/s; 3173 tgt tok/s;     71 s elapsed
Epoch  3,   300/  454; acc:  58.28; ppl:  11.59; 2951 src tok/s; 3072 tgt tok/s;     84 s elapsed
Epoch  3,   350/  454; acc:  57.77; ppl:  11.96; 3002 src tok/s; 3104 tgt tok/s;     98 s elapsed
Epoch  3,   400/  454; acc:  58.20; ppl:  11.36; 2973 src tok/s; 3103 tgt tok/s;    112 s elapsed
Epoch  3,   450/  454; acc:  58.59; ppl:  10.89; 2950 src tok/s; 3079 tgt tok/s;    126 s elapsed
Train perplexity: 13.0048
Train accuracy: 56.1162
Validation perplexity: 10.762
Validation accuracy: 59.1812

Epoch  4,    50/  454; acc:  59.99; ppl:   9.47; 2946 src tok/s; 3033 tgt tok/s;     15 s elapsed
Epoch  4,   100/  454; acc:  62.41; ppl:   8.15; 2971 src tok/s; 3135 tgt tok/s;     28 s elapsed
Epoch  4,   150/  454; acc:  60.86; ppl:   8.82; 2960 src tok/s; 3067 tgt tok/s;     43 s elapsed
Epoch  4,   200/  454; acc:  62.14; ppl:   8.06; 3029 src tok/s; 3143 tgt tok/s;     56 s elapsed
Epoch  4,   250/  454; acc:  61.92; ppl:   8.17; 3034 src tok/s; 3129 tgt tok/s;     70 s elapsed
Epoch  4,   300/  454; acc:  62.15; ppl:   8.35; 2954 src tok/s; 3055 tgt tok/s;     84 s elapsed
Epoch  4,   350/  454; acc:  63.11; ppl:   7.67; 2990 src tok/s; 3128 tgt tok/s;     98 s elapsed
Epoch  4,   400/  454; acc:  61.38; ppl:   8.67; 3013 src tok/s; 3110 tgt tok/s;    112 s elapsed
Epoch  4,   450/  454; acc:  62.94; ppl:   7.96; 2990 src tok/s; 3102 tgt tok/s;    127 s elapsed
Train perplexity: 8.3486
Train accuracy: 61.8965
Validation perplexity: 8.45862
Validation accuracy: 62.814

Epoch  5,    50/  454; acc:  65.88; ppl:   6.14; 3023 src tok/s; 3139 tgt tok/s;     14 s elapsed
Epoch  5,   100/  454; acc:  65.46; ppl:   6.28; 2970 src tok/s; 3067 tgt tok/s;     28 s elapsed
Epoch  5,   150/  454; acc:  65.58; ppl:   6.29; 2925 src tok/s; 3049 tgt tok/s;     42 s elapsed
Epoch  5,   200/  454; acc:  65.04; ppl:   6.34; 3032 src tok/s; 3138 tgt tok/s;     56 s elapsed
Epoch  5,   250/  454; acc:  64.63; ppl:   6.47; 2994 src tok/s; 3101 tgt tok/s;     71 s elapsed
Epoch  5,   300/  454; acc:  66.00; ppl:   6.08; 2957 src tok/s; 3097 tgt tok/s;     84 s elapsed
Epoch  5,   350/  454; acc:  65.84; ppl:   6.10; 3027 src tok/s; 3137 tgt tok/s;     98 s elapsed
Epoch  5,   400/  454; acc:  65.02; ppl:   6.51; 3022 src tok/s; 3121 tgt tok/s;    112 s elapsed
Epoch  5,   450/  454; acc:  66.01; ppl:   5.97; 2976 src tok/s; 3105 tgt tok/s;    126 s elapsed
Train perplexity: 6.26684
Train accuracy: 65.4131
Validation perplexity: 7.58728
Validation accuracy: 64.6303

Epoch  6,    50/  454; acc:  69.57; ppl:   4.74; 3010 src tok/s; 3139 tgt tok/s;     13 s elapsed
Epoch  6,   100/  454; acc:  67.48; ppl:   5.24; 3035 src tok/s; 3117 tgt tok/s;     28 s elapsed
Epoch  6,   150/  454; acc:  68.31; ppl:   4.93; 3004 src tok/s; 3113 tgt tok/s;     42 s elapsed
Epoch  6,   200/  454; acc:  68.48; ppl:   4.94; 2947 src tok/s; 3062 tgt tok/s;     56 s elapsed
Epoch  6,   250/  454; acc:  66.95; ppl:   5.23; 3011 src tok/s; 3097 tgt tok/s;     71 s elapsed
Epoch  6,   300/  454; acc:  68.71; ppl:   4.79; 2963 src tok/s; 3102 tgt tok/s;     84 s elapsed
Epoch  6,   350/  454; acc:  67.50; ppl:   5.22; 2997 src tok/s; 3109 tgt tok/s;     98 s elapsed
Epoch  6,   400/  454; acc:  68.43; ppl:   4.98; 2983 src tok/s; 3105 tgt tok/s;    112 s elapsed
Epoch  6,   450/  454; acc:  67.71; ppl:   5.20; 2798 src tok/s; 2920 tgt tok/s;    127 s elapsed
Train perplexity: 5.03548
Train accuracy: 68.105
Validation perplexity: 6.94535
Validation accuracy: 66.092

Epoch  7,    50/  454; acc:  72.13; ppl:   3.83; 3022 src tok/s; 3136 tgt tok/s;     14 s elapsed
Epoch  7,   100/  454; acc:  70.76; ppl:   4.09; 3024 src tok/s; 3121 tgt tok/s;     28 s elapsed
Epoch  7,   150/  454; acc:  70.83; ppl:   4.10; 3003 src tok/s; 3120 tgt tok/s;     42 s elapsed
Epoch  7,   200/  454; acc:  69.54; ppl:   4.37; 2988 src tok/s; 3100 tgt tok/s;     56 s elapsed
Epoch  7,   250/  454; acc:  69.58; ppl:   4.44; 2942 src tok/s; 3047 tgt tok/s;     70 s elapsed
Epoch  7,   300/  454; acc:  70.58; ppl:   4.12; 2985 src tok/s; 3096 tgt tok/s;     84 s elapsed
Epoch  7,   350/  454; acc:  70.05; ppl:   4.28; 2939 src tok/s; 3058 tgt tok/s;     99 s elapsed
Epoch  7,   400/  454; acc:  69.93; ppl:   4.30; 2955 src tok/s; 3070 tgt tok/s;    113 s elapsed
Epoch  7,   450/  454; acc:  69.37; ppl:   4.40; 2913 src tok/s; 3037 tgt tok/s;    127 s elapsed
Train perplexity: 4.21111
Train accuracy: 70.3174
Validation perplexity: 6.83436
Validation accuracy: 66.7447

Epoch  8,    50/  454; acc:  73.18; ppl:   3.47; 2959 src tok/s; 3066 tgt tok/s;     14 s elapsed
Epoch  8,   100/  454; acc:  73.43; ppl:   3.39; 3009 src tok/s; 3127 tgt tok/s;     28 s elapsed
Epoch  8,   150/  454; acc:  72.54; ppl:   3.52; 2997 src tok/s; 3120 tgt tok/s;     42 s elapsed
Epoch  8,   200/  454; acc:  71.48; ppl:   3.76; 2992 src tok/s; 3103 tgt tok/s;     56 s elapsed
Epoch  8,   250/  454; acc:  71.33; ppl:   3.83; 2976 src tok/s; 3076 tgt tok/s;     70 s elapsed
Epoch  8,   300/  454; acc:  72.46; ppl:   3.56; 2979 src tok/s; 3103 tgt tok/s;     84 s elapsed
Epoch  8,   350/  454; acc:  72.01; ppl:   3.61; 2997 src tok/s; 3135 tgt tok/s;     98 s elapsed
Epoch  8,   400/  454; acc:  71.09; ppl:   3.87; 3022 src tok/s; 3113 tgt tok/s;    112 s elapsed
Epoch  8,   450/  454; acc:  71.66; ppl:   3.77; 2955 src tok/s; 3061 tgt tok/s;    126 s elapsed
Train perplexity: 3.64092
Train accuracy: 72.1231
Validation perplexity: 6.78128
Validation accuracy: 67.0569
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.03; ppl:   2.91; 2960 src tok/s; 3068 tgt tok/s;     14 s elapsed
Epoch  9,   100/  454; acc:  78.18; ppl:   2.59; 3007 src tok/s; 3136 tgt tok/s;     28 s elapsed
Epoch  9,   150/  454; acc:  77.76; ppl:   2.65; 2958 src tok/s; 3088 tgt tok/s;     42 s elapsed
Epoch  9,   200/  454; acc:  77.12; ppl:   2.71; 3008 src tok/s; 3115 tgt tok/s;     56 s elapsed
Epoch  9,   250/  454; acc:  77.05; ppl:   2.72; 3039 src tok/s; 3145 tgt tok/s;     70 s elapsed
Epoch  9,   300/  454; acc:  77.16; ppl:   2.71; 3033 src tok/s; 3136 tgt tok/s;     84 s elapsed
Epoch  9,   350/  454; acc:  76.13; ppl:   2.90; 2981 src tok/s; 3074 tgt tok/s;     99 s elapsed
Epoch  9,   400/  454; acc:  78.01; ppl:   2.56; 2953 src tok/s; 3079 tgt tok/s;    112 s elapsed
Epoch  9,   450/  454; acc:  76.82; ppl:   2.71; 2992 src tok/s; 3113 tgt tok/s;    126 s elapsed
Train perplexity: 2.71902
Train accuracy: 77.1029
Validation perplexity: 6.31539
Validation accuracy: 68.5611
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.06; ppl:   2.23; 2958 src tok/s; 3063 tgt tok/s;     14 s elapsed
Epoch 10,   100/  454; acc:  81.38; ppl:   2.21; 2964 src tok/s; 3092 tgt tok/s;     28 s elapsed
Epoch 10,   150/  454; acc:  80.85; ppl:   2.25; 3000 src tok/s; 3123 tgt tok/s;     42 s elapsed
Epoch 10,   200/  454; acc:  81.72; ppl:   2.17; 2983 src tok/s; 3095 tgt tok/s;     56 s elapsed
Epoch 10,   250/  454; acc:  81.29; ppl:   2.18; 3026 src tok/s; 3144 tgt tok/s;     70 s elapsed
Epoch 10,   300/  454; acc:  79.93; ppl:   2.33; 3016 src tok/s; 3115 tgt tok/s;     84 s elapsed
Epoch 10,   350/  454; acc:  80.22; ppl:   2.35; 3016 src tok/s; 3114 tgt tok/s;     99 s elapsed
Epoch 10,   400/  454; acc:  81.70; ppl:   2.13; 2970 src tok/s; 3104 tgt tok/s;    112 s elapsed
Epoch 10,   450/  454; acc:  80.53; ppl:   2.29; 2957 src tok/s; 3056 tgt tok/s;    126 s elapsed
Train perplexity: 2.23632
Train accuracy: 80.9685
Validation perplexity: 6.25662
Validation accuracy: 69.3983
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  83.43; ppl:   2.00; 2986 src tok/s; 3109 tgt tok/s;     14 s elapsed
Epoch 11,   100/  454; acc:  83.53; ppl:   1.97; 3015 src tok/s; 3127 tgt tok/s;     28 s elapsed
Epoch 11,   150/  454; acc:  82.89; ppl:   2.05; 3009 src tok/s; 3123 tgt tok/s;     42 s elapsed
Epoch 11,   200/  454; acc:  83.78; ppl:   1.98; 2963 src tok/s; 3077 tgt tok/s;     56 s elapsed
Epoch 11,   250/  454; acc:  83.60; ppl:   1.97; 2971 src tok/s; 3101 tgt tok/s;     70 s elapsed
Epoch 11,   300/  454; acc:  82.23; ppl:   2.09; 2986 src tok/s; 3074 tgt tok/s;     84 s elapsed
Epoch 11,   350/  454; acc:  81.66; ppl:   2.19; 3031 src tok/s; 3119 tgt tok/s;     99 s elapsed
Epoch 11,   400/  454; acc:  84.10; ppl:   1.92; 2956 src tok/s; 3083 tgt tok/s;    112 s elapsed
Epoch 11,   450/  454; acc:  82.84; ppl:   2.05; 3000 src tok/s; 3123 tgt tok/s;    126 s elapsed
Train perplexity: 2.02189
Train accuracy: 83.1246
Validation perplexity: 6.38961
Validation accuracy: 69.6041
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  83.71; ppl:   1.96; 2985 src tok/s; 3085 tgt tok/s;     14 s elapsed
Epoch 12,   100/  454; acc:  85.18; ppl:   1.87; 2987 src tok/s; 3104 tgt tok/s;     28 s elapsed
Epoch 12,   150/  454; acc:  84.65; ppl:   1.89; 3031 src tok/s; 3157 tgt tok/s;     42 s elapsed
Epoch 12,   200/  454; acc:  84.36; ppl:   1.91; 3011 src tok/s; 3133 tgt tok/s;     56 s elapsed
Epoch 12,   250/  454; acc:  84.07; ppl:   1.95; 3041 src tok/s; 3114 tgt tok/s;     70 s elapsed
Epoch 12,   300/  454; acc:  84.13; ppl:   1.91; 2991 src tok/s; 3123 tgt tok/s;     84 s elapsed
Epoch 12,   350/  454; acc:  83.83; ppl:   1.95; 2942 src tok/s; 3073 tgt tok/s;     98 s elapsed
Epoch 12,   400/  454; acc:  83.81; ppl:   1.95; 2994 src tok/s; 3096 tgt tok/s;    112 s elapsed
Epoch 12,   450/  454; acc:  83.96; ppl:   1.95; 2973 src tok/s; 3087 tgt tok/s;    126 s elapsed
Train perplexity: 1.92359
Train accuracy: 84.2098
Validation perplexity: 6.49942
Validation accuracy: 69.6538
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  85.22; ppl:   1.83; 2975 src tok/s; 3089 tgt tok/s;     14 s elapsed
Epoch 13,   100/  454; acc:  84.24; ppl:   1.92; 2969 src tok/s; 3083 tgt tok/s;     28 s elapsed
Epoch 13,   150/  454; acc:  84.89; ppl:   1.86; 2944 src tok/s; 3050 tgt tok/s;     43 s elapsed
Epoch 13,   200/  454; acc:  84.74; ppl:   1.89; 2992 src tok/s; 3114 tgt tok/s;     57 s elapsed
Epoch 13,   250/  454; acc:  85.46; ppl:   1.81; 2998 src tok/s; 3129 tgt tok/s;     70 s elapsed
Epoch 13,   300/  454; acc:  84.32; ppl:   1.94; 3004 src tok/s; 3103 tgt tok/s;     84 s elapsed
Epoch 13,   350/  454; acc:  85.36; ppl:   1.81; 3038 src tok/s; 3162 tgt tok/s;     98 s elapsed
Epoch 13,   400/  454; acc:  84.01; ppl:   1.95; 3060 src tok/s; 3147 tgt tok/s;    112 s elapsed
Epoch 13,   450/  454; acc:  84.84; ppl:   1.87; 2975 src tok/s; 3097 tgt tok/s;    126 s elapsed
Train perplexity: 1.87613
Train accuracy: 84.7767
Validation perplexity: 6.55591
Validation accuracy: 69.4835
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.44; ppl:   1.84; 2988 src tok/s; 3091 tgt tok/s;     14 s elapsed
Epoch 14,   100/  454; acc:  84.97; ppl:   1.84; 2993 src tok/s; 3103 tgt tok/s;     28 s elapsed
Epoch 14,   150/  454; acc:  85.32; ppl:   1.84; 2993 src tok/s; 3110 tgt tok/s;     42 s elapsed
Epoch 14,   200/  454; acc:  84.71; ppl:   1.88; 3024 src tok/s; 3130 tgt tok/s;     56 s elapsed
Epoch 14,   250/  454; acc:  85.49; ppl:   1.81; 3003 src tok/s; 3127 tgt tok/s;     70 s elapsed
Epoch 14,   300/  454; acc:  84.77; ppl:   1.89; 2991 src tok/s; 3114 tgt tok/s;     84 s elapsed
Epoch 14,   350/  454; acc:  85.65; ppl:   1.80; 3003 src tok/s; 3113 tgt tok/s;     98 s elapsed
Epoch 14,   400/  454; acc:  84.23; ppl:   1.92; 2998 src tok/s; 3102 tgt tok/s;    112 s elapsed
Epoch 14,   450/  454; acc:  85.27; ppl:   1.85; 2980 src tok/s; 3098 tgt tok/s;    126 s elapsed
Train perplexity: 1.85105
Train accuracy: 85.1019
Validation perplexity: 6.58601
Validation accuracy: 69.5544
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.48; ppl:   1.82; 3019 src tok/s; 3140 tgt tok/s;     14 s elapsed
Epoch 15,   100/  454; acc:  84.59; ppl:   1.88; 3014 src tok/s; 3133 tgt tok/s;     28 s elapsed
Epoch 15,   150/  454; acc:  85.35; ppl:   1.81; 3076 src tok/s; 3179 tgt tok/s;     42 s elapsed
Epoch 15,   200/  454; acc:  85.20; ppl:   1.83; 2996 src tok/s; 3119 tgt tok/s;     56 s elapsed
Epoch 15,   250/  454; acc:  85.53; ppl:   1.80; 2971 src tok/s; 3094 tgt tok/s;     69 s elapsed
Epoch 15,   300/  454; acc:  85.13; ppl:   1.85; 3006 src tok/s; 3102 tgt tok/s;     84 s elapsed
Epoch 15,   350/  454; acc:  84.45; ppl:   1.91; 2964 src tok/s; 3067 tgt tok/s;     98 s elapsed
Epoch 15,   400/  454; acc:  85.60; ppl:   1.79; 2995 src tok/s; 3119 tgt tok/s;    112 s elapsed
Epoch 15,   450/  454; acc:  85.18; ppl:   1.86; 2908 src tok/s; 3010 tgt tok/s;    126 s elapsed
Train perplexity: 1.83782
Train accuracy: 85.1878
Validation perplexity: 6.60775
Validation accuracy: 69.5402
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  86.62; ppl:   1.70; 3029 src tok/s; 3148 tgt tok/s;     13 s elapsed
Epoch 16,   100/  454; acc:  84.35; ppl:   1.91; 3022 src tok/s; 3121 tgt tok/s;     28 s elapsed
Epoch 16,   150/  454; acc:  85.80; ppl:   1.79; 3006 src tok/s; 3128 tgt tok/s;     41 s elapsed
Epoch 16,   200/  454; acc:  84.57; ppl:   1.89; 3004 src tok/s; 3116 tgt tok/s;     56 s elapsed
Epoch 16,   250/  454; acc:  85.11; ppl:   1.85; 2976 src tok/s; 3091 tgt tok/s;     70 s elapsed
Epoch 16,   300/  454; acc:  85.39; ppl:   1.82; 2980 src tok/s; 3114 tgt tok/s;     84 s elapsed
Epoch 16,   350/  454; acc:  85.65; ppl:   1.80; 3008 src tok/s; 3116 tgt tok/s;     97 s elapsed
Epoch 16,   400/  454; acc:  84.80; ppl:   1.88; 2982 src tok/s; 3085 tgt tok/s;    112 s elapsed
Epoch 16,   450/  454; acc:  85.33; ppl:   1.82; 2993 src tok/s; 3112 tgt tok/s;    125 s elapsed
Train perplexity: 1.83345
Train accuracy: 85.2379
Validation perplexity: 6.61678
Validation accuracy: 69.5331
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  84.42; ppl:   1.92; 3001 src tok/s; 3089 tgt tok/s;     15 s elapsed
Epoch 17,   100/  454; acc:  86.06; ppl:   1.76; 2920 src tok/s; 3046 tgt tok/s;     28 s elapsed
Epoch 17,   150/  454; acc:  85.33; ppl:   1.83; 2994 src tok/s; 3109 tgt tok/s;     42 s elapsed
Epoch 17,   200/  454; acc:  85.09; ppl:   1.84; 3024 src tok/s; 3134 tgt tok/s;     56 s elapsed
Epoch 17,   250/  454; acc:  85.67; ppl:   1.81; 2996 src tok/s; 3117 tgt tok/s;     70 s elapsed
Epoch 17,   300/  454; acc:  85.14; ppl:   1.84; 3018 src tok/s; 3124 tgt tok/s;     84 s elapsed
Epoch 17,   350/  454; acc:  85.41; ppl:   1.80; 2959 src tok/s; 3080 tgt tok/s;     98 s elapsed
Epoch 17,   400/  454; acc:  85.10; ppl:   1.86; 3008 src tok/s; 3114 tgt tok/s;    112 s elapsed
Epoch 17,   450/  454; acc:  85.44; ppl:   1.82; 2918 src tok/s; 3043 tgt tok/s;    126 s elapsed
Train perplexity: 1.83194
Train accuracy: 85.2862
Validation perplexity: 6.62091
Validation accuracy: 69.5473
Decaying learning rate to 0.000976562
