<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.2, kappa_enc=0.25, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.25decoder0.20dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.25)
('Using Kappa L2 loss on decoder', 0.2)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.08; ppl: 23133.13; 4718 src tok/s; 4888 tgt tok/s;      9 s elapsed
Epoch  1,   100/  454; acc:  14.76; ppl: 2468.75; 5292 src tok/s; 5518 tgt tok/s;     17 s elapsed
Epoch  1,   150/  454; acc:  19.06; ppl: 455.73; 5393 src tok/s; 5646 tgt tok/s;     24 s elapsed
Epoch  1,   200/  454; acc:  19.32; ppl: 327.20; 5503 src tok/s; 5630 tgt tok/s;     32 s elapsed
Epoch  1,   250/  454; acc:  23.63; ppl: 183.74; 5383 src tok/s; 5602 tgt tok/s;     40 s elapsed
Epoch  1,   300/  454; acc:  26.32; ppl: 139.55; 5421 src tok/s; 5613 tgt tok/s;     48 s elapsed
Epoch  1,   350/  454; acc:  28.41; ppl: 104.45; 5362 src tok/s; 5558 tgt tok/s;     56 s elapsed
Epoch  1,   400/  454; acc:  31.48; ppl:  77.75; 5417 src tok/s; 5644 tgt tok/s;     63 s elapsed
Epoch  1,   450/  454; acc:  32.62; ppl:  69.80; 5409 src tok/s; 5615 tgt tok/s;     71 s elapsed
Train perplexity: 365.026
Train accuracy: 22.7042
Validation perplexity: 60.4151
Validation accuracy: 34.3621

Epoch  2,    50/  454; acc:  35.06; ppl:  55.08; 5380 src tok/s; 5582 tgt tok/s;      8 s elapsed
Epoch  2,   100/  454; acc:  35.81; ppl:  53.36; 5438 src tok/s; 5631 tgt tok/s;     16 s elapsed
Epoch  2,   150/  454; acc:  39.17; ppl:  42.77; 5315 src tok/s; 5596 tgt tok/s;     23 s elapsed
Epoch  2,   200/  454; acc:  38.72; ppl:  42.84; 5469 src tok/s; 5623 tgt tok/s;     31 s elapsed
Epoch  2,   250/  454; acc:  42.66; ppl:  33.92; 5478 src tok/s; 5675 tgt tok/s;     39 s elapsed
Epoch  2,   300/  454; acc:  45.85; ppl:  27.17; 5422 src tok/s; 5649 tgt tok/s;     46 s elapsed
Epoch  2,   350/  454; acc:  47.05; ppl:  24.66; 5478 src tok/s; 5711 tgt tok/s;     54 s elapsed
Epoch  2,   400/  454; acc:  48.29; ppl:  23.02; 5486 src tok/s; 5669 tgt tok/s;     62 s elapsed
Epoch  2,   450/  454; acc:  50.69; ppl:  19.76; 5317 src tok/s; 5512 tgt tok/s;     69 s elapsed
Train perplexity: 33.5864
Train accuracy: 42.6123
Validation perplexity: 18.0349
Validation accuracy: 52.8097

Epoch  3,    50/  454; acc:  52.48; ppl:  16.59; 5440 src tok/s; 5638 tgt tok/s;      8 s elapsed
Epoch  3,   100/  454; acc:  53.21; ppl:  15.22; 5358 src tok/s; 5585 tgt tok/s;     16 s elapsed
Epoch  3,   150/  454; acc:  54.11; ppl:  14.65; 5403 src tok/s; 5591 tgt tok/s;     24 s elapsed
Epoch  3,   200/  454; acc:  56.61; ppl:  12.82; 5496 src tok/s; 5735 tgt tok/s;     31 s elapsed
Epoch  3,   250/  454; acc:  56.97; ppl:  12.59; 5351 src tok/s; 5583 tgt tok/s;     38 s elapsed
Epoch  3,   300/  454; acc:  56.02; ppl:  13.10; 5476 src tok/s; 5612 tgt tok/s;     46 s elapsed
Epoch  3,   350/  454; acc:  58.00; ppl:  11.57; 5338 src tok/s; 5570 tgt tok/s;     54 s elapsed
Epoch  3,   400/  454; acc:  57.08; ppl:  12.20; 5495 src tok/s; 5691 tgt tok/s;     62 s elapsed
Epoch  3,   450/  454; acc:  57.90; ppl:  11.62; 5423 src tok/s; 5626 tgt tok/s;     70 s elapsed
Train perplexity: 13.2581
Train accuracy: 55.8384
Validation perplexity: 10.4795
Validation accuracy: 59.6921

Epoch  4,    50/  454; acc:  59.90; ppl:   9.65; 5552 src tok/s; 5721 tgt tok/s;      8 s elapsed
Epoch  4,   100/  454; acc:  62.61; ppl:   8.03; 5430 src tok/s; 5701 tgt tok/s;     15 s elapsed
Epoch  4,   150/  454; acc:  60.20; ppl:   9.37; 5454 src tok/s; 5619 tgt tok/s;     23 s elapsed
Epoch  4,   200/  454; acc:  62.91; ppl:   7.85; 5303 src tok/s; 5569 tgt tok/s;     31 s elapsed
Epoch  4,   250/  454; acc:  61.89; ppl:   8.27; 5378 src tok/s; 5581 tgt tok/s;     38 s elapsed
Epoch  4,   300/  454; acc:  61.48; ppl:   8.55; 5485 src tok/s; 5671 tgt tok/s;     46 s elapsed
Epoch  4,   350/  454; acc:  61.14; ppl:   8.76; 5520 src tok/s; 5677 tgt tok/s;     54 s elapsed
Epoch  4,   400/  454; acc:  63.39; ppl:   7.62; 5383 src tok/s; 5622 tgt tok/s;     62 s elapsed
Epoch  4,   450/  454; acc:  62.30; ppl:   8.16; 5239 src tok/s; 5433 tgt tok/s;     70 s elapsed
Train perplexity: 8.46129
Train accuracy: 61.7341
Validation perplexity: 8.08802
Validation accuracy: 63.8782

Epoch  5,    50/  454; acc:  65.54; ppl:   6.27; 5428 src tok/s; 5653 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  64.92; ppl:   6.43; 5384 src tok/s; 5590 tgt tok/s;     15 s elapsed
Epoch  5,   150/  454; acc:  65.65; ppl:   6.19; 5351 src tok/s; 5590 tgt tok/s;     23 s elapsed
Epoch  5,   200/  454; acc:  65.15; ppl:   6.31; 5375 src tok/s; 5563 tgt tok/s;     31 s elapsed
Epoch  5,   250/  454; acc:  65.71; ppl:   6.21; 5290 src tok/s; 5503 tgt tok/s;     39 s elapsed
Epoch  5,   300/  454; acc:  64.44; ppl:   6.73; 5465 src tok/s; 5660 tgt tok/s;     47 s elapsed
Epoch  5,   350/  454; acc:  64.04; ppl:   6.84; 5411 src tok/s; 5568 tgt tok/s;     55 s elapsed
Epoch  5,   400/  454; acc:  66.87; ppl:   5.69; 5222 src tok/s; 5456 tgt tok/s;     63 s elapsed
Epoch  5,   450/  454; acc:  65.59; ppl:   6.20; 5317 src tok/s; 5506 tgt tok/s;     70 s elapsed
Train perplexity: 6.33169
Train accuracy: 65.275
Validation perplexity: 7.30524
Validation accuracy: 65.4463

Epoch  6,    50/  454; acc:  69.55; ppl:   4.70; 5283 src tok/s; 5511 tgt tok/s;      8 s elapsed
Epoch  6,   100/  454; acc:  66.97; ppl:   5.39; 5409 src tok/s; 5605 tgt tok/s;     16 s elapsed
Epoch  6,   150/  454; acc:  67.06; ppl:   5.33; 5462 src tok/s; 5619 tgt tok/s;     24 s elapsed
Epoch  6,   200/  454; acc:  69.02; ppl:   4.79; 5316 src tok/s; 5554 tgt tok/s;     31 s elapsed
Epoch  6,   250/  454; acc:  67.97; ppl:   5.06; 5584 src tok/s; 5764 tgt tok/s;     39 s elapsed
Epoch  6,   300/  454; acc:  69.17; ppl:   4.84; 5359 src tok/s; 5592 tgt tok/s;     47 s elapsed
Epoch  6,   350/  454; acc:  67.25; ppl:   5.35; 5386 src tok/s; 5623 tgt tok/s;     54 s elapsed
Epoch  6,   400/  454; acc:  67.55; ppl:   5.19; 5486 src tok/s; 5664 tgt tok/s;     62 s elapsed
Epoch  6,   450/  454; acc:  67.19; ppl:   5.18; 5352 src tok/s; 5537 tgt tok/s;     70 s elapsed
Train perplexity: 5.08711
Train accuracy: 67.9633
Validation perplexity: 7.50194
Validation accuracy: 64.3252
Decaying learning rate to 0.5

Epoch  7,    50/  454; acc:  72.35; ppl:   3.78; 5385 src tok/s; 5570 tgt tok/s;      8 s elapsed
Epoch  7,   100/  454; acc:  73.67; ppl:   3.52; 5374 src tok/s; 5569 tgt tok/s;     16 s elapsed
Epoch  7,   150/  454; acc:  73.10; ppl:   3.63; 5415 src tok/s; 5621 tgt tok/s;     23 s elapsed
Epoch  7,   200/  454; acc:  73.41; ppl:   3.56; 5270 src tok/s; 5506 tgt tok/s;     31 s elapsed
Epoch  7,   250/  454; acc:  72.44; ppl:   3.69; 5443 src tok/s; 5654 tgt tok/s;     39 s elapsed
Epoch  7,   300/  454; acc:  73.90; ppl:   3.52; 5415 src tok/s; 5632 tgt tok/s;     47 s elapsed
Epoch  7,   350/  454; acc:  72.89; ppl:   3.75; 5470 src tok/s; 5643 tgt tok/s;     55 s elapsed
Epoch  7,   400/  454; acc:  73.21; ppl:   3.62; 5378 src tok/s; 5581 tgt tok/s;     62 s elapsed
Epoch  7,   450/  454; acc:  73.25; ppl:   3.59; 5319 src tok/s; 5529 tgt tok/s;     70 s elapsed
Train perplexity: 3.62596
Train accuracy: 73.1424
Validation perplexity: 6.26063
Validation accuracy: 67.7735
Decaying learning rate to 0.25

Epoch  8,    50/  454; acc:  76.85; ppl:   2.98; 5376 src tok/s; 5573 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  76.90; ppl:   2.91; 5430 src tok/s; 5606 tgt tok/s;     16 s elapsed
Epoch  8,   150/  454; acc:  77.59; ppl:   2.79; 5404 src tok/s; 5644 tgt tok/s;     23 s elapsed
Epoch  8,   200/  454; acc:  76.20; ppl:   3.02; 5395 src tok/s; 5586 tgt tok/s;     31 s elapsed
Epoch  8,   250/  454; acc:  77.12; ppl:   2.83; 5390 src tok/s; 5580 tgt tok/s;     39 s elapsed
Epoch  8,   300/  454; acc:  76.30; ppl:   2.99; 5391 src tok/s; 5591 tgt tok/s;     47 s elapsed
Epoch  8,   350/  454; acc:  76.88; ppl:   2.93; 5424 src tok/s; 5627 tgt tok/s;     54 s elapsed
Epoch  8,   400/  454; acc:  76.78; ppl:   2.92; 5362 src tok/s; 5600 tgt tok/s;     62 s elapsed
Epoch  8,   450/  454; acc:  76.94; ppl:   2.84; 5300 src tok/s; 5504 tgt tok/s;     70 s elapsed
Train perplexity: 2.92031
Train accuracy: 76.7877
Validation perplexity: 6.07082
Validation accuracy: 68.5114
Decaying learning rate to 0.125

Epoch  9,    50/  454; acc:  78.59; ppl:   2.64; 5439 src tok/s; 5624 tgt tok/s;      8 s elapsed
Epoch  9,   100/  454; acc:  79.34; ppl:   2.53; 5312 src tok/s; 5529 tgt tok/s;     16 s elapsed
Epoch  9,   150/  454; acc:  79.23; ppl:   2.53; 5431 src tok/s; 5641 tgt tok/s;     23 s elapsed
Epoch  9,   200/  454; acc:  79.01; ppl:   2.55; 5330 src tok/s; 5532 tgt tok/s;     31 s elapsed
Epoch  9,   250/  454; acc:  79.12; ppl:   2.56; 5405 src tok/s; 5634 tgt tok/s;     39 s elapsed
Epoch  9,   300/  454; acc:  78.35; ppl:   2.68; 5449 src tok/s; 5632 tgt tok/s;     47 s elapsed
Epoch  9,   350/  454; acc:  78.18; ppl:   2.69; 4777 src tok/s; 4942 tgt tok/s;     56 s elapsed
Epoch  9,   400/  454; acc:  79.02; ppl:   2.55; 5393 src tok/s; 5617 tgt tok/s;     63 s elapsed
Epoch  9,   450/  454; acc:  78.93; ppl:   2.62; 5487 src tok/s; 5691 tgt tok/s;     71 s elapsed
Train perplexity: 2.59398
Train accuracy: 78.867
Validation perplexity: 6.15626
Validation accuracy: 69.1145
Decaying learning rate to 0.0625

Epoch 10,    50/  454; acc:  80.62; ppl:   2.39; 5205 src tok/s; 5418 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  79.77; ppl:   2.44; 5218 src tok/s; 5426 tgt tok/s;     16 s elapsed
Epoch 10,   150/  454; acc:  79.77; ppl:   2.49; 5356 src tok/s; 5538 tgt tok/s;     24 s elapsed
Epoch 10,   200/  454; acc:  80.50; ppl:   2.34; 5520 src tok/s; 5713 tgt tok/s;     31 s elapsed
Epoch 10,   250/  454; acc:  79.91; ppl:   2.45; 5461 src tok/s; 5652 tgt tok/s;     39 s elapsed
Epoch 10,   300/  454; acc:  79.68; ppl:   2.48; 5382 src tok/s; 5584 tgt tok/s;     47 s elapsed
Epoch 10,   350/  454; acc:  81.02; ppl:   2.29; 5377 src tok/s; 5631 tgt tok/s;     55 s elapsed
Epoch 10,   400/  454; acc:  78.80; ppl:   2.63; 5417 src tok/s; 5588 tgt tok/s;     63 s elapsed
Epoch 10,   450/  454; acc:  79.79; ppl:   2.47; 5329 src tok/s; 5543 tgt tok/s;     70 s elapsed
Train perplexity: 2.43997
Train accuracy: 79.9969
Validation perplexity: 6.2354
Validation accuracy: 69.0861
Decaying learning rate to 0.03125

Epoch 11,    50/  454; acc:  80.33; ppl:   2.41; 5271 src tok/s; 5486 tgt tok/s;      8 s elapsed
Epoch 11,   100/  454; acc:  80.89; ppl:   2.33; 5338 src tok/s; 5507 tgt tok/s;     16 s elapsed
Epoch 11,   150/  454; acc:  80.78; ppl:   2.37; 5413 src tok/s; 5620 tgt tok/s;     24 s elapsed
Epoch 11,   200/  454; acc:  80.65; ppl:   2.35; 5390 src tok/s; 5608 tgt tok/s;     31 s elapsed
Epoch 11,   250/  454; acc:  80.83; ppl:   2.32; 5408 src tok/s; 5624 tgt tok/s;     39 s elapsed
Epoch 11,   300/  454; acc:  80.62; ppl:   2.37; 5368 src tok/s; 5563 tgt tok/s;     47 s elapsed
Epoch 11,   350/  454; acc:  80.88; ppl:   2.35; 5483 src tok/s; 5686 tgt tok/s;     55 s elapsed
Epoch 11,   400/  454; acc:  80.38; ppl:   2.39; 5458 src tok/s; 5656 tgt tok/s;     62 s elapsed
Epoch 11,   450/  454; acc:  80.21; ppl:   2.41; 5295 src tok/s; 5495 tgt tok/s;     70 s elapsed
Train perplexity: 2.36254
Train accuracy: 80.641
Validation perplexity: 6.2994
Validation accuracy: 69.0507
Decaying learning rate to 0.015625

Epoch 12,    50/  454; acc:  81.05; ppl:   2.32; 5314 src tok/s; 5537 tgt tok/s;      8 s elapsed
Epoch 12,   100/  454; acc:  80.70; ppl:   2.35; 5434 src tok/s; 5641 tgt tok/s;     16 s elapsed
Epoch 12,   150/  454; acc:  81.50; ppl:   2.26; 5319 src tok/s; 5528 tgt tok/s;     23 s elapsed
Epoch 12,   200/  454; acc:  80.68; ppl:   2.38; 5347 src tok/s; 5535 tgt tok/s;     31 s elapsed
Epoch 12,   250/  454; acc:  80.50; ppl:   2.40; 5331 src tok/s; 5526 tgt tok/s;     39 s elapsed
Epoch 12,   300/  454; acc:  81.00; ppl:   2.29; 5381 src tok/s; 5588 tgt tok/s;     47 s elapsed
Epoch 12,   350/  454; acc:  80.60; ppl:   2.36; 5523 src tok/s; 5679 tgt tok/s;     55 s elapsed
Epoch 12,   400/  454; acc:  81.00; ppl:   2.31; 5338 src tok/s; 5581 tgt tok/s;     62 s elapsed
Epoch 12,   450/  454; acc:  81.46; ppl:   2.25; 5445 src tok/s; 5654 tgt tok/s;     70 s elapsed
Train perplexity: 2.32568
Train accuracy: 80.9244
Validation perplexity: 6.3445
Validation accuracy: 68.9655
Decaying learning rate to 0.0078125

Epoch 13,    50/  454; acc:  80.29; ppl:   2.43; 5476 src tok/s; 5668 tgt tok/s;      8 s elapsed
Epoch 13,   100/  454; acc:  82.04; ppl:   2.18; 5352 src tok/s; 5561 tgt tok/s;     15 s elapsed
Epoch 13,   150/  454; acc:  81.34; ppl:   2.26; 5295 src tok/s; 5549 tgt tok/s;     23 s elapsed
Epoch 13,   200/  454; acc:  80.78; ppl:   2.37; 5364 src tok/s; 5527 tgt tok/s;     31 s elapsed
Epoch 13,   250/  454; acc:  80.74; ppl:   2.33; 5425 src tok/s; 5615 tgt tok/s;     39 s elapsed
Epoch 13,   300/  454; acc:  81.80; ppl:   2.24; 5412 src tok/s; 5637 tgt tok/s;     47 s elapsed
Epoch 13,   350/  454; acc:  80.21; ppl:   2.41; 5321 src tok/s; 5534 tgt tok/s;     55 s elapsed
Epoch 13,   400/  454; acc:  81.75; ppl:   2.20; 5378 src tok/s; 5589 tgt tok/s;     62 s elapsed
Epoch 13,   450/  454; acc:  80.76; ppl:   2.35; 5323 src tok/s; 5494 tgt tok/s;     70 s elapsed
Train perplexity: 2.30603
Train accuracy: 81.083
Validation perplexity: 6.34215
Validation accuracy: 69.0932
Decaying learning rate to 0.00390625

Epoch 14,    50/  454; acc:  80.55; ppl:   2.37; 5341 src tok/s; 5560 tgt tok/s;      8 s elapsed
Epoch 14,   100/  454; acc:  81.73; ppl:   2.20; 5514 src tok/s; 5709 tgt tok/s;     15 s elapsed
Epoch 14,   150/  454; acc:  81.48; ppl:   2.26; 5354 src tok/s; 5568 tgt tok/s;     23 s elapsed
Epoch 14,   200/  454; acc:  81.08; ppl:   2.33; 5403 src tok/s; 5573 tgt tok/s;     31 s elapsed
Epoch 14,   250/  454; acc:  81.99; ppl:   2.20; 5423 src tok/s; 5642 tgt tok/s;     39 s elapsed
Epoch 14,   300/  454; acc:  80.43; ppl:   2.41; 5194 src tok/s; 5400 tgt tok/s;     47 s elapsed
Epoch 14,   350/  454; acc:  81.83; ppl:   2.18; 5336 src tok/s; 5545 tgt tok/s;     54 s elapsed
Epoch 14,   400/  454; acc:  80.23; ppl:   2.43; 5381 src tok/s; 5538 tgt tok/s;     63 s elapsed
Epoch 14,   450/  454; acc:  81.54; ppl:   2.23; 5262 src tok/s; 5511 tgt tok/s;     70 s elapsed
Train perplexity: 2.29875
Train accuracy: 81.1262
Validation perplexity: 6.3495
Validation accuracy: 69.0507
Decaying learning rate to 0.00195312

Epoch 15,    50/  454; acc:  81.21; ppl:   2.29; 5400 src tok/s; 5560 tgt tok/s;      8 s elapsed
Epoch 15,   100/  454; acc:  81.36; ppl:   2.26; 5330 src tok/s; 5565 tgt tok/s;     16 s elapsed
Epoch 15,   150/  454; acc:  80.52; ppl:   2.39; 5384 src tok/s; 5547 tgt tok/s;     24 s elapsed
Epoch 15,   200/  454; acc:  82.07; ppl:   2.21; 5312 src tok/s; 5574 tgt tok/s;     31 s elapsed
Epoch 15,   250/  454; acc:  81.46; ppl:   2.27; 5470 src tok/s; 5677 tgt tok/s;     39 s elapsed
Epoch 15,   300/  454; acc:  81.06; ppl:   2.35; 5550 src tok/s; 5736 tgt tok/s;     46 s elapsed
Epoch 15,   350/  454; acc:  82.15; ppl:   2.17; 5353 src tok/s; 5605 tgt tok/s;     54 s elapsed
Epoch 15,   400/  454; acc:  80.15; ppl:   2.42; 5350 src tok/s; 5540 tgt tok/s;     62 s elapsed
Epoch 15,   450/  454; acc:  81.19; ppl:   2.31; 4838 src tok/s; 4999 tgt tok/s;     71 s elapsed
Train perplexity: 2.29565
Train accuracy: 81.2312
Validation perplexity: 6.35247
Validation accuracy: 69.0507
Decaying learning rate to 0.000976562

Epoch 16,    50/  454; acc:  80.98; ppl:   2.30; 5430 src tok/s; 5636 tgt tok/s;      8 s elapsed
Epoch 16,   100/  454; acc:  81.34; ppl:   2.27; 5254 src tok/s; 5450 tgt tok/s;     16 s elapsed
Epoch 16,   150/  454; acc:  82.28; ppl:   2.19; 5243 src tok/s; 5495 tgt tok/s;     23 s elapsed
Epoch 16,   200/  454; acc:  80.51; ppl:   2.37; 5435 src tok/s; 5597 tgt tok/s;     31 s elapsed
Epoch 16,   250/  454; acc:  81.30; ppl:   2.30; 5444 src tok/s; 5644 tgt tok/s;     39 s elapsed
Epoch 16,   300/  454; acc:  81.50; ppl:   2.29; 5348 src tok/s; 5572 tgt tok/s;     47 s elapsed
Epoch 16,   350/  454; acc:  80.92; ppl:   2.32; 5319 src tok/s; 5516 tgt tok/s;     55 s elapsed
Epoch 16,   400/  454; acc:  81.38; ppl:   2.28; 5321 src tok/s; 5523 tgt tok/s;     63 s elapsed
Epoch 16,   450/  454; acc:  80.97; ppl:   2.31; 5437 src tok/s; 5614 tgt tok/s;     70 s elapsed
Train perplexity: 2.29097
Train accuracy: 81.2409
Validation perplexity: 6.35651
Validation accuracy: 69.0861
Decaying learning rate to 0.000488281

Epoch 17,    50/  454; acc:  81.59; ppl:   2.26; 5357 src tok/s; 5569 tgt tok/s;      8 s elapsed
Epoch 17,   100/  454; acc:  80.79; ppl:   2.35; 5414 src tok/s; 5581 tgt tok/s;     16 s elapsed
Epoch 17,   150/  454; acc:  81.31; ppl:   2.31; 5387 src tok/s; 5584 tgt tok/s;     24 s elapsed
Epoch 17,   200/  454; acc:  81.51; ppl:   2.26; 5346 src tok/s; 5594 tgt tok/s;     31 s elapsed
Epoch 17,   250/  454; acc:  80.84; ppl:   2.37; 5287 src tok/s; 5487 tgt tok/s;     39 s elapsed
Epoch 17,   300/  454; acc:  81.61; ppl:   2.21; 5411 src tok/s; 5650 tgt tok/s;     47 s elapsed
Epoch 17,   350/  454; acc:  80.87; ppl:   2.32; 5445 src tok/s; 5620 tgt tok/s;     55 s elapsed
Epoch 17,   400/  454; acc:  81.14; ppl:   2.26; 5405 src tok/s; 5631 tgt tok/s;     62 s elapsed
Epoch 17,   450/  454; acc:  81.10; ppl:   2.29; 5350 src tok/s; 5522 tgt tok/s;     70 s elapsed
Train perplexity: 2.29255
Train accuracy: 81.1913
Validation perplexity: 6.35723
Validation accuracy: 69.0649
Decaying learning rate to 0.000244141
