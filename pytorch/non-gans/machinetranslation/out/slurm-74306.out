<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.5, kappa_enc=0.4, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/seeds/encoder0.4decoder0.5dropout0.3wdropTrueseed1', seed=1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.4)
('Using Kappa L2 loss on decoder', 0.5)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.38; ppl: 20128.72; 4670 src tok/s; 4838 tgt tok/s;      9 s elapsed
Epoch  1,   100/  454; acc:  15.77; ppl: 1264.06; 5356 src tok/s; 5579 tgt tok/s;     17 s elapsed
Epoch  1,   150/  454; acc:  18.03; ppl: 518.77; 5319 src tok/s; 5500 tgt tok/s;     25 s elapsed
Epoch  1,   200/  454; acc:  21.77; ppl: 248.87; 5359 src tok/s; 5549 tgt tok/s;     33 s elapsed
Epoch  1,   250/  454; acc:  25.68; ppl: 159.14; 5246 src tok/s; 5466 tgt tok/s;     40 s elapsed
Epoch  1,   300/  454; acc:  26.44; ppl: 126.81; 5385 src tok/s; 5563 tgt tok/s;     48 s elapsed
Epoch  1,   350/  454; acc:  29.52; ppl:  94.25; 5331 src tok/s; 5562 tgt tok/s;     56 s elapsed
Epoch  1,   400/  454; acc:  31.15; ppl:  81.72; 5331 src tok/s; 5521 tgt tok/s;     64 s elapsed
Epoch  1,   450/  454; acc:  33.62; ppl:  64.20; 5105 src tok/s; 5314 tgt tok/s;     72 s elapsed
Train perplexity: 315.954
Train accuracy: 23.4277
Validation perplexity: 63.0842
Validation accuracy: 33.6313

Epoch  2,    50/  454; acc:  35.28; ppl:  55.93; 5272 src tok/s; 5502 tgt tok/s;      8 s elapsed
Epoch  2,   100/  454; acc:  38.29; ppl:  46.22; 5282 src tok/s; 5478 tgt tok/s;     16 s elapsed
Epoch  2,   150/  454; acc:  40.46; ppl:  37.97; 5344 src tok/s; 5525 tgt tok/s;     24 s elapsed
Epoch  2,   200/  454; acc:  43.68; ppl:  31.98; 5266 src tok/s; 5473 tgt tok/s;     32 s elapsed
Epoch  2,   250/  454; acc:  47.02; ppl:  25.42; 5199 src tok/s; 5459 tgt tok/s;     39 s elapsed
Epoch  2,   300/  454; acc:  45.60; ppl:  27.62; 5463 src tok/s; 5601 tgt tok/s;     47 s elapsed
Epoch  2,   350/  454; acc:  49.20; ppl:  21.31; 5413 src tok/s; 5641 tgt tok/s;     55 s elapsed
Epoch  2,   400/  454; acc:  48.76; ppl:  22.03; 5227 src tok/s; 5415 tgt tok/s;     63 s elapsed
Epoch  2,   450/  454; acc:  50.89; ppl:  18.99; 5153 src tok/s; 5331 tgt tok/s;     71 s elapsed
Train perplexity: 29.8784
Train accuracy: 44.4034
Validation perplexity: 15.8594
Validation accuracy: 54.3068

Epoch  3,    50/  454; acc:  53.69; ppl:  15.35; 5372 src tok/s; 5562 tgt tok/s;      8 s elapsed
Epoch  3,   100/  454; acc:  54.78; ppl:  14.37; 5252 src tok/s; 5482 tgt tok/s;     16 s elapsed
Epoch  3,   150/  454; acc:  53.96; ppl:  14.77; 5412 src tok/s; 5555 tgt tok/s;     24 s elapsed
Epoch  3,   200/  454; acc:  57.60; ppl:  11.86; 5284 src tok/s; 5525 tgt tok/s;     31 s elapsed
Epoch  3,   250/  454; acc:  56.57; ppl:  12.78; 5136 src tok/s; 5373 tgt tok/s;     39 s elapsed
Epoch  3,   300/  454; acc:  56.60; ppl:  12.37; 5405 src tok/s; 5566 tgt tok/s;     47 s elapsed
Epoch  3,   350/  454; acc:  57.22; ppl:  11.67; 5433 src tok/s; 5610 tgt tok/s;     56 s elapsed
Epoch  3,   400/  454; acc:  58.71; ppl:  11.39; 5194 src tok/s; 5420 tgt tok/s;     63 s elapsed
Epoch  3,   450/  454; acc:  58.84; ppl:  10.85; 5260 src tok/s; 5461 tgt tok/s;     71 s elapsed
Train perplexity: 12.706
Train accuracy: 56.4636
Validation perplexity: 10.2814
Validation accuracy: 60.2597

Epoch  4,    50/  454; acc:  59.96; ppl:   9.46; 4596 src tok/s; 4746 tgt tok/s;      9 s elapsed
Epoch  4,   100/  454; acc:  61.86; ppl:   8.30; 5386 src tok/s; 5620 tgt tok/s;     17 s elapsed
Epoch  4,   150/  454; acc:  60.84; ppl:   8.96; 5461 src tok/s; 5643 tgt tok/s;     25 s elapsed
Epoch  4,   200/  454; acc:  62.94; ppl:   7.87; 5259 src tok/s; 5499 tgt tok/s;     33 s elapsed
Epoch  4,   250/  454; acc:  61.84; ppl:   8.44; 5178 src tok/s; 5347 tgt tok/s;     41 s elapsed
Epoch  4,   300/  454; acc:  62.88; ppl:   7.97; 5268 src tok/s; 5469 tgt tok/s;     49 s elapsed
Epoch  4,   350/  454; acc:  62.01; ppl:   8.19; 5312 src tok/s; 5516 tgt tok/s;     57 s elapsed
Epoch  4,   400/  454; acc:  62.45; ppl:   7.95; 5237 src tok/s; 5447 tgt tok/s;     65 s elapsed
Epoch  4,   450/  454; acc:  62.82; ppl:   7.82; 5350 src tok/s; 5543 tgt tok/s;     73 s elapsed
Train perplexity: 8.30788
Train accuracy: 61.9668
Validation perplexity: 8.49955
Validation accuracy: 62.9204

Epoch  5,    50/  454; acc:  66.15; ppl:   6.05; 5222 src tok/s; 5386 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  64.66; ppl:   6.66; 5252 src tok/s; 5454 tgt tok/s;     16 s elapsed
Epoch  5,   150/  454; acc:  66.51; ppl:   5.89; 5289 src tok/s; 5513 tgt tok/s;     24 s elapsed
Epoch  5,   200/  454; acc:  64.84; ppl:   6.37; 5134 src tok/s; 5313 tgt tok/s;     32 s elapsed
Epoch  5,   250/  454; acc:  64.39; ppl:   6.66; 5288 src tok/s; 5468 tgt tok/s;     40 s elapsed
Epoch  5,   300/  454; acc:  66.39; ppl:   5.89; 5169 src tok/s; 5401 tgt tok/s;     48 s elapsed
Epoch  5,   350/  454; acc:  66.30; ppl:   5.94; 5153 src tok/s; 5369 tgt tok/s;     56 s elapsed
Epoch  5,   400/  454; acc:  65.34; ppl:   6.31; 5125 src tok/s; 5303 tgt tok/s;     64 s elapsed
Epoch  5,   450/  454; acc:  64.65; ppl:   6.46; 5153 src tok/s; 5356 tgt tok/s;     72 s elapsed
Train perplexity: 6.24363
Train accuracy: 65.4713
Validation perplexity: 7.20476
Validation accuracy: 65.3541

Epoch  6,    50/  454; acc:  70.20; ppl:   4.47; 5056 src tok/s; 5317 tgt tok/s;      8 s elapsed
Epoch  6,   100/  454; acc:  66.89; ppl:   5.26; 5243 src tok/s; 5410 tgt tok/s;     16 s elapsed
Epoch  6,   150/  454; acc:  68.62; ppl:   4.86; 5142 src tok/s; 5324 tgt tok/s;     25 s elapsed
Epoch  6,   200/  454; acc:  67.94; ppl:   5.09; 5093 src tok/s; 5314 tgt tok/s;     33 s elapsed
Epoch  6,   250/  454; acc:  68.19; ppl:   4.96; 5184 src tok/s; 5377 tgt tok/s;     41 s elapsed
Epoch  6,   300/  454; acc:  67.53; ppl:   5.21; 5290 src tok/s; 5456 tgt tok/s;     49 s elapsed
Epoch  6,   350/  454; acc:  67.65; ppl:   5.16; 5200 src tok/s; 5400 tgt tok/s;     57 s elapsed
Epoch  6,   400/  454; acc:  67.75; ppl:   5.06; 5269 src tok/s; 5449 tgt tok/s;     65 s elapsed
Epoch  6,   450/  454; acc:  67.83; ppl:   5.17; 5201 src tok/s; 5409 tgt tok/s;     73 s elapsed
Train perplexity: 5.03078
Train accuracy: 68.0358
Validation perplexity: 6.81539
Validation accuracy: 66.3403

Epoch  7,    50/  454; acc:  72.03; ppl:   3.78; 5248 src tok/s; 5450 tgt tok/s;      8 s elapsed
Epoch  7,   100/  454; acc:  70.39; ppl:   4.21; 5183 src tok/s; 5383 tgt tok/s;     16 s elapsed
Epoch  7,   150/  454; acc:  70.69; ppl:   4.11; 5263 src tok/s; 5457 tgt tok/s;     24 s elapsed
Epoch  7,   200/  454; acc:  69.91; ppl:   4.31; 5204 src tok/s; 5421 tgt tok/s;     32 s elapsed
Epoch  7,   250/  454; acc:  70.10; ppl:   4.30; 5137 src tok/s; 5330 tgt tok/s;     40 s elapsed
Epoch  7,   300/  454; acc:  70.33; ppl:   4.17; 5234 src tok/s; 5447 tgt tok/s;     48 s elapsed
Epoch  7,   350/  454; acc:  71.18; ppl:   3.98; 5130 src tok/s; 5359 tgt tok/s;     56 s elapsed
Epoch  7,   400/  454; acc:  68.43; ppl:   4.70; 5207 src tok/s; 5355 tgt tok/s;     65 s elapsed
Epoch  7,   450/  454; acc:  69.50; ppl:   4.36; 5131 src tok/s; 5309 tgt tok/s;     73 s elapsed
Train perplexity: 4.21145
Train accuracy: 70.2601
Validation perplexity: 6.48103
Validation accuracy: 67.3194

Epoch  8,    50/  454; acc:  72.96; ppl:   3.49; 5136 src tok/s; 5324 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  73.37; ppl:   3.37; 5244 src tok/s; 5469 tgt tok/s;     16 s elapsed
Epoch  8,   150/  454; acc:  72.12; ppl:   3.64; 5281 src tok/s; 5470 tgt tok/s;     24 s elapsed
Epoch  8,   200/  454; acc:  72.71; ppl:   3.54; 5203 src tok/s; 5402 tgt tok/s;     32 s elapsed
Epoch  8,   250/  454; acc:  72.43; ppl:   3.60; 5179 src tok/s; 5387 tgt tok/s;     40 s elapsed
Epoch  8,   300/  454; acc:  71.54; ppl:   3.79; 5117 src tok/s; 5312 tgt tok/s;     48 s elapsed
Epoch  8,   350/  454; acc:  71.50; ppl:   3.75; 5145 src tok/s; 5343 tgt tok/s;     57 s elapsed
Epoch  8,   400/  454; acc:  71.87; ppl:   3.71; 5347 src tok/s; 5525 tgt tok/s;     64 s elapsed
Epoch  8,   450/  454; acc:  71.89; ppl:   3.64; 5189 src tok/s; 5392 tgt tok/s;     72 s elapsed
Train perplexity: 3.63296
Train accuracy: 72.1672
Validation perplexity: 6.71159
Validation accuracy: 66.9789
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.16; ppl:   2.69; 5251 src tok/s; 5473 tgt tok/s;      8 s elapsed
Epoch  9,   100/  454; acc:  77.00; ppl:   2.77; 5246 src tok/s; 5412 tgt tok/s;     16 s elapsed
Epoch  9,   150/  454; acc:  77.69; ppl:   2.65; 5306 src tok/s; 5501 tgt tok/s;     24 s elapsed
Epoch  9,   200/  454; acc:  76.78; ppl:   2.78; 5305 src tok/s; 5545 tgt tok/s;     32 s elapsed
Epoch  9,   250/  454; acc:  78.04; ppl:   2.58; 5248 src tok/s; 5437 tgt tok/s;     40 s elapsed
Epoch  9,   300/  454; acc:  76.95; ppl:   2.77; 5251 src tok/s; 5433 tgt tok/s;     48 s elapsed
Epoch  9,   350/  454; acc:  76.70; ppl:   2.75; 5341 src tok/s; 5539 tgt tok/s;     56 s elapsed
Epoch  9,   400/  454; acc:  76.85; ppl:   2.78; 5351 src tok/s; 5548 tgt tok/s;     63 s elapsed
Epoch  9,   450/  454; acc:  77.18; ppl:   2.76; 5175 src tok/s; 5382 tgt tok/s;     71 s elapsed
Train perplexity: 2.72076
Train accuracy: 77.1701
Validation perplexity: 6.16247
Validation accuracy: 69.0578
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.47; ppl:   2.19; 5258 src tok/s; 5468 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  80.78; ppl:   2.27; 5118 src tok/s; 5322 tgt tok/s;     16 s elapsed
Epoch 10,   150/  454; acc:  82.29; ppl:   2.09; 5212 src tok/s; 5451 tgt tok/s;     24 s elapsed
Epoch 10,   200/  454; acc:  80.15; ppl:   2.34; 5375 src tok/s; 5555 tgt tok/s;     32 s elapsed
Epoch 10,   250/  454; acc:  81.19; ppl:   2.19; 5312 src tok/s; 5511 tgt tok/s;     40 s elapsed
Epoch 10,   300/  454; acc:  80.33; ppl:   2.31; 5302 src tok/s; 5492 tgt tok/s;     48 s elapsed
Epoch 10,   350/  454; acc:  80.44; ppl:   2.27; 5391 src tok/s; 5601 tgt tok/s;     56 s elapsed
Epoch 10,   400/  454; acc:  80.44; ppl:   2.31; 5381 src tok/s; 5568 tgt tok/s;     63 s elapsed
Epoch 10,   450/  454; acc:  80.93; ppl:   2.23; 5267 src tok/s; 5454 tgt tok/s;     71 s elapsed
Train perplexity: 2.24085
Train accuracy: 80.8973
Validation perplexity: 6.14673
Validation accuracy: 69.5189
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  84.40; ppl:   1.89; 5236 src tok/s; 5446 tgt tok/s;      8 s elapsed
Epoch 11,   100/  454; acc:  82.31; ppl:   2.14; 5267 src tok/s; 5430 tgt tok/s;     16 s elapsed
Epoch 11,   150/  454; acc:  82.79; ppl:   2.06; 5321 src tok/s; 5528 tgt tok/s;     24 s elapsed
Epoch 11,   200/  454; acc:  83.39; ppl:   1.99; 5391 src tok/s; 5612 tgt tok/s;     32 s elapsed
Epoch 11,   250/  454; acc:  82.78; ppl:   2.07; 5213 src tok/s; 5420 tgt tok/s;     40 s elapsed
Epoch 11,   300/  454; acc:  83.79; ppl:   1.97; 5385 src tok/s; 5576 tgt tok/s;     48 s elapsed
Epoch 11,   350/  454; acc:  82.43; ppl:   2.09; 5291 src tok/s; 5472 tgt tok/s;     56 s elapsed
Epoch 11,   400/  454; acc:  83.95; ppl:   1.92; 5256 src tok/s; 5489 tgt tok/s;     63 s elapsed
Epoch 11,   450/  454; acc:  82.62; ppl:   2.05; 5202 src tok/s; 5393 tgt tok/s;     71 s elapsed
Train perplexity: 2.01996
Train accuracy: 83.1527
Validation perplexity: 6.27212
Validation accuracy: 69.6041
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.70; ppl:   1.88; 5250 src tok/s; 5466 tgt tok/s;      8 s elapsed
Epoch 12,   100/  454; acc:  84.66; ppl:   1.92; 5308 src tok/s; 5515 tgt tok/s;     16 s elapsed
Epoch 12,   150/  454; acc:  83.82; ppl:   1.95; 5266 src tok/s; 5481 tgt tok/s;     24 s elapsed
Epoch 12,   200/  454; acc:  84.97; ppl:   1.86; 5359 src tok/s; 5553 tgt tok/s;     32 s elapsed
Epoch 12,   250/  454; acc:  84.30; ppl:   1.93; 5337 src tok/s; 5517 tgt tok/s;     39 s elapsed
Epoch 12,   300/  454; acc:  84.13; ppl:   1.92; 5294 src tok/s; 5477 tgt tok/s;     47 s elapsed
Epoch 12,   350/  454; acc:  83.48; ppl:   1.99; 5244 src tok/s; 5430 tgt tok/s;     56 s elapsed
Epoch 12,   400/  454; acc:  84.09; ppl:   1.92; 5296 src tok/s; 5520 tgt tok/s;     63 s elapsed
Epoch 12,   450/  454; acc:  83.97; ppl:   1.93; 5256 src tok/s; 5455 tgt tok/s;     71 s elapsed
Train perplexity: 1.92006
Train accuracy: 84.2404
Validation perplexity: 6.40674
Validation accuracy: 69.6963
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.41; ppl:   1.91; 5224 src tok/s; 5452 tgt tok/s;      8 s elapsed
Epoch 13,   100/  454; acc:  85.27; ppl:   1.82; 5342 src tok/s; 5523 tgt tok/s;     16 s elapsed
Epoch 13,   150/  454; acc:  85.32; ppl:   1.80; 5204 src tok/s; 5449 tgt tok/s;     24 s elapsed
Epoch 13,   200/  454; acc:  84.14; ppl:   1.94; 5339 src tok/s; 5499 tgt tok/s;     32 s elapsed
Epoch 13,   250/  454; acc:  84.42; ppl:   1.92; 5307 src tok/s; 5526 tgt tok/s;     40 s elapsed
Epoch 13,   300/  454; acc:  85.42; ppl:   1.83; 5352 src tok/s; 5561 tgt tok/s;     48 s elapsed
Epoch 13,   350/  454; acc:  84.42; ppl:   1.91; 5312 src tok/s; 5455 tgt tok/s;     56 s elapsed
Epoch 13,   400/  454; acc:  85.28; ppl:   1.83; 5261 src tok/s; 5486 tgt tok/s;     63 s elapsed
Epoch 13,   450/  454; acc:  84.66; ppl:   1.87; 5190 src tok/s; 5371 tgt tok/s;     71 s elapsed
Train perplexity: 1.87065
Train accuracy: 84.8329
Validation perplexity: 6.45426
Validation accuracy: 69.5828
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.96; ppl:   1.77; 5304 src tok/s; 5546 tgt tok/s;      8 s elapsed
Epoch 14,   100/  454; acc:  84.17; ppl:   1.93; 5421 src tok/s; 5613 tgt tok/s;     16 s elapsed
Epoch 14,   150/  454; acc:  85.54; ppl:   1.82; 5299 src tok/s; 5527 tgt tok/s;     23 s elapsed
Epoch 14,   200/  454; acc:  84.68; ppl:   1.88; 5308 src tok/s; 5468 tgt tok/s;     32 s elapsed
Epoch 14,   250/  454; acc:  86.63; ppl:   1.71; 5320 src tok/s; 5531 tgt tok/s;     39 s elapsed
Epoch 14,   300/  454; acc:  83.94; ppl:   1.95; 5352 src tok/s; 5524 tgt tok/s;     47 s elapsed
Epoch 14,   350/  454; acc:  84.97; ppl:   1.85; 5252 src tok/s; 5471 tgt tok/s;     55 s elapsed
Epoch 14,   400/  454; acc:  85.11; ppl:   1.84; 5265 src tok/s; 5451 tgt tok/s;     63 s elapsed
Epoch 14,   450/  454; acc:  84.94; ppl:   1.87; 5119 src tok/s; 5325 tgt tok/s;     71 s elapsed
Train perplexity: 1.8476
Train accuracy: 85.0733
Validation perplexity: 6.50096
Validation accuracy: 69.5048
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.58; ppl:   1.82; 5322 src tok/s; 5514 tgt tok/s;      8 s elapsed
Epoch 15,   100/  454; acc:  85.33; ppl:   1.82; 5478 src tok/s; 5671 tgt tok/s;     16 s elapsed
Epoch 15,   150/  454; acc:  84.73; ppl:   1.89; 5349 src tok/s; 5523 tgt tok/s;     24 s elapsed
Epoch 15,   200/  454; acc:  85.69; ppl:   1.80; 5277 src tok/s; 5487 tgt tok/s;     31 s elapsed
Epoch 15,   250/  454; acc:  84.77; ppl:   1.88; 5363 src tok/s; 5544 tgt tok/s;     39 s elapsed
Epoch 15,   300/  454; acc:  85.77; ppl:   1.80; 5218 src tok/s; 5446 tgt tok/s;     47 s elapsed
Epoch 15,   350/  454; acc:  84.32; ppl:   1.91; 5364 src tok/s; 5554 tgt tok/s;     55 s elapsed
Epoch 15,   400/  454; acc:  86.01; ppl:   1.75; 5183 src tok/s; 5437 tgt tok/s;     63 s elapsed
Epoch 15,   450/  454; acc:  85.19; ppl:   1.84; 5106 src tok/s; 5281 tgt tok/s;     71 s elapsed
Train perplexity: 1.83463
Train accuracy: 85.2541
Validation perplexity: 6.51565
Validation accuracy: 69.5473
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  84.50; ppl:   1.90; 5208 src tok/s; 5374 tgt tok/s;      8 s elapsed
Epoch 16,   100/  454; acc:  86.02; ppl:   1.77; 5319 src tok/s; 5531 tgt tok/s;     16 s elapsed
Epoch 16,   150/  454; acc:  85.36; ppl:   1.83; 4936 src tok/s; 5118 tgt tok/s;     25 s elapsed
Epoch 16,   200/  454; acc:  85.49; ppl:   1.81; 5437 src tok/s; 5652 tgt tok/s;     32 s elapsed
Epoch 16,   250/  454; acc:  85.93; ppl:   1.78; 5462 src tok/s; 5708 tgt tok/s;     40 s elapsed
Epoch 16,   300/  454; acc:  85.23; ppl:   1.87; 5546 src tok/s; 5747 tgt tok/s;     47 s elapsed
Epoch 16,   350/  454; acc:  85.29; ppl:   1.84; 5055 src tok/s; 5257 tgt tok/s;     56 s elapsed
Epoch 16,   400/  454; acc:  85.36; ppl:   1.83; 5236 src tok/s; 5419 tgt tok/s;     64 s elapsed
Epoch 16,   450/  454; acc:  85.71; ppl:   1.81; 4955 src tok/s; 5151 tgt tok/s;     72 s elapsed
Train perplexity: 1.83138
Train accuracy: 85.3869
Validation perplexity: 6.51841
Validation accuracy: 69.5189
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.66; ppl:   1.81; 4949 src tok/s; 5126 tgt tok/s;      8 s elapsed
Epoch 17,   100/  454; acc:  85.11; ppl:   1.86; 5149 src tok/s; 5325 tgt tok/s;     17 s elapsed
Epoch 17,   150/  454; acc:  84.78; ppl:   1.88; 5189 src tok/s; 5368 tgt tok/s;     25 s elapsed
Epoch 17,   200/  454; acc:  86.03; ppl:   1.77; 5174 src tok/s; 5406 tgt tok/s;     33 s elapsed
Epoch 17,   250/  454; acc:  85.02; ppl:   1.84; 5184 src tok/s; 5397 tgt tok/s;     41 s elapsed
Epoch 17,   300/  454; acc:  85.85; ppl:   1.79; 5239 src tok/s; 5438 tgt tok/s;     49 s elapsed
Epoch 17,   350/  454; acc:  84.97; ppl:   1.86; 5136 src tok/s; 5324 tgt tok/s;     57 s elapsed
Epoch 17,   400/  454; acc:  85.55; ppl:   1.81; 5277 src tok/s; 5471 tgt tok/s;     65 s elapsed
Epoch 17,   450/  454; acc:  85.27; ppl:   1.84; 5208 src tok/s; 5398 tgt tok/s;     73 s elapsed
Train perplexity: 1.82653
Train accuracy: 85.3769
Validation perplexity: 6.52106
Validation accuracy: 69.5402
Decaying learning rate to 0.000976562
