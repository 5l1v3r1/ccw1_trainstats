<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.3, kappa_enc=0.2, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.20decoder0.30dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.2)
('Using Kappa L2 loss on decoder', 0.3)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:  10.81; ppl: 6401.48; 2679 src tok/s; 2775 tgt tok/s;     16 s elapsed
Epoch  1,   100/  454; acc:  15.54; ppl: 1173.41; 2806 src tok/s; 2914 tgt tok/s;     31 s elapsed
Epoch  1,   150/  454; acc:  18.85; ppl: 438.01; 2779 src tok/s; 2875 tgt tok/s;     46 s elapsed
Epoch  1,   200/  454; acc:  21.75; ppl: 241.83; 2830 src tok/s; 2941 tgt tok/s;     61 s elapsed
Epoch  1,   250/  454; acc:  24.29; ppl: 164.32; 2721 src tok/s; 2830 tgt tok/s;     76 s elapsed
Epoch  1,   300/  454; acc:  26.74; ppl: 122.53; 2800 src tok/s; 2899 tgt tok/s;     91 s elapsed
Epoch  1,   350/  454; acc:  29.94; ppl:  92.20; 2890 src tok/s; 2985 tgt tok/s;    106 s elapsed
Epoch  1,   400/  454; acc:  32.83; ppl:  72.50; 2797 src tok/s; 2918 tgt tok/s;    121 s elapsed
Epoch  1,   450/  454; acc:  33.48; ppl:  64.59; 2721 src tok/s; 2830 tgt tok/s;    136 s elapsed
Train perplexity: 265.058
Train accuracy: 23.8852
Validation perplexity: 60.6694
Validation accuracy: 35.1923

Epoch  2,    50/  454; acc:  37.00; ppl:  49.96; 2763 src tok/s; 2885 tgt tok/s;     15 s elapsed
Epoch  2,   100/  454; acc:  38.40; ppl:  46.79; 2811 src tok/s; 2894 tgt tok/s;     30 s elapsed
Epoch  2,   150/  454; acc:  41.51; ppl:  37.59; 2716 src tok/s; 2814 tgt tok/s;     45 s elapsed
Epoch  2,   200/  454; acc:  44.02; ppl:  31.41; 2823 src tok/s; 2920 tgt tok/s;     60 s elapsed
Epoch  2,   250/  454; acc:  47.19; ppl:  25.20; 2812 src tok/s; 2959 tgt tok/s;     74 s elapsed
Epoch  2,   300/  454; acc:  45.94; ppl:  27.54; 2775 src tok/s; 2870 tgt tok/s;     91 s elapsed
Epoch  2,   350/  454; acc:  49.67; ppl:  21.09; 2803 src tok/s; 2911 tgt tok/s;    106 s elapsed
Epoch  2,   400/  454; acc:  51.20; ppl:  19.10; 2806 src tok/s; 2917 tgt tok/s;    120 s elapsed
Epoch  2,   450/  454; acc:  51.53; ppl:  18.97; 2779 src tok/s; 2865 tgt tok/s;    135 s elapsed
Train perplexity: 28.9029
Train accuracy: 45.2351
Validation perplexity: 15.3762
Validation accuracy: 53.2709

Epoch  3,    50/  454; acc:  53.88; ppl:  15.16; 2800 src tok/s; 2902 tgt tok/s;     15 s elapsed
Epoch  3,   100/  454; acc:  55.88; ppl:  13.50; 2810 src tok/s; 2940 tgt tok/s;     30 s elapsed
Epoch  3,   150/  454; acc:  56.62; ppl:  12.57; 2787 src tok/s; 2898 tgt tok/s;     45 s elapsed
Epoch  3,   200/  454; acc:  55.90; ppl:  13.46; 2823 src tok/s; 2926 tgt tok/s;     60 s elapsed
Epoch  3,   250/  454; acc:  58.64; ppl:  11.22; 2730 src tok/s; 2858 tgt tok/s;     74 s elapsed
Epoch  3,   300/  454; acc:  56.79; ppl:  12.47; 2775 src tok/s; 2855 tgt tok/s;     90 s elapsed
Epoch  3,   350/  454; acc:  57.71; ppl:  11.83; 2790 src tok/s; 2892 tgt tok/s;    106 s elapsed
Epoch  3,   400/  454; acc:  59.61; ppl:  10.69; 2725 src tok/s; 2833 tgt tok/s;    121 s elapsed
Epoch  3,   450/  454; acc:  59.12; ppl:  10.54; 2821 src tok/s; 2905 tgt tok/s;    135 s elapsed
Train perplexity: 12.3086
Train accuracy: 57.1137
Validation perplexity: 9.84393
Validation accuracy: 61.0756

Epoch  4,    50/  454; acc:  61.52; ppl:   8.40; 2745 src tok/s; 2854 tgt tok/s;     15 s elapsed
Epoch  4,   100/  454; acc:  61.42; ppl:   8.59; 2706 src tok/s; 2805 tgt tok/s;     31 s elapsed
Epoch  4,   150/  454; acc:  62.74; ppl:   8.11; 2704 src tok/s; 2820 tgt tok/s;     45 s elapsed
Epoch  4,   200/  454; acc:  61.01; ppl:   8.78; 2803 src tok/s; 2892 tgt tok/s;     61 s elapsed
Epoch  4,   250/  454; acc:  64.00; ppl:   7.38; 2734 src tok/s; 2857 tgt tok/s;     76 s elapsed
Epoch  4,   300/  454; acc:  61.06; ppl:   8.71; 2782 src tok/s; 2863 tgt tok/s;     92 s elapsed
Epoch  4,   350/  454; acc:  63.06; ppl:   7.71; 2818 src tok/s; 2936 tgt tok/s;    106 s elapsed
Epoch  4,   400/  454; acc:  63.23; ppl:   7.77; 2735 src tok/s; 2836 tgt tok/s;    122 s elapsed
Epoch  4,   450/  454; acc:  62.57; ppl:   7.76; 2761 src tok/s; 2863 tgt tok/s;    137 s elapsed
Train perplexity: 8.12104
Train accuracy: 62.2833
Validation perplexity: 8.03996
Validation accuracy: 63.7576

Epoch  5,    50/  454; acc:  65.99; ppl:   5.97; 2745 src tok/s; 2854 tgt tok/s;     15 s elapsed
Epoch  5,   100/  454; acc:  64.94; ppl:   6.39; 2739 src tok/s; 2845 tgt tok/s;     31 s elapsed
Epoch  5,   150/  454; acc:  65.44; ppl:   6.23; 2746 src tok/s; 2856 tgt tok/s;     46 s elapsed
Epoch  5,   200/  454; acc:  66.13; ppl:   5.94; 2809 src tok/s; 2918 tgt tok/s;     61 s elapsed
Epoch  5,   250/  454; acc:  64.65; ppl:   6.53; 2805 src tok/s; 2881 tgt tok/s;     77 s elapsed
Epoch  5,   300/  454; acc:  67.22; ppl:   5.67; 2732 src tok/s; 2868 tgt tok/s;     91 s elapsed
Epoch  5,   350/  454; acc:  65.27; ppl:   6.28; 2756 src tok/s; 2844 tgt tok/s;    107 s elapsed
Epoch  5,   400/  454; acc:  65.98; ppl:   6.15; 2683 src tok/s; 2797 tgt tok/s;    122 s elapsed
Epoch  5,   450/  454; acc:  66.75; ppl:   5.86; 2664 src tok/s; 2771 tgt tok/s;    137 s elapsed
Train perplexity: 6.1377
Train accuracy: 65.7261
Validation perplexity: 7.4039
Validation accuracy: 64.7297

Epoch  6,    50/  454; acc:  69.30; ppl:   4.70; 2705 src tok/s; 2833 tgt tok/s;     15 s elapsed
Epoch  6,   100/  454; acc:  68.33; ppl:   4.92; 2820 src tok/s; 2915 tgt tok/s;     30 s elapsed
Epoch  6,   150/  454; acc:  68.34; ppl:   4.93; 2719 src tok/s; 2816 tgt tok/s;     46 s elapsed
Epoch  6,   200/  454; acc:  67.96; ppl:   5.15; 2713 src tok/s; 2813 tgt tok/s;     61 s elapsed
Epoch  6,   250/  454; acc:  67.42; ppl:   5.19; 2789 src tok/s; 2888 tgt tok/s;     77 s elapsed
Epoch  6,   300/  454; acc:  68.30; ppl:   4.93; 2817 src tok/s; 2915 tgt tok/s;     91 s elapsed
Epoch  6,   350/  454; acc:  67.85; ppl:   5.05; 2722 src tok/s; 2823 tgt tok/s;    107 s elapsed
Epoch  6,   400/  454; acc:  68.80; ppl:   4.88; 2787 src tok/s; 2902 tgt tok/s;    122 s elapsed
Epoch  6,   450/  454; acc:  68.55; ppl:   4.84; 2742 src tok/s; 2849 tgt tok/s;    137 s elapsed
Train perplexity: 4.94897
Train accuracy: 68.3227
Validation perplexity: 6.86235
Validation accuracy: 65.8649

Epoch  7,    50/  454; acc:  70.83; ppl:   4.06; 2703 src tok/s; 2808 tgt tok/s;     16 s elapsed
Epoch  7,   100/  454; acc:  71.05; ppl:   4.00; 2758 src tok/s; 2869 tgt tok/s;     31 s elapsed
Epoch  7,   150/  454; acc:  70.75; ppl:   4.07; 2795 src tok/s; 2901 tgt tok/s;     46 s elapsed
Epoch  7,   200/  454; acc:  70.43; ppl:   4.10; 2792 src tok/s; 2894 tgt tok/s;     61 s elapsed
Epoch  7,   250/  454; acc:  71.69; ppl:   3.86; 2789 src tok/s; 2925 tgt tok/s;     75 s elapsed
Epoch  7,   300/  454; acc:  68.81; ppl:   4.64; 2856 src tok/s; 2937 tgt tok/s;     91 s elapsed
Epoch  7,   350/  454; acc:  69.64; ppl:   4.39; 2705 src tok/s; 2803 tgt tok/s;    106 s elapsed
Epoch  7,   400/  454; acc:  70.42; ppl:   4.20; 2742 src tok/s; 2837 tgt tok/s;    121 s elapsed
Epoch  7,   450/  454; acc:  70.32; ppl:   4.19; 2742 src tok/s; 2854 tgt tok/s;    136 s elapsed
Train perplexity: 4.17202
Train accuracy: 70.4003
Validation perplexity: 6.90384
Validation accuracy: 66.021
Decaying learning rate to 0.5

Epoch  8,    50/  454; acc:  76.39; ppl:   2.90; 2756 src tok/s; 2876 tgt tok/s;     14 s elapsed
Epoch  8,   100/  454; acc:  74.43; ppl:   3.26; 2832 src tok/s; 2907 tgt tok/s;     30 s elapsed
Epoch  8,   150/  454; acc:  75.16; ppl:   3.12; 2796 src tok/s; 2893 tgt tok/s;     45 s elapsed
Epoch  8,   200/  454; acc:  75.85; ppl:   2.98; 2817 src tok/s; 2937 tgt tok/s;     60 s elapsed
Epoch  8,   250/  454; acc:  75.66; ppl:   3.06; 2802 src tok/s; 2919 tgt tok/s;     75 s elapsed
Epoch  8,   300/  454; acc:  75.54; ppl:   3.02; 2774 src tok/s; 2886 tgt tok/s;     90 s elapsed
Epoch  8,   350/  454; acc:  75.78; ppl:   3.00; 2715 src tok/s; 2816 tgt tok/s;    105 s elapsed
Epoch  8,   400/  454; acc:  75.54; ppl:   3.01; 2793 src tok/s; 2893 tgt tok/s;    120 s elapsed
Epoch  8,   450/  454; acc:  75.46; ppl:   3.08; 2765 src tok/s; 2867 tgt tok/s;    135 s elapsed
Train perplexity: 3.04968
Train accuracy: 75.5129
Validation perplexity: 5.94748
Validation accuracy: 69.1997
Decaying learning rate to 0.25

Epoch  9,    50/  454; acc:  78.55; ppl:   2.61; 2785 src tok/s; 2871 tgt tok/s;     15 s elapsed
Epoch  9,   100/  454; acc:  79.89; ppl:   2.41; 2791 src tok/s; 2901 tgt tok/s;     30 s elapsed
Epoch  9,   150/  454; acc:  79.77; ppl:   2.42; 2780 src tok/s; 2898 tgt tok/s;     45 s elapsed
Epoch  9,   200/  454; acc:  79.20; ppl:   2.51; 2811 src tok/s; 2895 tgt tok/s;     60 s elapsed
Epoch  9,   250/  454; acc:  79.06; ppl:   2.50; 2716 src tok/s; 2848 tgt tok/s;     75 s elapsed
Epoch  9,   300/  454; acc:  79.20; ppl:   2.48; 2924 src tok/s; 3029 tgt tok/s;     90 s elapsed
Epoch  9,   350/  454; acc:  79.44; ppl:   2.44; 2807 src tok/s; 2925 tgt tok/s;    104 s elapsed
Epoch  9,   400/  454; acc:  78.38; ppl:   2.54; 2727 src tok/s; 2813 tgt tok/s;    120 s elapsed
Epoch  9,   450/  454; acc:  78.89; ppl:   2.52; 2700 src tok/s; 2806 tgt tok/s;    136 s elapsed
Train perplexity: 2.48821
Train accuracy: 79.1628
Validation perplexity: 6.04924
Validation accuracy: 69.1429
Decaying learning rate to 0.125

Epoch 10,    50/  454; acc:  81.49; ppl:   2.23; 2830 src tok/s; 2935 tgt tok/s;     15 s elapsed
Epoch 10,   100/  454; acc:  81.35; ppl:   2.20; 2806 src tok/s; 2918 tgt tok/s;     30 s elapsed
Epoch 10,   150/  454; acc:  81.32; ppl:   2.22; 2832 src tok/s; 2942 tgt tok/s;     45 s elapsed
Epoch 10,   200/  454; acc:  81.16; ppl:   2.25; 2788 src tok/s; 2895 tgt tok/s;     60 s elapsed
Epoch 10,   250/  454; acc:  81.68; ppl:   2.20; 2769 src tok/s; 2881 tgt tok/s;     74 s elapsed
Epoch 10,   300/  454; acc:  80.29; ppl:   2.34; 2800 src tok/s; 2883 tgt tok/s;     90 s elapsed
Epoch 10,   350/  454; acc:  81.02; ppl:   2.25; 2836 src tok/s; 2913 tgt tok/s;    105 s elapsed
Epoch 10,   400/  454; acc:  81.60; ppl:   2.18; 2790 src tok/s; 2933 tgt tok/s;    120 s elapsed
Epoch 10,   450/  454; acc:  81.53; ppl:   2.21; 2788 src tok/s; 2892 tgt tok/s;    134 s elapsed
Train perplexity: 2.23162
Train accuracy: 81.2701
Validation perplexity: 6.14734
Validation accuracy: 69.1287
Decaying learning rate to 0.0625

Epoch 11,    50/  454; acc:  82.50; ppl:   2.12; 2734 src tok/s; 2833 tgt tok/s;     16 s elapsed
Epoch 11,   100/  454; acc:  82.60; ppl:   2.08; 2781 src tok/s; 2895 tgt tok/s;     30 s elapsed
Epoch 11,   150/  454; acc:  81.21; ppl:   2.25; 2820 src tok/s; 2901 tgt tok/s;     46 s elapsed
Epoch 11,   200/  454; acc:  83.61; ppl:   1.97; 2820 src tok/s; 2943 tgt tok/s;     60 s elapsed
Epoch 11,   250/  454; acc:  83.60; ppl:   2.00; 2758 src tok/s; 2884 tgt tok/s;     75 s elapsed
Epoch 11,   300/  454; acc:  81.84; ppl:   2.19; 2813 src tok/s; 2908 tgt tok/s;     90 s elapsed
Epoch 11,   350/  454; acc:  81.85; ppl:   2.16; 2832 src tok/s; 2925 tgt tok/s;    105 s elapsed
Epoch 11,   400/  454; acc:  82.66; ppl:   2.08; 2779 src tok/s; 2900 tgt tok/s;    120 s elapsed
Epoch 11,   450/  454; acc:  82.22; ppl:   2.13; 2802 src tok/s; 2907 tgt tok/s;    135 s elapsed
Train perplexity: 2.10939
Train accuracy: 82.4431
Validation perplexity: 6.20907
Validation accuracy: 69.6325
Decaying learning rate to 0.03125

Epoch 12,    50/  454; acc:  82.90; ppl:   2.08; 2878 src tok/s; 2969 tgt tok/s;     15 s elapsed
Epoch 12,   100/  454; acc:  84.14; ppl:   1.95; 2760 src tok/s; 2887 tgt tok/s;     30 s elapsed
Epoch 12,   150/  454; acc:  83.69; ppl:   1.97; 2769 src tok/s; 2899 tgt tok/s;     44 s elapsed
Epoch 12,   200/  454; acc:  81.92; ppl:   2.15; 2872 src tok/s; 2963 tgt tok/s;     59 s elapsed
Epoch 12,   250/  454; acc:  82.89; ppl:   2.08; 2803 src tok/s; 2910 tgt tok/s;     75 s elapsed
Epoch 12,   300/  454; acc:  83.33; ppl:   2.02; 2773 src tok/s; 2882 tgt tok/s;     90 s elapsed
Epoch 12,   350/  454; acc:  82.33; ppl:   2.13; 2830 src tok/s; 2921 tgt tok/s;    105 s elapsed
Epoch 12,   400/  454; acc:  83.12; ppl:   2.03; 2806 src tok/s; 2916 tgt tok/s;    119 s elapsed
Epoch 12,   450/  454; acc:  82.98; ppl:   2.05; 2674 src tok/s; 2777 tgt tok/s;    135 s elapsed
Train perplexity: 2.05124
Train accuracy: 83.028
Validation perplexity: 6.26806
Validation accuracy: 69.4054
Decaying learning rate to 0.015625

Epoch 13,    50/  454; acc:  83.87; ppl:   1.99; 2806 src tok/s; 2920 tgt tok/s;     15 s elapsed
Epoch 13,   100/  454; acc:  82.98; ppl:   2.05; 2717 src tok/s; 2827 tgt tok/s;     30 s elapsed
Epoch 13,   150/  454; acc:  82.36; ppl:   2.12; 2782 src tok/s; 2867 tgt tok/s;     46 s elapsed
Epoch 13,   200/  454; acc:  84.36; ppl:   1.93; 2824 src tok/s; 2942 tgt tok/s;     60 s elapsed
Epoch 13,   250/  454; acc:  83.19; ppl:   2.05; 2805 src tok/s; 2909 tgt tok/s;     75 s elapsed
Epoch 13,   300/  454; acc:  83.58; ppl:   2.00; 2888 src tok/s; 3007 tgt tok/s;     90 s elapsed
Epoch 13,   350/  454; acc:  83.55; ppl:   2.00; 2799 src tok/s; 2898 tgt tok/s;    105 s elapsed
Epoch 13,   400/  454; acc:  83.18; ppl:   2.04; 2812 src tok/s; 2908 tgt tok/s;    120 s elapsed
Epoch 13,   450/  454; acc:  83.22; ppl:   2.04; 2724 src tok/s; 2830 tgt tok/s;    135 s elapsed
Train perplexity: 2.02157
Train accuracy: 83.3721
Validation perplexity: 6.29189
Validation accuracy: 69.3699
Decaying learning rate to 0.0078125

Epoch 14,    50/  454; acc:  83.20; ppl:   2.06; 2854 src tok/s; 2952 tgt tok/s;     15 s elapsed
Epoch 14,   100/  454; acc:  83.60; ppl:   1.97; 2726 src tok/s; 2823 tgt tok/s;     30 s elapsed
Epoch 14,   150/  454; acc:  83.63; ppl:   1.99; 2833 src tok/s; 2933 tgt tok/s;     45 s elapsed
Epoch 14,   200/  454; acc:  83.49; ppl:   2.01; 2796 src tok/s; 2922 tgt tok/s;     60 s elapsed
Epoch 14,   250/  454; acc:  82.89; ppl:   2.07; 2903 src tok/s; 2979 tgt tok/s;     75 s elapsed
Epoch 14,   300/  454; acc:  84.59; ppl:   1.90; 2857 src tok/s; 2990 tgt tok/s;     89 s elapsed
Epoch 14,   350/  454; acc:  83.25; ppl:   2.03; 3027 src tok/s; 3146 tgt tok/s;    103 s elapsed
Epoch 14,   400/  454; acc:  83.44; ppl:   2.00; 2973 src tok/s; 3088 tgt tok/s;    117 s elapsed
Epoch 14,   450/  454; acc:  83.07; ppl:   2.03; 2970 src tok/s; 3091 tgt tok/s;    131 s elapsed
Train perplexity: 2.00461
Train accuracy: 83.4715
Validation perplexity: 6.31674
Validation accuracy: 69.3487
Decaying learning rate to 0.00390625

Epoch 15,    50/  454; acc:  83.25; ppl:   2.02; 3020 src tok/s; 3126 tgt tok/s;     14 s elapsed
Epoch 15,   100/  454; acc:  84.13; ppl:   1.94; 2957 src tok/s; 3093 tgt tok/s;     28 s elapsed
Epoch 15,   150/  454; acc:  82.83; ppl:   2.10; 3021 src tok/s; 3097 tgt tok/s;     42 s elapsed
Epoch 15,   200/  454; acc:  84.25; ppl:   1.94; 3010 src tok/s; 3128 tgt tok/s;     56 s elapsed
Epoch 15,   250/  454; acc:  83.12; ppl:   2.06; 2998 src tok/s; 3109 tgt tok/s;     70 s elapsed
Epoch 15,   300/  454; acc:  83.77; ppl:   1.99; 3012 src tok/s; 3146 tgt tok/s;     84 s elapsed
Epoch 15,   350/  454; acc:  83.75; ppl:   1.97; 3053 src tok/s; 3167 tgt tok/s;     98 s elapsed
Epoch 15,   400/  454; acc:  83.91; ppl:   1.96; 3013 src tok/s; 3135 tgt tok/s;    111 s elapsed
Epoch 15,   450/  454; acc:  83.28; ppl:   2.04; 2984 src tok/s; 3087 tgt tok/s;    125 s elapsed
Train perplexity: 2.00168
Train accuracy: 83.5881
Validation perplexity: 6.32588
Validation accuracy: 69.3416
Decaying learning rate to 0.00195312

Epoch 16,    50/  454; acc:  84.46; ppl:   1.90; 2993 src tok/s; 3123 tgt tok/s;     13 s elapsed
Epoch 16,   100/  454; acc:  83.05; ppl:   2.04; 3022 src tok/s; 3105 tgt tok/s;     28 s elapsed
Epoch 16,   150/  454; acc:  82.48; ppl:   2.10; 3083 src tok/s; 3171 tgt tok/s;     42 s elapsed
Epoch 16,   200/  454; acc:  84.60; ppl:   1.90; 2971 src tok/s; 3113 tgt tok/s;     55 s elapsed
Epoch 16,   250/  454; acc:  82.55; ppl:   2.12; 3017 src tok/s; 3117 tgt tok/s;     70 s elapsed
Epoch 16,   300/  454; acc:  84.11; ppl:   1.94; 2960 src tok/s; 3091 tgt tok/s;     84 s elapsed
Epoch 16,   350/  454; acc:  83.99; ppl:   1.97; 3039 src tok/s; 3161 tgt tok/s;     98 s elapsed
Epoch 16,   400/  454; acc:  84.04; ppl:   1.98; 2962 src tok/s; 3097 tgt tok/s;    112 s elapsed
Epoch 16,   450/  454; acc:  83.71; ppl:   2.00; 2982 src tok/s; 3079 tgt tok/s;    125 s elapsed
Train perplexity: 1.99666
Train accuracy: 83.6368
Validation perplexity: 6.32734
Validation accuracy: 69.3274
Decaying learning rate to 0.000976562

Epoch 17,    50/  454; acc:  84.05; ppl:   1.95; 2921 src tok/s; 3055 tgt tok/s;     14 s elapsed
Epoch 17,   100/  454; acc:  83.37; ppl:   2.02; 3064 src tok/s; 3156 tgt tok/s;     28 s elapsed
Epoch 17,   150/  454; acc:  82.61; ppl:   2.11; 3054 src tok/s; 3140 tgt tok/s;     43 s elapsed
Epoch 17,   200/  454; acc:  84.68; ppl:   1.90; 2967 src tok/s; 3108 tgt tok/s;     56 s elapsed
Epoch 17,   250/  454; acc:  84.05; ppl:   1.96; 2994 src tok/s; 3110 tgt tok/s;     70 s elapsed
Epoch 17,   300/  454; acc:  83.28; ppl:   2.02; 2945 src tok/s; 3064 tgt tok/s;     84 s elapsed
Epoch 17,   350/  454; acc:  83.13; ppl:   2.04; 3056 src tok/s; 3161 tgt tok/s;     98 s elapsed
Epoch 17,   400/  454; acc:  84.15; ppl:   1.94; 3002 src tok/s; 3127 tgt tok/s;    112 s elapsed
Epoch 17,   450/  454; acc:  83.71; ppl:   2.01; 3000 src tok/s; 3102 tgt tok/s;    126 s elapsed
Train perplexity: 1.99647
Train accuracy: 83.6411
Validation perplexity: 6.32899
Validation accuracy: 69.3628
Decaying learning rate to 0.000488281
