<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.4, kappa_enc=0.3, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/seeds/encoder0.3decoder0.4dropout0.3wdropTrueseed1', seed=1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.3)
('Using Kappa L2 loss on decoder', 0.4)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.79; ppl: 14036.47; 4333 src tok/s; 4449 tgt tok/s;     10 s elapsed
Epoch  1,   100/  454; acc:  15.84; ppl: 2065.45; 5257 src tok/s; 5513 tgt tok/s;     18 s elapsed
Epoch  1,   150/  454; acc:  18.05; ppl: 505.41; 5206 src tok/s; 5409 tgt tok/s;     26 s elapsed
Epoch  1,   200/  454; acc:  21.10; ppl: 294.48; 5483 src tok/s; 5666 tgt tok/s;     34 s elapsed
Epoch  1,   250/  454; acc:  24.70; ppl: 171.32; 5311 src tok/s; 5582 tgt tok/s;     41 s elapsed
Epoch  1,   300/  454; acc:  25.29; ppl: 146.56; 5383 src tok/s; 5538 tgt tok/s;     49 s elapsed
Epoch  1,   350/  454; acc:  28.87; ppl: 102.99; 5468 src tok/s; 5676 tgt tok/s;     57 s elapsed
Epoch  1,   400/  454; acc:  31.62; ppl:  77.90; 5361 src tok/s; 5584 tgt tok/s;     65 s elapsed
Epoch  1,   450/  454; acc:  33.26; ppl:  68.21; 5458 src tok/s; 5650 tgt tok/s;     72 s elapsed
Train perplexity: 339.961
Train accuracy: 23.0774
Validation perplexity: 66.2402
Validation accuracy: 32.2194

Epoch  2,    50/  454; acc:  36.69; ppl:  50.90; 5291 src tok/s; 5559 tgt tok/s;      8 s elapsed
Epoch  2,   100/  454; acc:  37.25; ppl:  47.99; 5364 src tok/s; 5522 tgt tok/s;     16 s elapsed
Epoch  2,   150/  454; acc:  40.88; ppl:  38.26; 5301 src tok/s; 5484 tgt tok/s;     24 s elapsed
Epoch  2,   200/  454; acc:  43.77; ppl:  31.81; 5403 src tok/s; 5611 tgt tok/s;     31 s elapsed
Epoch  2,   250/  454; acc:  44.01; ppl:  29.75; 5423 src tok/s; 5619 tgt tok/s;     39 s elapsed
Epoch  2,   300/  454; acc:  47.77; ppl:  24.29; 5383 src tok/s; 5594 tgt tok/s;     47 s elapsed
Epoch  2,   350/  454; acc:  48.34; ppl:  22.75; 5379 src tok/s; 5570 tgt tok/s;     55 s elapsed
Epoch  2,   400/  454; acc:  50.86; ppl:  19.17; 5478 src tok/s; 5686 tgt tok/s;     62 s elapsed
Epoch  2,   450/  454; acc:  51.72; ppl:  18.62; 5334 src tok/s; 5561 tgt tok/s;     70 s elapsed
Train perplexity: 29.6077
Train accuracy: 44.5815
Validation perplexity: 17.6999
Validation accuracy: 52.2208

Epoch  3,    50/  454; acc:  53.25; ppl:  15.75; 5480 src tok/s; 5701 tgt tok/s;      8 s elapsed
Epoch  3,   100/  454; acc:  54.76; ppl:  14.35; 5370 src tok/s; 5597 tgt tok/s;     16 s elapsed
Epoch  3,   150/  454; acc:  57.07; ppl:  12.22; 5395 src tok/s; 5636 tgt tok/s;     23 s elapsed
Epoch  3,   200/  454; acc:  54.62; ppl:  14.47; 5397 src tok/s; 5554 tgt tok/s;     31 s elapsed
Epoch  3,   250/  454; acc:  56.65; ppl:  12.39; 5444 src tok/s; 5649 tgt tok/s;     39 s elapsed
Epoch  3,   300/  454; acc:  56.56; ppl:  12.68; 5378 src tok/s; 5571 tgt tok/s;     47 s elapsed
Epoch  3,   350/  454; acc:  57.08; ppl:  12.11; 5441 src tok/s; 5606 tgt tok/s;     55 s elapsed
Epoch  3,   400/  454; acc:  60.23; ppl:   9.99; 5351 src tok/s; 5596 tgt tok/s;     62 s elapsed
Epoch  3,   450/  454; acc:  58.78; ppl:  10.62; 5378 src tok/s; 5579 tgt tok/s;     70 s elapsed
Train perplexity: 12.6441
Train accuracy: 56.5181
Validation perplexity: 10.0349
Validation accuracy: 60.9195

Epoch  4,    50/  454; acc:  61.58; ppl:   8.69; 5331 src tok/s; 5561 tgt tok/s;      8 s elapsed
Epoch  4,   100/  454; acc:  61.65; ppl:   8.41; 5493 src tok/s; 5676 tgt tok/s;     15 s elapsed
Epoch  4,   150/  454; acc:  62.12; ppl:   8.25; 5291 src tok/s; 5548 tgt tok/s;     23 s elapsed
Epoch  4,   200/  454; acc:  60.70; ppl:   9.01; 5386 src tok/s; 5551 tgt tok/s;     31 s elapsed
Epoch  4,   250/  454; acc:  62.82; ppl:   8.00; 5498 src tok/s; 5700 tgt tok/s;     39 s elapsed
Epoch  4,   300/  454; acc:  61.30; ppl:   8.49; 5396 src tok/s; 5591 tgt tok/s;     47 s elapsed
Epoch  4,   350/  454; acc:  62.53; ppl:   8.08; 5276 src tok/s; 5451 tgt tok/s;     55 s elapsed
Epoch  4,   400/  454; acc:  63.35; ppl:   7.57; 5261 src tok/s; 5477 tgt tok/s;     63 s elapsed
Epoch  4,   450/  454; acc:  62.54; ppl:   7.96; 5294 src tok/s; 5495 tgt tok/s;     70 s elapsed
Train perplexity: 8.25472
Train accuracy: 62.0841
Validation perplexity: 8.2258
Validation accuracy: 63.7363

Epoch  5,    50/  454; acc:  64.88; ppl:   6.43; 5288 src tok/s; 5440 tgt tok/s;      8 s elapsed
Epoch  5,   100/  454; acc:  66.52; ppl:   5.82; 5308 src tok/s; 5542 tgt tok/s;     16 s elapsed
Epoch  5,   150/  454; acc:  65.45; ppl:   6.18; 5279 src tok/s; 5489 tgt tok/s;     24 s elapsed
Epoch  5,   200/  454; acc:  65.88; ppl:   6.08; 5312 src tok/s; 5503 tgt tok/s;     32 s elapsed
Epoch  5,   250/  454; acc:  64.56; ppl:   6.68; 5320 src tok/s; 5491 tgt tok/s;     40 s elapsed
Epoch  5,   300/  454; acc:  66.20; ppl:   6.06; 5173 src tok/s; 5416 tgt tok/s;     48 s elapsed
Epoch  5,   350/  454; acc:  65.69; ppl:   6.00; 5301 src tok/s; 5552 tgt tok/s;     56 s elapsed
Epoch  5,   400/  454; acc:  64.82; ppl:   6.48; 5251 src tok/s; 5410 tgt tok/s;     64 s elapsed
Epoch  5,   450/  454; acc:  65.41; ppl:   6.35; 5302 src tok/s; 5489 tgt tok/s;     72 s elapsed
Train perplexity: 6.23354
Train accuracy: 65.4799
Validation perplexity: 7.55034
Validation accuracy: 64.4742

Epoch  6,    50/  454; acc:  68.36; ppl:   5.01; 5354 src tok/s; 5510 tgt tok/s;      8 s elapsed
Epoch  6,   100/  454; acc:  68.51; ppl:   4.84; 5346 src tok/s; 5570 tgt tok/s;     16 s elapsed
Epoch  6,   150/  454; acc:  69.27; ppl:   4.61; 5193 src tok/s; 5464 tgt tok/s;     23 s elapsed
Epoch  6,   200/  454; acc:  67.30; ppl:   5.29; 5310 src tok/s; 5467 tgt tok/s;     32 s elapsed
Epoch  6,   250/  454; acc:  68.64; ppl:   4.84; 5287 src tok/s; 5502 tgt tok/s;     39 s elapsed
Epoch  6,   300/  454; acc:  67.53; ppl:   5.19; 5354 src tok/s; 5541 tgt tok/s;     47 s elapsed
Epoch  6,   350/  454; acc:  68.64; ppl:   4.81; 5221 src tok/s; 5480 tgt tok/s;     55 s elapsed
Epoch  6,   400/  454; acc:  67.11; ppl:   5.31; 5282 src tok/s; 5443 tgt tok/s;     63 s elapsed
Epoch  6,   450/  454; acc:  68.10; ppl:   5.15; 5272 src tok/s; 5450 tgt tok/s;     71 s elapsed
Train perplexity: 5.0049
Train accuracy: 68.1491
Validation perplexity: 7.00179
Validation accuracy: 65.7585

Epoch  7,    50/  454; acc:  71.50; ppl:   3.90; 5255 src tok/s; 5476 tgt tok/s;      8 s elapsed
Epoch  7,   100/  454; acc:  70.52; ppl:   4.18; 5257 src tok/s; 5441 tgt tok/s;     16 s elapsed
Epoch  7,   150/  454; acc:  70.83; ppl:   4.04; 5291 src tok/s; 5490 tgt tok/s;     24 s elapsed
Epoch  7,   200/  454; acc:  70.13; ppl:   4.18; 5298 src tok/s; 5502 tgt tok/s;     32 s elapsed
Epoch  7,   250/  454; acc:  70.13; ppl:   4.23; 5400 src tok/s; 5624 tgt tok/s;     39 s elapsed
Epoch  7,   300/  454; acc:  69.81; ppl:   4.33; 5370 src tok/s; 5556 tgt tok/s;     47 s elapsed
Epoch  7,   350/  454; acc:  71.26; ppl:   4.01; 5290 src tok/s; 5510 tgt tok/s;     55 s elapsed
Epoch  7,   400/  454; acc:  68.99; ppl:   4.50; 5231 src tok/s; 5410 tgt tok/s;     63 s elapsed
Epoch  7,   450/  454; acc:  70.06; ppl:   4.29; 5253 src tok/s; 5453 tgt tok/s;     71 s elapsed
Train perplexity: 4.19443
Train accuracy: 70.3022
Validation perplexity: 6.80533
Validation accuracy: 65.7585

Epoch  8,    50/  454; acc:  73.48; ppl:   3.38; 5274 src tok/s; 5459 tgt tok/s;      8 s elapsed
Epoch  8,   100/  454; acc:  73.02; ppl:   3.47; 5393 src tok/s; 5602 tgt tok/s;     16 s elapsed
Epoch  8,   150/  454; acc:  72.13; ppl:   3.66; 5282 src tok/s; 5491 tgt tok/s;     24 s elapsed
Epoch  8,   200/  454; acc:  72.47; ppl:   3.47; 5405 src tok/s; 5616 tgt tok/s;     32 s elapsed
Epoch  8,   250/  454; acc:  72.15; ppl:   3.61; 5363 src tok/s; 5585 tgt tok/s;     39 s elapsed
Epoch  8,   300/  454; acc:  72.62; ppl:   3.59; 5406 src tok/s; 5603 tgt tok/s;     47 s elapsed
Epoch  8,   350/  454; acc:  71.56; ppl:   3.76; 5417 src tok/s; 5647 tgt tok/s;     55 s elapsed
Epoch  8,   400/  454; acc:  71.07; ppl:   3.81; 5407 src tok/s; 5595 tgt tok/s;     62 s elapsed
Epoch  8,   450/  454; acc:  71.35; ppl:   3.85; 5338 src tok/s; 5519 tgt tok/s;     70 s elapsed
Train perplexity: 3.62013
Train accuracy: 72.1994
Validation perplexity: 6.62977
Validation accuracy: 67.1988
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.76; ppl:   2.73; 5409 src tok/s; 5613 tgt tok/s;      8 s elapsed
Epoch  9,   100/  454; acc:  77.23; ppl:   2.73; 5335 src tok/s; 5541 tgt tok/s;     16 s elapsed
Epoch  9,   150/  454; acc:  77.76; ppl:   2.65; 5427 src tok/s; 5642 tgt tok/s;     23 s elapsed
Epoch  9,   200/  454; acc:  76.98; ppl:   2.76; 5349 src tok/s; 5569 tgt tok/s;     31 s elapsed
Epoch  9,   250/  454; acc:  77.07; ppl:   2.76; 5301 src tok/s; 5516 tgt tok/s;     39 s elapsed
Epoch  9,   300/  454; acc:  77.85; ppl:   2.61; 5426 src tok/s; 5633 tgt tok/s;     47 s elapsed
Epoch  9,   350/  454; acc:  77.35; ppl:   2.66; 5354 src tok/s; 5545 tgt tok/s;     54 s elapsed
Epoch  9,   400/  454; acc:  76.64; ppl:   2.77; 5452 src tok/s; 5628 tgt tok/s;     62 s elapsed
Epoch  9,   450/  454; acc:  76.89; ppl:   2.75; 5316 src tok/s; 5499 tgt tok/s;     70 s elapsed
Train perplexity: 2.71268
Train accuracy: 77.1744
Validation perplexity: 6.21733
Validation accuracy: 68.6817
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  81.40; ppl:   2.21; 5304 src tok/s; 5503 tgt tok/s;      8 s elapsed
Epoch 10,   100/  454; acc:  80.63; ppl:   2.31; 5396 src tok/s; 5582 tgt tok/s;     16 s elapsed
Epoch 10,   150/  454; acc:  81.26; ppl:   2.21; 5395 src tok/s; 5597 tgt tok/s;     23 s elapsed
Epoch 10,   200/  454; acc:  81.04; ppl:   2.20; 5476 src tok/s; 5664 tgt tok/s;     31 s elapsed
Epoch 10,   250/  454; acc:  80.84; ppl:   2.22; 5403 src tok/s; 5620 tgt tok/s;     39 s elapsed
Epoch 10,   300/  454; acc:  80.34; ppl:   2.29; 5438 src tok/s; 5623 tgt tok/s;     47 s elapsed
Epoch 10,   350/  454; acc:  80.27; ppl:   2.32; 5367 src tok/s; 5576 tgt tok/s;     54 s elapsed
Epoch 10,   400/  454; acc:  82.06; ppl:   2.09; 5272 src tok/s; 5469 tgt tok/s;     62 s elapsed
Epoch 10,   450/  454; acc:  80.61; ppl:   2.27; 5296 src tok/s; 5540 tgt tok/s;     70 s elapsed
Train perplexity: 2.23572
Train accuracy: 80.9279
Validation perplexity: 6.20982
Validation accuracy: 69.4977
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  82.94; ppl:   2.05; 5318 src tok/s; 5484 tgt tok/s;      8 s elapsed
Epoch 11,   100/  454; acc:  83.67; ppl:   1.98; 5515 src tok/s; 5733 tgt tok/s;     16 s elapsed
Epoch 11,   150/  454; acc:  82.88; ppl:   2.03; 5545 src tok/s; 5698 tgt tok/s;     23 s elapsed
Epoch 11,   200/  454; acc:  83.54; ppl:   1.97; 5352 src tok/s; 5601 tgt tok/s;     31 s elapsed
Epoch 11,   250/  454; acc:  84.00; ppl:   1.93; 5296 src tok/s; 5520 tgt tok/s;     39 s elapsed
Epoch 11,   300/  454; acc:  82.54; ppl:   2.10; 5399 src tok/s; 5607 tgt tok/s;     47 s elapsed
Epoch 11,   350/  454; acc:  83.02; ppl:   1.99; 5354 src tok/s; 5581 tgt tok/s;     54 s elapsed
Epoch 11,   400/  454; acc:  82.23; ppl:   2.10; 5312 src tok/s; 5499 tgt tok/s;     62 s elapsed
Epoch 11,   450/  454; acc:  82.89; ppl:   2.02; 5383 src tok/s; 5574 tgt tok/s;     70 s elapsed
Train perplexity: 2.01754
Train accuracy: 83.0878
Validation perplexity: 6.3771
Validation accuracy: 69.4764
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  85.15; ppl:   1.83; 5286 src tok/s; 5524 tgt tok/s;      8 s elapsed
Epoch 12,   100/  454; acc:  83.83; ppl:   1.96; 5402 src tok/s; 5590 tgt tok/s;     16 s elapsed
Epoch 12,   150/  454; acc:  85.04; ppl:   1.84; 5387 src tok/s; 5641 tgt tok/s;     23 s elapsed
Epoch 12,   200/  454; acc:  83.30; ppl:   2.03; 5403 src tok/s; 5569 tgt tok/s;     31 s elapsed
Epoch 12,   250/  454; acc:  85.43; ppl:   1.82; 5204 src tok/s; 5466 tgt tok/s;     39 s elapsed
Epoch 12,   300/  454; acc:  83.60; ppl:   1.99; 5467 src tok/s; 5607 tgt tok/s;     47 s elapsed
Epoch 12,   350/  454; acc:  84.02; ppl:   1.95; 5333 src tok/s; 5516 tgt tok/s;     55 s elapsed
Epoch 12,   400/  454; acc:  84.17; ppl:   1.90; 5398 src tok/s; 5599 tgt tok/s;     63 s elapsed
Epoch 12,   450/  454; acc:  83.83; ppl:   1.95; 5311 src tok/s; 5507 tgt tok/s;     70 s elapsed
Train perplexity: 1.91702
Train accuracy: 84.2645
Validation perplexity: 6.51702
Validation accuracy: 69.3841
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.51; ppl:   1.90; 5367 src tok/s; 5550 tgt tok/s;      8 s elapsed
Epoch 13,   100/  454; acc:  85.02; ppl:   1.84; 5418 src tok/s; 5652 tgt tok/s;     16 s elapsed
Epoch 13,   150/  454; acc:  85.46; ppl:   1.81; 5371 src tok/s; 5631 tgt tok/s;     23 s elapsed
Epoch 13,   200/  454; acc:  84.69; ppl:   1.88; 5407 src tok/s; 5582 tgt tok/s;     31 s elapsed
Epoch 13,   250/  454; acc:  83.51; ppl:   1.99; 5332 src tok/s; 5470 tgt tok/s;     40 s elapsed
Epoch 13,   300/  454; acc:  85.77; ppl:   1.78; 5318 src tok/s; 5565 tgt tok/s;     47 s elapsed
Epoch 13,   350/  454; acc:  86.15; ppl:   1.73; 5179 src tok/s; 5446 tgt tok/s;     54 s elapsed
Epoch 13,   400/  454; acc:  83.47; ppl:   2.00; 5460 src tok/s; 5600 tgt tok/s;     63 s elapsed
Epoch 13,   450/  454; acc:  84.85; ppl:   1.88; 5334 src tok/s; 5537 tgt tok/s;     70 s elapsed
Train perplexity: 1.86885
Train accuracy: 84.8079
Validation perplexity: 6.5366
Validation accuracy: 69.3983
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.36; ppl:   1.84; 5286 src tok/s; 5495 tgt tok/s;      8 s elapsed
Epoch 14,   100/  454; acc:  85.19; ppl:   1.83; 5436 src tok/s; 5612 tgt tok/s;     16 s elapsed
Epoch 14,   150/  454; acc:  85.50; ppl:   1.82; 5319 src tok/s; 5526 tgt tok/s;     23 s elapsed
Epoch 14,   200/  454; acc:  84.91; ppl:   1.87; 5500 src tok/s; 5691 tgt tok/s;     31 s elapsed
Epoch 14,   250/  454; acc:  83.93; ppl:   1.95; 5238 src tok/s; 5436 tgt tok/s;     39 s elapsed
Epoch 14,   300/  454; acc:  86.20; ppl:   1.75; 5360 src tok/s; 5580 tgt tok/s;     47 s elapsed
Epoch 14,   350/  454; acc:  86.12; ppl:   1.76; 5269 src tok/s; 5506 tgt tok/s;     54 s elapsed
Epoch 14,   400/  454; acc:  84.08; ppl:   1.95; 5372 src tok/s; 5541 tgt tok/s;     63 s elapsed
Epoch 14,   450/  454; acc:  84.98; ppl:   1.85; 5289 src tok/s; 5509 tgt tok/s;     70 s elapsed
Train perplexity: 1.84683
Train accuracy: 85.1225
Validation perplexity: 6.57228
Validation accuracy: 69.3983
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  85.17; ppl:   1.85; 5402 src tok/s; 5583 tgt tok/s;      8 s elapsed
Epoch 15,   100/  454; acc:  85.30; ppl:   1.83; 5228 src tok/s; 5462 tgt tok/s;     16 s elapsed
Epoch 15,   150/  454; acc:  84.74; ppl:   1.86; 5298 src tok/s; 5486 tgt tok/s;     24 s elapsed
Epoch 15,   200/  454; acc:  85.37; ppl:   1.82; 5293 src tok/s; 5499 tgt tok/s;     32 s elapsed
Epoch 15,   250/  454; acc:  86.44; ppl:   1.72; 5164 src tok/s; 5418 tgt tok/s;     39 s elapsed
Epoch 15,   300/  454; acc:  84.41; ppl:   1.90; 5352 src tok/s; 5509 tgt tok/s;     48 s elapsed
Epoch 15,   350/  454; acc:  85.90; ppl:   1.77; 5256 src tok/s; 5487 tgt tok/s;     55 s elapsed
Epoch 15,   400/  454; acc:  84.28; ppl:   1.94; 5353 src tok/s; 5522 tgt tok/s;     63 s elapsed
Epoch 15,   450/  454; acc:  85.56; ppl:   1.80; 5292 src tok/s; 5497 tgt tok/s;     71 s elapsed
Train perplexity: 1.83524
Train accuracy: 85.2016
Validation perplexity: 6.5786
Validation accuracy: 69.377
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  85.50; ppl:   1.79; 5215 src tok/s; 5428 tgt tok/s;      8 s elapsed
Epoch 16,   100/  454; acc:  84.64; ppl:   1.89; 5452 src tok/s; 5643 tgt tok/s;     16 s elapsed
Epoch 16,   150/  454; acc:  86.12; ppl:   1.77; 5255 src tok/s; 5503 tgt tok/s;     23 s elapsed
Epoch 16,   200/  454; acc:  84.67; ppl:   1.89; 5261 src tok/s; 5426 tgt tok/s;     32 s elapsed
Epoch 16,   250/  454; acc:  84.95; ppl:   1.86; 5366 src tok/s; 5555 tgt tok/s;     40 s elapsed
Epoch 16,   300/  454; acc:  85.81; ppl:   1.78; 5383 src tok/s; 5601 tgt tok/s;     47 s elapsed
Epoch 16,   350/  454; acc:  84.11; ppl:   1.94; 5295 src tok/s; 5456 tgt tok/s;     56 s elapsed
Epoch 16,   400/  454; acc:  86.55; ppl:   1.72; 5316 src tok/s; 5565 tgt tok/s;     63 s elapsed
Epoch 16,   450/  454; acc:  85.91; ppl:   1.77; 5285 src tok/s; 5478 tgt tok/s;     71 s elapsed
Train perplexity: 1.82856
Train accuracy: 85.2939
Validation perplexity: 6.58881
Validation accuracy: 69.4125
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  86.41; ppl:   1.74; 5261 src tok/s; 5528 tgt tok/s;      8 s elapsed
Epoch 17,   100/  454; acc:  84.64; ppl:   1.88; 5286 src tok/s; 5452 tgt tok/s;     16 s elapsed
Epoch 17,   150/  454; acc:  84.86; ppl:   1.86; 5353 src tok/s; 5504 tgt tok/s;     24 s elapsed
Epoch 17,   200/  454; acc:  85.45; ppl:   1.82; 5296 src tok/s; 5527 tgt tok/s;     32 s elapsed
Epoch 17,   250/  454; acc:  86.27; ppl:   1.75; 5323 src tok/s; 5533 tgt tok/s;     39 s elapsed
Epoch 17,   300/  454; acc:  84.65; ppl:   1.89; 5339 src tok/s; 5526 tgt tok/s;     47 s elapsed
Epoch 17,   350/  454; acc:  85.70; ppl:   1.80; 5204 src tok/s; 5436 tgt tok/s;     55 s elapsed
Epoch 17,   400/  454; acc:  84.46; ppl:   1.88; 5405 src tok/s; 5577 tgt tok/s;     63 s elapsed
Epoch 17,   450/  454; acc:  85.78; ppl:   1.77; 5272 src tok/s; 5487 tgt tok/s;     71 s elapsed
Train perplexity: 1.82545
Train accuracy: 85.2937
Validation perplexity: 6.59234
Validation accuracy: 69.3912
Decaying learning rate to 0.000976562
