<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.05, kappa_enc=0.25, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.25decoder0.05dropout0.3wdropFalse', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=False, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.25)
('Using Kappa L2 loss on decoder', 0.05)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): LSTM(500, 500, dropout=0.3)
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTM (
      (dropout): Dropout (p = 0.3)
      (layers): ModuleList (
        (0): LSTMCell(1000, 500)
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

Epoch  1,    50/  454; acc:   8.25; ppl: 24023.98; 5478 src tok/s; 5694 tgt tok/s;      7 s elapsed
Epoch  1,   100/  454; acc:  14.65; ppl: 1920.48; 5928 src tok/s; 6148 tgt tok/s;     15 s elapsed
Epoch  1,   150/  454; acc:  18.54; ppl: 524.95; 5862 src tok/s; 6088 tgt tok/s;     22 s elapsed
Epoch  1,   200/  454; acc:  21.38; ppl: 272.50; 5833 src tok/s; 6057 tgt tok/s;     29 s elapsed
Epoch  1,   250/  454; acc:  25.74; ppl: 157.87; 5721 src tok/s; 6012 tgt tok/s;     36 s elapsed
Epoch  1,   300/  454; acc:  26.19; ppl: 132.39; 6023 src tok/s; 6162 tgt tok/s;     43 s elapsed
Epoch  1,   350/  454; acc:  29.14; ppl:  96.89; 5819 src tok/s; 5995 tgt tok/s;     51 s elapsed
Epoch  1,   400/  454; acc:  32.13; ppl:  76.49; 5801 src tok/s; 6041 tgt tok/s;     58 s elapsed
Epoch  1,   450/  454; acc:  32.23; ppl:  71.35; 5770 src tok/s; 6021 tgt tok/s;     65 s elapsed
Train perplexity: 338.379
Train accuracy: 23.2506
Validation perplexity: 53.8139
Validation accuracy: 37.3279

Epoch  2,    50/  454; acc:  35.83; ppl:  53.03; 5822 src tok/s; 6069 tgt tok/s;      7 s elapsed
Epoch  2,   100/  454; acc:  36.06; ppl:  50.27; 5998 src tok/s; 6173 tgt tok/s;     14 s elapsed
Epoch  2,   150/  454; acc:  39.96; ppl:  39.92; 5798 src tok/s; 6023 tgt tok/s;     21 s elapsed
Epoch  2,   200/  454; acc:  43.01; ppl:  33.04; 5788 src tok/s; 5997 tgt tok/s;     29 s elapsed
Epoch  2,   250/  454; acc:  45.28; ppl:  28.29; 5828 src tok/s; 6063 tgt tok/s;     36 s elapsed
Epoch  2,   300/  454; acc:  45.38; ppl:  27.88; 6010 src tok/s; 6197 tgt tok/s;     43 s elapsed
Epoch  2,   350/  454; acc:  47.76; ppl:  23.58; 5810 src tok/s; 6027 tgt tok/s;     50 s elapsed
Epoch  2,   400/  454; acc:  50.49; ppl:  20.15; 5848 src tok/s; 6104 tgt tok/s;     57 s elapsed
Epoch  2,   450/  454; acc:  51.02; ppl:  19.52; 5754 src tok/s; 5999 tgt tok/s;     64 s elapsed
Train perplexity: 30.7926
Train accuracy: 43.9054
Validation perplexity: 16.6717
Validation accuracy: 53.0297

Epoch  3,    50/  454; acc:  52.75; ppl:  16.00; 5963 src tok/s; 6171 tgt tok/s;      7 s elapsed
Epoch  3,   100/  454; acc:  55.28; ppl:  13.90; 5874 src tok/s; 6112 tgt tok/s;     14 s elapsed
Epoch  3,   150/  454; acc:  54.52; ppl:  14.16; 5833 src tok/s; 6047 tgt tok/s;     22 s elapsed
Epoch  3,   200/  454; acc:  56.51; ppl:  12.66; 5813 src tok/s; 6055 tgt tok/s;     29 s elapsed
Epoch  3,   250/  454; acc:  55.51; ppl:  13.56; 5820 src tok/s; 5998 tgt tok/s;     36 s elapsed
Epoch  3,   300/  454; acc:  57.26; ppl:  11.95; 5916 src tok/s; 6121 tgt tok/s;     43 s elapsed
Epoch  3,   350/  454; acc:  58.09; ppl:  11.75; 5695 src tok/s; 5964 tgt tok/s;     50 s elapsed
Epoch  3,   400/  454; acc:  58.37; ppl:  11.62; 5910 src tok/s; 6110 tgt tok/s;     57 s elapsed
Epoch  3,   450/  454; acc:  58.54; ppl:  10.89; 5637 src tok/s; 5858 tgt tok/s;     65 s elapsed
Train perplexity: 12.8259
Train accuracy: 56.3575
Validation perplexity: 9.88055
Validation accuracy: 61.3523

Epoch  4,    50/  454; acc:  62.01; ppl:   8.39; 5844 src tok/s; 6055 tgt tok/s;      7 s elapsed
Epoch  4,   100/  454; acc:  60.86; ppl:   8.92; 5974 src tok/s; 6176 tgt tok/s;     14 s elapsed
Epoch  4,   150/  454; acc:  61.82; ppl:   8.54; 5696 src tok/s; 5944 tgt tok/s;     22 s elapsed
Epoch  4,   200/  454; acc:  61.69; ppl:   8.51; 5899 src tok/s; 6129 tgt tok/s;     29 s elapsed
Epoch  4,   250/  454; acc:  61.43; ppl:   8.64; 5961 src tok/s; 6144 tgt tok/s;     36 s elapsed
Epoch  4,   300/  454; acc:  63.40; ppl:   7.57; 5909 src tok/s; 6186 tgt tok/s;     43 s elapsed
Epoch  4,   350/  454; acc:  62.26; ppl:   8.11; 5871 src tok/s; 6099 tgt tok/s;     50 s elapsed
Epoch  4,   400/  454; acc:  62.00; ppl:   8.39; 5937 src tok/s; 6167 tgt tok/s;     57 s elapsed
Epoch  4,   450/  454; acc:  62.26; ppl:   8.27; 6001 src tok/s; 6194 tgt tok/s;     64 s elapsed
Train perplexity: 8.3585
Train accuracy: 61.9741
Validation perplexity: 8.52595
Validation accuracy: 63.0907

Epoch  5,    50/  454; acc:  65.51; ppl:   6.26; 5734 src tok/s; 5997 tgt tok/s;      7 s elapsed
Epoch  5,   100/  454; acc:  65.60; ppl:   6.34; 5977 src tok/s; 6152 tgt tok/s;     14 s elapsed
Epoch  5,   150/  454; acc:  65.12; ppl:   6.45; 5993 src tok/s; 6203 tgt tok/s;     21 s elapsed
Epoch  5,   200/  454; acc:  64.84; ppl:   6.42; 5999 src tok/s; 6216 tgt tok/s;     28 s elapsed
Epoch  5,   250/  454; acc:  65.61; ppl:   6.24; 5954 src tok/s; 6206 tgt tok/s;     35 s elapsed
Epoch  5,   300/  454; acc:  65.17; ppl:   6.33; 6063 src tok/s; 6286 tgt tok/s;     42 s elapsed
Epoch  5,   350/  454; acc:  65.69; ppl:   6.36; 5899 src tok/s; 6125 tgt tok/s;     49 s elapsed
Epoch  5,   400/  454; acc:  65.31; ppl:   6.28; 5928 src tok/s; 6171 tgt tok/s;     56 s elapsed
Epoch  5,   450/  454; acc:  65.46; ppl:   6.18; 5964 src tok/s; 6172 tgt tok/s;     63 s elapsed
Train perplexity: 6.31116
Train accuracy: 65.3898
Validation perplexity: 7.15324
Validation accuracy: 65.7656

Epoch  6,    50/  454; acc:  68.73; ppl:   4.87; 5893 src tok/s; 6094 tgt tok/s;      7 s elapsed
Epoch  6,   100/  454; acc:  68.11; ppl:   5.09; 5918 src tok/s; 6142 tgt tok/s;     14 s elapsed
Epoch  6,   150/  454; acc:  68.79; ppl:   4.91; 5982 src tok/s; 6210 tgt tok/s;     21 s elapsed
Epoch  6,   200/  454; acc:  67.33; ppl:   5.28; 5993 src tok/s; 6212 tgt tok/s;     28 s elapsed
Epoch  6,   250/  454; acc:  68.20; ppl:   4.99; 5943 src tok/s; 6190 tgt tok/s;     35 s elapsed
Epoch  6,   300/  454; acc:  67.37; ppl:   5.32; 5926 src tok/s; 6149 tgt tok/s;     42 s elapsed
Epoch  6,   350/  454; acc:  66.57; ppl:   5.54; 6015 src tok/s; 6206 tgt tok/s;     50 s elapsed
Epoch  6,   400/  454; acc:  68.66; ppl:   4.87; 5834 src tok/s; 6111 tgt tok/s;     57 s elapsed
Epoch  6,   450/  454; acc:  67.46; ppl:   5.22; 5876 src tok/s; 6091 tgt tok/s;     64 s elapsed
Train perplexity: 5.11419
Train accuracy: 67.9101
Validation perplexity: 6.78923
Validation accuracy: 66.7873

Epoch  7,    50/  454; acc:  71.06; ppl:   4.09; 5986 src tok/s; 6180 tgt tok/s;      7 s elapsed
Epoch  7,   100/  454; acc:  70.69; ppl:   4.12; 5931 src tok/s; 6163 tgt tok/s;     14 s elapsed
Epoch  7,   150/  454; acc:  69.42; ppl:   4.45; 6016 src tok/s; 6237 tgt tok/s;     21 s elapsed
Epoch  7,   200/  454; acc:  70.15; ppl:   4.25; 5885 src tok/s; 6121 tgt tok/s;     28 s elapsed
Epoch  7,   250/  454; acc:  70.66; ppl:   4.11; 5964 src tok/s; 6219 tgt tok/s;     35 s elapsed
Epoch  7,   300/  454; acc:  69.11; ppl:   4.53; 5971 src tok/s; 6163 tgt tok/s;     42 s elapsed
Epoch  7,   350/  454; acc:  68.88; ppl:   4.64; 6048 src tok/s; 6248 tgt tok/s;     50 s elapsed
Epoch  7,   400/  454; acc:  70.79; ppl:   4.09; 5937 src tok/s; 6198 tgt tok/s;     56 s elapsed
Epoch  7,   450/  454; acc:  69.08; ppl:   4.51; 5754 src tok/s; 5977 tgt tok/s;     63 s elapsed
Train perplexity: 4.3052
Train accuracy: 69.9859
Validation perplexity: 6.60756
Validation accuracy: 67.0995

Epoch  8,    50/  454; acc:  73.54; ppl:   3.29; 5929 src tok/s; 6195 tgt tok/s;      7 s elapsed
Epoch  8,   100/  454; acc:  71.69; ppl:   3.73; 6083 src tok/s; 6279 tgt tok/s;     14 s elapsed
Epoch  8,   150/  454; acc:  71.89; ppl:   3.70; 5864 src tok/s; 6120 tgt tok/s;     21 s elapsed
Epoch  8,   200/  454; acc:  71.76; ppl:   3.76; 5826 src tok/s; 6070 tgt tok/s;     28 s elapsed
Epoch  8,   250/  454; acc:  71.02; ppl:   3.96; 6069 src tok/s; 6221 tgt tok/s;     36 s elapsed
Epoch  8,   300/  454; acc:  72.64; ppl:   3.55; 5673 src tok/s; 5964 tgt tok/s;     43 s elapsed
Epoch  8,   350/  454; acc:  71.33; ppl:   3.85; 5897 src tok/s; 6075 tgt tok/s;     50 s elapsed
Epoch  8,   400/  454; acc:  71.59; ppl:   3.81; 5932 src tok/s; 6144 tgt tok/s;     57 s elapsed
Epoch  8,   450/  454; acc:  71.07; ppl:   3.86; 5731 src tok/s; 5949 tgt tok/s;     64 s elapsed
Train perplexity: 3.72006
Train accuracy: 71.8261
Validation perplexity: 6.60698
Validation accuracy: 66.9363
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  75.47; ppl:   2.98; 5989 src tok/s; 6158 tgt tok/s;      7 s elapsed
Epoch  9,   100/  454; acc:  77.15; ppl:   2.72; 5877 src tok/s; 6118 tgt tok/s;     14 s elapsed
Epoch  9,   150/  454; acc:  76.77; ppl:   2.78; 5951 src tok/s; 6193 tgt tok/s;     21 s elapsed
Epoch  9,   200/  454; acc:  77.02; ppl:   2.79; 5918 src tok/s; 6152 tgt tok/s;     28 s elapsed
Epoch  9,   250/  454; acc:  77.80; ppl:   2.59; 5898 src tok/s; 6184 tgt tok/s;     35 s elapsed
Epoch  9,   300/  454; acc:  75.34; ppl:   3.01; 6079 src tok/s; 6272 tgt tok/s;     42 s elapsed
Epoch  9,   350/  454; acc:  76.28; ppl:   2.82; 6059 src tok/s; 6270 tgt tok/s;     49 s elapsed
Epoch  9,   400/  454; acc:  76.49; ppl:   2.81; 5901 src tok/s; 6141 tgt tok/s;     56 s elapsed
Epoch  9,   450/  454; acc:  76.30; ppl:   2.82; 5912 src tok/s; 6150 tgt tok/s;     63 s elapsed
Train perplexity: 2.81315
Train accuracy: 76.4891
Validation perplexity: 6.03239
Validation accuracy: 68.8875
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.75; ppl:   2.25; 5914 src tok/s; 6149 tgt tok/s;      7 s elapsed
Epoch 10,   100/  454; acc:  79.49; ppl:   2.40; 5185 src tok/s; 5395 tgt tok/s;     15 s elapsed
Epoch 10,   150/  454; acc:  80.56; ppl:   2.28; 6167 src tok/s; 6422 tgt tok/s;     22 s elapsed
Epoch 10,   200/  454; acc:  79.54; ppl:   2.41; 6114 src tok/s; 6322 tgt tok/s;     29 s elapsed
Epoch 10,   250/  454; acc:  79.81; ppl:   2.37; 6159 src tok/s; 6339 tgt tok/s;     36 s elapsed
Epoch 10,   300/  454; acc:  80.48; ppl:   2.31; 6147 src tok/s; 6422 tgt tok/s;     43 s elapsed
Epoch 10,   350/  454; acc:  79.75; ppl:   2.39; 5723 src tok/s; 5900 tgt tok/s;     50 s elapsed
Epoch 10,   400/  454; acc:  80.41; ppl:   2.29; 5886 src tok/s; 6138 tgt tok/s;     57 s elapsed
Epoch 10,   450/  454; acc:  79.90; ppl:   2.34; 5897 src tok/s; 6136 tgt tok/s;     64 s elapsed
Train perplexity: 2.33906
Train accuracy: 80.0399
Validation perplexity: 6.10193
Validation accuracy: 69.597
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  82.27; ppl:   2.08; 5977 src tok/s; 6192 tgt tok/s;      7 s elapsed
Epoch 11,   100/  454; acc:  82.30; ppl:   2.11; 5899 src tok/s; 6121 tgt tok/s;     14 s elapsed
Epoch 11,   150/  454; acc:  82.43; ppl:   2.07; 5821 src tok/s; 6074 tgt tok/s;     21 s elapsed
Epoch 11,   200/  454; acc:  82.03; ppl:   2.14; 5861 src tok/s; 6077 tgt tok/s;     28 s elapsed
Epoch 11,   250/  454; acc:  82.18; ppl:   2.10; 6055 src tok/s; 6242 tgt tok/s;     35 s elapsed
Epoch 11,   300/  454; acc:  81.44; ppl:   2.16; 5392 src tok/s; 5608 tgt tok/s;     43 s elapsed
Epoch 11,   350/  454; acc:  81.78; ppl:   2.16; 5897 src tok/s; 6173 tgt tok/s;     50 s elapsed
Epoch 11,   400/  454; acc:  81.79; ppl:   2.12; 6178 src tok/s; 6392 tgt tok/s;     57 s elapsed
Epoch 11,   450/  454; acc:  82.09; ppl:   2.11; 6051 src tok/s; 6268 tgt tok/s;     64 s elapsed
Train perplexity: 2.12078
Train accuracy: 82.0043
Validation perplexity: 6.21058
Validation accuracy: 69.526
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  82.76; ppl:   2.07; 5558 src tok/s; 5734 tgt tok/s;      8 s elapsed
Epoch 12,   100/  454; acc:  83.93; ppl:   1.95; 5934 src tok/s; 6199 tgt tok/s;     15 s elapsed
Epoch 12,   150/  454; acc:  82.11; ppl:   2.12; 5920 src tok/s; 6096 tgt tok/s;     22 s elapsed
Epoch 12,   200/  454; acc:  84.39; ppl:   1.88; 5904 src tok/s; 6184 tgt tok/s;     29 s elapsed
Epoch 12,   250/  454; acc:  83.23; ppl:   2.00; 5873 src tok/s; 6120 tgt tok/s;     36 s elapsed
Epoch 12,   300/  454; acc:  82.46; ppl:   2.08; 5931 src tok/s; 6128 tgt tok/s;     43 s elapsed
Epoch 12,   350/  454; acc:  82.97; ppl:   2.03; 5933 src tok/s; 6135 tgt tok/s;     50 s elapsed
Epoch 12,   400/  454; acc:  83.24; ppl:   2.01; 5748 src tok/s; 5993 tgt tok/s;     57 s elapsed
Epoch 12,   450/  454; acc:  82.88; ppl:   2.03; 5792 src tok/s; 6008 tgt tok/s;     64 s elapsed
Train perplexity: 2.01789
Train accuracy: 83.0864
Validation perplexity: 6.29709
Validation accuracy: 69.7318
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.50; ppl:   1.88; 5630 src tok/s; 5879 tgt tok/s;      7 s elapsed
Epoch 13,   100/  454; acc:  82.86; ppl:   2.07; 5716 src tok/s; 5883 tgt tok/s;     15 s elapsed
Epoch 13,   150/  454; acc:  84.21; ppl:   1.89; 5760 src tok/s; 6009 tgt tok/s;     22 s elapsed
Epoch 13,   200/  454; acc:  83.13; ppl:   2.02; 5873 src tok/s; 6071 tgt tok/s;     29 s elapsed
Epoch 13,   250/  454; acc:  83.43; ppl:   2.00; 5702 src tok/s; 5926 tgt tok/s;     37 s elapsed
Epoch 13,   300/  454; acc:  83.80; ppl:   1.93; 5963 src tok/s; 6164 tgt tok/s;     44 s elapsed
Epoch 13,   350/  454; acc:  83.80; ppl:   1.96; 5835 src tok/s; 6086 tgt tok/s;     51 s elapsed
Epoch 13,   400/  454; acc:  83.33; ppl:   1.98; 5984 src tok/s; 6185 tgt tok/s;     58 s elapsed
Epoch 13,   450/  454; acc:  84.32; ppl:   1.90; 5751 src tok/s; 6016 tgt tok/s;     65 s elapsed
Train perplexity: 1.96907
Train accuracy: 83.604
Validation perplexity: 6.3424
Validation accuracy: 69.6679
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  83.90; ppl:   1.93; 5937 src tok/s; 6159 tgt tok/s;      7 s elapsed
Epoch 14,   100/  454; acc:  83.77; ppl:   1.95; 5852 src tok/s; 6055 tgt tok/s;     14 s elapsed
Epoch 14,   150/  454; acc:  84.39; ppl:   1.90; 5858 src tok/s; 6116 tgt tok/s;     21 s elapsed
Epoch 14,   200/  454; acc:  83.37; ppl:   2.00; 5985 src tok/s; 6195 tgt tok/s;     28 s elapsed
Epoch 14,   250/  454; acc:  83.47; ppl:   1.95; 5919 src tok/s; 6130 tgt tok/s;     36 s elapsed
Epoch 14,   300/  454; acc:  84.01; ppl:   1.92; 6002 src tok/s; 6270 tgt tok/s;     43 s elapsed
slurmstepd-mila01: error: *** JOB 69157 ON mila01 CANCELLED AT 2017-10-26T17:08:42 DUE TO PREEMPTION ***
<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.05, kappa_enc=0.25, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.25decoder0.05dropout0.3wdropFalse', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=False, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.25)
('Using Kappa L2 loss on decoder', 0.05)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): LSTM(500, 500, dropout=0.3)
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTM (
      (dropout): Dropout (p = 0.3)
      (layers): ModuleList (
        (0): LSTMCell(1000, 500)
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

Epoch  1,    50/  454; acc:   9.57; ppl: 12168.18; 2869 src tok/s; 2974 tgt tok/s;     15 s elapsed
Epoch  1,   100/  454; acc:  14.93; ppl: 1701.74; 2926 src tok/s; 3036 tgt tok/s;     29 s elapsed
Epoch  1,   150/  454; acc:  17.94; ppl: 499.06; 2932 src tok/s; 3042 tgt tok/s;     43 s elapsed
Epoch  1,   200/  454; acc:  20.97; ppl: 270.97; 2937 src tok/s; 3035 tgt tok/s;     58 s elapsed
Epoch  1,   250/  454; acc:  25.28; ppl: 172.90; 2911 src tok/s; 3031 tgt tok/s;     72 s elapsed
Epoch  1,   300/  454; acc:  27.29; ppl: 126.81; 2938 src tok/s; 3044 tgt tok/s;     87 s elapsed
Epoch  1,   350/  454; acc:  28.91; ppl: 100.35; 2917 src tok/s; 3024 tgt tok/s;    101 s elapsed
Epoch  1,   400/  454; acc:  32.27; ppl:  74.49; 2862 src tok/s; 2985 tgt tok/s;    115 s elapsed
Epoch  1,   450/  454; acc:  33.22; ppl:  68.75; 2865 src tok/s; 2974 tgt tok/s;    130 s elapsed
Train perplexity: 312.666
Train accuracy: 23.4445
Validation perplexity: 49.8276
Validation accuracy: 38.3638

Epoch  2,    50/  454; acc:  35.61; ppl:  53.75; 2991 src tok/s; 3085 tgt tok/s;     14 s elapsed
Epoch  2,   100/  454; acc:  38.97; ppl:  44.30; 2922 src tok/s; 3057 tgt tok/s;     28 s elapsed
Epoch  2,   150/  454; acc:  42.46; ppl:  34.72; 2861 src tok/s; 2991 tgt tok/s;     42 s elapsed
Epoch  2,   200/  454; acc:  42.31; ppl:  33.55; 2903 src tok/s; 3003 tgt tok/s;     57 s elapsed
Epoch  2,   250/  454; acc:  44.18; ppl:  29.81; 2919 src tok/s; 3019 tgt tok/s;     72 s elapsed
Epoch  2,   300/  454; acc:  47.74; ppl:  23.94; 2940 src tok/s; 3064 tgt tok/s;     86 s elapsed
Epoch  2,   350/  454; acc:  49.42; ppl:  21.67; 2958 src tok/s; 3069 tgt tok/s;    100 s elapsed
Epoch  2,   400/  454; acc:  49.40; ppl:  20.76; 2987 src tok/s; 3085 tgt tok/s;    114 s elapsed
Epoch  2,   450/  454; acc:  51.79; ppl:  18.31; 2920 src tok/s; 3026 tgt tok/s;    129 s elapsed
Train perplexity: 29.3061
Train accuracy: 44.6918
Validation perplexity: 16.3972
Validation accuracy: 53.8385

Epoch  3,    50/  454; acc:  53.91; ppl:  15.11; 2944 src tok/s; 3062 tgt tok/s;     14 s elapsed
Epoch  3,   100/  454; acc:  54.12; ppl:  14.84; 2949 src tok/s; 3055 tgt tok/s;     28 s elapsed
Epoch  3,   150/  454; acc:  54.40; ppl:  14.30; 2958 src tok/s; 3043 tgt tok/s;     44 s elapsed
Epoch  3,   200/  454; acc:  57.14; ppl:  12.31; 2905 src tok/s; 3028 tgt tok/s;     57 s elapsed
Epoch  3,   250/  454; acc:  57.32; ppl:  11.83; 2893 src tok/s; 3028 tgt tok/s;     71 s elapsed
Epoch  3,   300/  454; acc:  56.50; ppl:  12.56; 2964 src tok/s; 3057 tgt tok/s;     86 s elapsed
Epoch  3,   350/  454; acc:  58.49; ppl:  11.31; 2964 src tok/s; 3096 tgt tok/s;     99 s elapsed
Epoch  3,   400/  454; acc:  57.63; ppl:  11.63; 2907 src tok/s; 3004 tgt tok/s;    114 s elapsed
Epoch  3,   450/  454; acc:  58.16; ppl:  10.99; 2940 src tok/s; 3055 tgt tok/s;    128 s elapsed
Train perplexity: 12.6846
Train accuracy: 56.4074
Validation perplexity: 10.1533
Validation accuracy: 60.9408

Epoch  4,    50/  454; acc:  63.50; ppl:   7.71; 2878 src tok/s; 3019 tgt tok/s;     13 s elapsed
Epoch  4,   100/  454; acc:  60.04; ppl:   9.41; 2920 src tok/s; 2993 tgt tok/s;     29 s elapsed
Epoch  4,   150/  454; acc:  61.18; ppl:   8.83; 2920 src tok/s; 3025 tgt tok/s;     43 s elapsed
Epoch  4,   200/  454; acc:  61.52; ppl:   8.56; 2936 src tok/s; 3056 tgt tok/s;     58 s elapsed
Epoch  4,   250/  454; acc:  61.69; ppl:   8.47; 2964 src tok/s; 3057 tgt tok/s;     72 s elapsed
Epoch  4,   300/  454; acc:  62.09; ppl:   8.25; 2902 src tok/s; 3031 tgt tok/s;     86 s elapsed
Epoch  4,   350/  454; acc:  62.07; ppl:   8.12; 2960 src tok/s; 3070 tgt tok/s;    100 s elapsed
Epoch  4,   400/  454; acc:  61.44; ppl:   8.47; 2932 src tok/s; 3043 tgt tok/s;    115 s elapsed
Epoch  4,   450/  454; acc:  62.99; ppl:   7.64; 2848 src tok/s; 2961 tgt tok/s;    129 s elapsed
Train perplexity: 8.37029
Train accuracy: 61.8299
Validation perplexity: 8.62138
Validation accuracy: 62.7643

Epoch  5,    50/  454; acc:  64.95; ppl:   6.51; 2897 src tok/s; 2998 tgt tok/s;     15 s elapsed
Epoch  5,   100/  454; acc:  65.60; ppl:   6.23; 2964 src tok/s; 3064 tgt tok/s;     29 s elapsed
Epoch  5,   150/  454; acc:  64.83; ppl:   6.57; 2956 src tok/s; 3056 tgt tok/s;     43 s elapsed
Epoch  5,   200/  454; acc:  65.92; ppl:   6.06; 2932 src tok/s; 3061 tgt tok/s;     57 s elapsed
Epoch  5,   250/  454; acc:  65.38; ppl:   6.24; 2981 src tok/s; 3097 tgt tok/s;     71 s elapsed
Epoch  5,   300/  454; acc:  64.81; ppl:   6.47; 2928 src tok/s; 3034 tgt tok/s;     85 s elapsed
Epoch  5,   350/  454; acc:  65.54; ppl:   6.18; 2886 src tok/s; 3013 tgt tok/s;    100 s elapsed
Epoch  5,   400/  454; acc:  65.11; ppl:   6.48; 2868 src tok/s; 2980 tgt tok/s;    115 s elapsed
Epoch  5,   450/  454; acc:  65.34; ppl:   6.31; 2852 src tok/s; 2952 tgt tok/s;    129 s elapsed
Train perplexity: 6.33019
Train accuracy: 65.295
Validation perplexity: 7.36616
Validation accuracy: 65.347

Epoch  6,    50/  454; acc:  68.85; ppl:   4.85; 2924 src tok/s; 3042 tgt tok/s;     14 s elapsed
Epoch  6,   100/  454; acc:  68.07; ppl:   5.08; 2898 src tok/s; 3001 tgt tok/s;     29 s elapsed
Epoch  6,   150/  454; acc:  69.03; ppl:   4.76; 2957 src tok/s; 3082 tgt tok/s;     42 s elapsed
Epoch  6,   200/  454; acc:  66.95; ppl:   5.40; 2939 src tok/s; 3030 tgt tok/s;     57 s elapsed
Epoch  6,   250/  454; acc:  67.07; ppl:   5.29; 2875 src tok/s; 2973 tgt tok/s;     72 s elapsed
Epoch  6,   300/  454; acc:  68.12; ppl:   5.06; 2905 src tok/s; 3032 tgt tok/s;     86 s elapsed
Epoch  6,   350/  454; acc:  68.14; ppl:   5.05; 2893 src tok/s; 3020 tgt tok/s;    100 s elapsed
Epoch  6,   400/  454; acc:  67.11; ppl:   5.48; 2957 src tok/s; 3053 tgt tok/s;    115 s elapsed
Epoch  6,   450/  454; acc:  68.15; ppl:   4.97; 2904 src tok/s; 3020 tgt tok/s;    129 s elapsed
Train perplexity: 5.11363
Train accuracy: 67.9053
Validation perplexity: 6.87166
Validation accuracy: 66.2906

Epoch  7,    50/  454; acc:  71.85; ppl:   3.91; 2860 src tok/s; 2994 tgt tok/s;     14 s elapsed
Epoch  7,   100/  454; acc:  70.36; ppl:   4.25; 2954 src tok/s; 3069 tgt tok/s;     29 s elapsed
Epoch  7,   150/  454; acc:  70.49; ppl:   4.19; 3013 src tok/s; 3115 tgt tok/s;     43 s elapsed
Epoch  7,   200/  454; acc:  69.30; ppl:   4.42; 2878 src tok/s; 3008 tgt tok/s;     57 s elapsed
Epoch  7,   250/  454; acc:  68.78; ppl:   4.56; 2870 src tok/s; 2978 tgt tok/s;     72 s elapsed
Epoch  7,   300/  454; acc:  70.67; ppl:   4.20; 2924 src tok/s; 3043 tgt tok/s;     86 s elapsed
Epoch  7,   350/  454; acc:  69.75; ppl:   4.29; 2906 src tok/s; 2987 tgt tok/s;    101 s elapsed
Epoch  7,   400/  454; acc:  68.72; ppl:   4.59; 2887 src tok/s; 2984 tgt tok/s;    115 s elapsed
Epoch  7,   450/  454; acc:  69.79; ppl:   4.38; 2944 src tok/s; 3056 tgt tok/s;    129 s elapsed
Train perplexity: 4.30938
Train accuracy: 69.9537
Validation perplexity: 6.61997
Validation accuracy: 67.1208

Epoch  8,    50/  454; acc:  71.89; ppl:   3.75; 2769 src tok/s; 2850 tgt tok/s;     16 s elapsed
Epoch  8,   100/  454; acc:  73.65; ppl:   3.37; 2885 src tok/s; 3021 tgt tok/s;     30 s elapsed
Epoch  8,   150/  454; acc:  71.54; ppl:   3.79; 2969 src tok/s; 3064 tgt tok/s;     44 s elapsed
Epoch  8,   200/  454; acc:  72.34; ppl:   3.56; 2945 src tok/s; 3071 tgt tok/s;     58 s elapsed
Epoch  8,   250/  454; acc:  71.74; ppl:   3.76; 2924 src tok/s; 3041 tgt tok/s;     72 s elapsed
Epoch  8,   300/  454; acc:  71.19; ppl:   3.83; 2970 src tok/s; 3068 tgt tok/s;     87 s elapsed
Epoch  8,   350/  454; acc:  71.64; ppl:   3.78; 2889 src tok/s; 2995 tgt tok/s;    101 s elapsed
Epoch  8,   400/  454; acc:  71.08; ppl:   3.87; 2908 src tok/s; 3029 tgt tok/s;    116 s elapsed
Epoch  8,   450/  454; acc:  71.32; ppl:   3.81; 2880 src tok/s; 2993 tgt tok/s;    130 s elapsed
Train perplexity: 3.72727
Train accuracy: 71.8063
Validation perplexity: 6.38768
Validation accuracy: 67.3833
Decaying learning rate to 0.5
Traceback (most recent call last):
  File "train.py", line 416, in <module>
    main()
  File "train.py", line 412, in main
    train_model(model, train, valid, fields, optim)
  File "train.py", line 288, in train_model
    trainer.drop_checkpoint(opt, epoch, fields, valid_stats)
  File "/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/onmt/Trainer.py", line 210, in drop_checkpoint
    valid_stats.ppl(), epoch))
  File "/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/serialization.py", line 118, in save
    f = open(f, "wb")
IOError: [Errno 2] No such file or directory: '/data/lisatmp3/suhubdyd/models/encoder0.25decoder0.05dropout0.3wdropFalse_acc_67.38_ppl_6.39_e8.pt'
