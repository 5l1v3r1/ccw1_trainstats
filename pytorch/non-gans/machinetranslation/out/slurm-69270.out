<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.3, kappa_enc=0.0, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0decoder0.30dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on decoder', 0.3)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   7.60; ppl: 76231.05; 3808 src tok/s; 3967 tgt tok/s;     11 s elapsed
Epoch  1,   100/  454; acc:  14.55; ppl: 1322.70; 4547 src tok/s; 4706 tgt tok/s;     20 s elapsed
Epoch  1,   150/  454; acc:  18.47; ppl: 534.17; 4683 src tok/s; 4848 tgt tok/s;     29 s elapsed
Epoch  1,   200/  454; acc:  21.02; ppl: 268.95; 4638 src tok/s; 4807 tgt tok/s;     38 s elapsed
Epoch  1,   250/  454; acc:  24.30; ppl: 177.42; 4656 src tok/s; 4816 tgt tok/s;     47 s elapsed
Epoch  1,   300/  454; acc:  26.82; ppl: 131.52; 4699 src tok/s; 4874 tgt tok/s;     56 s elapsed
Epoch  1,   350/  454; acc:  29.46; ppl:  96.45; 4691 src tok/s; 4872 tgt tok/s;     65 s elapsed
Epoch  1,   400/  454; acc:  31.03; ppl:  82.27; 4633 src tok/s; 4825 tgt tok/s;     74 s elapsed
Epoch  1,   450/  454; acc:  32.50; ppl:  72.02; 4497 src tok/s; 4669 tgt tok/s;     83 s elapsed
Train perplexity: 374.571
Train accuracy: 23.0131
Validation perplexity: 54.4429
Validation accuracy: 36.7745

Epoch  2,    50/  454; acc:  35.19; ppl:  56.16; 4607 src tok/s; 4800 tgt tok/s;      9 s elapsed
Epoch  2,   100/  454; acc:  38.15; ppl:  46.39; 4652 src tok/s; 4831 tgt tok/s;     18 s elapsed
Epoch  2,   150/  454; acc:  40.03; ppl:  40.72; 4585 src tok/s; 4771 tgt tok/s;     28 s elapsed
Epoch  2,   200/  454; acc:  43.35; ppl:  31.72; 4595 src tok/s; 4768 tgt tok/s;     36 s elapsed
Epoch  2,   250/  454; acc:  43.34; ppl:  31.25; 4648 src tok/s; 4810 tgt tok/s;     46 s elapsed
Epoch  2,   300/  454; acc:  47.80; ppl:  23.37; 4692 src tok/s; 4888 tgt tok/s;     54 s elapsed
Epoch  2,   350/  454; acc:  48.17; ppl:  22.82; 4669 src tok/s; 4829 tgt tok/s;     63 s elapsed
Epoch  2,   400/  454; acc:  49.59; ppl:  21.28; 4618 src tok/s; 4796 tgt tok/s;     72 s elapsed
Epoch  2,   450/  454; acc:  51.32; ppl:  18.99; 4495 src tok/s; 4646 tgt tok/s;     82 s elapsed
Train perplexity: 30.3831
Train accuracy: 44.1517
Validation perplexity: 16.7392
Validation accuracy: 52.9161

Epoch  3,    50/  454; acc:  54.22; ppl:  15.36; 4593 src tok/s; 4757 tgt tok/s;      9 s elapsed
Epoch  3,   100/  454; acc:  54.34; ppl:  14.55; 4631 src tok/s; 4804 tgt tok/s;     18 s elapsed
Epoch  3,   150/  454; acc:  55.25; ppl:  13.90; 4583 src tok/s; 4770 tgt tok/s;     27 s elapsed
Epoch  3,   200/  454; acc:  55.51; ppl:  13.34; 4611 src tok/s; 4789 tgt tok/s;     36 s elapsed
Epoch  3,   250/  454; acc:  56.46; ppl:  12.27; 4604 src tok/s; 4766 tgt tok/s;     46 s elapsed
Epoch  3,   300/  454; acc:  58.03; ppl:  11.40; 4466 src tok/s; 4674 tgt tok/s;     55 s elapsed
Epoch  3,   350/  454; acc:  58.84; ppl:  10.85; 4624 src tok/s; 4840 tgt tok/s;     63 s elapsed
Epoch  3,   400/  454; acc:  57.13; ppl:  12.21; 4637 src tok/s; 4749 tgt tok/s;     73 s elapsed
Epoch  3,   450/  454; acc:  58.18; ppl:  11.18; 4611 src tok/s; 4769 tgt tok/s;     82 s elapsed
Train perplexity: 12.6592
Train accuracy: 56.5004
Validation perplexity: 9.77327
Validation accuracy: 61.4872

Epoch  4,    50/  454; acc:  62.54; ppl:   8.11; 4671 src tok/s; 4855 tgt tok/s;      9 s elapsed
Epoch  4,   100/  454; acc:  60.21; ppl:   9.26; 4639 src tok/s; 4789 tgt tok/s;     18 s elapsed
Epoch  4,   150/  454; acc:  61.46; ppl:   8.55; 4510 src tok/s; 4670 tgt tok/s;     27 s elapsed
Epoch  4,   200/  454; acc:  61.57; ppl:   8.46; 4659 src tok/s; 4835 tgt tok/s;     36 s elapsed
Epoch  4,   250/  454; acc:  62.24; ppl:   8.29; 4610 src tok/s; 4787 tgt tok/s;     45 s elapsed
Epoch  4,   300/  454; acc:  61.74; ppl:   8.31; 4678 src tok/s; 4876 tgt tok/s;     54 s elapsed
Epoch  4,   350/  454; acc:  63.00; ppl:   7.81; 4587 src tok/s; 4770 tgt tok/s;     64 s elapsed
Epoch  4,   400/  454; acc:  62.39; ppl:   8.09; 4668 src tok/s; 4824 tgt tok/s;     73 s elapsed
Epoch  4,   450/  454; acc:  63.65; ppl:   7.54; 4640 src tok/s; 4843 tgt tok/s;     81 s elapsed
Train perplexity: 8.28952
Train accuracy: 62.0252
Validation perplexity: 8.08885
Validation accuracy: 64.3749

Epoch  5,    50/  454; acc:  65.97; ppl:   6.09; 4648 src tok/s; 4833 tgt tok/s;      9 s elapsed
Epoch  5,   100/  454; acc:  64.94; ppl:   6.38; 4566 src tok/s; 4732 tgt tok/s;     18 s elapsed
Epoch  5,   150/  454; acc:  66.74; ppl:   5.76; 4636 src tok/s; 4837 tgt tok/s;     27 s elapsed
Epoch  5,   200/  454; acc:  64.60; ppl:   6.52; 4704 src tok/s; 4839 tgt tok/s;     36 s elapsed
Epoch  5,   250/  454; acc:  66.02; ppl:   6.07; 4632 src tok/s; 4833 tgt tok/s;     45 s elapsed
Epoch  5,   300/  454; acc:  64.06; ppl:   6.85; 4655 src tok/s; 4808 tgt tok/s;     54 s elapsed
Epoch  5,   350/  454; acc:  66.01; ppl:   6.18; 4581 src tok/s; 4769 tgt tok/s;     63 s elapsed
Epoch  5,   400/  454; acc:  65.52; ppl:   6.28; 4568 src tok/s; 4760 tgt tok/s;     73 s elapsed
Epoch  5,   450/  454; acc:  66.05; ppl:   6.07; 4609 src tok/s; 4764 tgt tok/s;     82 s elapsed
Train perplexity: 6.23606
Train accuracy: 65.5566
Validation perplexity: 7.62435
Validation accuracy: 64.8361

Epoch  6,    50/  454; acc:  68.43; ppl:   4.90; 4549 src tok/s; 4734 tgt tok/s;      9 s elapsed
Epoch  6,   100/  454; acc:  68.09; ppl:   5.01; 4720 src tok/s; 4876 tgt tok/s;     18 s elapsed
Epoch  6,   150/  454; acc:  68.42; ppl:   4.95; 4620 src tok/s; 4794 tgt tok/s;     27 s elapsed
Epoch  6,   200/  454; acc:  67.50; ppl:   5.12; 4571 src tok/s; 4771 tgt tok/s;     36 s elapsed
Epoch  6,   250/  454; acc:  68.88; ppl:   4.89; 4503 src tok/s; 4694 tgt tok/s;     45 s elapsed
Epoch  6,   300/  454; acc:  67.92; ppl:   5.06; 4667 src tok/s; 4830 tgt tok/s;     55 s elapsed
Epoch  6,   350/  454; acc:  68.24; ppl:   5.07; 4644 src tok/s; 4790 tgt tok/s;     64 s elapsed
Epoch  6,   400/  454; acc:  68.27; ppl:   5.02; 4635 src tok/s; 4811 tgt tok/s;     73 s elapsed
Epoch  6,   450/  454; acc:  68.04; ppl:   5.09; 4629 src tok/s; 4804 tgt tok/s;     82 s elapsed
Train perplexity: 5.01235
Train accuracy: 68.195
Validation perplexity: 7.03287
Validation accuracy: 65.5243

Epoch  7,    50/  454; acc:  71.80; ppl:   3.84; 4599 src tok/s; 4783 tgt tok/s;      9 s elapsed
Epoch  7,   100/  454; acc:  70.41; ppl:   4.17; 4611 src tok/s; 4779 tgt tok/s;     18 s elapsed
Epoch  7,   150/  454; acc:  71.17; ppl:   4.08; 4575 src tok/s; 4753 tgt tok/s;     27 s elapsed
Epoch  7,   200/  454; acc:  70.01; ppl:   4.29; 4725 src tok/s; 4890 tgt tok/s;     36 s elapsed
Epoch  7,   250/  454; acc:  70.62; ppl:   4.14; 4586 src tok/s; 4756 tgt tok/s;     45 s elapsed
Epoch  7,   300/  454; acc:  69.39; ppl:   4.49; 4586 src tok/s; 4764 tgt tok/s;     55 s elapsed
Epoch  7,   350/  454; acc:  69.00; ppl:   4.51; 4657 src tok/s; 4809 tgt tok/s;     64 s elapsed
Epoch  7,   400/  454; acc:  70.71; ppl:   4.08; 4514 src tok/s; 4710 tgt tok/s;     73 s elapsed
Epoch  7,   450/  454; acc:  69.71; ppl:   4.37; 4588 src tok/s; 4773 tgt tok/s;     82 s elapsed
Train perplexity: 4.2152
Train accuracy: 70.3106
Validation perplexity: 6.82139
Validation accuracy: 67.0498

Epoch  8,    50/  454; acc:  73.52; ppl:   3.39; 4556 src tok/s; 4752 tgt tok/s;      9 s elapsed
Epoch  8,   100/  454; acc:  72.44; ppl:   3.55; 4593 src tok/s; 4750 tgt tok/s;     18 s elapsed
Epoch  8,   150/  454; acc:  72.42; ppl:   3.56; 4488 src tok/s; 4689 tgt tok/s;     28 s elapsed
Epoch  8,   200/  454; acc:  72.21; ppl:   3.60; 4597 src tok/s; 4731 tgt tok/s;     37 s elapsed
Epoch  8,   250/  454; acc:  71.40; ppl:   3.74; 4631 src tok/s; 4810 tgt tok/s;     46 s elapsed
Epoch  8,   300/  454; acc:  71.90; ppl:   3.60; 4630 src tok/s; 4827 tgt tok/s;     55 s elapsed
Epoch  8,   350/  454; acc:  72.62; ppl:   3.59; 4624 src tok/s; 4831 tgt tok/s;     64 s elapsed
Epoch  8,   400/  454; acc:  71.04; ppl:   3.94; 4755 src tok/s; 4889 tgt tok/s;     73 s elapsed
Epoch  8,   450/  454; acc:  71.81; ppl:   3.73; 4539 src tok/s; 4718 tgt tok/s;     82 s elapsed
Train perplexity: 3.64698
Train accuracy: 72.0716
Validation perplexity: 6.59596
Validation accuracy: 67.0569
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  77.35; ppl:   2.74; 4564 src tok/s; 4778 tgt tok/s;      9 s elapsed
Epoch  9,   100/  454; acc:  77.20; ppl:   2.71; 4580 src tok/s; 4771 tgt tok/s;     18 s elapsed
Epoch  9,   150/  454; acc:  75.78; ppl:   2.95; 4747 src tok/s; 4854 tgt tok/s;     28 s elapsed
Epoch  9,   200/  454; acc:  78.16; ppl:   2.53; 4531 src tok/s; 4746 tgt tok/s;     36 s elapsed
Epoch  9,   250/  454; acc:  77.86; ppl:   2.62; 4666 src tok/s; 4837 tgt tok/s;     45 s elapsed
Epoch  9,   300/  454; acc:  76.49; ppl:   2.78; 4608 src tok/s; 4769 tgt tok/s;     55 s elapsed
Epoch  9,   350/  454; acc:  76.77; ppl:   2.78; 4577 src tok/s; 4726 tgt tok/s;     64 s elapsed
Epoch  9,   400/  454; acc:  77.16; ppl:   2.67; 4595 src tok/s; 4805 tgt tok/s;     73 s elapsed
Epoch  9,   450/  454; acc:  77.08; ppl:   2.72; 4609 src tok/s; 4768 tgt tok/s;     82 s elapsed
Train perplexity: 2.72421
Train accuracy: 77.0647
Validation perplexity: 6.07536
Validation accuracy: 69.2564
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  80.84; ppl:   2.24; 4535 src tok/s; 4740 tgt tok/s;      9 s elapsed
Epoch 10,   100/  454; acc:  80.99; ppl:   2.25; 4610 src tok/s; 4766 tgt tok/s;     18 s elapsed
Epoch 10,   150/  454; acc:  81.23; ppl:   2.20; 4584 src tok/s; 4736 tgt tok/s;     28 s elapsed
Epoch 10,   200/  454; acc:  81.23; ppl:   2.23; 4684 src tok/s; 4838 tgt tok/s;     36 s elapsed
Epoch 10,   250/  454; acc:  80.14; ppl:   2.36; 4715 src tok/s; 4862 tgt tok/s;     46 s elapsed
Epoch 10,   300/  454; acc:  81.87; ppl:   2.15; 4494 src tok/s; 4689 tgt tok/s;     55 s elapsed
Epoch 10,   350/  454; acc:  80.57; ppl:   2.25; 4594 src tok/s; 4796 tgt tok/s;     64 s elapsed
Epoch 10,   400/  454; acc:  80.74; ppl:   2.26; 4579 src tok/s; 4742 tgt tok/s;     73 s elapsed
Epoch 10,   450/  454; acc:  81.02; ppl:   2.22; 4605 src tok/s; 4809 tgt tok/s;     82 s elapsed
Train perplexity: 2.24462
Train accuracy: 80.897
Validation perplexity: 6.14034
Validation accuracy: 69.7034
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  82.96; ppl:   2.03; 4569 src tok/s; 4723 tgt tok/s;      9 s elapsed
Epoch 11,   100/  454; acc:  83.72; ppl:   1.96; 4675 src tok/s; 4856 tgt tok/s;     18 s elapsed
Epoch 11,   150/  454; acc:  84.35; ppl:   1.89; 4606 src tok/s; 4800 tgt tok/s;     27 s elapsed
Epoch 11,   200/  454; acc:  82.03; ppl:   2.14; 4601 src tok/s; 4762 tgt tok/s;     36 s elapsed
Epoch 11,   250/  454; acc:  83.42; ppl:   2.01; 4596 src tok/s; 4790 tgt tok/s;     45 s elapsed
Epoch 11,   300/  454; acc:  82.65; ppl:   2.06; 4650 src tok/s; 4816 tgt tok/s;     54 s elapsed
Epoch 11,   350/  454; acc:  83.16; ppl:   2.00; 4661 src tok/s; 4819 tgt tok/s;     63 s elapsed
Epoch 11,   400/  454; acc:  82.33; ppl:   2.08; 4617 src tok/s; 4798 tgt tok/s;     73 s elapsed
Epoch 11,   450/  454; acc:  82.95; ppl:   2.05; 4565 src tok/s; 4753 tgt tok/s;     82 s elapsed
Train perplexity: 2.0245
Train accuracy: 83.0436
Validation perplexity: 6.34251
Validation accuracy: 69.526
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.62; ppl:   1.89; 4587 src tok/s; 4766 tgt tok/s;      9 s elapsed
Epoch 12,   100/  454; acc:  84.02; ppl:   1.93; 4657 src tok/s; 4829 tgt tok/s;     18 s elapsed
Epoch 12,   150/  454; acc:  83.81; ppl:   1.96; 4535 src tok/s; 4709 tgt tok/s;     28 s elapsed
Epoch 12,   200/  454; acc:  84.53; ppl:   1.89; 4685 src tok/s; 4875 tgt tok/s;     36 s elapsed
Epoch 12,   250/  454; acc:  83.86; ppl:   1.94; 4500 src tok/s; 4673 tgt tok/s;     46 s elapsed
Epoch 12,   300/  454; acc:  84.24; ppl:   1.91; 4631 src tok/s; 4800 tgt tok/s;     55 s elapsed
Epoch 12,   350/  454; acc:  84.68; ppl:   1.89; 4715 src tok/s; 4877 tgt tok/s;     63 s elapsed
Epoch 12,   400/  454; acc:  84.10; ppl:   1.92; 4611 src tok/s; 4774 tgt tok/s;     73 s elapsed
Epoch 12,   450/  454; acc:  83.60; ppl:   1.98; 4484 src tok/s; 4663 tgt tok/s;     82 s elapsed
Train perplexity: 1.92248
Train accuracy: 84.1669
Validation perplexity: 6.42187
Validation accuracy: 69.6608
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  83.93; ppl:   1.94; 4531 src tok/s; 4704 tgt tok/s;      9 s elapsed
Epoch 13,   100/  454; acc:  85.78; ppl:   1.78; 4660 src tok/s; 4811 tgt tok/s;     18 s elapsed
Epoch 13,   150/  454; acc:  84.85; ppl:   1.87; 4611 src tok/s; 4809 tgt tok/s;     27 s elapsed
Epoch 13,   200/  454; acc:  84.80; ppl:   1.90; 4649 src tok/s; 4801 tgt tok/s;     36 s elapsed
Epoch 13,   250/  454; acc:  84.37; ppl:   1.93; 4542 src tok/s; 4710 tgt tok/s;     46 s elapsed
Epoch 13,   300/  454; acc:  85.09; ppl:   1.84; 4570 src tok/s; 4778 tgt tok/s;     55 s elapsed
Epoch 13,   350/  454; acc:  84.69; ppl:   1.87; 4682 src tok/s; 4858 tgt tok/s;     64 s elapsed
Epoch 13,   400/  454; acc:  84.66; ppl:   1.88; 4637 src tok/s; 4806 tgt tok/s;     73 s elapsed
Epoch 13,   450/  454; acc:  84.99; ppl:   1.84; 4522 src tok/s; 4701 tgt tok/s;     82 s elapsed
Train perplexity: 1.87618
Train accuracy: 84.7575
Validation perplexity: 6.50147
Validation accuracy: 69.6396
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  84.65; ppl:   1.91; 4592 src tok/s; 4759 tgt tok/s;      9 s elapsed
Epoch 14,   100/  454; acc:  86.07; ppl:   1.79; 4555 src tok/s; 4763 tgt tok/s;     18 s elapsed
Epoch 14,   150/  454; acc:  84.77; ppl:   1.88; 4524 src tok/s; 4727 tgt tok/s;     27 s elapsed
Epoch 14,   200/  454; acc:  84.80; ppl:   1.83; 4606 src tok/s; 4767 tgt tok/s;     37 s elapsed
Epoch 14,   250/  454; acc:  85.46; ppl:   1.80; 4594 src tok/s; 4786 tgt tok/s;     46 s elapsed
Epoch 14,   300/  454; acc:  85.04; ppl:   1.87; 4616 src tok/s; 4747 tgt tok/s;     55 s elapsed
Epoch 14,   350/  454; acc:  84.27; ppl:   1.94; 4616 src tok/s; 4745 tgt tok/s;     65 s elapsed
Epoch 14,   400/  454; acc:  85.85; ppl:   1.78; 4605 src tok/s; 4819 tgt tok/s;     73 s elapsed
Epoch 14,   450/  454; acc:  85.27; ppl:   1.82; 4597 src tok/s; 4767 tgt tok/s;     82 s elapsed
Train perplexity: 1.8511
Train accuracy: 85.0689
Validation perplexity: 6.52685
Validation accuracy: 69.6821
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  84.90; ppl:   1.86; 4568 src tok/s; 4743 tgt tok/s;      9 s elapsed
Epoch 15,   100/  454; acc:  85.28; ppl:   1.83; 4637 src tok/s; 4797 tgt tok/s;     18 s elapsed
Epoch 15,   150/  454; acc:  85.72; ppl:   1.79; 4576 src tok/s; 4730 tgt tok/s;     27 s elapsed
Epoch 15,   200/  454; acc:  84.33; ppl:   1.91; 4659 src tok/s; 4829 tgt tok/s;     37 s elapsed
Epoch 15,   250/  454; acc:  84.81; ppl:   1.88; 4544 src tok/s; 4730 tgt tok/s;     46 s elapsed
Epoch 15,   300/  454; acc:  85.59; ppl:   1.80; 4610 src tok/s; 4793 tgt tok/s;     55 s elapsed
Epoch 15,   350/  454; acc:  85.97; ppl:   1.76; 4617 src tok/s; 4830 tgt tok/s;     64 s elapsed
Epoch 15,   400/  454; acc:  84.58; ppl:   1.91; 4592 src tok/s; 4751 tgt tok/s;     73 s elapsed
Epoch 15,   450/  454; acc:  85.22; ppl:   1.82; 4619 src tok/s; 4789 tgt tok/s;     82 s elapsed
Train perplexity: 1.8394
Train accuracy: 85.1502
Validation perplexity: 6.53979
Validation accuracy: 69.5899
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  86.15; ppl:   1.77; 4567 src tok/s; 4770 tgt tok/s;      9 s elapsed
Epoch 16,   100/  454; acc:  84.58; ppl:   1.88; 4611 src tok/s; 4763 tgt tok/s;     18 s elapsed
Epoch 16,   150/  454; acc:  85.06; ppl:   1.85; 4578 src tok/s; 4762 tgt tok/s;     27 s elapsed
Epoch 16,   200/  454; acc:  85.30; ppl:   1.80; 4666 src tok/s; 4814 tgt tok/s;     36 s elapsed
Epoch 16,   250/  454; acc:  85.77; ppl:   1.79; 4574 src tok/s; 4743 tgt tok/s;     45 s elapsed
Epoch 16,   300/  454; acc:  84.96; ppl:   1.85; 4543 src tok/s; 4728 tgt tok/s;     55 s elapsed
Epoch 16,   350/  454; acc:  84.41; ppl:   1.92; 4629 src tok/s; 4784 tgt tok/s;     64 s elapsed
Epoch 16,   400/  454; acc:  85.67; ppl:   1.80; 4627 src tok/s; 4853 tgt tok/s;     73 s elapsed
Epoch 16,   450/  454; acc:  85.15; ppl:   1.85; 4563 src tok/s; 4715 tgt tok/s;     82 s elapsed
Train perplexity: 1.83576
Train accuracy: 85.2194
Validation perplexity: 6.54882
Validation accuracy: 69.6112
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  85.28; ppl:   1.83; 4619 src tok/s; 4806 tgt tok/s;      9 s elapsed
Epoch 17,   100/  454; acc:  85.15; ppl:   1.83; 4562 src tok/s; 4743 tgt tok/s;     18 s elapsed
Epoch 17,   150/  454; acc:  86.03; ppl:   1.74; 4592 src tok/s; 4793 tgt tok/s;     27 s elapsed
Epoch 17,   200/  454; acc:  84.63; ppl:   1.90; 4599 src tok/s; 4752 tgt tok/s;     37 s elapsed
Epoch 17,   250/  454; acc:  87.06; ppl:   1.69; 4484 src tok/s; 4694 tgt tok/s;     45 s elapsed
Epoch 17,   300/  454; acc:  84.08; ppl:   1.96; 4677 src tok/s; 4791 tgt tok/s;     55 s elapsed
Epoch 17,   350/  454; acc:  85.41; ppl:   1.82; 4558 src tok/s; 4741 tgt tok/s;     64 s elapsed
Epoch 17,   400/  454; acc:  84.88; ppl:   1.86; 4579 src tok/s; 4740 tgt tok/s;     73 s elapsed
Epoch 17,   450/  454; acc:  85.14; ppl:   1.85; 4586 src tok/s; 4756 tgt tok/s;     82 s elapsed
Train perplexity: 1.83218
Train accuracy: 85.2681
Validation perplexity: 6.55143
Validation accuracy: 69.6254
Decaying learning rate to 0.000976562
