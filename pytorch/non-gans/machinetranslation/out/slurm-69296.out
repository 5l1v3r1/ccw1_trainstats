<module 'opts' from '/u/suhubdyd/research/projects/jumble_lstm/code/auxiliary-nmt/opts.pyc'>
Namespace(batch_size=64, brnn=False, brnn_merge='concat', cnn_kernel_width=3, context_gate=None, copy_attn=False, copy_attn_force=False, coverage_attn=False, data='/data/lisatmp3/suhubdyd/multi30k.atok.low', dec_layers=1, decay_method='', decoder_type='rnn', dropout=0.3, enc_layers=2, encoder_type='rnn', epochs=17, exp='', exp_host='', feat_merge='concat', feat_vec_exponent=0.7, feat_vec_size=-1, fix_word_vecs_dec=False, fix_word_vecs_enc=False, global_attention='general', gpuid=[0], input_feed=1, kappa_dec=0.2, kappa_enc=0.2, lambda_coverage=1, layers=-1, learning_rate=1.0, learning_rate_decay=0.5, max_generator_batches=32, max_grad_norm=5, model_type='text', optim='sgd', param_init=0.1, position_encoding=False, pre_word_vecs_dec=None, pre_word_vecs_enc=None, report_every=50, rnn_size=500, rnn_type='LSTM', save_model='/data/lisatmp3/suhubdyd/models/encoder0.20decoder0.20dropout0.3wdropTrue', seed=-1, share_decoder_embeddings=False, share_embeddings=False, src_word_vec_size=500, start_checkpoint_at=0, start_decay_at=8, start_epoch=1, tgt_word_vec_size=500, train_from='', truncated_decoder=0, warmup_steps=4000, weightdropout=True, word_vec_size=-1)
('Using Kappa L2 loss on encoder', 0.2)
('Using Kappa L2 loss on decoder', 0.2)
('Using weight dropout', True)
Loading train and validate data from '/data/lisatmp3/suhubdyd/multi30k.atok.low'
 * number of training sentences: 29000
 * maximum batch size: 64
 * vocabulary size. source = 10841; target = 18563
Building model...
Applying weight drop of 0.3 to weight_hh_l0
Applying weight drop of 0.3 to weight_hh
Intializing model parameters.
NMTModel (
  (encoder): RNNEncoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(10841, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): WeightDrop (
      (module): LSTM(500, 500, dropout=0.3)
    )
  )
  (decoder): InputFeedRNNDecoder (
    (embeddings): Embeddings (
      (make_embedding): Sequential (
        (emb_luts): Elementwise (
          (0): Embedding(18563, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout (p = 0.3)
    (rnn): StackedLSTMWDropout (
      (dropout): Dropout (p = 0)
      (layers): ModuleList (
        (0): WeightDrop (
          (module): LSTMCell(1000, 500)
        )
      )
    )
    (attn): GlobalAttention (
      (linear_in): Linear (500 -> 500)
      (linear_out): Linear (1000 -> 500)
      (sm): Softmax ()
      (tanh): Tanh ()
    )
  )
  (generator): Sequential (
    (0): Linear (500 -> 18563)
    (1): LogSoftmax ()
  )
)
* number of parameters: 29760063
('encoder: ', 7424500)
('decoder: ', 22335563)

/u/suhubdyd/.conda/envs/lisa/lib/python2.7/site-packages/torch/nn/modules/module.py:224: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().
  result = self.forward(*input, **kwargs)
Epoch  1,    50/  454; acc:   8.80; ppl: 21241.78; 3228 src tok/s; 3361 tgt tok/s;     13 s elapsed
Epoch  1,   100/  454; acc:  14.60; ppl: 1522.67; 3408 src tok/s; 3509 tgt tok/s;     25 s elapsed
Epoch  1,   150/  454; acc:  17.12; ppl: 582.51; 3301 src tok/s; 3425 tgt tok/s;     38 s elapsed
Epoch  1,   200/  454; acc:  21.96; ppl: 254.93; 3347 src tok/s; 3496 tgt tok/s;     50 s elapsed
Epoch  1,   250/  454; acc:  23.75; ppl: 178.95; 3341 src tok/s; 3449 tgt tok/s;     63 s elapsed
Epoch  1,   300/  454; acc:  27.57; ppl: 119.90; 3366 src tok/s; 3484 tgt tok/s;     76 s elapsed
Epoch  1,   350/  454; acc:  30.66; ppl:  92.23; 3298 src tok/s; 3450 tgt tok/s;     88 s elapsed
Epoch  1,   400/  454; acc:  30.79; ppl:  85.21; 3323 src tok/s; 3436 tgt tok/s;    101 s elapsed
Epoch  1,   450/  454; acc:  32.66; ppl:  70.11; 3154 src tok/s; 3290 tgt tok/s;    114 s elapsed
Train perplexity: 331.831
Train accuracy: 23.1566
Validation perplexity: 64.1244
Validation accuracy: 33.7449

Epoch  2,    50/  454; acc:  35.75; ppl:  53.85; 3338 src tok/s; 3462 tgt tok/s;     12 s elapsed
Epoch  2,   100/  454; acc:  36.78; ppl:  48.57; 3291 src tok/s; 3415 tgt tok/s;     25 s elapsed
Epoch  2,   150/  454; acc:  38.82; ppl:  43.40; 3339 src tok/s; 3450 tgt tok/s;     39 s elapsed
Epoch  2,   200/  454; acc:  43.32; ppl:  32.16; 3276 src tok/s; 3433 tgt tok/s;     51 s elapsed
Epoch  2,   250/  454; acc:  43.83; ppl:  30.81; 3309 src tok/s; 3428 tgt tok/s;     63 s elapsed
Epoch  2,   300/  454; acc:  46.91; ppl:  24.99; 3315 src tok/s; 3439 tgt tok/s;     76 s elapsed
Epoch  2,   350/  454; acc:  47.40; ppl:  23.92; 3265 src tok/s; 3366 tgt tok/s;     89 s elapsed
Epoch  2,   400/  454; acc:  50.90; ppl:  19.62; 3302 src tok/s; 3429 tgt tok/s;    102 s elapsed
Epoch  2,   450/  454; acc:  50.64; ppl:  19.28; 3287 src tok/s; 3427 tgt tok/s;    114 s elapsed
Train perplexity: 30.8486
Train accuracy: 43.8275
Validation perplexity: 16.8422
Validation accuracy: 53.0155

Epoch  3,    50/  454; acc:  52.64; ppl:  16.26; 3319 src tok/s; 3455 tgt tok/s;     13 s elapsed
Epoch  3,   100/  454; acc:  54.89; ppl:  14.00; 3334 src tok/s; 3460 tgt tok/s;     25 s elapsed
Epoch  3,   150/  454; acc:  55.39; ppl:  13.43; 3295 src tok/s; 3414 tgt tok/s;     38 s elapsed
Epoch  3,   200/  454; acc:  55.97; ppl:  12.82; 3290 src tok/s; 3422 tgt tok/s;     51 s elapsed
Epoch  3,   250/  454; acc:  56.79; ppl:  12.58; 3352 src tok/s; 3459 tgt tok/s;     64 s elapsed
Epoch  3,   300/  454; acc:  57.96; ppl:  11.69; 3256 src tok/s; 3384 tgt tok/s;     76 s elapsed
Epoch  3,   350/  454; acc:  58.74; ppl:  11.00; 3248 src tok/s; 3397 tgt tok/s;     88 s elapsed
Epoch  3,   400/  454; acc:  56.97; ppl:  12.26; 3274 src tok/s; 3388 tgt tok/s;    102 s elapsed
Epoch  3,   450/  454; acc:  59.52; ppl:  10.52; 3305 src tok/s; 3416 tgt tok/s;    114 s elapsed
Train perplexity: 12.6602
Train accuracy: 56.4961
Validation perplexity: 10.4209
Validation accuracy: 60.2455

Epoch  4,    50/  454; acc:  60.78; ppl:   9.03; 3347 src tok/s; 3457 tgt tok/s;     13 s elapsed
Epoch  4,   100/  454; acc:  62.14; ppl:   8.31; 3140 src tok/s; 3274 tgt tok/s;     26 s elapsed
Epoch  4,   150/  454; acc:  61.63; ppl:   8.55; 3312 src tok/s; 3446 tgt tok/s;     39 s elapsed
Epoch  4,   200/  454; acc:  62.11; ppl:   8.41; 3243 src tok/s; 3384 tgt tok/s;     51 s elapsed
Epoch  4,   250/  454; acc:  62.55; ppl:   7.93; 3329 src tok/s; 3451 tgt tok/s;     64 s elapsed
Epoch  4,   300/  454; acc:  61.82; ppl:   8.58; 3304 src tok/s; 3429 tgt tok/s;     77 s elapsed
Epoch  4,   350/  454; acc:  61.42; ppl:   8.51; 3305 src tok/s; 3404 tgt tok/s;     90 s elapsed
Epoch  4,   400/  454; acc:  64.26; ppl:   7.25; 3312 src tok/s; 3465 tgt tok/s;    102 s elapsed
Epoch  4,   450/  454; acc:  63.19; ppl:   7.71; 3337 src tok/s; 3438 tgt tok/s;    115 s elapsed
Train perplexity: 8.22972
Train accuracy: 62.213
Validation perplexity: 8.6295
Validation accuracy: 63.3461

Epoch  5,    50/  454; acc:  66.06; ppl:   6.12; 3304 src tok/s; 3439 tgt tok/s;     13 s elapsed
Epoch  5,   100/  454; acc:  65.96; ppl:   6.10; 3317 src tok/s; 3443 tgt tok/s;     25 s elapsed
Epoch  5,   150/  454; acc:  65.91; ppl:   6.16; 3290 src tok/s; 3412 tgt tok/s;     38 s elapsed
Epoch  5,   200/  454; acc:  65.03; ppl:   6.36; 3297 src tok/s; 3417 tgt tok/s;     51 s elapsed
Epoch  5,   250/  454; acc:  64.75; ppl:   6.66; 3330 src tok/s; 3422 tgt tok/s;     64 s elapsed
Epoch  5,   300/  454; acc:  66.96; ppl:   5.62; 3223 src tok/s; 3384 tgt tok/s;     76 s elapsed
Epoch  5,   350/  454; acc:  66.27; ppl:   6.11; 3245 src tok/s; 3368 tgt tok/s;     89 s elapsed
Epoch  5,   400/  454; acc:  65.51; ppl:   6.26; 3372 src tok/s; 3487 tgt tok/s;    102 s elapsed
Epoch  5,   450/  454; acc:  65.28; ppl:   6.33; 3319 src tok/s; 3452 tgt tok/s;    114 s elapsed
Train perplexity: 6.18218
Train accuracy: 65.7611
Validation perplexity: 7.36002
Validation accuracy: 64.9638

Epoch  6,    50/  454; acc:  69.24; ppl:   4.69; 3304 src tok/s; 3433 tgt tok/s;     13 s elapsed
Epoch  6,   100/  454; acc:  68.53; ppl:   4.96; 3300 src tok/s; 3421 tgt tok/s;     25 s elapsed
Epoch  6,   150/  454; acc:  67.86; ppl:   5.10; 3250 src tok/s; 3374 tgt tok/s;     38 s elapsed
Epoch  6,   200/  454; acc:  68.47; ppl:   4.96; 3286 src tok/s; 3414 tgt tok/s;     51 s elapsed
Epoch  6,   250/  454; acc:  68.18; ppl:   5.08; 3275 src tok/s; 3418 tgt tok/s;     63 s elapsed
Epoch  6,   300/  454; acc:  67.73; ppl:   5.13; 3365 src tok/s; 3473 tgt tok/s;     76 s elapsed
Epoch  6,   350/  454; acc:  67.83; ppl:   5.13; 3298 src tok/s; 3417 tgt tok/s;     89 s elapsed
Epoch  6,   400/  454; acc:  68.44; ppl:   4.96; 3291 src tok/s; 3419 tgt tok/s;    102 s elapsed
Epoch  6,   450/  454; acc:  67.43; ppl:   5.24; 3242 src tok/s; 3359 tgt tok/s;    115 s elapsed
Train perplexity: 5.01964
Train accuracy: 68.2043
Validation perplexity: 6.94867
Validation accuracy: 66.4822

Epoch  7,    50/  454; acc:  70.58; ppl:   4.19; 3325 src tok/s; 3448 tgt tok/s;     13 s elapsed
Epoch  7,   100/  454; acc:  71.59; ppl:   3.88; 3250 src tok/s; 3396 tgt tok/s;     26 s elapsed
Epoch  7,   150/  454; acc:  70.99; ppl:   4.06; 3302 src tok/s; 3429 tgt tok/s;     38 s elapsed
Epoch  7,   200/  454; acc:  70.50; ppl:   4.22; 3347 src tok/s; 3474 tgt tok/s;     51 s elapsed
Epoch  7,   250/  454; acc:  70.05; ppl:   4.26; 3272 src tok/s; 3380 tgt tok/s;     64 s elapsed
Epoch  7,   300/  454; acc:  70.32; ppl:   4.20; 3269 src tok/s; 3399 tgt tok/s;     76 s elapsed
Epoch  7,   350/  454; acc:  69.98; ppl:   4.33; 3344 src tok/s; 3460 tgt tok/s;     89 s elapsed
Epoch  7,   400/  454; acc:  70.47; ppl:   4.20; 3216 src tok/s; 3348 tgt tok/s;    102 s elapsed
Epoch  7,   450/  454; acc:  69.44; ppl:   4.40; 3252 src tok/s; 3360 tgt tok/s;    115 s elapsed
Train perplexity: 4.18648
Train accuracy: 70.4541
Validation perplexity: 6.83779
Validation accuracy: 67.064

Epoch  8,    50/  454; acc:  73.89; ppl:   3.33; 3228 src tok/s; 3364 tgt tok/s;     13 s elapsed
Epoch  8,   100/  454; acc:  72.62; ppl:   3.57; 3350 src tok/s; 3445 tgt tok/s;     25 s elapsed
Epoch  8,   150/  454; acc:  71.98; ppl:   3.65; 3334 src tok/s; 3431 tgt tok/s;     38 s elapsed
Epoch  8,   200/  454; acc:  72.96; ppl:   3.40; 3305 src tok/s; 3452 tgt tok/s;     51 s elapsed
Epoch  8,   250/  454; acc:  72.26; ppl:   3.59; 3287 src tok/s; 3418 tgt tok/s;     64 s elapsed
Epoch  8,   300/  454; acc:  71.80; ppl:   3.68; 3298 src tok/s; 3418 tgt tok/s;     76 s elapsed
Epoch  8,   350/  454; acc:  71.53; ppl:   3.83; 3233 src tok/s; 3363 tgt tok/s;     89 s elapsed
Epoch  8,   400/  454; acc:  71.79; ppl:   3.77; 3325 src tok/s; 3465 tgt tok/s;    102 s elapsed
Epoch  8,   450/  454; acc:  71.26; ppl:   3.85; 3251 src tok/s; 3380 tgt tok/s;    115 s elapsed
Train perplexity: 3.62664
Train accuracy: 72.2176
Validation perplexity: 6.76254
Validation accuracy: 66.7163
Decaying learning rate to 0.5

Epoch  9,    50/  454; acc:  76.92; ppl:   2.77; 3388 src tok/s; 3497 tgt tok/s;     13 s elapsed
Epoch  9,   100/  454; acc:  77.37; ppl:   2.74; 3252 src tok/s; 3394 tgt tok/s;     25 s elapsed
Epoch  9,   150/  454; acc:  78.70; ppl:   2.49; 3263 src tok/s; 3414 tgt tok/s;     38 s elapsed
Epoch  9,   200/  454; acc:  76.46; ppl:   2.88; 3312 src tok/s; 3431 tgt tok/s;     51 s elapsed
Epoch  9,   250/  454; acc:  77.57; ppl:   2.63; 3330 src tok/s; 3463 tgt tok/s;     64 s elapsed
Epoch  9,   300/  454; acc:  76.93; ppl:   2.75; 3298 src tok/s; 3416 tgt tok/s;     76 s elapsed
Epoch  9,   350/  454; acc:  76.83; ppl:   2.76; 3219 src tok/s; 3333 tgt tok/s;     89 s elapsed
Epoch  9,   400/  454; acc:  77.51; ppl:   2.66; 3337 src tok/s; 3456 tgt tok/s;    102 s elapsed
Epoch  9,   450/  454; acc:  77.49; ppl:   2.63; 3245 src tok/s; 3381 tgt tok/s;    114 s elapsed
Train perplexity: 2.7134
Train accuracy: 77.2157
Validation perplexity: 6.25567
Validation accuracy: 68.7243
Decaying learning rate to 0.25

Epoch 10,    50/  454; acc:  82.57; ppl:   2.06; 3274 src tok/s; 3417 tgt tok/s;     12 s elapsed
Epoch 10,   100/  454; acc:  80.46; ppl:   2.31; 3315 src tok/s; 3425 tgt tok/s;     25 s elapsed
Epoch 10,   150/  454; acc:  81.13; ppl:   2.24; 3325 src tok/s; 3445 tgt tok/s;     38 s elapsed
Epoch 10,   200/  454; acc:  81.32; ppl:   2.20; 3361 src tok/s; 3479 tgt tok/s;     50 s elapsed
Epoch 10,   250/  454; acc:  80.62; ppl:   2.27; 3330 src tok/s; 3446 tgt tok/s;     64 s elapsed
Epoch 10,   300/  454; acc:  81.83; ppl:   2.15; 3252 src tok/s; 3407 tgt tok/s;     76 s elapsed
Epoch 10,   350/  454; acc:  81.27; ppl:   2.21; 3290 src tok/s; 3421 tgt tok/s;     88 s elapsed
Epoch 10,   400/  454; acc:  80.03; ppl:   2.34; 3261 src tok/s; 3387 tgt tok/s;    102 s elapsed
Epoch 10,   450/  454; acc:  80.30; ppl:   2.30; 3309 src tok/s; 3416 tgt tok/s;    114 s elapsed
Train perplexity: 2.23181
Train accuracy: 81.0394
Validation perplexity: 6.28644
Validation accuracy: 69.6041
Decaying learning rate to 0.125

Epoch 11,    50/  454; acc:  82.81; ppl:   2.03; 3302 src tok/s; 3421 tgt tok/s;     13 s elapsed
Epoch 11,   100/  454; acc:  83.56; ppl:   1.97; 3258 src tok/s; 3407 tgt tok/s;     25 s elapsed
Epoch 11,   150/  454; acc:  83.38; ppl:   2.00; 3343 src tok/s; 3460 tgt tok/s;     38 s elapsed
Epoch 11,   200/  454; acc:  82.64; ppl:   2.08; 3357 src tok/s; 3486 tgt tok/s;     50 s elapsed
Epoch 11,   250/  454; acc:  84.07; ppl:   1.94; 3268 src tok/s; 3421 tgt tok/s;     63 s elapsed
Epoch 11,   300/  454; acc:  82.29; ppl:   2.10; 3308 src tok/s; 3407 tgt tok/s;     76 s elapsed
Epoch 11,   350/  454; acc:  83.13; ppl:   1.98; 3196 src tok/s; 3339 tgt tok/s;     89 s elapsed
Epoch 11,   400/  454; acc:  82.80; ppl:   2.04; 3347 src tok/s; 3445 tgt tok/s;    102 s elapsed
Epoch 11,   450/  454; acc:  83.61; ppl:   1.95; 3290 src tok/s; 3428 tgt tok/s;    114 s elapsed
Train perplexity: 2.01722
Train accuracy: 83.0747
Validation perplexity: 6.45825
Validation accuracy: 69.6467
Decaying learning rate to 0.0625

Epoch 12,    50/  454; acc:  84.23; ppl:   1.95; 3267 src tok/s; 3415 tgt tok/s;     13 s elapsed
Epoch 12,   100/  454; acc:  84.41; ppl:   1.91; 3415 src tok/s; 3542 tgt tok/s;     25 s elapsed
Epoch 12,   150/  454; acc:  84.11; ppl:   1.95; 3296 src tok/s; 3427 tgt tok/s;     38 s elapsed
Epoch 12,   200/  454; acc:  84.82; ppl:   1.85; 3302 src tok/s; 3415 tgt tok/s;     51 s elapsed
Epoch 12,   250/  454; acc:  84.19; ppl:   1.94; 3273 src tok/s; 3386 tgt tok/s;     63 s elapsed
Epoch 12,   300/  454; acc:  84.50; ppl:   1.89; 3326 src tok/s; 3452 tgt tok/s;     76 s elapsed
Epoch 12,   350/  454; acc:  84.06; ppl:   1.92; 3277 src tok/s; 3400 tgt tok/s;     89 s elapsed
Epoch 12,   400/  454; acc:  83.97; ppl:   1.94; 3302 src tok/s; 3412 tgt tok/s;    102 s elapsed
Epoch 12,   450/  454; acc:  84.58; ppl:   1.88; 3255 src tok/s; 3393 tgt tok/s;    114 s elapsed
Train perplexity: 1.9179
Train accuracy: 84.2757
Validation perplexity: 6.58314
Validation accuracy: 69.4835
Decaying learning rate to 0.03125

Epoch 13,    50/  454; acc:  84.66; ppl:   1.88; 3314 src tok/s; 3425 tgt tok/s;     13 s elapsed
Epoch 13,   100/  454; acc:  85.31; ppl:   1.83; 3383 src tok/s; 3516 tgt tok/s;     25 s elapsed
Epoch 13,   150/  454; acc:  84.07; ppl:   1.96; 3296 src tok/s; 3412 tgt tok/s;     38 s elapsed
Epoch 13,   200/  454; acc:  85.30; ppl:   1.80; 3256 src tok/s; 3389 tgt tok/s;     51 s elapsed
Epoch 13,   250/  454; acc:  83.71; ppl:   1.97; 3335 src tok/s; 3460 tgt tok/s;     64 s elapsed
Epoch 13,   300/  454; acc:  86.01; ppl:   1.76; 3229 src tok/s; 3381 tgt tok/s;     76 s elapsed
Epoch 13,   350/  454; acc:  84.15; ppl:   1.93; 3334 src tok/s; 3444 tgt tok/s;     89 s elapsed
Epoch 13,   400/  454; acc:  85.48; ppl:   1.82; 3271 src tok/s; 3400 tgt tok/s;    102 s elapsed
Epoch 13,   450/  454; acc:  84.60; ppl:   1.89; 3243 src tok/s; 3358 tgt tok/s;    114 s elapsed
Train perplexity: 1.86973
Train accuracy: 84.8072
Validation perplexity: 6.65543
Validation accuracy: 69.4409
Decaying learning rate to 0.015625

Epoch 14,    50/  454; acc:  85.13; ppl:   1.85; 3298 src tok/s; 3428 tgt tok/s;     13 s elapsed
Epoch 14,   100/  454; acc:  85.01; ppl:   1.85; 3269 src tok/s; 3403 tgt tok/s;     26 s elapsed
Epoch 14,   150/  454; acc:  85.47; ppl:   1.80; 3289 src tok/s; 3431 tgt tok/s;     38 s elapsed
Epoch 14,   200/  454; acc:  84.83; ppl:   1.88; 3278 src tok/s; 3392 tgt tok/s;     51 s elapsed
Epoch 14,   250/  454; acc:  84.61; ppl:   1.91; 3360 src tok/s; 3475 tgt tok/s;     64 s elapsed
Epoch 14,   300/  454; acc:  85.73; ppl:   1.78; 3310 src tok/s; 3444 tgt tok/s;     76 s elapsed
Epoch 14,   350/  454; acc:  84.54; ppl:   1.90; 3266 src tok/s; 3375 tgt tok/s;     90 s elapsed
Epoch 14,   400/  454; acc:  85.63; ppl:   1.79; 3277 src tok/s; 3416 tgt tok/s;    102 s elapsed
Epoch 14,   450/  454; acc:  85.07; ppl:   1.85; 3284 src tok/s; 3384 tgt tok/s;    115 s elapsed
Train perplexity: 1.84537
Train accuracy: 85.1121
Validation perplexity: 6.68487
Validation accuracy: 69.377
Decaying learning rate to 0.0078125

Epoch 15,    50/  454; acc:  84.31; ppl:   1.93; 3322 src tok/s; 3436 tgt tok/s;     13 s elapsed
Epoch 15,   100/  454; acc:  85.95; ppl:   1.76; 3310 src tok/s; 3439 tgt tok/s;     25 s elapsed
Epoch 15,   150/  454; acc:  85.10; ppl:   1.86; 3313 src tok/s; 3426 tgt tok/s;     38 s elapsed
Epoch 15,   200/  454; acc:  85.26; ppl:   1.84; 3321 src tok/s; 3444 tgt tok/s;     51 s elapsed
Epoch 15,   250/  454; acc:  85.93; ppl:   1.78; 3307 src tok/s; 3462 tgt tok/s;     63 s elapsed
Epoch 15,   300/  454; acc:  84.99; ppl:   1.85; 3293 src tok/s; 3403 tgt tok/s;     76 s elapsed
Epoch 15,   350/  454; acc:  85.69; ppl:   1.78; 3287 src tok/s; 3432 tgt tok/s;     89 s elapsed
Epoch 15,   400/  454; acc:  84.45; ppl:   1.93; 3296 src tok/s; 3413 tgt tok/s;    102 s elapsed
Epoch 15,   450/  454; acc:  85.50; ppl:   1.80; 3243 src tok/s; 3370 tgt tok/s;    114 s elapsed
Train perplexity: 1.83598
Train accuracy: 85.2301
Validation perplexity: 6.70033
Validation accuracy: 69.4409
Decaying learning rate to 0.00390625

Epoch 16,    50/  454; acc:  84.53; ppl:   1.88; 3310 src tok/s; 3413 tgt tok/s;     13 s elapsed
Epoch 16,   100/  454; acc:  86.18; ppl:   1.73; 3234 src tok/s; 3383 tgt tok/s;     26 s elapsed
Epoch 16,   150/  454; acc:  84.85; ppl:   1.88; 3309 src tok/s; 3444 tgt tok/s;     38 s elapsed
Epoch 16,   200/  454; acc:  85.42; ppl:   1.82; 3300 src tok/s; 3420 tgt tok/s;     51 s elapsed
Epoch 16,   250/  454; acc:  86.31; ppl:   1.76; 3278 src tok/s; 3414 tgt tok/s;     63 s elapsed
Epoch 16,   300/  454; acc:  84.86; ppl:   1.88; 3350 src tok/s; 3455 tgt tok/s;     76 s elapsed
Epoch 16,   350/  454; acc:  84.56; ppl:   1.90; 3347 src tok/s; 3459 tgt tok/s;     89 s elapsed
Epoch 16,   400/  454; acc:  86.02; ppl:   1.76; 3298 src tok/s; 3438 tgt tok/s;    102 s elapsed
Epoch 16,   450/  454; acc:  85.87; ppl:   1.78; 3233 src tok/s; 3367 tgt tok/s;    114 s elapsed
Train perplexity: 1.82964
Train accuracy: 85.3094
Validation perplexity: 6.70529
Validation accuracy: 69.4409
Decaying learning rate to 0.00195312

Epoch 17,    50/  454; acc:  84.89; ppl:   1.86; 3261 src tok/s; 3392 tgt tok/s;     13 s elapsed
Epoch 17,   100/  454; acc:  85.32; ppl:   1.82; 3303 src tok/s; 3424 tgt tok/s;     26 s elapsed
Epoch 17,   150/  454; acc:  84.97; ppl:   1.88; 3360 src tok/s; 3456 tgt tok/s;     39 s elapsed
Epoch 17,   200/  454; acc:  86.01; ppl:   1.77; 3278 src tok/s; 3422 tgt tok/s;     51 s elapsed
Epoch 17,   250/  454; acc:  86.26; ppl:   1.75; 3241 src tok/s; 3369 tgt tok/s;     63 s elapsed
Epoch 17,   300/  454; acc:  84.80; ppl:   1.87; 3291 src tok/s; 3419 tgt tok/s;     77 s elapsed
Epoch 17,   350/  454; acc:  85.62; ppl:   1.81; 3237 src tok/s; 3360 tgt tok/s;     90 s elapsed
Epoch 17,   400/  454; acc:  84.83; ppl:   1.86; 3310 src tok/s; 3452 tgt tok/s;    102 s elapsed
Epoch 17,   450/  454; acc:  85.34; ppl:   1.82; 3311 src tok/s; 3421 tgt tok/s;    115 s elapsed
Train perplexity: 1.82706
Train accuracy: 85.3167
Validation perplexity: 6.71048
Validation accuracy: 69.4409
Decaying learning rate to 0.000976562
